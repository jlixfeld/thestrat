{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"TheStrat Documentation","text":"<p>A Python module for financial data aggregation and technical analysis using #TheStrat methodology.</p>"},{"location":"#overview","title":"Overview","text":"<p>TheStrat provides a comprehensive framework for implementing the #TheStrat trading methodology in Python. It offers high-performance timeframe aggregation, complete technical indicators, and robust support for multiple asset classes.</p>"},{"location":"#key-features","title":"Key Features","text":"<p> Multi-Timeframe Aggregation</p> <p>OHLCV data aggregation across multiple timeframes simultaneously with timezone handling</p> <p> #TheStrat Indicators</p> <p>Complete implementation of TheStrat technical indicators with per-timeframe configurations</p> <p> Multi-Asset Support</p> <p>Crypto, Equities, and FX with appropriate market hours and timezone handling</p> <p> Factory Pattern</p> <p>Clean component creation and configuration management</p> <p> High Performance</p> <p>Vectorized operations using Polars and Pandas for optimal speed</p> <p> Comprehensive Testing</p> <p>High test coverage with 190+ tests ensuring reliability</p>"},{"location":"#quick-example","title":"Quick Example","text":"Basic TheStrat Usage with Pydantic Models<pre><code>from thestrat import Factory\nfrom thestrat.schemas import (\n    FactoryConfig, AggregationConfig, IndicatorsConfig,\n    TimeframeItemConfig, SwingPointsConfig\n)\n\n# Configure your pipeline with Pydantic models\nconfig = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"5m\", \"15m\"],  # Multiple timeframes supported\n        asset_class=\"equities\",\n        timezone=\"US/Eastern\"\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"5m\"],\n                swing_points=SwingPointsConfig(window=3, threshold=1.5)  # Short-term settings\n            ),\n            TimeframeItemConfig(\n                timeframes=[\"15m\"],\n                swing_points=SwingPointsConfig(window=7, threshold=2.5)  # Long-term settings\n            )\n        ]\n    )\n)\n\n# Create and use components\npipeline = Factory.create_all(config)\naggregated = pipeline[\"aggregation\"].process(market_data)\nanalyzed = pipeline[\"indicators\"].process(aggregated)\n\nprint(f\"Processed {len(analyzed)} bars with TheStrat indicators\")\nprint(f\"Timeframes: {analyzed['timeframe'].unique()}\")\n</code></pre>"},{"location":"#core-components","title":"Core Components","text":"Component Purpose Features Aggregation OHLCV timeframe aggregation Timezone handling, simultaneous multi-timeframe processing Indicators TheStrat technical indicators Inside/Outside bars, Swing points, per-timeframe configurations Factory Component creation Validation, configuration management Schemas Configuration models Pydantic validation, comprehensive documentation"},{"location":"#supported-markets","title":"Supported Markets","text":"CryptoEquitiesForex <ul> <li>24/7 trading</li> <li>UTC timezone enforcement</li> <li>Continuous aggregation</li> </ul> <ul> <li>Market hours (9:30-16:00 ET)</li> <li>Configurable timezones</li> <li>Pre/post market handling</li> </ul> <ul> <li>24/5 trading (Sun 5pm - Fri 5pm ET)</li> <li>UTC timezone enforcement</li> <li>Weekend gap handling</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<p>Ready to implement #TheStrat in your trading system?</p> <p>Get Started with Installation View API Reference</p>"},{"location":"#project-status","title":"Project Status","text":"<p> Python: 3.11+ License: Private - All rights reserved</p>"},{"location":"developer-guide/","title":"Developer Guide","text":"<p>Welcome to the TheStrat developer guide. This section provides comprehensive information for contributors and developers working with the TheStrat codebase.</p>"},{"location":"developer-guide/#for-maintainers","title":"For Maintainers","text":"<p>This project is currently private. Contact the author for access and contribution guidelines.</p>"},{"location":"developer-guide/#architecture-overview","title":"Architecture Overview","text":"<p>TheStrat follows a modular design with clear separation of concerns:</p>"},{"location":"developer-guide/#core-components","title":"Core Components","text":"<ul> <li>Factory - Component creation and configuration management</li> <li>Aggregation - OHLCV timeframe data processing</li> <li>Indicators - TheStrat technical analysis implementation</li> <li>Schemas - Configuration models and validation</li> </ul>"},{"location":"developer-guide/#design-patterns","title":"Design Patterns","text":"<ul> <li>Factory Pattern - Centralized component creation with validation</li> <li>Abstract Base Classes - Consistent interfaces across components</li> <li>Configuration-Driven - Flexible behavior through configuration objects</li> <li>Functional Programming - Immutable data transformations where possible</li> </ul>"},{"location":"developer-guide/#quick-development-setup","title":"Quick Development Setup","text":"<pre><code># Clone repository\ngit clone https://github.com/jlixfeld/thestrat.git\ncd thestrat\n\n# Install all development dependencies\nuv sync --extra test --extra dev --extra docs\n\n# Verify installation\nuv run pytest\nuv run ruff check .\nuv run mkdocs serve\n</code></pre>"},{"location":"developer-guide/#guide-sections","title":"Guide Sections","text":""},{"location":"developer-guide/#contributing","title":"Contributing","text":"<p>Guidelines for making contributions, code style, and pull request process.</p>"},{"location":"developer-guide/#development-workflow","title":"Development Workflow","text":"<ol> <li>Setup - Install dependencies and verify environment</li> <li>Development - Write code following project conventions</li> <li>Testing - Ensure comprehensive test coverage</li> <li>Documentation - Update docs for any API changes</li> <li>Quality - Run linting and formatting tools</li> <li>Review - Submit changes for review</li> </ol>"},{"location":"developer-guide/#code-quality-standards","title":"Code Quality Standards","text":"<ul> <li>Test Coverage: Maintain &gt;95% coverage</li> <li>Code Formatting: Automated with Ruff</li> <li>Type Hints: Required for all public APIs</li> <li>Documentation: Comprehensive docstrings</li> <li>Performance: Benchmarked critical paths</li> </ul>"},{"location":"developer-guide/#technology-stack","title":"Technology Stack","text":"<ul> <li>Python 3.11+ - Modern Python features</li> <li>Polars - High-performance data processing</li> <li>Pandas - Legacy support and interoperability</li> <li>Pytest - Testing framework</li> <li>Ruff - Linting and formatting</li> <li>MkDocs Material - Documentation</li> </ul>"},{"location":"developer-guide/#getting-help","title":"Getting Help","text":"<p>For development questions:</p> <ol> <li>Check existing documentation</li> <li>Review test cases for examples</li> <li>Contact the maintainer directly</li> </ol>"},{"location":"developer-guide/#project-status","title":"Project Status","text":"<p>Version: 1.0.1 - Production/Stable Maintenance: Active development License: Private - All rights reserved</p>"},{"location":"developer-guide/contributing/","title":"Contributing","text":"<p>Thank you for your interest in contributing to TheStrat! This guide outlines the process for making contributions to this private project.</p>"},{"location":"developer-guide/contributing/#getting-access","title":"Getting Access","text":"<p>This is a private module. Contact the author at <code>nominal_choroid0y@icloud.com</code> for:</p> <ul> <li>Access to the repository</li> <li>Contribution guidelines</li> <li>Development discussions</li> <li>Feature requests</li> </ul>"},{"location":"developer-guide/contributing/#development-setup","title":"Development Setup","text":"<p>Once you have access, set up your development environment:</p>"},{"location":"developer-guide/contributing/#1-clone-and-install","title":"1. Clone and Install","text":"<pre><code>git clone https://github.com/jlixfeld/thestrat.git\ncd thestrat\n\n# Install with all extras\nuv sync --extra test --extra dev --extra docs\n</code></pre>"},{"location":"developer-guide/contributing/#2-verify-setup","title":"2. Verify Setup","text":"<pre><code># Run tests\nuv run pytest\n\n# Check formatting\nuv run ruff format --check .\n\n# Check linting\nuv run ruff check .\n\n# Test documentation build\nuv run mkdocs serve\n</code></pre>"},{"location":"developer-guide/contributing/#3-run-quality-checks","title":"3. Run Quality Checks","text":"<pre><code># Check code quality\nuv run ruff check .\nuv run ruff format --check .\n</code></pre>"},{"location":"developer-guide/contributing/#code-standards","title":"Code Standards","text":""},{"location":"developer-guide/contributing/#code-style","title":"Code Style","text":"<p>We use Ruff for both linting and formatting:</p> <pre><code># Format code\nuv run ruff format .\n\n# Check linting\nuv run ruff check .\n\n# Auto-fix issues\nuv run ruff check --fix .\n</code></pre> <p>Configuration (already in <code>pyproject.toml</code>): - Line length: 120 characters - Quote style: Double quotes - Python target: 3.11+</p>"},{"location":"developer-guide/contributing/#type-hints","title":"Type Hints","text":"<p>All public APIs must include type hints:</p> <pre><code># Good\ndef process_data(data: pd.DataFrame, config: dict) -&gt; pd.DataFrame:\n    \"\"\"Process market data with configuration.\"\"\"\n    return data\n\n# Bad\ndef process_data(data, config):\n    return data\n</code></pre>"},{"location":"developer-guide/contributing/#documentation","title":"Documentation","text":"<p>Docstring Style: Use Google-style docstrings:</p> <pre><code>def aggregate_timeframe(data: pd.DataFrame, timeframe: str) -&gt; pd.DataFrame:\n    \"\"\"Aggregate OHLCV data to specified timeframe.\n\n    Args:\n        data: Input OHLCV DataFrame with required columns\n        timeframe: Target timeframe (e.g., '5m', '1h', '1d')\n\n    Returns:\n        Aggregated DataFrame with same schema as input\n\n    Raises:\n        ValueError: If required columns are missing\n\n    Example:\n        &gt;&gt;&gt; data = pd.DataFrame(...)\n        &gt;&gt;&gt; result = aggregate_timeframe(data, '5m')\n        &gt;&gt;&gt; len(result) &lt; len(data)  # Fewer bars after aggregation\n        True\n    \"\"\"\n</code></pre> <p>API Documentation: All public methods need comprehensive docstrings that will be included in the generated API documentation.</p>"},{"location":"developer-guide/contributing/#testing-requirements","title":"Testing Requirements","text":""},{"location":"developer-guide/contributing/#test-coverage","title":"Test Coverage","text":"<p>Maintain &gt;95% test coverage:</p> <pre><code># Run with coverage\nuv run pytest --cov=thestrat --cov-report=html\n\n# View coverage report\nopen htmlcov/index.html\n</code></pre>"},{"location":"developer-guide/contributing/#test-categories","title":"Test Categories","text":"<p>We use pytest markers to categorize tests:</p> <pre><code>import pytest\n\n@pytest.mark.unit\ndef test_aggregation_logic():\n    \"\"\"Unit test for aggregation logic.\"\"\"\n    pass\n\n@pytest.mark.integration\ndef test_full_pipeline():\n    \"\"\"Integration test for complete pipeline.\"\"\"\n    pass\n</code></pre> <p>Run specific categories:</p> <pre><code># Unit tests only\nuv run pytest -m unit\n\n# Integration tests only\nuv run pytest -m integration\n\n# All tests\nuv run pytest\n</code></pre>"},{"location":"developer-guide/contributing/#writing-tests","title":"Writing Tests","text":"<p>Test Structure: Follow the Arrange-Act-Assert pattern:</p> <pre><code>def test_timeframe_aggregation():\n    # Arrange\n    input_data = create_sample_ohlcv_data()\n    expected_bars = 20\n\n    # Act\n    result = aggregate_timeframe(input_data, '5m')\n\n    # Assert\n    assert len(result) == expected_bars\n    assert all(col in result.columns for col in REQUIRED_COLUMNS)\n</code></pre> <p>Test Data: Use fixtures for reusable test data:</p> <pre><code>@pytest.fixture\ndef sample_ohlcv():\n    \"\"\"Sample OHLCV data for testing.\"\"\"\n    return pd.DataFrame({\n        'timestamp': pd.date_range('2024-01-01', periods=100, freq='1min'),\n        'open': [100.0] * 100,\n        'high': [101.0] * 100,\n        'low': [99.0] * 100,\n        'close': [100.5] * 100,\n        'volume': [1000] * 100\n    })\n</code></pre>"},{"location":"developer-guide/contributing/#contribution-workflow","title":"Contribution Workflow","text":""},{"location":"developer-guide/contributing/#1-create-feature-branch","title":"1. Create Feature Branch","text":"<pre><code># From main branch\ngit checkout main\ngit pull origin main\n\n# Create feature branch\ngit checkout -b feature/your-feature-name\n</code></pre>"},{"location":"developer-guide/contributing/#2-make-changes","title":"2. Make Changes","text":"<ul> <li>Write code following our standards</li> <li>Add comprehensive tests</li> <li>Update documentation if needed</li> <li>Ensure all tests pass</li> </ul>"},{"location":"developer-guide/contributing/#3-quality-checks","title":"3. Quality Checks","text":"<p>Before committing, run full quality checks:</p> <pre><code># Format code\nuv run ruff format .\n\n# Check linting\nuv run ruff check .\n\n# Run full test suite\nuv run pytest --cov=thestrat\n\n# Test documentation\nuv run mkdocs build\n</code></pre>"},{"location":"developer-guide/contributing/#4-commit-changes","title":"4. Commit Changes","text":"<p>Use conventional commit messages:</p> <pre><code># Feature\ngit commit -m \"feat: add multi-timeframe aggregation support\"\n\n# Bug fix\ngit commit -m \"fix: handle missing volume data in aggregation\"\n\n# Documentation\ngit commit -m \"docs: add examples for forex analysis\"\n\n# Tests\ngit commit -m \"test: add integration tests for factory pattern\"\n</code></pre>"},{"location":"developer-guide/contributing/#5-push-and-create-pr","title":"5. Push and Create PR","text":"<pre><code>git push origin feature/your-feature-name\n</code></pre> <p>Then create a pull request with: - Clear description of changes - Link to any related issues - Test coverage report - Documentation updates</p>"},{"location":"developer-guide/contributing/#review-process","title":"Review Process","text":"<p>All contributions go through code review:</p> <ol> <li>Automated Checks: CI runs tests, linting, coverage</li> <li>Manual Review: Code quality, design, documentation</li> <li>Testing: Functionality and edge cases</li> <li>Documentation: API docs and user guides updated</li> </ol>"},{"location":"developer-guide/contributing/#areas-for-contribution","title":"Areas for Contribution","text":"<p>Current focus areas (contact maintainer for details):</p> <ul> <li>Performance Optimization: Polars-first implementations</li> <li>Additional Indicators: Extended TheStrat patterns</li> <li>Asset Class Support: New market types</li> <li>Testing: Edge cases and integration scenarios</li> <li>Documentation: More examples and tutorials</li> </ul>"},{"location":"developer-guide/contributing/#release-process","title":"Release Process","text":"<p>Releases follow semantic versioning:</p> <ul> <li>Patch (1.0.1): Bug fixes, documentation</li> <li>Minor (1.1.0): New features, backwards compatible</li> <li>Major (2.0.0): Breaking changes</li> </ul>"},{"location":"developer-guide/contributing/#getting-help","title":"Getting Help","text":"<p>For contribution questions:</p> <ol> <li>Documentation: Check existing docs and examples</li> <li>Issues: Search existing issues and discussions</li> <li>Contact: Email the maintainer directly</li> <li>Code Review: Learn from existing PR reviews</li> </ol>"},{"location":"developer-guide/contributing/#license","title":"License","text":"<p>All contributions are subject to the project's private license. By contributing, you agree that your contributions will be licensed under the same terms.</p> <p>Thank you for helping make TheStrat better!</p>"},{"location":"reference/","title":"API Reference","text":"<p>Complete API documentation for all TheStrat components.</p>"},{"location":"reference/#core-modules","title":"Core Modules","text":"Module Description aggregation OHLCV timeframe aggregation indicators TheStrat technical indicators signals Signal processing and metadata factory Component creation with factory pattern schemas Pydantic configuration schemas base Abstract base classes"},{"location":"reference/#quick-navigation","title":"Quick Navigation","text":"<ul> <li>Factory - Start here for component creation</li> <li>Schemas - Configuration models and validation</li> <li>Aggregation - Timeframe data processing</li> <li>Indicators - TheStrat analysis functions</li> <li>Base - Abstract base classes</li> </ul>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>thestrat<ul> <li>aggregation</li> <li>indicators</li> <li>signals</li> <li>factory</li> <li>schemas</li> <li>base</li> </ul> </li> </ul>"},{"location":"reference/thestrat/","title":"Thestrat","text":"<p>TheStrat package root</p>"},{"location":"reference/thestrat/#thestrat","title":"thestrat","text":"<p>TheStrat Python Module</p> <p>Standalone module for vectorized Strat technical analysis and OHLC timeframe aggregation. Supports historical and real-time market data processing across all asset classes.</p> <p>Modules:</p> Name Description <code>aggregation</code> <p>OHLC timeframe aggregation with precise time boundary control.</p> <code>base</code> <p>Base component classes for TheStrat module.</p> <code>factory</code> <p>Factory pattern for TheStrat component creation and configuration.</p> <code>indicators</code> <p>Vectorized Strat technical indicators implementation.</p> <code>schemas</code> <p>Pydantic schema models for TheStrat configuration validation.</p> <code>signals</code> <p>Signal metadata implementation for TheStrat trading system.</p> <p>Classes:</p> Name Description <code>Aggregation</code> <p>Convert OHLC data between timeframes with precise time boundary control.</p> <code>AggregationConfig</code> <p>Complete configuration for aggregation component with market-aware settings.</p> <code>Component</code> <p>Base class for all TheStrat components.</p> <code>Factory</code> <p>Factory class for creating TheStrat components.</p> <code>FactoryConfig</code> <p>Root configuration for Factory.create_all method with complete pipeline setup.</p> <code>GapDetectionConfig</code> <p>Configuration for gap detection with comprehensive threshold documentation.</p> <code>IndicatorSchema</code> <p>Complete Indicator Schema</p> <code>Indicators</code> <p>Vectorized implementation of all Strat technical indicators.</p> <code>IndicatorsConfig</code> <p>Complete configuration for indicators component with per-timeframe settings.</p> <code>PriceChange</code> <p>Track changes to stop/target prices.</p> <code>SignalBias</code> <p>Signal directional bias.</p> <code>SignalCategory</code> <p>Signal categorization types.</p> <code>SignalMetadata</code> <p>Complete signal metadata with change tracking and serialization.</p> <code>SignalStatus</code> <p>Signal lifecycle status.</p> <code>SwingPointsConfig</code> <p>Configuration for swing point detection with comprehensive parameter documentation.</p> <code>TimeframeItemConfig</code> <p>Configuration for a single timeframe item with flexible timeframe targeting.</p>"},{"location":"reference/thestrat/#thestrat.Aggregation","title":"Aggregation","text":"<pre><code>Aggregation(config: AggregationConfig)\n</code></pre> <p>               Bases: <code>Component</code></p> <p>Convert OHLC data between timeframes with precise time boundary control.</p> Features <ul> <li>Time Boundary Control: hour_boundary flag for hourly+ aggregation alignment</li> <li>Session Control: session_start parameter for sub-hourly alignment</li> <li>Asset Class Support: Crypto, equities, FX, futures with timezone handling</li> <li>Vectorized Processing: Pure Polars operations for maximum performance</li> </ul> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>AggregationConfig</code> <p>Validated AggregationConfig containing all configuration settings</p> required <p>Methods:</p> Name Description <code>normalize_timezone</code> <p>Convert naive timestamps to timezone-aware using timezone resolution priority.</p> <code>process</code> <p>Convert OHLC data to target timeframes with boundary alignment.</p> <code>validate_input</code> <p>Validate input data format.</p> Source code in <code>thestrat/aggregation.py</code> <pre><code>def __init__(self, config: AggregationConfig):\n    \"\"\"\n    Initialize aggregation component with validated configuration.\n\n    Args:\n        config: Validated AggregationConfig containing all configuration settings\n    \"\"\"\n    super().__init__()\n\n    # Store the validated Pydantic config\n    self.config = config\n\n    # Extract commonly used values for convenience\n    self.target_timeframes = config.target_timeframes.copy()\n    self.asset_class = config.asset_class\n\n    # These fields are guaranteed to be non-None after model validation\n    assert config.timezone is not None\n    assert config.session_start is not None\n    assert config.hour_boundary is not None\n\n    self.timezone = config.timezone\n    self.session_start = config.session_start\n    self.hour_boundary = config.hour_boundary\n\n    # Validate all timeframes\n    from .schemas import TimeframeConfig\n\n    for tf in self.target_timeframes:\n        if not TimeframeConfig.validate_timeframe(tf):\n            raise ValueError(\n                f\"Invalid timeframe '{tf}'. Supported timeframes: {sorted(TimeframeConfig.TIMEFRAME_METADATA.keys())}\"\n            )\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Aggregation.normalize_timezone","title":"normalize_timezone","text":"<pre><code>normalize_timezone(data: DataFrame) -&gt; DataFrame\n</code></pre> <p>Convert naive timestamps to timezone-aware using timezone resolution priority.</p> Source code in <code>thestrat/aggregation.py</code> <pre><code>def normalize_timezone(self, data: PolarsDataFrame) -&gt; PolarsDataFrame:\n    \"\"\"Convert naive timestamps to timezone-aware using timezone resolution priority.\"\"\"\n    df = data.clone()\n\n    # Check if timestamp is already timezone-aware\n    if df.schema[\"timestamp\"] == Datetime(\"us\", None):  # Naive timestamp\n        # Convert to timezone-aware\n        df = df.with_columns([col(\"timestamp\").dt.replace_time_zone(self.timezone).alias(\"timestamp\")])\n\n    return df\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Aggregation.process","title":"process","text":"<pre><code>process(data: DataFrame | DataFrame) -&gt; DataFrame\n</code></pre> <p>Convert OHLC data to target timeframes with boundary alignment. Supports both single-timeframe and multi-timeframe source data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | DataFrame</code> <p>Input DataFrame with OHLC data</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>Aggregated OHLC DataFrame with timeframe column</p> Source code in <code>thestrat/aggregation.py</code> <pre><code>def process(self, data: PolarsDataFrame | PandasDataFrame) -&gt; PolarsDataFrame:\n    \"\"\"\n    Convert OHLC data to target timeframes with boundary alignment.\n    Supports both single-timeframe and multi-timeframe source data.\n\n    Args:\n        data: Input DataFrame with OHLC data\n\n    Returns:\n        Aggregated OHLC DataFrame with timeframe column\n    \"\"\"\n    if not self.validate_input(data):\n        raise ValueError(\"Input data validation failed\")\n\n    df = self._convert_to_polars(data)\n    df = self.normalize_timezone(df)\n\n    # Auto-detect mode\n    is_multi_timeframe = \"timeframe\" in df.columns\n\n    if is_multi_timeframe:\n        return self._process_multi_timeframe_source(df)\n    else:\n        return self._process_single_timeframe_source(df)\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Aggregation.validate_input","title":"validate_input","text":"<pre><code>validate_input(data: DataFrame | DataFrame) -&gt; bool\n</code></pre> <p>Validate input data format.</p> Source code in <code>thestrat/aggregation.py</code> <pre><code>def validate_input(self, data: PolarsDataFrame | PandasDataFrame) -&gt; bool:\n    \"\"\"Validate input data format.\"\"\"\n    df = self._convert_to_polars(data)\n\n    # Check required columns using schema-driven approach\n    from .schemas import IndicatorSchema\n\n    required_cols = IndicatorSchema.get_required_input_columns()\n\n    # Remove timeframe if not in multi-timeframe mode\n    if \"timeframe\" not in df.columns and \"timeframe\" in required_cols:\n        required_cols = [col for col in required_cols if col != \"timeframe\"]\n\n    if not all(col in df.columns for col in required_cols):\n        return False\n\n    # Validate timeframes if in multi-timeframe mode\n    if \"timeframe\" in df.columns:\n        from .schemas import TimeframeConfig\n\n        unique_timeframes = df[\"timeframe\"].unique().to_list()\n        for tf in unique_timeframes:\n            if not TimeframeConfig.validate_timeframe(tf):\n                return False\n\n    # Check for minimum data points\n    if len(df) &lt; 2:\n        return False\n\n    return True\n</code></pre>"},{"location":"reference/thestrat/#thestrat.AggregationConfig","title":"AggregationConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Complete configuration for aggregation component with market-aware settings.</p> <p>Methods:</p> Name Description <code>apply_asset_class_defaults</code> <p>Apply AssetClassConfig defaults for timezone, hour_boundary, and session_start.</p> <code>validate_and_expand_target_timeframes</code> <p>Validate target_timeframes field and expand 'all' keyword.</p>"},{"location":"reference/thestrat/#thestrat.AggregationConfig.apply_asset_class_defaults","title":"apply_asset_class_defaults  <code>classmethod</code>","text":"<pre><code>apply_asset_class_defaults(data: Any) -&gt; Any\n</code></pre> <p>Apply AssetClassConfig defaults for timezone, hour_boundary, and session_start.</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@model_validator(mode=\"before\")\n@classmethod\ndef apply_asset_class_defaults(cls, data: Any) -&gt; Any:\n    \"\"\"Apply AssetClassConfig defaults for timezone, hour_boundary, and session_start.\"\"\"\n    if not isinstance(data, dict):\n        return data\n\n    # Get asset class, default to \"equities\"\n    asset_class = data.get(\"asset_class\", \"equities\")\n    asset_config = AssetClassConfig.get_config(asset_class)\n\n    # Force UTC timezone for crypto and fx regardless of input\n    if asset_class in [\"crypto\", \"fx\"]:\n        data[\"timezone\"] = \"UTC\"\n    elif \"timezone\" not in data or data[\"timezone\"] is None:\n        data[\"timezone\"] = asset_config.timezone\n\n    # Apply other defaults only if fields are not provided or are None\n    if \"hour_boundary\" not in data or data[\"hour_boundary\"] is None:\n        data[\"hour_boundary\"] = asset_config.hour_boundary\n    if \"session_start\" not in data or data[\"session_start\"] is None:\n        data[\"session_start\"] = asset_config.session_start\n\n    return data\n</code></pre>"},{"location":"reference/thestrat/#thestrat.AggregationConfig.validate_and_expand_target_timeframes","title":"validate_and_expand_target_timeframes  <code>classmethod</code>","text":"<pre><code>validate_and_expand_target_timeframes(\n    target_timeframes: list[str],\n) -&gt; list[str]\n</code></pre> <p>Validate target_timeframes field and expand 'all' keyword.</p> <p>This Pydantic field validator is automatically called when AggregationConfig is instantiated. It validates individual timeframes and expands ['all'] to all supported timeframes.</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@field_validator(\"target_timeframes\")\n@classmethod\ndef validate_and_expand_target_timeframes(cls, target_timeframes: list[str]) -&gt; list[str]:\n    \"\"\"\n    Validate target_timeframes field and expand 'all' keyword.\n\n    This Pydantic field validator is automatically called when AggregationConfig\n    is instantiated. It validates individual timeframes and expands ['all'] to\n    all supported timeframes.\n    \"\"\"\n    if not target_timeframes:\n        raise ValueError(\"target_timeframes cannot be empty\")\n\n    # Check for 'all' keyword\n    if \"all\" in target_timeframes:\n        if len(target_timeframes) &gt; 1:\n            raise ValueError(\"'all' cannot be combined with specific timeframes\")\n        # Expand to all supported timeframes\n        return list(TimeframeConfig.TIMEFRAME_METADATA.keys())\n\n    # Validate each specific timeframe\n    for i, timeframe in enumerate(target_timeframes):\n        if not isinstance(timeframe, str) or not timeframe.strip():\n            raise ValueError(f\"target_timeframes[{i}] must be a non-empty string\")\n\n        # Validate timeframe format using TimeframeConfig\n        if not TimeframeConfig.validate_timeframe(timeframe):\n            raise ValueError(f\"Invalid timeframe '{timeframe}'\")\n\n    return target_timeframes\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Component","title":"Component","text":"<pre><code>Component()\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Base class for all TheStrat components.</p> <p>Methods:</p> Name Description <code>process</code> <p>Process data and return Polars DataFrame results.</p> <code>validate_input</code> <p>Validate input data format.</p> Source code in <code>thestrat/base.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize base component with metadata tracking.\"\"\"\n    from datetime import datetime\n\n    self._created_at = datetime.now()\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Component.process","title":"process  <code>abstractmethod</code>","text":"<pre><code>process(data: DataFrame | DataFrame) -&gt; DataFrame\n</code></pre> <p>Process data and return Polars DataFrame results.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | DataFrame</code> <p>Input DataFrame (Polars or Pandas)</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>Processed PolarsDataFrame with results</p> Source code in <code>thestrat/base.py</code> <pre><code>@abstractmethod\ndef process(self, data: PolarsDataFrame | PandasDataFrame) -&gt; PolarsDataFrame:\n    \"\"\"\n    Process data and return Polars DataFrame results.\n\n    Args:\n        data: Input DataFrame (Polars or Pandas)\n\n    Returns:\n        Processed PolarsDataFrame with results\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Component.validate_input","title":"validate_input  <code>abstractmethod</code>","text":"<pre><code>validate_input(data: DataFrame | DataFrame) -&gt; None\n</code></pre> <p>Validate input data format.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | DataFrame</code> <p>Input DataFrame to validate</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If data format is invalid, with specific error message</p> Source code in <code>thestrat/base.py</code> <pre><code>@abstractmethod\ndef validate_input(self, data: PolarsDataFrame | PandasDataFrame) -&gt; None:\n    \"\"\"\n    Validate input data format.\n\n    Args:\n        data: Input DataFrame to validate\n\n    Raises:\n        ValueError: If data format is invalid, with specific error message\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Factory","title":"Factory","text":"<p>Factory class for creating TheStrat components.</p> <p>Provides static methods for creating individual components and class methods for creating complete processing pipelines. All methods accept validated Pydantic configuration models.</p> <p>Methods:</p> Name Description <code>create_aggregation</code> <p>Create aggregation component from validated configuration.</p> <code>create_all</code> <p>Create complete processing pipeline with aggregation and indicators.</p> <code>create_indicators</code> <p>Create indicators component from validated configuration.</p> <code>get_asset_class_config</code> <p>Get default configuration for specific asset class.</p> <code>get_supported_asset_classes</code> <p>Get list of supported asset classes.</p> <code>get_supported_timeframes</code> <p>Get list of all supported timeframes in chronological order.</p> <code>get_timeframe_metadata</code> <p>Get detailed metadata for a specific timeframe.</p>"},{"location":"reference/thestrat/#thestrat.Factory.create_aggregation","title":"create_aggregation  <code>staticmethod</code>","text":"<pre><code>create_aggregation(config: AggregationConfig) -&gt; Aggregation\n</code></pre> <p>Create aggregation component from validated configuration.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>AggregationConfig</code> <p>Validated AggregationConfig containing: - <code>target_timeframes</code>: Target timeframes list (e.g., [\"1H\", \"5m\", \"1D\"]) - <code>asset_class</code>: Asset class type (crypto, equities, fx, futures, commodities) - <code>timezone</code>: Timezone override (UTC asset classes always use UTC;            non-UTC uses priority: specified &gt; system &gt; asset_class default) - <code>hour_boundary</code>: Align to hour boundaries (auto-determined if None) - <code>session_start</code>: Session start time (asset class default if None)</p> required <p>Returns:</p> Type Description <code>Aggregation</code> <p>Configured Aggregation component</p> Example <p>from thestrat.schemas import AggregationConfig config = AggregationConfig( ...     target_timeframes=[\"5m\", \"1H\"], ...     asset_class=\"crypto\", ...     timezone=\"UTC\" ... ) aggregation = Factory.create_aggregation(config)</p> Source code in <code>thestrat/factory.py</code> <pre><code>@staticmethod\ndef create_aggregation(config: AggregationConfig) -&gt; Aggregation:\n    \"\"\"\n    Create aggregation component from validated configuration.\n\n    Args:\n        config: Validated AggregationConfig containing:\n            - `target_timeframes`: Target timeframes list (e.g., [\"1H\", \"5m\", \"1D\"])\n            - `asset_class`: Asset class type (crypto, equities, fx, futures, commodities)\n            - `timezone`: Timezone override (UTC asset classes always use UTC;\n                       non-UTC uses priority: specified &gt; system &gt; asset_class default)\n            - `hour_boundary`: Align to hour boundaries (auto-determined if None)\n            - `session_start`: Session start time (asset class default if None)\n\n    Returns:\n        Configured Aggregation component\n\n    Example:\n        &gt;&gt;&gt; from thestrat.schemas import AggregationConfig\n        &gt;&gt;&gt; config = AggregationConfig(\n        ...     target_timeframes=[\"5m\", \"1H\"],\n        ...     asset_class=\"crypto\",\n        ...     timezone=\"UTC\"\n        ... )\n        &gt;&gt;&gt; aggregation = Factory.create_aggregation(config)\n    \"\"\"\n    return Aggregation(config)\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Factory.create_all","title":"create_all  <code>classmethod</code>","text":"<pre><code>create_all(config: FactoryConfig) -&gt; ComponentDict\n</code></pre> <p>Create complete processing pipeline with aggregation and indicators.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>FactoryConfig</code> <p>Validated FactoryConfig containing: <code>aggregation</code>: AggregationConfig with target timeframes and settings <code>indicators</code>: IndicatorsConfig with per-timeframe configurations</p> required <p>Returns:</p> Type Description <code>ComponentDict</code> <p>Dictionary containing created components:</p> <code>ComponentDict</code> <p>{ \"aggregation\": Aggregation, \"indicators\": Indicators</p> <code>ComponentDict</code> <p>}</p> Example <p>from thestrat.schemas import FactoryConfig, AggregationConfig, IndicatorsConfig, TimeframeItemConfig config = FactoryConfig( ...     aggregation=AggregationConfig(target_timeframes=[\"5m\"]), ...     indicators=IndicatorsConfig( ...         timeframe_configs=[TimeframeItemConfig(timeframes=[\"all\"])] ...     ) ... ) components = Factory.create_all(config)</p> Source code in <code>thestrat/factory.py</code> <pre><code>@classmethod\ndef create_all(cls, config: FactoryConfig) -&gt; ComponentDict:\n    \"\"\"\n    Create complete processing pipeline with aggregation and indicators.\n\n    Args:\n        config: Validated FactoryConfig containing:\n            `aggregation`: AggregationConfig with target timeframes and settings\n            `indicators`: IndicatorsConfig with per-timeframe configurations\n\n    Returns:\n        Dictionary containing created components:\n        {\n            \"aggregation\": Aggregation,\n            \"indicators\": Indicators\n        }\n\n    Example:\n        &gt;&gt;&gt; from thestrat.schemas import FactoryConfig, AggregationConfig, IndicatorsConfig, TimeframeItemConfig\n        &gt;&gt;&gt; config = FactoryConfig(\n        ...     aggregation=AggregationConfig(target_timeframes=[\"5m\"]),\n        ...     indicators=IndicatorsConfig(\n        ...         timeframe_configs=[TimeframeItemConfig(timeframes=[\"all\"])]\n        ...     )\n        ... )\n        &gt;&gt;&gt; components = Factory.create_all(config)\n    \"\"\"\n    return {\n        \"aggregation\": cls.create_aggregation(config.aggregation),\n        \"indicators\": cls.create_indicators(config.indicators),\n    }\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Factory.create_indicators","title":"create_indicators  <code>staticmethod</code>","text":"<pre><code>create_indicators(config: IndicatorsConfig) -&gt; Indicators\n</code></pre> <p>Create indicators component from validated configuration.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>IndicatorsConfig</code> <p>Validated IndicatorsConfig containing per-timeframe configurations using Pydantic models</p> required <p>Returns:</p> Type Description <code>Indicators</code> <p>Configured Indicators component</p> Example <p>from thestrat.schemas import IndicatorsConfig, TimeframeItemConfig, SwingPointsConfig config = IndicatorsConfig( ...     timeframe_configs=[ ...         TimeframeItemConfig( ...             timeframes=[\"5m\", \"15m\"], ...             swing_points=SwingPointsConfig(window=7, threshold=3.0) ...         ) ...     ] ... ) indicators = Factory.create_indicators(config)</p> Source code in <code>thestrat/factory.py</code> <pre><code>@staticmethod\ndef create_indicators(config: IndicatorsConfig) -&gt; Indicators:\n    \"\"\"\n    Create indicators component from validated configuration.\n\n    Args:\n        config: Validated IndicatorsConfig containing per-timeframe configurations\n            using Pydantic models\n\n    Returns:\n        Configured Indicators component\n\n    Example:\n        &gt;&gt;&gt; from thestrat.schemas import IndicatorsConfig, TimeframeItemConfig, SwingPointsConfig\n        &gt;&gt;&gt; config = IndicatorsConfig(\n        ...     timeframe_configs=[\n        ...         TimeframeItemConfig(\n        ...             timeframes=[\"5m\", \"15m\"],\n        ...             swing_points=SwingPointsConfig(window=7, threshold=3.0)\n        ...         )\n        ...     ]\n        ... )\n        &gt;&gt;&gt; indicators = Factory.create_indicators(config)\n    \"\"\"\n    return Indicators(config)\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Factory.get_asset_class_config","title":"get_asset_class_config  <code>staticmethod</code>","text":"<pre><code>get_asset_class_config(asset_class: str) -&gt; dict[str, Any]\n</code></pre> <p>Get default configuration for specific asset class.</p> <p>Parameters:</p> Name Type Description Default <code>asset_class</code> <code>str</code> <p>Asset class type</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary with default <code>timezone</code> and <code>session_start</code></p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If asset_class is not supported</p> Source code in <code>thestrat/factory.py</code> <pre><code>@staticmethod\ndef get_asset_class_config(asset_class: str) -&gt; dict[str, Any]:\n    \"\"\"\n    Get default configuration for specific asset class.\n\n    Args:\n        asset_class: Asset class type\n\n    Returns:\n        Dictionary with default `timezone` and `session_start`\n\n    Raises:\n        ValueError: If asset_class is not supported\n    \"\"\"\n    from .schemas import AssetClassConfig\n\n    if asset_class not in Factory.get_supported_asset_classes():\n        raise ValueError(f\"Unsupported asset class: {asset_class}\")\n\n    return AssetClassConfig.REGISTRY[asset_class].model_dump()\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Factory.get_supported_asset_classes","title":"get_supported_asset_classes  <code>staticmethod</code>","text":"<pre><code>get_supported_asset_classes() -&gt; list[str]\n</code></pre> <p>Get list of supported asset classes.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of supported asset class strings</p> Source code in <code>thestrat/factory.py</code> <pre><code>@staticmethod\ndef get_supported_asset_classes() -&gt; list[str]:\n    \"\"\"\n    Get list of supported asset classes.\n\n    Returns:\n        List of supported asset class strings\n    \"\"\"\n    from .schemas import AssetClassConfig\n\n    return list(AssetClassConfig.REGISTRY.keys())\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Factory.get_supported_timeframes","title":"get_supported_timeframes  <code>cached</code> <code>staticmethod</code>","text":"<pre><code>get_supported_timeframes() -&gt; list[str]\n</code></pre> <p>Get list of all supported timeframes in chronological order.</p> <p>Returns a chronologically ordered list of timeframe strings that can be used with the aggregation and indicators components. These timeframes are validated when creating configurations.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>Chronologically ordered list of supported timeframe strings (shortest to longest)</p> Example <p>from thestrat import Factory timeframes = Factory.get_supported_timeframes() print(timeframes) ['1min', '5min', '15min', '30min', '1h', '4h', '6h', '12h', '1d', '1w', '1m', '1q', '1y']</p> Note <p>The timeframes are ordered by duration (shortest to longest) and follow standard conventions: - Minutes: <code>1min</code>, <code>5min</code>, <code>15min</code>, <code>30min</code> - Hours: <code>1h</code>, <code>4h</code>, <code>6h</code>, <code>12h</code> - Days/Weeks/Months: <code>1d</code>, <code>1w</code>, <code>1m</code> (month), <code>1q</code> (quarter), <code>1y</code></p> Source code in <code>thestrat/factory.py</code> <pre><code>@staticmethod\n@lru_cache(maxsize=1)\ndef get_supported_timeframes() -&gt; list[str]:\n    \"\"\"\n    Get list of all supported timeframes in chronological order.\n\n    Returns a chronologically ordered list of timeframe strings that can be used with\n    the aggregation and indicators components. These timeframes are\n    validated when creating configurations.\n\n    Returns:\n        Chronologically ordered list of supported timeframe strings (shortest to longest)\n\n    Example:\n        &gt;&gt;&gt; from thestrat import Factory\n        &gt;&gt;&gt; timeframes = Factory.get_supported_timeframes()\n        &gt;&gt;&gt; print(timeframes)\n        ['1min', '5min', '15min', '30min', '1h', '4h', '6h', '12h', '1d', '1w', '1m', '1q', '1y']\n\n        &gt;&gt;&gt; # Use in configuration\n        &gt;&gt;&gt; from thestrat.schemas import AggregationConfig\n        &gt;&gt;&gt; available_timeframes = Factory.get_supported_timeframes()\n        &gt;&gt;&gt; config = AggregationConfig(\n        ...     target_timeframes=[available_timeframes[0], available_timeframes[1]],\n        ...     asset_class=\"equities\"\n        ... )\n\n    Note:\n        The timeframes are ordered by duration (shortest to longest) and follow standard conventions:\n        - Minutes: `1min`, `5min`, `15min`, `30min`\n        - Hours: `1h`, `4h`, `6h`, `12h`\n        - Days/Weeks/Months: `1d`, `1w`, `1m` (month), `1q` (quarter), `1y`\n    \"\"\"\n    from .schemas import TimeframeConfig\n\n    # Pre-compute timeframes with their durations for efficient sorting\n    timeframes_with_duration = [\n        (tf, TimeframeConfig.TIMEFRAME_METADATA.get(tf, {}).get(\"seconds\", float(\"inf\")))\n        for tf in TimeframeConfig.TIMEFRAME_METADATA.keys()\n    ]\n\n    # Sort by duration and return just the timeframe strings\n    return [tf for tf, _ in sorted(timeframes_with_duration, key=lambda x: x[1])]\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Factory.get_supported_timeframes--use-in-configuration","title":"Use in configuration","text":"<p>from thestrat.schemas import AggregationConfig available_timeframes = Factory.get_supported_timeframes() config = AggregationConfig( ...     target_timeframes=[available_timeframes[0], available_timeframes[1]], ...     asset_class=\"equities\" ... )</p>"},{"location":"reference/thestrat/#thestrat.Factory.get_timeframe_metadata","title":"get_timeframe_metadata  <code>staticmethod</code>","text":"<pre><code>get_timeframe_metadata(timeframe: str) -&gt; dict[str, Any]\n</code></pre> <p>Get detailed metadata for a specific timeframe.</p> <p>Provides comprehensive information about a timeframe including its category, duration in seconds, description, and typical use cases. This is useful for understanding the characteristics and appropriate applications of different timeframes.</p> <p>Parameters:</p> Name Type Description Default <code>timeframe</code> <code>str</code> <p>Timeframe string to get metadata for (e.g., \"5min\", \"1h\", \"1d\")</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary containing:</p> <code>dict[str, Any]</code> <ul> <li><code>category</code>: Timeframe category (e.g., \"sub-hourly\", \"hourly\", \"daily\")</li> </ul> <code>dict[str, Any]</code> <ul> <li><code>seconds</code>: Duration in seconds</li> </ul> <code>dict[str, Any]</code> <ul> <li><code>description</code>: Human-readable description</li> </ul> <code>dict[str, Any]</code> <ul> <li><code>typical_use</code>: Common use cases for this timeframe</li> </ul> <code>dict[str, Any]</code> <ul> <li><code>data_volume</code>: Expected data volume level</li> </ul> <p>Raises:</p> Type Description <code>ValueError</code> <p>If timeframe is not supported</p> Example <p>from thestrat import Factory metadata = Factory.get_timeframe_metadata(\"1h\") print(metadata) {     'category': 'hourly',     'seconds': 3600,     'description': '1-hour bars for daily structure analysis',     'typical_use': 'Day trading context, hourly levels',     'data_volume': 'low' }</p> See Also <ul> <li>:meth:<code>get_supported_timeframes</code>: Get list of all supported timeframes</li> <li>:meth:<code>validate_timeframe_format</code>: Validate a timeframe string</li> </ul> Source code in <code>thestrat/factory.py</code> <pre><code>@staticmethod\ndef get_timeframe_metadata(timeframe: str) -&gt; dict[str, Any]:\n    \"\"\"\n    Get detailed metadata for a specific timeframe.\n\n    Provides comprehensive information about a timeframe including its\n    category, duration in seconds, description, and typical use cases.\n    This is useful for understanding the characteristics and appropriate\n    applications of different timeframes.\n\n    Args:\n        timeframe: Timeframe string to get metadata for (e.g., \"5min\", \"1h\", \"1d\")\n\n    Returns:\n        Dictionary containing:\n        - `category`: Timeframe category (e.g., \"sub-hourly\", \"hourly\", \"daily\")\n        - `seconds`: Duration in seconds\n        - `description`: Human-readable description\n        - `typical_use`: Common use cases for this timeframe\n        - `data_volume`: Expected data volume level\n\n    Raises:\n        ValueError: If timeframe is not supported\n\n    Example:\n        &gt;&gt;&gt; from thestrat import Factory\n        &gt;&gt;&gt; metadata = Factory.get_timeframe_metadata(\"1h\")\n        &gt;&gt;&gt; print(metadata)\n        {\n            'category': 'hourly',\n            'seconds': 3600,\n            'description': '1-hour bars for daily structure analysis',\n            'typical_use': 'Day trading context, hourly levels',\n            'data_volume': 'low'\n        }\n\n        &gt;&gt;&gt; # Check if a timeframe is suitable for day trading\n        &gt;&gt;&gt; metadata = Factory.get_timeframe_metadata(\"5min\")\n        &gt;&gt;&gt; if \"day trading\" in metadata[\"typical_use\"].lower():\n        ...     print(f\"5min is suitable for day trading\")\n\n        &gt;&gt;&gt; # Get all intraday timeframes\n        &gt;&gt;&gt; all_timeframes = Factory.get_supported_timeframes()\n        &gt;&gt;&gt; intraday = []\n        &gt;&gt;&gt; for tf in all_timeframes:\n        ...     meta = Factory.get_timeframe_metadata(tf)\n        ...     if meta[\"category\"] in [\"sub-hourly\", \"hourly\"]:\n        ...         intraday.append(tf)\n\n    See Also:\n        - :meth:`get_supported_timeframes`: Get list of all supported timeframes\n        - :meth:`validate_timeframe_format`: Validate a timeframe string\n    \"\"\"\n    # Use cached helper method to get metadata efficiently\n    metadata = Factory._get_cached_timeframe_metadata(timeframe)\n    return metadata.copy()  # Return a copy to prevent modification\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Factory.get_timeframe_metadata--check-if-a-timeframe-is-suitable-for-day-trading","title":"Check if a timeframe is suitable for day trading","text":"<p>metadata = Factory.get_timeframe_metadata(\"5min\") if \"day trading\" in metadata[\"typical_use\"].lower(): ...     print(f\"5min is suitable for day trading\")</p>"},{"location":"reference/thestrat/#thestrat.Factory.get_timeframe_metadata--get-all-intraday-timeframes","title":"Get all intraday timeframes","text":"<p>all_timeframes = Factory.get_supported_timeframes() intraday = [] for tf in all_timeframes: ...     meta = Factory.get_timeframe_metadata(tf) ...     if meta[\"category\"] in [\"sub-hourly\", \"hourly\"]: ...         intraday.append(tf)</p>"},{"location":"reference/thestrat/#thestrat.FactoryConfig","title":"FactoryConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Root configuration for Factory.create_all method with complete pipeline setup.</p> <p>Methods:</p> Name Description <code>validate_configuration_consistency</code> <p>Validate consistency between aggregation and indicators configurations.</p>"},{"location":"reference/thestrat/#thestrat.FactoryConfig.validate_configuration_consistency","title":"validate_configuration_consistency","text":"<pre><code>validate_configuration_consistency() -&gt; Self\n</code></pre> <p>Validate consistency between aggregation and indicators configurations.</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@model_validator(mode=\"after\")\ndef validate_configuration_consistency(self) -&gt; Self:\n    \"\"\"Validate consistency between aggregation and indicators configurations.\"\"\"\n    # Future enhancement: Could validate that indicator timeframes are compatible\n    # with aggregation target timeframes, but this is not currently enforced\n    # in the existing system\n    return self\n</code></pre>"},{"location":"reference/thestrat/#thestrat.GapDetectionConfig","title":"GapDetectionConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for gap detection with comprehensive threshold documentation.</p>"},{"location":"reference/thestrat/#thestrat.IndicatorSchema","title":"IndicatorSchema","text":"<p>               Bases: <code>BaseModel</code></p> <p>Complete Indicator Schema</p> <p>Defines all columns that are created by TheStrat processing pipeline. All columns are required as the indicators component creates them all.</p> <p>Methods:</p> Name Description <code>get_all_input_columns</code> <p>Get list of all input columns (required + optional).</p> <code>get_column_categories</code> <p>Get columns organized by functional categories.</p> <code>get_column_descriptions</code> <p>Get descriptions for all possible DataFrame columns.</p> <code>get_optional_input_columns</code> <p>Get list of optional input columns based on schema definition.</p> <code>get_polars_dtypes</code> <p>Get Polars data types for all DataFrame columns.</p> <code>get_required_input_columns</code> <p>Get list of required input columns based on schema definition.</p> <code>validate_dataframe</code> <p>Validate input DataFrame columns and data types against IndicatorSchema input requirements.</p>"},{"location":"reference/thestrat/#thestrat.IndicatorSchema.get_all_input_columns","title":"get_all_input_columns  <code>classmethod</code>","text":"<pre><code>get_all_input_columns() -&gt; list[str]\n</code></pre> <p>Get list of all input columns (required + optional).</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of all input column names</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_all_input_columns(cls) -&gt; list[str]:\n    \"\"\"\n    Get list of all input columns (required + optional).\n\n    Returns:\n        List of all input column names\n    \"\"\"\n    return sorted(cls.get_required_input_columns() + cls.get_optional_input_columns())\n</code></pre>"},{"location":"reference/thestrat/#thestrat.IndicatorSchema.get_column_categories","title":"get_column_categories  <code>classmethod</code>","text":"<pre><code>get_column_categories() -&gt; dict[str, list[str]]\n</code></pre> <p>Get columns organized by functional categories.</p> <p>Dynamically extracts categories from the IndicatorSchema metadata.</p> <p>Returns:</p> Type Description <code>dict[str, list[str]]</code> <p>Dictionary mapping category names to lists of column names</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_column_categories(cls) -&gt; dict[str, list[str]]:\n    \"\"\"\n    Get columns organized by functional categories.\n\n    Dynamically extracts categories from the IndicatorSchema metadata.\n\n    Returns:\n        Dictionary mapping category names to lists of column names\n    \"\"\"\n    categories: dict[str, list[str]] = {}\n\n    for field_name, field_info in cls.model_fields.items():\n        json_extra = getattr(field_info, \"json_schema_extra\", {})\n        if isinstance(json_extra, dict) and \"category\" in json_extra:\n            category = json_extra[\"category\"]\n            if category not in categories:\n                categories[category] = []\n            categories[category].append(field_name)\n\n    # Sort columns within each category for consistent output\n    for category in categories:\n        categories[category].sort()\n\n    return categories\n</code></pre>"},{"location":"reference/thestrat/#thestrat.IndicatorSchema.get_column_descriptions","title":"get_column_descriptions  <code>classmethod</code>","text":"<pre><code>get_column_descriptions() -&gt; dict[str, str]\n</code></pre> <p>Get descriptions for all possible DataFrame columns.</p> <p>Returns:</p> Type Description <code>dict[str, str]</code> <p>Dictionary mapping column names to their descriptions</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_column_descriptions(cls) -&gt; dict[str, str]:\n    \"\"\"\n    Get descriptions for all possible DataFrame columns.\n\n    Returns:\n        Dictionary mapping column names to their descriptions\n    \"\"\"\n    descriptions = {}\n\n    # Get descriptions from the schema\n    for field_name, field_info in cls.model_fields.items():\n        if field_info.description:\n            descriptions[field_name] = field_info.description\n\n    return descriptions\n</code></pre>"},{"location":"reference/thestrat/#thestrat.IndicatorSchema.get_optional_input_columns","title":"get_optional_input_columns  <code>classmethod</code>","text":"<pre><code>get_optional_input_columns() -&gt; list[str]\n</code></pre> <p>Get list of optional input columns based on schema definition.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of column names that are optional for input data</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_optional_input_columns(cls) -&gt; list[str]:\n    \"\"\"\n    Get list of optional input columns based on schema definition.\n\n    Returns:\n        List of column names that are optional for input data\n    \"\"\"\n    from pydantic_core import PydanticUndefined\n\n    optional_columns = []\n    for field_name, field_info in cls.model_fields.items():\n        json_extra = getattr(field_info, \"json_schema_extra\", {}) or {}\n        if (\n            json_extra.get(\"input\") is True  # Is an input column\n            and (\n                json_extra.get(\"optional\", False)  # Marked as optional\n                or getattr(field_info, \"default\", PydanticUndefined) is not PydanticUndefined\n            )  # Has default value\n        ):\n            optional_columns.append(field_name)\n    return sorted(optional_columns)\n</code></pre>"},{"location":"reference/thestrat/#thestrat.IndicatorSchema.get_polars_dtypes","title":"get_polars_dtypes  <code>classmethod</code>","text":"<pre><code>get_polars_dtypes() -&gt; dict[str, Any]\n</code></pre> <p>Get Polars data types for all DataFrame columns.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary mapping column names to their Polars data types</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_polars_dtypes(cls) -&gt; dict[str, Any]:\n    \"\"\"\n    Get Polars data types for all DataFrame columns.\n\n    Returns:\n        Dictionary mapping column names to their Polars data types\n    \"\"\"\n    types = {}\n\n    for field_name, field_info in cls.model_fields.items():\n        json_extra = getattr(field_info, \"json_schema_extra\", {})\n        if isinstance(json_extra, dict) and \"polars_dtype\" in json_extra:\n            types[field_name] = json_extra[\"polars_dtype\"]\n\n    return types\n</code></pre>"},{"location":"reference/thestrat/#thestrat.IndicatorSchema.get_required_input_columns","title":"get_required_input_columns  <code>classmethod</code>","text":"<pre><code>get_required_input_columns() -&gt; list[str]\n</code></pre> <p>Get list of required input columns based on schema definition.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of column names that are required for input data</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_required_input_columns(cls) -&gt; list[str]:\n    \"\"\"\n    Get list of required input columns based on schema definition.\n\n    Returns:\n        List of column names that are required for input data\n    \"\"\"\n    from pydantic_core import PydanticUndefined\n\n    required_columns = []\n    for field_name, field_info in cls.model_fields.items():\n        json_extra = getattr(field_info, \"json_schema_extra\", {}) or {}\n        if (\n            json_extra.get(\"input\") is True  # Is an input column\n            and not json_extra.get(\"optional\", False)  # Not marked as optional\n            and getattr(field_info, \"default\", PydanticUndefined)\n            is PydanticUndefined  # No default value (required)\n        ):\n            required_columns.append(field_name)\n    return sorted(required_columns)\n</code></pre>"},{"location":"reference/thestrat/#thestrat.IndicatorSchema.validate_dataframe","title":"validate_dataframe  <code>classmethod</code>","text":"<pre><code>validate_dataframe(df) -&gt; dict[str, Any]\n</code></pre> <p>Validate input DataFrame columns and data types against IndicatorSchema input requirements.</p> <p>Automatically converts Pandas DataFrames to Polars for consistent validation.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <p>Polars or Pandas DataFrame to validate</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary with validation results including missing/extra columns, type issues,</p> <code>dict[str, Any]</code> <p>and the converted Polars DataFrame if conversion occurred</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef validate_dataframe(cls, df) -&gt; dict[str, Any]:\n    \"\"\"\n    Validate input DataFrame columns and data types against IndicatorSchema input requirements.\n\n    Automatically converts Pandas DataFrames to Polars for consistent validation.\n\n    Args:\n        df: Polars or Pandas DataFrame to validate\n\n    Returns:\n        Dictionary with validation results including missing/extra columns, type issues,\n        and the converted Polars DataFrame if conversion occurred\n    \"\"\"\n    import polars as pl\n\n    # Detect DataFrame type and convert if necessary\n    df_type = \"unknown\"\n    converted_df = None\n    conversion_errors = []\n\n    if hasattr(df, \"columns\"):\n        # Check if it's a Pandas DataFrame\n        if hasattr(df, \"dtypes\") and not hasattr(df, \"schema\"):\n            df_type = \"pandas\"\n            try:\n                # Convert Pandas to Polars\n                converted_df = pl.from_pandas(df)\n                df = converted_df  # Use converted DataFrame for validation\n            except Exception as e:\n                conversion_errors.append(f\"Failed to convert Pandas to Polars: {str(e)}\")\n                # Fall back to column-only validation\n                df_columns = list(df.columns)\n                return {\n                    \"valid\": False,\n                    \"conversion_error\": conversion_errors[0],\n                    \"df_type\": df_type,\n                    \"columns\": df_columns,\n                    \"message\": \"Could not convert Pandas DataFrame to Polars for full validation\",\n                }\n        # Check if it's already a Polars DataFrame\n        elif hasattr(df, \"schema\"):\n            df_type = \"polars\"\n        else:\n            raise ValueError(\"Unknown DataFrame type - must be Pandas or Polars DataFrame\")\n\n        df_columns = list(df.columns)\n    else:\n        raise ValueError(\"Input must be a DataFrame with .columns attribute\")\n\n    required_fields = []\n    optional_fields = []\n    expected_types = {}\n\n    # Extract input field requirements from schema\n    for field_name, field_info in cls.model_fields.items():\n        json_extra = getattr(field_info, \"json_schema_extra\", {})\n        if isinstance(json_extra, dict) and json_extra.get(\"input\"):\n            if field_info.is_required():\n                required_fields.append(field_name)\n            else:\n                optional_fields.append(field_name)\n\n            # Store expected Polars type for validation\n            if \"polars_dtype\" in json_extra:\n                expected_types[field_name] = json_extra[\"polars_dtype\"]\n\n    # Check for missing and extra columns\n    missing_required = [col for col in required_fields if col not in df_columns]\n    missing_optional = [col for col in optional_fields if col not in df_columns]\n    extra_columns = [col for col in df_columns if col not in required_fields + optional_fields]\n\n    # Check data types for present columns (now guaranteed to be Polars)\n    type_issues = []\n    if hasattr(df, \"schema\"):  # Polars DataFrame\n        for col_name, expected_type in expected_types.items():\n            if col_name in df_columns:\n                actual_type = df.schema[col_name]\n                if actual_type != expected_type:\n                    type_issues.append(\n                        {\n                            \"column\": col_name,\n                            \"expected\": expected_type.__name__\n                            if hasattr(expected_type, \"__name__\")\n                            else str(expected_type),\n                            \"actual\": str(actual_type),\n                        }\n                    )\n\n    result = {\n        \"valid\": len(missing_required) == 0 and len(type_issues) == 0,\n        \"missing_required\": missing_required,\n        \"missing_optional\": missing_optional,\n        \"extra_columns\": extra_columns,\n        \"type_issues\": type_issues,\n        \"required_fields\": required_fields,\n        \"optional_fields\": optional_fields,\n        \"expected_types\": {k: v.__name__ if hasattr(v, \"__name__\") else str(v) for k, v in expected_types.items()},\n        \"df_type\": df_type,\n    }\n\n    # Include converted DataFrame if conversion occurred\n    if converted_df is not None:\n        result[\"converted_df\"] = converted_df\n        result[\"conversion_performed\"] = True\n    else:\n        result[\"conversion_performed\"] = False\n\n    return result\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Indicators","title":"Indicators","text":"<pre><code>Indicators(config: IndicatorsConfig)\n</code></pre> <p>               Bases: <code>Component</code></p> <p>Vectorized implementation of all Strat technical indicators.</p> <p>Provides comprehensive technical analysis including swing point detection, market structure analysis, pattern recognition, and gap detection optimized for TheStrat methodology.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>IndicatorsConfig</code> <p>Validated IndicatorsConfig containing per-timeframe configurations</p> required <p>Methods:</p> Name Description <code>process</code> <p>Calculate all Strat indicators for OHLC data.</p> <code>validate_input</code> <p>Validate input data format.</p> Source code in <code>thestrat/indicators.py</code> <pre><code>def __init__(self, config: IndicatorsConfig):\n    \"\"\"\n    Initialize indicators component with validated configuration.\n\n    Args:\n        config: Validated IndicatorsConfig containing per-timeframe configurations\n    \"\"\"\n    super().__init__()\n\n    # Store the validated Pydantic config\n    self.config = config\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Indicators.process","title":"process","text":"<pre><code>process(data: DataFrame | DataFrame) -&gt; DataFrame\n</code></pre> <p>Calculate all Strat indicators for OHLC data.</p> <p>Performs comprehensive technical analysis including swing point detection, market structure analysis, pattern recognition, and gap detection. Calculations run sequentially due to data dependencies between indicators.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | DataFrame</code> <p>Input DataFrame with OHLC data</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with all Strat indicators added</p> Source code in <code>thestrat/indicators.py</code> <pre><code>def process(self, data: PolarsDataFrame | PandasDataFrame) -&gt; PolarsDataFrame:\n    \"\"\"\n    Calculate all Strat indicators for OHLC data.\n\n    Performs comprehensive technical analysis including swing point detection, market structure\n    analysis, pattern recognition, and gap detection. Calculations run sequentially due to\n    data dependencies between indicators.\n\n    Args:\n        data: Input DataFrame with OHLC data\n\n    Returns:\n        DataFrame with all Strat indicators added\n    \"\"\"\n    self.validate_input(data)\n\n    # Convert to Polars if needed\n    df = self._convert_to_polars(data)\n\n    # Check if data has timeframe column for per-timeframe processing\n    if \"timeframe\" in df.columns:\n        # Check if \"all\" timeframe is configured\n        has_all_config = any(\"all\" in tf_config.timeframes for tf_config in self.config.timeframe_configs)\n\n        if has_all_config:\n            # Process all data with the \"all\" configuration\n            all_config = self._get_config_for_timeframe(\"any_timeframe_will_get_all_config\")\n            df = self._process_single_timeframe(df, all_config)\n        else:\n            # Process each timeframe group with its specific configuration\n            timeframe_groups = df.partition_by(\"timeframe\", as_dict=True)\n            processed_groups = []\n\n            for timeframe_key, timeframe_data in timeframe_groups.items():\n                # Extract timeframe string from tuple key\n                timeframe = timeframe_key[0] if isinstance(timeframe_key, tuple) else timeframe_key\n\n                # Get config for this timeframe\n                tf_config = self._get_config_for_timeframe(timeframe)\n\n                # Process this timeframe with its specific config\n                processed_data = self._process_single_timeframe(timeframe_data, tf_config)\n                processed_groups.append(processed_data)\n\n            # Combine all processed groups\n            df = processed_groups[0]\n            for group in processed_groups[1:]:\n                df = df.vstack(group)\n\n            # Sort by original order (symbol, timeframe, timestamp)\n            sort_cols = []\n            if \"symbol\" in df.columns:\n                sort_cols.append(\"symbol\")\n            sort_cols.extend([\"timeframe\", \"timestamp\"])\n            df = df.sort(sort_cols)\n    else:\n        # No timeframe column - must have \"all\" configuration\n        has_all_config = any(\"all\" in tf_config.timeframes for tf_config in self.config.timeframe_configs)\n        if not has_all_config:\n            raise ValueError(\"Data without timeframe column requires an 'all' timeframe configuration.\")\n\n        all_config = self._get_config_for_timeframe(\"any_timeframe_will_get_all_config\")\n        df = self._process_single_timeframe(df, all_config)\n\n    return df\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Indicators.validate_input","title":"validate_input","text":"<pre><code>validate_input(data: DataFrame | DataFrame) -&gt; None\n</code></pre> <p>Validate input data format.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If data format is invalid, with specific error message</p> Source code in <code>thestrat/indicators.py</code> <pre><code>def validate_input(self, data: PolarsDataFrame | PandasDataFrame) -&gt; None:\n    \"\"\"\n    Validate input data format.\n\n    Raises:\n        ValueError: If data format is invalid, with specific error message\n    \"\"\"\n    df = self._convert_to_polars(data)\n\n    # Check required columns\n    required_cols = [\"timestamp\", \"open\", \"high\", \"low\", \"close\"]\n    missing_cols = [col for col in required_cols if col not in df.columns]\n    if missing_cols:\n        raise ValueError(f\"Missing required columns: {missing_cols}\")\n\n    # Get minimum swing window from any configuration\n    min_swing_window = 5  # default\n    for tf_config in self.config.timeframe_configs:\n        swing_config = tf_config.swing_points\n        if swing_config is not None:\n            window = swing_config.window\n            min_swing_window = min(min_swing_window, window)\n\n    # Check for minimum data points for swing analysis\n    if len(df) &lt; min_swing_window * 2:\n        raise ValueError(\n            f\"Insufficient data: {len(df)} rows provided, need at least {min_swing_window * 2} rows \"\n            f\"for swing analysis with window={min_swing_window}\"\n        )\n\n    # Verify price data integrity\n    validations = df.select(\n        [\n            (col(\"high\") &gt;= col(\"low\")).all().alias(\"high_gte_low\"),\n            (col(\"high\") &gt;= col(\"open\")).all().alias(\"high_gte_open\"),\n            (col(\"high\") &gt;= col(\"close\")).all().alias(\"high_gte_close\"),\n            (col(\"low\") &lt;= col(\"open\")).all().alias(\"low_lte_open\"),\n            (col(\"low\") &lt;= col(\"close\")).all().alias(\"low_lte_close\"),\n        ]\n    )\n\n    validation_results = validations.to_numpy().flatten()\n    validation_names = [\"high &gt;= low\", \"high &gt;= open\", \"high &gt;= close\", \"low &lt;= open\", \"low &lt;= close\"]\n\n    failed_validations = [\n        name for name, result in zip(validation_names, validation_results, strict=False) if not result\n    ]\n    if failed_validations:\n        raise ValueError(f\"Invalid price data: failed validations: {failed_validations}\")\n</code></pre>"},{"location":"reference/thestrat/#thestrat.IndicatorsConfig","title":"IndicatorsConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Complete configuration for indicators component with per-timeframe settings.</p>"},{"location":"reference/thestrat/#thestrat.PriceChange","title":"PriceChange  <code>dataclass</code>","text":"<pre><code>PriceChange(\n    field_name: str,\n    from_value: float,\n    to_value: float,\n    timestamp: datetime,\n    reason: str | None = None,\n)\n</code></pre> <p>Track changes to stop/target prices.</p>"},{"location":"reference/thestrat/#thestrat.SignalBias","title":"SignalBias","text":"<p>               Bases: <code>Enum</code></p> <p>Signal directional bias.</p>"},{"location":"reference/thestrat/#thestrat.SignalCategory","title":"SignalCategory","text":"<p>               Bases: <code>Enum</code></p> <p>Signal categorization types.</p>"},{"location":"reference/thestrat/#thestrat.SignalMetadata","title":"SignalMetadata  <code>dataclass</code>","text":"<pre><code>SignalMetadata(\n    pattern: str,\n    category: SignalCategory,\n    bias: SignalBias,\n    bar_count: int,\n    entry_bar_index: int,\n    trigger_bar_index: int,\n    entry_price: float,\n    stop_price: float,\n    timestamp: datetime,\n    signal_id: str = (lambda: str(uuid4()))(),\n    target_bar_index: int | None = None,\n    target_price: float | None = None,\n    status: SignalStatus = PENDING,\n    triggered_at: datetime | None = None,\n    closed_at: datetime | None = None,\n    close_reason: str | None = None,\n    change_history: list[PriceChange] = list(),\n    symbol: str | None = None,\n    timeframe: str | None = None,\n    risk_amount: float | None = None,\n    reward_amount: float | None = None,\n    risk_reward_ratio: float | None = None,\n    entry_filled_price: float | None = None,\n    exit_price: float | None = None,\n    pnl: float | None = None,\n    max_favorable_excursion: float | None = None,\n    max_adverse_excursion: float | None = None,\n)\n</code></pre> <p>Complete signal metadata with change tracking and serialization.</p> <p>Methods:</p> Name Description <code>__post_init__</code> <p>Store original values and calculate metrics.</p> <code>from_dict</code> <p>Reconstruct SignalMetadata from dictionary.</p> <code>from_json</code> <p>Deserialize from JSON string.</p> <code>to_dict</code> <p>Convert to dictionary for JSON serialization.</p> <code>to_json</code> <p>Serialize to JSON string.</p> <code>trail_stop</code> <p>Trail stop loss, only allowing favorable moves.</p> <code>update_stop</code> <p>Update stop with change tracking.</p> <code>update_target</code> <p>Update target with change tracking.</p>"},{"location":"reference/thestrat/#thestrat.SignalMetadata.__post_init__","title":"__post_init__","text":"<pre><code>__post_init__()\n</code></pre> <p>Store original values and calculate metrics.</p> Source code in <code>thestrat/signals.py</code> <pre><code>def __post_init__(self):\n    \"\"\"Store original values and calculate metrics.\"\"\"\n    self.original_stop = self.stop_price\n    self.original_target = self.target_price\n    self._calculate_risk_metrics()\n</code></pre>"},{"location":"reference/thestrat/#thestrat.SignalMetadata.from_dict","title":"from_dict  <code>classmethod</code>","text":"<pre><code>from_dict(data: dict[str, Any]) -&gt; SignalMetadata\n</code></pre> <p>Reconstruct SignalMetadata from dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict[str, Any]</code> <p>Dictionary representation from <code>to_dict()</code></p> required <p>Returns:</p> Type Description <code>SignalMetadata</code> <p>SignalMetadata instance with original values and metrics recalculated</p> Source code in <code>thestrat/signals.py</code> <pre><code>@classmethod\ndef from_dict(cls, data: dict[str, Any]) -&gt; \"SignalMetadata\":\n    \"\"\"\n    Reconstruct SignalMetadata from dictionary.\n\n    Args:\n        data: Dictionary representation from `to_dict()`\n\n    Returns:\n        SignalMetadata instance with original values and metrics recalculated\n    \"\"\"\n    # Make a copy to avoid modifying the original\n    data = data.copy()\n\n    # Convert strings back to enums\n    data[\"category\"] = SignalCategory(data[\"category\"])\n    data[\"bias\"] = SignalBias(data[\"bias\"])\n    data[\"status\"] = SignalStatus(data[\"status\"])\n\n    # Convert ISO strings to datetime\n    data[\"timestamp\"] = datetime.fromisoformat(data[\"timestamp\"])\n\n    if data.get(\"triggered_at\"):\n        data[\"triggered_at\"] = datetime.fromisoformat(data[\"triggered_at\"])\n    if data.get(\"closed_at\"):\n        data[\"closed_at\"] = datetime.fromisoformat(data[\"closed_at\"])\n\n    # Reconstruct change history\n    data[\"change_history\"] = [\n        PriceChange(**{**ch, \"timestamp\": datetime.fromisoformat(ch[\"timestamp\"])})\n        for ch in data.get(\"change_history\", [])\n    ]\n\n    # Convert string prices back to floats\n    float_fields = [\n        \"entry_price\",\n        \"stop_price\",\n        \"target_price\",\n        \"original_stop\",\n        \"original_target\",\n        \"risk_amount\",\n        \"reward_amount\",\n        \"risk_reward_ratio\",\n        \"entry_filled_price\",\n        \"exit_price\",\n        \"pnl\",\n        \"max_favorable_excursion\",\n        \"max_adverse_excursion\",\n    ]\n\n    for float_field in float_fields:\n        if data.get(float_field) is not None and isinstance(data[float_field], str):\n            data[float_field] = float(data[float_field])\n\n    # Remove fields that are calculated in __post_init__ and shouldn't be passed to constructor\n    calculated_fields = [\"original_stop\", \"original_target\", \"risk_amount\", \"reward_amount\", \"risk_reward_ratio\"]\n    for calc_field in calculated_fields:\n        data.pop(calc_field, None)\n\n    # Create the object (original values and metrics will be recalculated in __post_init__)\n    return cls(**data)\n</code></pre>"},{"location":"reference/thestrat/#thestrat.SignalMetadata.from_json","title":"from_json  <code>classmethod</code>","text":"<pre><code>from_json(json_str: str) -&gt; SignalMetadata\n</code></pre> <p>Deserialize from JSON string.</p> <p>Parameters:</p> Name Type Description Default <code>json_str</code> <code>str</code> <p>JSON string from <code>to_json()</code></p> required <p>Returns:</p> Type Description <code>SignalMetadata</code> <p>SignalMetadata instance reconstructed from JSON</p> Source code in <code>thestrat/signals.py</code> <pre><code>@classmethod\ndef from_json(cls, json_str: str) -&gt; \"SignalMetadata\":\n    \"\"\"\n    Deserialize from JSON string.\n\n    Args:\n        json_str: JSON string from `to_json()`\n\n    Returns:\n        SignalMetadata instance reconstructed from JSON\n    \"\"\"\n    return cls.from_dict(json.loads(json_str))\n</code></pre>"},{"location":"reference/thestrat/#thestrat.SignalMetadata.to_dict","title":"to_dict","text":"<pre><code>to_dict() -&gt; dict[str, Any]\n</code></pre> <p>Convert to dictionary for JSON serialization.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary representation with all fields serializable to JSON</p> Source code in <code>thestrat/signals.py</code> <pre><code>def to_dict(self) -&gt; dict[str, Any]:\n    \"\"\"\n    Convert to dictionary for JSON serialization.\n\n    Returns:\n        Dictionary representation with all fields serializable to JSON\n    \"\"\"\n    data = asdict(self)\n\n    # Convert enums to strings\n    data[\"category\"] = self.category.value\n    data[\"bias\"] = self.bias.value\n    data[\"status\"] = self.status.value\n\n    # Convert datetime to ISO format\n    data[\"timestamp\"] = self.timestamp.isoformat()\n\n    if self.triggered_at:\n        data[\"triggered_at\"] = self.triggered_at.isoformat()\n    if self.closed_at:\n        data[\"closed_at\"] = self.closed_at.isoformat()\n\n    # Convert change history\n    data[\"change_history\"] = [\n        {**asdict(change), \"timestamp\": change.timestamp.isoformat()} for change in self.change_history\n    ]\n\n    # Convert floats to strings for precision (optional)\n    float_fields = [\n        \"entry_price\",\n        \"stop_price\",\n        \"target_price\",\n        \"original_stop\",\n        \"original_target\",\n        \"risk_amount\",\n        \"reward_amount\",\n        \"risk_reward_ratio\",\n        \"entry_filled_price\",\n        \"exit_price\",\n        \"pnl\",\n        \"max_favorable_excursion\",\n        \"max_adverse_excursion\",\n    ]\n\n    for float_field in float_fields:\n        if data.get(float_field) is not None:\n            data[float_field] = str(data[float_field])\n\n    return data\n</code></pre>"},{"location":"reference/thestrat/#thestrat.SignalMetadata.to_json","title":"to_json","text":"<pre><code>to_json() -&gt; str\n</code></pre> <p>Serialize to JSON string.</p> <p>Returns:</p> Type Description <code>str</code> <p>JSON string representation of the signal metadata</p> Source code in <code>thestrat/signals.py</code> <pre><code>def to_json(self) -&gt; str:\n    \"\"\"\n    Serialize to JSON string.\n\n    Returns:\n        JSON string representation of the signal metadata\n    \"\"\"\n    return json.dumps(self.to_dict(), default=str)\n</code></pre>"},{"location":"reference/thestrat/#thestrat.SignalMetadata.trail_stop","title":"trail_stop","text":"<pre><code>trail_stop(new_stop: float, reason: str = 'trailing_stop') -&gt; bool\n</code></pre> <p>Trail stop loss, only allowing favorable moves.</p> <p>Parameters:</p> Name Type Description Default <code>new_stop</code> <code>float</code> <p>Proposed new stop price</p> required <code>reason</code> <code>str</code> <p>Reason for trailing (default: \"trailing_stop\")</p> <code>'trailing_stop'</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if stop was trailed, False if move was unfavorable and rejected</p> Source code in <code>thestrat/signals.py</code> <pre><code>def trail_stop(self, new_stop: float, reason: str = \"trailing_stop\") -&gt; bool:\n    \"\"\"\n    Trail stop loss, only allowing favorable moves.\n\n    Args:\n        new_stop: Proposed new stop price\n        reason: Reason for trailing (default: \"trailing_stop\")\n\n    Returns:\n        True if stop was trailed, False if move was unfavorable and rejected\n    \"\"\"\n    if self.bias == SignalBias.LONG:\n        # For long trades, only trail up\n        if new_stop &gt; self.stop_price:\n            self.update_stop(new_stop, reason)\n            return True\n    else:\n        # For short trades, only trail down\n        if new_stop &lt; self.stop_price:\n            self.update_stop(new_stop, reason)\n            return True\n    return False\n</code></pre>"},{"location":"reference/thestrat/#thestrat.SignalMetadata.update_stop","title":"update_stop","text":"<pre><code>update_stop(new_stop: float, reason: str = None) -&gt; None\n</code></pre> <p>Update stop with change tracking.</p> <p>Parameters:</p> Name Type Description Default <code>new_stop</code> <code>float</code> <p>New stop loss price</p> required <code>reason</code> <code>str</code> <p>Optional reason for the update (e.g., \"trailing_stop\", \"manual_adjustment\")</p> <code>None</code> Source code in <code>thestrat/signals.py</code> <pre><code>def update_stop(self, new_stop: float, reason: str = None) -&gt; None:\n    \"\"\"\n    Update stop with change tracking.\n\n    Args:\n        new_stop: New stop loss price\n        reason: Optional reason for the update (e.g., \"trailing_stop\", \"manual_adjustment\")\n    \"\"\"\n    if new_stop == self.stop_price:\n        return\n\n    change = PriceChange(\n        field_name=\"stop_price\",\n        from_value=self.stop_price,\n        to_value=new_stop,\n        timestamp=datetime.now(),\n        reason=reason,\n    )\n    self.change_history.append(change)\n    self.stop_price = new_stop\n    self._calculate_risk_metrics()\n</code></pre>"},{"location":"reference/thestrat/#thestrat.SignalMetadata.update_target","title":"update_target","text":"<pre><code>update_target(new_target: float, reason: str = None) -&gt; None\n</code></pre> <p>Update target with change tracking.</p> <p>Parameters:</p> Name Type Description Default <code>new_target</code> <code>float</code> <p>New target price</p> required <code>reason</code> <code>str</code> <p>Optional reason for the update (e.g., \"manual_adjustment\", \"scale_out\")</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If called on continuation signals (they have no target)</p> Source code in <code>thestrat/signals.py</code> <pre><code>def update_target(self, new_target: float, reason: str = None) -&gt; None:\n    \"\"\"\n    Update target with change tracking.\n\n    Args:\n        new_target: New target price\n        reason: Optional reason for the update (e.g., \"manual_adjustment\", \"scale_out\")\n\n    Raises:\n        ValueError: If called on continuation signals (they have no target)\n    \"\"\"\n    if self.category == SignalCategory.CONTINUATION:\n        raise ValueError(\"Continuation signals have no target\")\n\n    if new_target == self.target_price:\n        return\n\n    change = PriceChange(\n        field_name=\"target_price\",\n        from_value=self.target_price,\n        to_value=new_target,\n        timestamp=datetime.now(),\n        reason=reason,\n    )\n    self.change_history.append(change)\n    self.target_price = new_target\n    self._calculate_risk_metrics()\n</code></pre>"},{"location":"reference/thestrat/#thestrat.SignalStatus","title":"SignalStatus","text":"<p>               Bases: <code>Enum</code></p> <p>Signal lifecycle status.</p>"},{"location":"reference/thestrat/#thestrat.SwingPointsConfig","title":"SwingPointsConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for swing point detection with comprehensive parameter documentation.</p>"},{"location":"reference/thestrat/#thestrat.TimeframeItemConfig","title":"TimeframeItemConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for a single timeframe item with flexible timeframe targeting.</p> <p>Methods:</p> Name Description <code>validate_timeframe_combinations</code> <p>Validate that 'all' is not mixed with specific timeframes.</p>"},{"location":"reference/thestrat/#thestrat.TimeframeItemConfig.validate_timeframe_combinations","title":"validate_timeframe_combinations","text":"<pre><code>validate_timeframe_combinations() -&gt; Self\n</code></pre> <p>Validate that 'all' is not mixed with specific timeframes.</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@model_validator(mode=\"after\")\ndef validate_timeframe_combinations(self) -&gt; Self:\n    \"\"\"Validate that 'all' is not mixed with specific timeframes.\"\"\"\n    if \"all\" in self.timeframes and len(self.timeframes) &gt; 1:\n        raise ValueError(\"'all' cannot be combined with specific timeframes\")\n    return self\n</code></pre>"},{"location":"reference/thestrat/aggregation/","title":"Aggregation","text":"<p>OHLCV timeframe aggregation</p> <p>OHLC timeframe aggregation with precise time boundary control.</p> <p>This module provides vectorized OHLC aggregation across different timeframes with support for asset class-specific timezone handling and boundary alignment.</p> <p>Classes:</p> Name Description <code>Aggregation</code> <p>Convert OHLC data between timeframes with precise time boundary control.</p>"},{"location":"reference/thestrat/aggregation/#thestrat.aggregation.Aggregation","title":"Aggregation","text":"<pre><code>Aggregation(config: AggregationConfig)\n</code></pre> <p>               Bases: <code>Component</code></p> <p>Convert OHLC data between timeframes with precise time boundary control.</p> Features <ul> <li>Time Boundary Control: hour_boundary flag for hourly+ aggregation alignment</li> <li>Session Control: session_start parameter for sub-hourly alignment</li> <li>Asset Class Support: Crypto, equities, FX, futures with timezone handling</li> <li>Vectorized Processing: Pure Polars operations for maximum performance</li> </ul> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>AggregationConfig</code> <p>Validated AggregationConfig containing all configuration settings</p> required <p>Methods:</p> Name Description <code>normalize_timezone</code> <p>Convert naive timestamps to timezone-aware using timezone resolution priority.</p> <code>process</code> <p>Convert OHLC data to target timeframes with boundary alignment.</p> <code>validate_input</code> <p>Validate input data format.</p> Source code in <code>thestrat/aggregation.py</code> <pre><code>def __init__(self, config: AggregationConfig):\n    \"\"\"\n    Initialize aggregation component with validated configuration.\n\n    Args:\n        config: Validated AggregationConfig containing all configuration settings\n    \"\"\"\n    super().__init__()\n\n    # Store the validated Pydantic config\n    self.config = config\n\n    # Extract commonly used values for convenience\n    self.target_timeframes = config.target_timeframes.copy()\n    self.asset_class = config.asset_class\n\n    # These fields are guaranteed to be non-None after model validation\n    assert config.timezone is not None\n    assert config.session_start is not None\n    assert config.hour_boundary is not None\n\n    self.timezone = config.timezone\n    self.session_start = config.session_start\n    self.hour_boundary = config.hour_boundary\n\n    # Validate all timeframes\n    from .schemas import TimeframeConfig\n\n    for tf in self.target_timeframes:\n        if not TimeframeConfig.validate_timeframe(tf):\n            raise ValueError(\n                f\"Invalid timeframe '{tf}'. Supported timeframes: {sorted(TimeframeConfig.TIMEFRAME_METADATA.keys())}\"\n            )\n</code></pre>"},{"location":"reference/thestrat/aggregation/#thestrat.aggregation.Aggregation.normalize_timezone","title":"normalize_timezone","text":"<pre><code>normalize_timezone(data: DataFrame) -&gt; DataFrame\n</code></pre> <p>Convert naive timestamps to timezone-aware using timezone resolution priority.</p> Source code in <code>thestrat/aggregation.py</code> <pre><code>def normalize_timezone(self, data: PolarsDataFrame) -&gt; PolarsDataFrame:\n    \"\"\"Convert naive timestamps to timezone-aware using timezone resolution priority.\"\"\"\n    df = data.clone()\n\n    # Check if timestamp is already timezone-aware\n    if df.schema[\"timestamp\"] == Datetime(\"us\", None):  # Naive timestamp\n        # Convert to timezone-aware\n        df = df.with_columns([col(\"timestamp\").dt.replace_time_zone(self.timezone).alias(\"timestamp\")])\n\n    return df\n</code></pre>"},{"location":"reference/thestrat/aggregation/#thestrat.aggregation.Aggregation.process","title":"process","text":"<pre><code>process(data: DataFrame | DataFrame) -&gt; DataFrame\n</code></pre> <p>Convert OHLC data to target timeframes with boundary alignment. Supports both single-timeframe and multi-timeframe source data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | DataFrame</code> <p>Input DataFrame with OHLC data</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>Aggregated OHLC DataFrame with timeframe column</p> Source code in <code>thestrat/aggregation.py</code> <pre><code>def process(self, data: PolarsDataFrame | PandasDataFrame) -&gt; PolarsDataFrame:\n    \"\"\"\n    Convert OHLC data to target timeframes with boundary alignment.\n    Supports both single-timeframe and multi-timeframe source data.\n\n    Args:\n        data: Input DataFrame with OHLC data\n\n    Returns:\n        Aggregated OHLC DataFrame with timeframe column\n    \"\"\"\n    if not self.validate_input(data):\n        raise ValueError(\"Input data validation failed\")\n\n    df = self._convert_to_polars(data)\n    df = self.normalize_timezone(df)\n\n    # Auto-detect mode\n    is_multi_timeframe = \"timeframe\" in df.columns\n\n    if is_multi_timeframe:\n        return self._process_multi_timeframe_source(df)\n    else:\n        return self._process_single_timeframe_source(df)\n</code></pre>"},{"location":"reference/thestrat/aggregation/#thestrat.aggregation.Aggregation.validate_input","title":"validate_input","text":"<pre><code>validate_input(data: DataFrame | DataFrame) -&gt; bool\n</code></pre> <p>Validate input data format.</p> Source code in <code>thestrat/aggregation.py</code> <pre><code>def validate_input(self, data: PolarsDataFrame | PandasDataFrame) -&gt; bool:\n    \"\"\"Validate input data format.\"\"\"\n    df = self._convert_to_polars(data)\n\n    # Check required columns using schema-driven approach\n    from .schemas import IndicatorSchema\n\n    required_cols = IndicatorSchema.get_required_input_columns()\n\n    # Remove timeframe if not in multi-timeframe mode\n    if \"timeframe\" not in df.columns and \"timeframe\" in required_cols:\n        required_cols = [col for col in required_cols if col != \"timeframe\"]\n\n    if not all(col in df.columns for col in required_cols):\n        return False\n\n    # Validate timeframes if in multi-timeframe mode\n    if \"timeframe\" in df.columns:\n        from .schemas import TimeframeConfig\n\n        unique_timeframes = df[\"timeframe\"].unique().to_list()\n        for tf in unique_timeframes:\n            if not TimeframeConfig.validate_timeframe(tf):\n                return False\n\n    # Check for minimum data points\n    if len(df) &lt; 2:\n        return False\n\n    return True\n</code></pre>"},{"location":"reference/thestrat/base/","title":"Base","text":"<p>Abstract base classes</p> <p>Base component classes for TheStrat module.</p> <p>This module provides the abstract base class and core functionality for all TheStrat components.</p> <p>Classes:</p> Name Description <code>Component</code> <p>Base class for all TheStrat components.</p>"},{"location":"reference/thestrat/base/#thestrat.base.Component","title":"Component","text":"<pre><code>Component()\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Base class for all TheStrat components.</p> <p>Methods:</p> Name Description <code>process</code> <p>Process data and return Polars DataFrame results.</p> <code>validate_input</code> <p>Validate input data format.</p> Source code in <code>thestrat/base.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize base component with metadata tracking.\"\"\"\n    from datetime import datetime\n\n    self._created_at = datetime.now()\n</code></pre>"},{"location":"reference/thestrat/base/#thestrat.base.Component.process","title":"process  <code>abstractmethod</code>","text":"<pre><code>process(data: DataFrame | DataFrame) -&gt; DataFrame\n</code></pre> <p>Process data and return Polars DataFrame results.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | DataFrame</code> <p>Input DataFrame (Polars or Pandas)</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>Processed PolarsDataFrame with results</p> Source code in <code>thestrat/base.py</code> <pre><code>@abstractmethod\ndef process(self, data: PolarsDataFrame | PandasDataFrame) -&gt; PolarsDataFrame:\n    \"\"\"\n    Process data and return Polars DataFrame results.\n\n    Args:\n        data: Input DataFrame (Polars or Pandas)\n\n    Returns:\n        Processed PolarsDataFrame with results\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/thestrat/base/#thestrat.base.Component.validate_input","title":"validate_input  <code>abstractmethod</code>","text":"<pre><code>validate_input(data: DataFrame | DataFrame) -&gt; None\n</code></pre> <p>Validate input data format.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | DataFrame</code> <p>Input DataFrame to validate</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If data format is invalid, with specific error message</p> Source code in <code>thestrat/base.py</code> <pre><code>@abstractmethod\ndef validate_input(self, data: PolarsDataFrame | PandasDataFrame) -&gt; None:\n    \"\"\"\n    Validate input data format.\n\n    Args:\n        data: Input DataFrame to validate\n\n    Raises:\n        ValueError: If data format is invalid, with specific error message\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/thestrat/factory/","title":"Factory","text":"<p>Component creation with factory pattern</p> <p>Factory pattern for TheStrat component creation and configuration.</p> <p>This module provides clean factory methods for creating and configuring TheStrat components with Pydantic schema validation.</p> <p>Classes:</p> Name Description <code>ComponentDict</code> <p>Type definition for component dictionary returned by Factory.create_all().</p> <code>Factory</code> <p>Factory class for creating TheStrat components.</p>"},{"location":"reference/thestrat/factory/#thestrat.factory.ComponentDict","title":"ComponentDict","text":"<p>               Bases: <code>TypedDict</code></p> <p>Type definition for component dictionary returned by Factory.create_all().</p>"},{"location":"reference/thestrat/factory/#thestrat.factory.Factory","title":"Factory","text":"<p>Factory class for creating TheStrat components.</p> <p>Provides static methods for creating individual components and class methods for creating complete processing pipelines. All methods accept validated Pydantic configuration models.</p> <p>Methods:</p> Name Description <code>create_aggregation</code> <p>Create aggregation component from validated configuration.</p> <code>create_all</code> <p>Create complete processing pipeline with aggregation and indicators.</p> <code>create_indicators</code> <p>Create indicators component from validated configuration.</p> <code>get_asset_class_config</code> <p>Get default configuration for specific asset class.</p> <code>get_supported_asset_classes</code> <p>Get list of supported asset classes.</p> <code>get_supported_timeframes</code> <p>Get list of all supported timeframes in chronological order.</p> <code>get_timeframe_metadata</code> <p>Get detailed metadata for a specific timeframe.</p>"},{"location":"reference/thestrat/factory/#thestrat.factory.Factory.create_aggregation","title":"create_aggregation  <code>staticmethod</code>","text":"<pre><code>create_aggregation(config: AggregationConfig) -&gt; Aggregation\n</code></pre> <p>Create aggregation component from validated configuration.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>AggregationConfig</code> <p>Validated AggregationConfig containing: - <code>target_timeframes</code>: Target timeframes list (e.g., [\"1H\", \"5m\", \"1D\"]) - <code>asset_class</code>: Asset class type (crypto, equities, fx, futures, commodities) - <code>timezone</code>: Timezone override (UTC asset classes always use UTC;            non-UTC uses priority: specified &gt; system &gt; asset_class default) - <code>hour_boundary</code>: Align to hour boundaries (auto-determined if None) - <code>session_start</code>: Session start time (asset class default if None)</p> required <p>Returns:</p> Type Description <code>Aggregation</code> <p>Configured Aggregation component</p> Example <p>from thestrat.schemas import AggregationConfig config = AggregationConfig( ...     target_timeframes=[\"5m\", \"1H\"], ...     asset_class=\"crypto\", ...     timezone=\"UTC\" ... ) aggregation = Factory.create_aggregation(config)</p> Source code in <code>thestrat/factory.py</code> <pre><code>@staticmethod\ndef create_aggregation(config: AggregationConfig) -&gt; Aggregation:\n    \"\"\"\n    Create aggregation component from validated configuration.\n\n    Args:\n        config: Validated AggregationConfig containing:\n            - `target_timeframes`: Target timeframes list (e.g., [\"1H\", \"5m\", \"1D\"])\n            - `asset_class`: Asset class type (crypto, equities, fx, futures, commodities)\n            - `timezone`: Timezone override (UTC asset classes always use UTC;\n                       non-UTC uses priority: specified &gt; system &gt; asset_class default)\n            - `hour_boundary`: Align to hour boundaries (auto-determined if None)\n            - `session_start`: Session start time (asset class default if None)\n\n    Returns:\n        Configured Aggregation component\n\n    Example:\n        &gt;&gt;&gt; from thestrat.schemas import AggregationConfig\n        &gt;&gt;&gt; config = AggregationConfig(\n        ...     target_timeframes=[\"5m\", \"1H\"],\n        ...     asset_class=\"crypto\",\n        ...     timezone=\"UTC\"\n        ... )\n        &gt;&gt;&gt; aggregation = Factory.create_aggregation(config)\n    \"\"\"\n    return Aggregation(config)\n</code></pre>"},{"location":"reference/thestrat/factory/#thestrat.factory.Factory.create_all","title":"create_all  <code>classmethod</code>","text":"<pre><code>create_all(config: FactoryConfig) -&gt; ComponentDict\n</code></pre> <p>Create complete processing pipeline with aggregation and indicators.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>FactoryConfig</code> <p>Validated FactoryConfig containing: <code>aggregation</code>: AggregationConfig with target timeframes and settings <code>indicators</code>: IndicatorsConfig with per-timeframe configurations</p> required <p>Returns:</p> Type Description <code>ComponentDict</code> <p>Dictionary containing created components:</p> <code>ComponentDict</code> <p>{ \"aggregation\": Aggregation, \"indicators\": Indicators</p> <code>ComponentDict</code> <p>}</p> Example <p>from thestrat.schemas import FactoryConfig, AggregationConfig, IndicatorsConfig, TimeframeItemConfig config = FactoryConfig( ...     aggregation=AggregationConfig(target_timeframes=[\"5m\"]), ...     indicators=IndicatorsConfig( ...         timeframe_configs=[TimeframeItemConfig(timeframes=[\"all\"])] ...     ) ... ) components = Factory.create_all(config)</p> Source code in <code>thestrat/factory.py</code> <pre><code>@classmethod\ndef create_all(cls, config: FactoryConfig) -&gt; ComponentDict:\n    \"\"\"\n    Create complete processing pipeline with aggregation and indicators.\n\n    Args:\n        config: Validated FactoryConfig containing:\n            `aggregation`: AggregationConfig with target timeframes and settings\n            `indicators`: IndicatorsConfig with per-timeframe configurations\n\n    Returns:\n        Dictionary containing created components:\n        {\n            \"aggregation\": Aggregation,\n            \"indicators\": Indicators\n        }\n\n    Example:\n        &gt;&gt;&gt; from thestrat.schemas import FactoryConfig, AggregationConfig, IndicatorsConfig, TimeframeItemConfig\n        &gt;&gt;&gt; config = FactoryConfig(\n        ...     aggregation=AggregationConfig(target_timeframes=[\"5m\"]),\n        ...     indicators=IndicatorsConfig(\n        ...         timeframe_configs=[TimeframeItemConfig(timeframes=[\"all\"])]\n        ...     )\n        ... )\n        &gt;&gt;&gt; components = Factory.create_all(config)\n    \"\"\"\n    return {\n        \"aggregation\": cls.create_aggregation(config.aggregation),\n        \"indicators\": cls.create_indicators(config.indicators),\n    }\n</code></pre>"},{"location":"reference/thestrat/factory/#thestrat.factory.Factory.create_indicators","title":"create_indicators  <code>staticmethod</code>","text":"<pre><code>create_indicators(config: IndicatorsConfig) -&gt; Indicators\n</code></pre> <p>Create indicators component from validated configuration.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>IndicatorsConfig</code> <p>Validated IndicatorsConfig containing per-timeframe configurations using Pydantic models</p> required <p>Returns:</p> Type Description <code>Indicators</code> <p>Configured Indicators component</p> Example <p>from thestrat.schemas import IndicatorsConfig, TimeframeItemConfig, SwingPointsConfig config = IndicatorsConfig( ...     timeframe_configs=[ ...         TimeframeItemConfig( ...             timeframes=[\"5m\", \"15m\"], ...             swing_points=SwingPointsConfig(window=7, threshold=3.0) ...         ) ...     ] ... ) indicators = Factory.create_indicators(config)</p> Source code in <code>thestrat/factory.py</code> <pre><code>@staticmethod\ndef create_indicators(config: IndicatorsConfig) -&gt; Indicators:\n    \"\"\"\n    Create indicators component from validated configuration.\n\n    Args:\n        config: Validated IndicatorsConfig containing per-timeframe configurations\n            using Pydantic models\n\n    Returns:\n        Configured Indicators component\n\n    Example:\n        &gt;&gt;&gt; from thestrat.schemas import IndicatorsConfig, TimeframeItemConfig, SwingPointsConfig\n        &gt;&gt;&gt; config = IndicatorsConfig(\n        ...     timeframe_configs=[\n        ...         TimeframeItemConfig(\n        ...             timeframes=[\"5m\", \"15m\"],\n        ...             swing_points=SwingPointsConfig(window=7, threshold=3.0)\n        ...         )\n        ...     ]\n        ... )\n        &gt;&gt;&gt; indicators = Factory.create_indicators(config)\n    \"\"\"\n    return Indicators(config)\n</code></pre>"},{"location":"reference/thestrat/factory/#thestrat.factory.Factory.get_asset_class_config","title":"get_asset_class_config  <code>staticmethod</code>","text":"<pre><code>get_asset_class_config(asset_class: str) -&gt; dict[str, Any]\n</code></pre> <p>Get default configuration for specific asset class.</p> <p>Parameters:</p> Name Type Description Default <code>asset_class</code> <code>str</code> <p>Asset class type</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary with default <code>timezone</code> and <code>session_start</code></p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If asset_class is not supported</p> Source code in <code>thestrat/factory.py</code> <pre><code>@staticmethod\ndef get_asset_class_config(asset_class: str) -&gt; dict[str, Any]:\n    \"\"\"\n    Get default configuration for specific asset class.\n\n    Args:\n        asset_class: Asset class type\n\n    Returns:\n        Dictionary with default `timezone` and `session_start`\n\n    Raises:\n        ValueError: If asset_class is not supported\n    \"\"\"\n    from .schemas import AssetClassConfig\n\n    if asset_class not in Factory.get_supported_asset_classes():\n        raise ValueError(f\"Unsupported asset class: {asset_class}\")\n\n    return AssetClassConfig.REGISTRY[asset_class].model_dump()\n</code></pre>"},{"location":"reference/thestrat/factory/#thestrat.factory.Factory.get_supported_asset_classes","title":"get_supported_asset_classes  <code>staticmethod</code>","text":"<pre><code>get_supported_asset_classes() -&gt; list[str]\n</code></pre> <p>Get list of supported asset classes.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of supported asset class strings</p> Source code in <code>thestrat/factory.py</code> <pre><code>@staticmethod\ndef get_supported_asset_classes() -&gt; list[str]:\n    \"\"\"\n    Get list of supported asset classes.\n\n    Returns:\n        List of supported asset class strings\n    \"\"\"\n    from .schemas import AssetClassConfig\n\n    return list(AssetClassConfig.REGISTRY.keys())\n</code></pre>"},{"location":"reference/thestrat/factory/#thestrat.factory.Factory.get_supported_timeframes","title":"get_supported_timeframes  <code>cached</code> <code>staticmethod</code>","text":"<pre><code>get_supported_timeframes() -&gt; list[str]\n</code></pre> <p>Get list of all supported timeframes in chronological order.</p> <p>Returns a chronologically ordered list of timeframe strings that can be used with the aggregation and indicators components. These timeframes are validated when creating configurations.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>Chronologically ordered list of supported timeframe strings (shortest to longest)</p> Example <p>from thestrat import Factory timeframes = Factory.get_supported_timeframes() print(timeframes) ['1min', '5min', '15min', '30min', '1h', '4h', '6h', '12h', '1d', '1w', '1m', '1q', '1y']</p> Note <p>The timeframes are ordered by duration (shortest to longest) and follow standard conventions: - Minutes: <code>1min</code>, <code>5min</code>, <code>15min</code>, <code>30min</code> - Hours: <code>1h</code>, <code>4h</code>, <code>6h</code>, <code>12h</code> - Days/Weeks/Months: <code>1d</code>, <code>1w</code>, <code>1m</code> (month), <code>1q</code> (quarter), <code>1y</code></p> Source code in <code>thestrat/factory.py</code> <pre><code>@staticmethod\n@lru_cache(maxsize=1)\ndef get_supported_timeframes() -&gt; list[str]:\n    \"\"\"\n    Get list of all supported timeframes in chronological order.\n\n    Returns a chronologically ordered list of timeframe strings that can be used with\n    the aggregation and indicators components. These timeframes are\n    validated when creating configurations.\n\n    Returns:\n        Chronologically ordered list of supported timeframe strings (shortest to longest)\n\n    Example:\n        &gt;&gt;&gt; from thestrat import Factory\n        &gt;&gt;&gt; timeframes = Factory.get_supported_timeframes()\n        &gt;&gt;&gt; print(timeframes)\n        ['1min', '5min', '15min', '30min', '1h', '4h', '6h', '12h', '1d', '1w', '1m', '1q', '1y']\n\n        &gt;&gt;&gt; # Use in configuration\n        &gt;&gt;&gt; from thestrat.schemas import AggregationConfig\n        &gt;&gt;&gt; available_timeframes = Factory.get_supported_timeframes()\n        &gt;&gt;&gt; config = AggregationConfig(\n        ...     target_timeframes=[available_timeframes[0], available_timeframes[1]],\n        ...     asset_class=\"equities\"\n        ... )\n\n    Note:\n        The timeframes are ordered by duration (shortest to longest) and follow standard conventions:\n        - Minutes: `1min`, `5min`, `15min`, `30min`\n        - Hours: `1h`, `4h`, `6h`, `12h`\n        - Days/Weeks/Months: `1d`, `1w`, `1m` (month), `1q` (quarter), `1y`\n    \"\"\"\n    from .schemas import TimeframeConfig\n\n    # Pre-compute timeframes with their durations for efficient sorting\n    timeframes_with_duration = [\n        (tf, TimeframeConfig.TIMEFRAME_METADATA.get(tf, {}).get(\"seconds\", float(\"inf\")))\n        for tf in TimeframeConfig.TIMEFRAME_METADATA.keys()\n    ]\n\n    # Sort by duration and return just the timeframe strings\n    return [tf for tf, _ in sorted(timeframes_with_duration, key=lambda x: x[1])]\n</code></pre>"},{"location":"reference/thestrat/factory/#thestrat.factory.Factory.get_supported_timeframes--use-in-configuration","title":"Use in configuration","text":"<p>from thestrat.schemas import AggregationConfig available_timeframes = Factory.get_supported_timeframes() config = AggregationConfig( ...     target_timeframes=[available_timeframes[0], available_timeframes[1]], ...     asset_class=\"equities\" ... )</p>"},{"location":"reference/thestrat/factory/#thestrat.factory.Factory.get_timeframe_metadata","title":"get_timeframe_metadata  <code>staticmethod</code>","text":"<pre><code>get_timeframe_metadata(timeframe: str) -&gt; dict[str, Any]\n</code></pre> <p>Get detailed metadata for a specific timeframe.</p> <p>Provides comprehensive information about a timeframe including its category, duration in seconds, description, and typical use cases. This is useful for understanding the characteristics and appropriate applications of different timeframes.</p> <p>Parameters:</p> Name Type Description Default <code>timeframe</code> <code>str</code> <p>Timeframe string to get metadata for (e.g., \"5min\", \"1h\", \"1d\")</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary containing:</p> <code>dict[str, Any]</code> <ul> <li><code>category</code>: Timeframe category (e.g., \"sub-hourly\", \"hourly\", \"daily\")</li> </ul> <code>dict[str, Any]</code> <ul> <li><code>seconds</code>: Duration in seconds</li> </ul> <code>dict[str, Any]</code> <ul> <li><code>description</code>: Human-readable description</li> </ul> <code>dict[str, Any]</code> <ul> <li><code>typical_use</code>: Common use cases for this timeframe</li> </ul> <code>dict[str, Any]</code> <ul> <li><code>data_volume</code>: Expected data volume level</li> </ul> <p>Raises:</p> Type Description <code>ValueError</code> <p>If timeframe is not supported</p> Example <p>from thestrat import Factory metadata = Factory.get_timeframe_metadata(\"1h\") print(metadata) {     'category': 'hourly',     'seconds': 3600,     'description': '1-hour bars for daily structure analysis',     'typical_use': 'Day trading context, hourly levels',     'data_volume': 'low' }</p> See Also <ul> <li>:meth:<code>get_supported_timeframes</code>: Get list of all supported timeframes</li> <li>:meth:<code>validate_timeframe_format</code>: Validate a timeframe string</li> </ul> Source code in <code>thestrat/factory.py</code> <pre><code>@staticmethod\ndef get_timeframe_metadata(timeframe: str) -&gt; dict[str, Any]:\n    \"\"\"\n    Get detailed metadata for a specific timeframe.\n\n    Provides comprehensive information about a timeframe including its\n    category, duration in seconds, description, and typical use cases.\n    This is useful for understanding the characteristics and appropriate\n    applications of different timeframes.\n\n    Args:\n        timeframe: Timeframe string to get metadata for (e.g., \"5min\", \"1h\", \"1d\")\n\n    Returns:\n        Dictionary containing:\n        - `category`: Timeframe category (e.g., \"sub-hourly\", \"hourly\", \"daily\")\n        - `seconds`: Duration in seconds\n        - `description`: Human-readable description\n        - `typical_use`: Common use cases for this timeframe\n        - `data_volume`: Expected data volume level\n\n    Raises:\n        ValueError: If timeframe is not supported\n\n    Example:\n        &gt;&gt;&gt; from thestrat import Factory\n        &gt;&gt;&gt; metadata = Factory.get_timeframe_metadata(\"1h\")\n        &gt;&gt;&gt; print(metadata)\n        {\n            'category': 'hourly',\n            'seconds': 3600,\n            'description': '1-hour bars for daily structure analysis',\n            'typical_use': 'Day trading context, hourly levels',\n            'data_volume': 'low'\n        }\n\n        &gt;&gt;&gt; # Check if a timeframe is suitable for day trading\n        &gt;&gt;&gt; metadata = Factory.get_timeframe_metadata(\"5min\")\n        &gt;&gt;&gt; if \"day trading\" in metadata[\"typical_use\"].lower():\n        ...     print(f\"5min is suitable for day trading\")\n\n        &gt;&gt;&gt; # Get all intraday timeframes\n        &gt;&gt;&gt; all_timeframes = Factory.get_supported_timeframes()\n        &gt;&gt;&gt; intraday = []\n        &gt;&gt;&gt; for tf in all_timeframes:\n        ...     meta = Factory.get_timeframe_metadata(tf)\n        ...     if meta[\"category\"] in [\"sub-hourly\", \"hourly\"]:\n        ...         intraday.append(tf)\n\n    See Also:\n        - :meth:`get_supported_timeframes`: Get list of all supported timeframes\n        - :meth:`validate_timeframe_format`: Validate a timeframe string\n    \"\"\"\n    # Use cached helper method to get metadata efficiently\n    metadata = Factory._get_cached_timeframe_metadata(timeframe)\n    return metadata.copy()  # Return a copy to prevent modification\n</code></pre>"},{"location":"reference/thestrat/factory/#thestrat.factory.Factory.get_timeframe_metadata--check-if-a-timeframe-is-suitable-for-day-trading","title":"Check if a timeframe is suitable for day trading","text":"<p>metadata = Factory.get_timeframe_metadata(\"5min\") if \"day trading\" in metadata[\"typical_use\"].lower(): ...     print(f\"5min is suitable for day trading\")</p>"},{"location":"reference/thestrat/factory/#thestrat.factory.Factory.get_timeframe_metadata--get-all-intraday-timeframes","title":"Get all intraday timeframes","text":"<p>all_timeframes = Factory.get_supported_timeframes() intraday = [] for tf in all_timeframes: ...     meta = Factory.get_timeframe_metadata(tf) ...     if meta[\"category\"] in [\"sub-hourly\", \"hourly\"]: ...         intraday.append(tf)</p>"},{"location":"reference/thestrat/indicators/","title":"Indicators","text":"<p>TheStrat technical indicators</p> <p>Vectorized Strat technical indicators implementation.</p> <p>This module provides comprehensive Strat pattern analysis with high-performance vectorized calculations using Polars operations.</p> <p>Classes:</p> Name Description <code>Indicators</code> <p>Vectorized implementation of all Strat technical indicators.</p>"},{"location":"reference/thestrat/indicators/#thestrat.indicators.Indicators","title":"Indicators","text":"<pre><code>Indicators(config: IndicatorsConfig)\n</code></pre> <p>               Bases: <code>Component</code></p> <p>Vectorized implementation of all Strat technical indicators.</p> <p>Provides comprehensive technical analysis including swing point detection, market structure analysis, pattern recognition, and gap detection optimized for TheStrat methodology.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>IndicatorsConfig</code> <p>Validated IndicatorsConfig containing per-timeframe configurations</p> required <p>Methods:</p> Name Description <code>process</code> <p>Calculate all Strat indicators for OHLC data.</p> <code>validate_input</code> <p>Validate input data format.</p> Source code in <code>thestrat/indicators.py</code> <pre><code>def __init__(self, config: IndicatorsConfig):\n    \"\"\"\n    Initialize indicators component with validated configuration.\n\n    Args:\n        config: Validated IndicatorsConfig containing per-timeframe configurations\n    \"\"\"\n    super().__init__()\n\n    # Store the validated Pydantic config\n    self.config = config\n</code></pre>"},{"location":"reference/thestrat/indicators/#thestrat.indicators.Indicators.process","title":"process","text":"<pre><code>process(data: DataFrame | DataFrame) -&gt; DataFrame\n</code></pre> <p>Calculate all Strat indicators for OHLC data.</p> <p>Performs comprehensive technical analysis including swing point detection, market structure analysis, pattern recognition, and gap detection. Calculations run sequentially due to data dependencies between indicators.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | DataFrame</code> <p>Input DataFrame with OHLC data</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with all Strat indicators added</p> Source code in <code>thestrat/indicators.py</code> <pre><code>def process(self, data: PolarsDataFrame | PandasDataFrame) -&gt; PolarsDataFrame:\n    \"\"\"\n    Calculate all Strat indicators for OHLC data.\n\n    Performs comprehensive technical analysis including swing point detection, market structure\n    analysis, pattern recognition, and gap detection. Calculations run sequentially due to\n    data dependencies between indicators.\n\n    Args:\n        data: Input DataFrame with OHLC data\n\n    Returns:\n        DataFrame with all Strat indicators added\n    \"\"\"\n    self.validate_input(data)\n\n    # Convert to Polars if needed\n    df = self._convert_to_polars(data)\n\n    # Check if data has timeframe column for per-timeframe processing\n    if \"timeframe\" in df.columns:\n        # Check if \"all\" timeframe is configured\n        has_all_config = any(\"all\" in tf_config.timeframes for tf_config in self.config.timeframe_configs)\n\n        if has_all_config:\n            # Process all data with the \"all\" configuration\n            all_config = self._get_config_for_timeframe(\"any_timeframe_will_get_all_config\")\n            df = self._process_single_timeframe(df, all_config)\n        else:\n            # Process each timeframe group with its specific configuration\n            timeframe_groups = df.partition_by(\"timeframe\", as_dict=True)\n            processed_groups = []\n\n            for timeframe_key, timeframe_data in timeframe_groups.items():\n                # Extract timeframe string from tuple key\n                timeframe = timeframe_key[0] if isinstance(timeframe_key, tuple) else timeframe_key\n\n                # Get config for this timeframe\n                tf_config = self._get_config_for_timeframe(timeframe)\n\n                # Process this timeframe with its specific config\n                processed_data = self._process_single_timeframe(timeframe_data, tf_config)\n                processed_groups.append(processed_data)\n\n            # Combine all processed groups\n            df = processed_groups[0]\n            for group in processed_groups[1:]:\n                df = df.vstack(group)\n\n            # Sort by original order (symbol, timeframe, timestamp)\n            sort_cols = []\n            if \"symbol\" in df.columns:\n                sort_cols.append(\"symbol\")\n            sort_cols.extend([\"timeframe\", \"timestamp\"])\n            df = df.sort(sort_cols)\n    else:\n        # No timeframe column - must have \"all\" configuration\n        has_all_config = any(\"all\" in tf_config.timeframes for tf_config in self.config.timeframe_configs)\n        if not has_all_config:\n            raise ValueError(\"Data without timeframe column requires an 'all' timeframe configuration.\")\n\n        all_config = self._get_config_for_timeframe(\"any_timeframe_will_get_all_config\")\n        df = self._process_single_timeframe(df, all_config)\n\n    return df\n</code></pre>"},{"location":"reference/thestrat/indicators/#thestrat.indicators.Indicators.validate_input","title":"validate_input","text":"<pre><code>validate_input(data: DataFrame | DataFrame) -&gt; None\n</code></pre> <p>Validate input data format.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If data format is invalid, with specific error message</p> Source code in <code>thestrat/indicators.py</code> <pre><code>def validate_input(self, data: PolarsDataFrame | PandasDataFrame) -&gt; None:\n    \"\"\"\n    Validate input data format.\n\n    Raises:\n        ValueError: If data format is invalid, with specific error message\n    \"\"\"\n    df = self._convert_to_polars(data)\n\n    # Check required columns\n    required_cols = [\"timestamp\", \"open\", \"high\", \"low\", \"close\"]\n    missing_cols = [col for col in required_cols if col not in df.columns]\n    if missing_cols:\n        raise ValueError(f\"Missing required columns: {missing_cols}\")\n\n    # Get minimum swing window from any configuration\n    min_swing_window = 5  # default\n    for tf_config in self.config.timeframe_configs:\n        swing_config = tf_config.swing_points\n        if swing_config is not None:\n            window = swing_config.window\n            min_swing_window = min(min_swing_window, window)\n\n    # Check for minimum data points for swing analysis\n    if len(df) &lt; min_swing_window * 2:\n        raise ValueError(\n            f\"Insufficient data: {len(df)} rows provided, need at least {min_swing_window * 2} rows \"\n            f\"for swing analysis with window={min_swing_window}\"\n        )\n\n    # Verify price data integrity\n    validations = df.select(\n        [\n            (col(\"high\") &gt;= col(\"low\")).all().alias(\"high_gte_low\"),\n            (col(\"high\") &gt;= col(\"open\")).all().alias(\"high_gte_open\"),\n            (col(\"high\") &gt;= col(\"close\")).all().alias(\"high_gte_close\"),\n            (col(\"low\") &lt;= col(\"open\")).all().alias(\"low_lte_open\"),\n            (col(\"low\") &lt;= col(\"close\")).all().alias(\"low_lte_close\"),\n        ]\n    )\n\n    validation_results = validations.to_numpy().flatten()\n    validation_names = [\"high &gt;= low\", \"high &gt;= open\", \"high &gt;= close\", \"low &lt;= open\", \"low &lt;= close\"]\n\n    failed_validations = [\n        name for name, result in zip(validation_names, validation_results, strict=False) if not result\n    ]\n    if failed_validations:\n        raise ValueError(f\"Invalid price data: failed validations: {failed_validations}\")\n</code></pre>"},{"location":"reference/thestrat/schemas/","title":"Schemas","text":"<p>Pydantic configuration schemas</p> <p>Pydantic schema models for TheStrat configuration validation.</p> <p>This module provides comprehensive validation schemas that replace all manual validation logic in the Factory class. Models use Pydantic v2 features for maximum performance, type safety, and detailed error reporting.</p> <p>Classes:</p> Name Description <code>AggregationConfig</code> <p>Complete configuration for aggregation component with market-aware settings.</p> <code>AssetClassConfig</code> <p>Configuration for a specific asset class with comprehensive market metadata.</p> <code>FactoryConfig</code> <p>Root configuration for Factory.create_all method with complete pipeline setup.</p> <code>GapDetectionConfig</code> <p>Configuration for gap detection with comprehensive threshold documentation.</p> <code>IndicatorSchema</code> <p>Complete Indicator Schema</p> <code>IndicatorsConfig</code> <p>Complete configuration for indicators component with per-timeframe settings.</p> <code>SchemaDocGenerator</code> <p>Generate comprehensive documentation from Pydantic schemas.</p> <code>SwingPointsConfig</code> <p>Configuration for swing point detection with comprehensive parameter documentation.</p> <code>TimeframeConfig</code> <p>Configuration and validation for timeframes with comprehensive metadata.</p> <code>TimeframeItemConfig</code> <p>Configuration for a single timeframe item with flexible timeframe targeting.</p>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.AggregationConfig","title":"AggregationConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Complete configuration for aggregation component with market-aware settings.</p> <p>Methods:</p> Name Description <code>apply_asset_class_defaults</code> <p>Apply AssetClassConfig defaults for timezone, hour_boundary, and session_start.</p> <code>validate_and_expand_target_timeframes</code> <p>Validate target_timeframes field and expand 'all' keyword.</p>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.AggregationConfig.apply_asset_class_defaults","title":"apply_asset_class_defaults  <code>classmethod</code>","text":"<pre><code>apply_asset_class_defaults(data: Any) -&gt; Any\n</code></pre> <p>Apply AssetClassConfig defaults for timezone, hour_boundary, and session_start.</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@model_validator(mode=\"before\")\n@classmethod\ndef apply_asset_class_defaults(cls, data: Any) -&gt; Any:\n    \"\"\"Apply AssetClassConfig defaults for timezone, hour_boundary, and session_start.\"\"\"\n    if not isinstance(data, dict):\n        return data\n\n    # Get asset class, default to \"equities\"\n    asset_class = data.get(\"asset_class\", \"equities\")\n    asset_config = AssetClassConfig.get_config(asset_class)\n\n    # Force UTC timezone for crypto and fx regardless of input\n    if asset_class in [\"crypto\", \"fx\"]:\n        data[\"timezone\"] = \"UTC\"\n    elif \"timezone\" not in data or data[\"timezone\"] is None:\n        data[\"timezone\"] = asset_config.timezone\n\n    # Apply other defaults only if fields are not provided or are None\n    if \"hour_boundary\" not in data or data[\"hour_boundary\"] is None:\n        data[\"hour_boundary\"] = asset_config.hour_boundary\n    if \"session_start\" not in data or data[\"session_start\"] is None:\n        data[\"session_start\"] = asset_config.session_start\n\n    return data\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.AggregationConfig.validate_and_expand_target_timeframes","title":"validate_and_expand_target_timeframes  <code>classmethod</code>","text":"<pre><code>validate_and_expand_target_timeframes(\n    target_timeframes: list[str],\n) -&gt; list[str]\n</code></pre> <p>Validate target_timeframes field and expand 'all' keyword.</p> <p>This Pydantic field validator is automatically called when AggregationConfig is instantiated. It validates individual timeframes and expands ['all'] to all supported timeframes.</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@field_validator(\"target_timeframes\")\n@classmethod\ndef validate_and_expand_target_timeframes(cls, target_timeframes: list[str]) -&gt; list[str]:\n    \"\"\"\n    Validate target_timeframes field and expand 'all' keyword.\n\n    This Pydantic field validator is automatically called when AggregationConfig\n    is instantiated. It validates individual timeframes and expands ['all'] to\n    all supported timeframes.\n    \"\"\"\n    if not target_timeframes:\n        raise ValueError(\"target_timeframes cannot be empty\")\n\n    # Check for 'all' keyword\n    if \"all\" in target_timeframes:\n        if len(target_timeframes) &gt; 1:\n            raise ValueError(\"'all' cannot be combined with specific timeframes\")\n        # Expand to all supported timeframes\n        return list(TimeframeConfig.TIMEFRAME_METADATA.keys())\n\n    # Validate each specific timeframe\n    for i, timeframe in enumerate(target_timeframes):\n        if not isinstance(timeframe, str) or not timeframe.strip():\n            raise ValueError(f\"target_timeframes[{i}] must be a non-empty string\")\n\n        # Validate timeframe format using TimeframeConfig\n        if not TimeframeConfig.validate_timeframe(timeframe):\n            raise ValueError(f\"Invalid timeframe '{timeframe}'\")\n\n    return target_timeframes\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.AssetClassConfig","title":"AssetClassConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for a specific asset class with comprehensive market metadata.</p> <p>Methods:</p> Name Description <code>get_config</code> <p>Get configuration for specific asset class.</p>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.AssetClassConfig.get_config","title":"get_config  <code>classmethod</code>","text":"<pre><code>get_config(asset_class: str) -&gt; AssetClassConfig\n</code></pre> <p>Get configuration for specific asset class.</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_config(cls, asset_class: str) -&gt; \"AssetClassConfig\":\n    \"\"\"Get configuration for specific asset class.\"\"\"\n    return cls.REGISTRY.get(asset_class, cls.REGISTRY[\"equities\"])\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.FactoryConfig","title":"FactoryConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Root configuration for Factory.create_all method with complete pipeline setup.</p> <p>Methods:</p> Name Description <code>validate_configuration_consistency</code> <p>Validate consistency between aggregation and indicators configurations.</p>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.FactoryConfig.validate_configuration_consistency","title":"validate_configuration_consistency","text":"<pre><code>validate_configuration_consistency() -&gt; Self\n</code></pre> <p>Validate consistency between aggregation and indicators configurations.</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@model_validator(mode=\"after\")\ndef validate_configuration_consistency(self) -&gt; Self:\n    \"\"\"Validate consistency between aggregation and indicators configurations.\"\"\"\n    # Future enhancement: Could validate that indicator timeframes are compatible\n    # with aggregation target timeframes, but this is not currently enforced\n    # in the existing system\n    return self\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.GapDetectionConfig","title":"GapDetectionConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for gap detection with comprehensive threshold documentation.</p>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.IndicatorSchema","title":"IndicatorSchema","text":"<p>               Bases: <code>BaseModel</code></p> <p>Complete Indicator Schema</p> <p>Defines all columns that are created by TheStrat processing pipeline. All columns are required as the indicators component creates them all.</p> <p>Methods:</p> Name Description <code>get_all_input_columns</code> <p>Get list of all input columns (required + optional).</p> <code>get_column_categories</code> <p>Get columns organized by functional categories.</p> <code>get_column_descriptions</code> <p>Get descriptions for all possible DataFrame columns.</p> <code>get_optional_input_columns</code> <p>Get list of optional input columns based on schema definition.</p> <code>get_polars_dtypes</code> <p>Get Polars data types for all DataFrame columns.</p> <code>get_required_input_columns</code> <p>Get list of required input columns based on schema definition.</p> <code>validate_dataframe</code> <p>Validate input DataFrame columns and data types against IndicatorSchema input requirements.</p>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.IndicatorSchema.get_all_input_columns","title":"get_all_input_columns  <code>classmethod</code>","text":"<pre><code>get_all_input_columns() -&gt; list[str]\n</code></pre> <p>Get list of all input columns (required + optional).</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of all input column names</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_all_input_columns(cls) -&gt; list[str]:\n    \"\"\"\n    Get list of all input columns (required + optional).\n\n    Returns:\n        List of all input column names\n    \"\"\"\n    return sorted(cls.get_required_input_columns() + cls.get_optional_input_columns())\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.IndicatorSchema.get_column_categories","title":"get_column_categories  <code>classmethod</code>","text":"<pre><code>get_column_categories() -&gt; dict[str, list[str]]\n</code></pre> <p>Get columns organized by functional categories.</p> <p>Dynamically extracts categories from the IndicatorSchema metadata.</p> <p>Returns:</p> Type Description <code>dict[str, list[str]]</code> <p>Dictionary mapping category names to lists of column names</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_column_categories(cls) -&gt; dict[str, list[str]]:\n    \"\"\"\n    Get columns organized by functional categories.\n\n    Dynamically extracts categories from the IndicatorSchema metadata.\n\n    Returns:\n        Dictionary mapping category names to lists of column names\n    \"\"\"\n    categories: dict[str, list[str]] = {}\n\n    for field_name, field_info in cls.model_fields.items():\n        json_extra = getattr(field_info, \"json_schema_extra\", {})\n        if isinstance(json_extra, dict) and \"category\" in json_extra:\n            category = json_extra[\"category\"]\n            if category not in categories:\n                categories[category] = []\n            categories[category].append(field_name)\n\n    # Sort columns within each category for consistent output\n    for category in categories:\n        categories[category].sort()\n\n    return categories\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.IndicatorSchema.get_column_descriptions","title":"get_column_descriptions  <code>classmethod</code>","text":"<pre><code>get_column_descriptions() -&gt; dict[str, str]\n</code></pre> <p>Get descriptions for all possible DataFrame columns.</p> <p>Returns:</p> Type Description <code>dict[str, str]</code> <p>Dictionary mapping column names to their descriptions</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_column_descriptions(cls) -&gt; dict[str, str]:\n    \"\"\"\n    Get descriptions for all possible DataFrame columns.\n\n    Returns:\n        Dictionary mapping column names to their descriptions\n    \"\"\"\n    descriptions = {}\n\n    # Get descriptions from the schema\n    for field_name, field_info in cls.model_fields.items():\n        if field_info.description:\n            descriptions[field_name] = field_info.description\n\n    return descriptions\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.IndicatorSchema.get_optional_input_columns","title":"get_optional_input_columns  <code>classmethod</code>","text":"<pre><code>get_optional_input_columns() -&gt; list[str]\n</code></pre> <p>Get list of optional input columns based on schema definition.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of column names that are optional for input data</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_optional_input_columns(cls) -&gt; list[str]:\n    \"\"\"\n    Get list of optional input columns based on schema definition.\n\n    Returns:\n        List of column names that are optional for input data\n    \"\"\"\n    from pydantic_core import PydanticUndefined\n\n    optional_columns = []\n    for field_name, field_info in cls.model_fields.items():\n        json_extra = getattr(field_info, \"json_schema_extra\", {}) or {}\n        if (\n            json_extra.get(\"input\") is True  # Is an input column\n            and (\n                json_extra.get(\"optional\", False)  # Marked as optional\n                or getattr(field_info, \"default\", PydanticUndefined) is not PydanticUndefined\n            )  # Has default value\n        ):\n            optional_columns.append(field_name)\n    return sorted(optional_columns)\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.IndicatorSchema.get_polars_dtypes","title":"get_polars_dtypes  <code>classmethod</code>","text":"<pre><code>get_polars_dtypes() -&gt; dict[str, Any]\n</code></pre> <p>Get Polars data types for all DataFrame columns.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary mapping column names to their Polars data types</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_polars_dtypes(cls) -&gt; dict[str, Any]:\n    \"\"\"\n    Get Polars data types for all DataFrame columns.\n\n    Returns:\n        Dictionary mapping column names to their Polars data types\n    \"\"\"\n    types = {}\n\n    for field_name, field_info in cls.model_fields.items():\n        json_extra = getattr(field_info, \"json_schema_extra\", {})\n        if isinstance(json_extra, dict) and \"polars_dtype\" in json_extra:\n            types[field_name] = json_extra[\"polars_dtype\"]\n\n    return types\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.IndicatorSchema.get_required_input_columns","title":"get_required_input_columns  <code>classmethod</code>","text":"<pre><code>get_required_input_columns() -&gt; list[str]\n</code></pre> <p>Get list of required input columns based on schema definition.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of column names that are required for input data</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_required_input_columns(cls) -&gt; list[str]:\n    \"\"\"\n    Get list of required input columns based on schema definition.\n\n    Returns:\n        List of column names that are required for input data\n    \"\"\"\n    from pydantic_core import PydanticUndefined\n\n    required_columns = []\n    for field_name, field_info in cls.model_fields.items():\n        json_extra = getattr(field_info, \"json_schema_extra\", {}) or {}\n        if (\n            json_extra.get(\"input\") is True  # Is an input column\n            and not json_extra.get(\"optional\", False)  # Not marked as optional\n            and getattr(field_info, \"default\", PydanticUndefined)\n            is PydanticUndefined  # No default value (required)\n        ):\n            required_columns.append(field_name)\n    return sorted(required_columns)\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.IndicatorSchema.validate_dataframe","title":"validate_dataframe  <code>classmethod</code>","text":"<pre><code>validate_dataframe(df) -&gt; dict[str, Any]\n</code></pre> <p>Validate input DataFrame columns and data types against IndicatorSchema input requirements.</p> <p>Automatically converts Pandas DataFrames to Polars for consistent validation.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <p>Polars or Pandas DataFrame to validate</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary with validation results including missing/extra columns, type issues,</p> <code>dict[str, Any]</code> <p>and the converted Polars DataFrame if conversion occurred</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef validate_dataframe(cls, df) -&gt; dict[str, Any]:\n    \"\"\"\n    Validate input DataFrame columns and data types against IndicatorSchema input requirements.\n\n    Automatically converts Pandas DataFrames to Polars for consistent validation.\n\n    Args:\n        df: Polars or Pandas DataFrame to validate\n\n    Returns:\n        Dictionary with validation results including missing/extra columns, type issues,\n        and the converted Polars DataFrame if conversion occurred\n    \"\"\"\n    import polars as pl\n\n    # Detect DataFrame type and convert if necessary\n    df_type = \"unknown\"\n    converted_df = None\n    conversion_errors = []\n\n    if hasattr(df, \"columns\"):\n        # Check if it's a Pandas DataFrame\n        if hasattr(df, \"dtypes\") and not hasattr(df, \"schema\"):\n            df_type = \"pandas\"\n            try:\n                # Convert Pandas to Polars\n                converted_df = pl.from_pandas(df)\n                df = converted_df  # Use converted DataFrame for validation\n            except Exception as e:\n                conversion_errors.append(f\"Failed to convert Pandas to Polars: {str(e)}\")\n                # Fall back to column-only validation\n                df_columns = list(df.columns)\n                return {\n                    \"valid\": False,\n                    \"conversion_error\": conversion_errors[0],\n                    \"df_type\": df_type,\n                    \"columns\": df_columns,\n                    \"message\": \"Could not convert Pandas DataFrame to Polars for full validation\",\n                }\n        # Check if it's already a Polars DataFrame\n        elif hasattr(df, \"schema\"):\n            df_type = \"polars\"\n        else:\n            raise ValueError(\"Unknown DataFrame type - must be Pandas or Polars DataFrame\")\n\n        df_columns = list(df.columns)\n    else:\n        raise ValueError(\"Input must be a DataFrame with .columns attribute\")\n\n    required_fields = []\n    optional_fields = []\n    expected_types = {}\n\n    # Extract input field requirements from schema\n    for field_name, field_info in cls.model_fields.items():\n        json_extra = getattr(field_info, \"json_schema_extra\", {})\n        if isinstance(json_extra, dict) and json_extra.get(\"input\"):\n            if field_info.is_required():\n                required_fields.append(field_name)\n            else:\n                optional_fields.append(field_name)\n\n            # Store expected Polars type for validation\n            if \"polars_dtype\" in json_extra:\n                expected_types[field_name] = json_extra[\"polars_dtype\"]\n\n    # Check for missing and extra columns\n    missing_required = [col for col in required_fields if col not in df_columns]\n    missing_optional = [col for col in optional_fields if col not in df_columns]\n    extra_columns = [col for col in df_columns if col not in required_fields + optional_fields]\n\n    # Check data types for present columns (now guaranteed to be Polars)\n    type_issues = []\n    if hasattr(df, \"schema\"):  # Polars DataFrame\n        for col_name, expected_type in expected_types.items():\n            if col_name in df_columns:\n                actual_type = df.schema[col_name]\n                if actual_type != expected_type:\n                    type_issues.append(\n                        {\n                            \"column\": col_name,\n                            \"expected\": expected_type.__name__\n                            if hasattr(expected_type, \"__name__\")\n                            else str(expected_type),\n                            \"actual\": str(actual_type),\n                        }\n                    )\n\n    result = {\n        \"valid\": len(missing_required) == 0 and len(type_issues) == 0,\n        \"missing_required\": missing_required,\n        \"missing_optional\": missing_optional,\n        \"extra_columns\": extra_columns,\n        \"type_issues\": type_issues,\n        \"required_fields\": required_fields,\n        \"optional_fields\": optional_fields,\n        \"expected_types\": {k: v.__name__ if hasattr(v, \"__name__\") else str(v) for k, v in expected_types.items()},\n        \"df_type\": df_type,\n    }\n\n    # Include converted DataFrame if conversion occurred\n    if converted_df is not None:\n        result[\"converted_df\"] = converted_df\n        result[\"conversion_performed\"] = True\n    else:\n        result[\"conversion_performed\"] = False\n\n    return result\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.IndicatorsConfig","title":"IndicatorsConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Complete configuration for indicators component with per-timeframe settings.</p>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.SchemaDocGenerator","title":"SchemaDocGenerator","text":"<p>Generate comprehensive documentation from Pydantic schemas.</p> <p>Methods:</p> Name Description <code>export_json_schemas</code> <p>Export JSON schemas for all models (useful for OpenAPI/AsyncAPI generation).</p> <code>generate_all_model_docs</code> <p>Generate documentation for all schema models.</p> <code>generate_complete_documentation</code> <p>Generate complete markdown documentation for all schema models.</p> <code>generate_field_docs</code> <p>Extract comprehensive field documentation from a Pydantic model.</p> <code>generate_json_schema</code> <p>Generate JSON Schema for a Pydantic model with all metadata.</p> <code>generate_markdown_table</code> <p>Generate a markdown table for a Pydantic model's fields.</p>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.SchemaDocGenerator.export_json_schemas","title":"export_json_schemas  <code>staticmethod</code>","text":"<pre><code>export_json_schemas() -&gt; dict[str, dict[str, Any]]\n</code></pre> <p>Export JSON schemas for all models (useful for OpenAPI/AsyncAPI generation).</p> <p>Returns:</p> Type Description <code>dict[str, dict[str, Any]]</code> <p>Dictionary mapping model names to their JSON schemas</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@staticmethod\ndef export_json_schemas() -&gt; dict[str, dict[str, Any]]:\n    \"\"\"\n    Export JSON schemas for all models (useful for OpenAPI/AsyncAPI generation).\n\n    Returns:\n        Dictionary mapping model names to their JSON schemas\n    \"\"\"\n    docs = SchemaDocGenerator.generate_all_model_docs()\n    return {name: doc_info[\"json_schema\"] for name, doc_info in docs.items()}\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.SchemaDocGenerator.generate_all_model_docs","title":"generate_all_model_docs  <code>staticmethod</code>","text":"<pre><code>generate_all_model_docs() -&gt; dict[str, dict[str, Any]]\n</code></pre> <p>Generate documentation for all schema models.</p> <p>Returns:</p> Type Description <code>dict[str, dict[str, Any]]</code> <p>Dictionary mapping model names to their complete documentation</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@staticmethod\ndef generate_all_model_docs() -&gt; dict[str, dict[str, Any]]:\n    \"\"\"\n    Generate documentation for all schema models.\n\n    Returns:\n        Dictionary mapping model names to their complete documentation\n    \"\"\"\n    models = [\n        AssetClassConfig,\n        TimeframeConfig,\n        SwingPointsConfig,\n        GapDetectionConfig,\n        TimeframeItemConfig,\n        IndicatorsConfig,\n        AggregationConfig,\n        FactoryConfig,\n        IndicatorSchema,\n    ]\n\n    all_docs = {}\n    for model in models:\n        all_docs[model.__name__] = {\n            \"class_doc\": model.__doc__,\n            \"field_docs\": SchemaDocGenerator.generate_field_docs(model),\n            \"markdown\": SchemaDocGenerator.generate_markdown_table(model),\n            \"json_schema\": SchemaDocGenerator.generate_json_schema(model),\n        }\n\n    return all_docs\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.SchemaDocGenerator.generate_complete_documentation","title":"generate_complete_documentation  <code>staticmethod</code>","text":"<pre><code>generate_complete_documentation() -&gt; str\n</code></pre> <p>Generate complete markdown documentation for all schema models.</p> <p>Returns:</p> Type Description <code>str</code> <p>Complete markdown documentation string</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@staticmethod\ndef generate_complete_documentation() -&gt; str:\n    \"\"\"\n    Generate complete markdown documentation for all schema models.\n\n    Returns:\n        Complete markdown documentation string\n    \"\"\"\n    docs = SchemaDocGenerator.generate_all_model_docs()\n\n    markdown = \"# TheStrat Schema Documentation\\n\\n\"\n    markdown += \"Auto-generated documentation for all Pydantic configuration models.\\n\\n\"\n    markdown += \"---\\n\\n\"\n\n    for model_docs in docs.values():\n        markdown += model_docs[\"markdown\"] + \"\\n\\n\"\n\n    return markdown\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.SchemaDocGenerator.generate_field_docs","title":"generate_field_docs  <code>staticmethod</code>","text":"<pre><code>generate_field_docs(model: type[BaseModel]) -&gt; dict[str, dict[str, Any]]\n</code></pre> <p>Extract comprehensive field documentation from a Pydantic model.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>type[BaseModel]</code> <p>Pydantic model class to document</p> required <p>Returns:</p> Type Description <code>dict[str, dict[str, Any]]</code> <p>Dictionary mapping field names to their documentation metadata</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@staticmethod\ndef generate_field_docs(model: type[BaseModel]) -&gt; dict[str, dict[str, Any]]:\n    \"\"\"\n    Extract comprehensive field documentation from a Pydantic model.\n\n    Args:\n        model: Pydantic model class to document\n\n    Returns:\n        Dictionary mapping field names to their documentation metadata\n    \"\"\"\n    field_docs = {}\n\n    for field_name, field_info in model.model_fields.items():\n        field_doc = {\n            \"name\": field_name,\n            \"type\": SchemaDocGenerator._get_type_string(field_info.annotation),\n            \"description\": field_info.description or \"No description provided\",\n            \"default\": SchemaDocGenerator._format_default(field_info.default),\n            \"required\": field_info.is_required(),\n            \"examples\": getattr(field_info, \"examples\", []),\n        }\n\n        # Add validation constraints\n        constraints = SchemaDocGenerator._extract_constraints(field_info)\n        if constraints:\n            field_doc[\"constraints\"] = constraints\n\n        # Add json_schema_extra information (convert Polars types to strings)\n        if hasattr(field_info, \"json_schema_extra\") and field_info.json_schema_extra:\n            metadata = field_info.json_schema_extra.copy()\n            # Convert Polars data types to string representations for serialization\n            if \"polars_dtype\" in metadata:\n                polars_type = metadata[\"polars_dtype\"]\n                # Convert Polars type to string representation for JSON serialization\n                try:\n                    metadata[\"polars_dtype\"] = getattr(polars_type, \"__name__\", str(polars_type))\n                except (AttributeError, TypeError):\n                    metadata[\"polars_dtype\"] = str(polars_type)\n            field_doc[\"metadata\"] = metadata\n\n        field_docs[field_name] = field_doc\n\n    return field_docs\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.SchemaDocGenerator.generate_json_schema","title":"generate_json_schema  <code>staticmethod</code>","text":"<pre><code>generate_json_schema(model: type[BaseModel]) -&gt; dict[str, Any]\n</code></pre> <p>Generate JSON Schema for a Pydantic model with all metadata.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>type[BaseModel]</code> <p>Pydantic model class</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>JSON Schema dictionary with enhanced metadata</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@staticmethod\ndef generate_json_schema(model: type[BaseModel]) -&gt; dict[str, Any]:\n    \"\"\"\n    Generate JSON Schema for a Pydantic model with all metadata.\n\n    Args:\n        model: Pydantic model class\n\n    Returns:\n        JSON Schema dictionary with enhanced metadata\n    \"\"\"\n    # Special handling for IndicatorSchema which contains non-serializable Polars types\n    if hasattr(model, \"__name__\") and model.__name__ == \"IndicatorSchema\":\n        # Generate a basic JSON schema structure manually for IndicatorSchema\n        schema = {\n            \"type\": \"object\",\n            \"title\": model.__name__,\n            \"description\": model.__doc__ or f\"Schema for {model.__name__}\",\n            \"properties\": {},\n            \"required\": [],\n        }\n\n        # Add properties from field documentation (which has serializable metadata)\n        field_docs = SchemaDocGenerator.generate_field_docs(model)\n\n        for field_name, field_doc in field_docs.items():\n            prop_schema = {\n                \"type\": SchemaDocGenerator._pydantic_type_to_json_type(field_doc[\"type\"]),\n                \"description\": field_doc[\"description\"],\n            }\n\n            # Add metadata (already converted to strings)\n            if \"metadata\" in field_doc:\n                prop_schema.update(field_doc[\"metadata\"])\n\n            # Add examples if available\n            if field_doc[\"examples\"]:\n                prop_schema[\"examples\"] = field_doc[\"examples\"]\n\n            schema[\"properties\"][field_name] = prop_schema\n\n            # Add to required if field is required\n            if field_doc[\"required\"]:\n                schema[\"required\"].append(field_name)\n\n        return schema\n    else:\n        # Use standard Pydantic JSON schema generation for other models\n        schema = model.model_json_schema()\n\n        # Enhance with field documentation\n        field_docs = SchemaDocGenerator.generate_field_docs(model)\n\n        if \"properties\" in schema:\n            for field_name, field_schema in schema[\"properties\"].items():\n                if field_name in field_docs:\n                    field_doc = field_docs[field_name]\n\n                    # Add examples if available\n                    if field_doc[\"examples\"]:\n                        field_schema[\"examples\"] = field_doc[\"examples\"]\n\n                    # Add metadata (already converted to strings in generate_field_docs)\n                    if \"metadata\" in field_doc:\n                        field_schema.update(field_doc[\"metadata\"])\n\n        return schema\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.SchemaDocGenerator.generate_markdown_table","title":"generate_markdown_table  <code>staticmethod</code>","text":"<pre><code>generate_markdown_table(model: type[BaseModel]) -&gt; str\n</code></pre> <p>Generate a markdown table for a Pydantic model's fields.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>type[BaseModel]</code> <p>Pydantic model class to document</p> required <p>Returns:</p> Type Description <code>str</code> <p>Markdown table string</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@staticmethod\ndef generate_markdown_table(model: type[BaseModel]) -&gt; str:\n    \"\"\"\n    Generate a markdown table for a Pydantic model's fields.\n\n    Args:\n        model: Pydantic model class to document\n\n    Returns:\n        Markdown table string\n    \"\"\"\n    field_docs = SchemaDocGenerator.generate_field_docs(model)\n\n    # Table header\n    markdown = f\"## {model.__name__}\\n\\n\"\n    markdown += f\"{model.__doc__ or 'Configuration model'}\\n\\n\"\n    markdown += \"| Field | Type | Default | Description |\\n\"\n    markdown += \"|-------|------|---------|-------------|\\n\"\n\n    # Table rows\n    for field_name, field_doc in field_docs.items():\n        type_str = field_doc[\"type\"]\n        default_str = field_doc[\"default\"]\n        desc_str = field_doc[\"description\"]\n\n        # Add constraints to description if present\n        if \"constraints\" in field_doc:\n            constraints = field_doc[\"constraints\"]\n            constraint_parts = []\n            if \"min_length\" in constraints:\n                constraint_parts.append(f\"min length: {constraints['min_length']}\")\n            if \"max_length\" in constraints:\n                constraint_parts.append(f\"max length: {constraints['max_length']}\")\n            if \"ge\" in constraints:\n                constraint_parts.append(f\"&gt;= {constraints['ge']}\")\n            if \"le\" in constraints:\n                constraint_parts.append(f\"&lt;= {constraints['le']}\")\n            if \"pattern\" in constraints:\n                constraint_parts.append(f\"pattern: `{constraints['pattern']}`\")\n\n            if constraint_parts:\n                desc_str += f\" ({', '.join(constraint_parts)})\"\n\n        markdown += f\"| `{field_name}` | {type_str} | {default_str} | {desc_str} |\\n\"\n\n    # Add ClassVar information if present\n    classvars = SchemaDocGenerator._get_classvars(model)\n    if classvars:\n        markdown += \"\\n### Class Constants\\n\\n\"\n        for var_name, var_info in classvars.items():\n            markdown += f\"- **`{var_name}`**: {var_info['description']}\\n\"\n            if var_info.get(\"keys\"):\n                markdown += f\"  - Available keys: {', '.join(var_info['keys'])}\\n\"\n\n            # Add detailed configuration tables for registries\n            if var_name == \"REGISTRY\" and var_info.get(\"detailed_configs\"):\n                markdown += \"\\n#### Configured Asset Classes\\n\\n\"\n                for config_name, config_details in var_info[\"detailed_configs\"].items():\n                    markdown += f\"**{config_name}**\\n\"\n                    markdown += f\"- Trading Hours: {config_details.get('trading_hours', 'N/A')}\\n\"\n                    markdown += f\"- Timezone: `{config_details.get('timezone', 'N/A')}`\\n\"\n                    markdown += f\"- Session Start: `{config_details.get('session_start', 'N/A')}`\\n\"\n                    markdown += f\"- Hour Boundary: `{config_details.get('hour_boundary', 'N/A')}`\\n\"\n                    markdown += \"\\n\"\n\n            # Add detailed timeframe metadata tables\n            elif var_name == \"TIMEFRAME_METADATA\" and var_info.get(\"detailed_metadata\"):\n                markdown += \"\\n#### Timeframe Details\\n\\n\"\n                markdown += \"| Timeframe | Category | Duration | Description | Typical Use |\\n\"\n                markdown += \"|-----------|----------|----------|-------------|-------------|\\n\"\n\n                for tf_name, tf_details in var_info[\"detailed_metadata\"].items():\n                    category = tf_details.get(\"category\", \"N/A\")\n                    seconds = tf_details.get(\"seconds\", 0)\n                    description = tf_details.get(\"description\", \"N/A\")\n                    typical_use = tf_details.get(\"typical_use\", \"N/A\")\n\n                    # Convert seconds to readable duration\n                    if seconds &lt; 3600:\n                        duration = f\"{seconds // 60}m\"\n                    elif seconds &lt; 86400:\n                        duration = f\"{seconds // 3600}h\"\n                    elif seconds &lt; 604800:\n                        duration = f\"{seconds // 86400}d\"\n                    else:\n                        duration = f\"{seconds // 604800}w\"\n\n                    markdown += f\"| `{tf_name}` | {category} | {duration} | {description} | {typical_use} |\\n\"\n                markdown += \"\\n\"\n\n    return markdown\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.SwingPointsConfig","title":"SwingPointsConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for swing point detection with comprehensive parameter documentation.</p>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.TimeframeConfig","title":"TimeframeConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration and validation for timeframes with comprehensive metadata.</p> <p>Methods:</p> Name Description <code>get_optimal_source_timeframe</code> <p>Get optimal source timeframe for aggregating to target.</p> <code>get_polars_format</code> <p>Get the Polars format for a timeframe.</p> <code>validate_timeframe</code> <p>Validate that the timeframe is supported (strict mode only).</p>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.TimeframeConfig.get_optimal_source_timeframe","title":"get_optimal_source_timeframe  <code>classmethod</code>","text":"<pre><code>get_optimal_source_timeframe(\n    target_timeframe: str, available_timeframes: list[str]\n) -&gt; str | None\n</code></pre> <p>Get optimal source timeframe for aggregating to target.</p> <p>Parameters:</p> Name Type Description Default <code>target_timeframe</code> <code>str</code> <p>Target timeframe to aggregate to</p> required <code>available_timeframes</code> <code>list[str]</code> <p>List of available source timeframes</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>Optimal source timeframe or None if target already exists or no valid source</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_optimal_source_timeframe(cls, target_timeframe: str, available_timeframes: list[str]) -&gt; str | None:\n    \"\"\"\n    Get optimal source timeframe for aggregating to target.\n\n    Args:\n        target_timeframe: Target timeframe to aggregate to\n        available_timeframes: List of available source timeframes\n\n    Returns:\n        Optimal source timeframe or None if target already exists or no valid source\n    \"\"\"\n    # If target exists, use it directly (pass-through)\n    if target_timeframe in available_timeframes:\n        return target_timeframe\n\n    target_metadata = cls.TIMEFRAME_METADATA.get(target_timeframe)\n    if not target_metadata:\n        return None\n\n    target_seconds = target_metadata[\"seconds\"]\n\n    # Find all mathematically valid sources (those that divide evenly into target)\n    valid_sources = []\n    for source_tf in available_timeframes:\n        source_metadata = cls.TIMEFRAME_METADATA.get(source_tf)\n        if source_metadata:\n            source_seconds = source_metadata[\"seconds\"]\n            if target_seconds % source_seconds == 0:\n                valid_sources.append((source_tf, source_seconds))\n\n    if not valid_sources:\n        return None\n\n    # Return the source with the largest duration (minimize aggregation operations)\n    return max(valid_sources, key=lambda x: x[1])[0]\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.TimeframeConfig.get_polars_format","title":"get_polars_format  <code>classmethod</code>","text":"<pre><code>get_polars_format(timeframe: str) -&gt; str\n</code></pre> <p>Get the Polars format for a timeframe.</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_polars_format(cls, timeframe: str) -&gt; str:\n    \"\"\"Get the Polars format for a timeframe.\"\"\"\n    metadata = cls.TIMEFRAME_METADATA.get(timeframe)\n    if metadata:\n        return metadata.get(\"polars_format\", timeframe)\n    return timeframe\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.TimeframeConfig.validate_timeframe","title":"validate_timeframe  <code>classmethod</code>","text":"<pre><code>validate_timeframe(timeframe: str) -&gt; bool\n</code></pre> <p>Validate that the timeframe is supported (strict mode only).</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef validate_timeframe(cls, timeframe: str) -&gt; bool:\n    \"\"\"Validate that the timeframe is supported (strict mode only).\"\"\"\n    return timeframe in cls.TIMEFRAME_METADATA\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.TimeframeItemConfig","title":"TimeframeItemConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for a single timeframe item with flexible timeframe targeting.</p> <p>Methods:</p> Name Description <code>validate_timeframe_combinations</code> <p>Validate that 'all' is not mixed with specific timeframes.</p>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.TimeframeItemConfig.validate_timeframe_combinations","title":"validate_timeframe_combinations","text":"<pre><code>validate_timeframe_combinations() -&gt; Self\n</code></pre> <p>Validate that 'all' is not mixed with specific timeframes.</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@model_validator(mode=\"after\")\ndef validate_timeframe_combinations(self) -&gt; Self:\n    \"\"\"Validate that 'all' is not mixed with specific timeframes.\"\"\"\n    if \"all\" in self.timeframes and len(self.timeframes) &gt; 1:\n        raise ValueError(\"'all' cannot be combined with specific timeframes\")\n    return self\n</code></pre>"},{"location":"reference/thestrat/signals/","title":"Signals","text":"<p>Signal processing and metadata</p> <p>Signal metadata implementation for TheStrat trading system.</p> <p>This module provides comprehensive signal metadata objects that transform simple pattern strings into rich objects with trading logic, risk management, and change tracking.</p> <p>Classes:</p> Name Description <code>PriceChange</code> <p>Track changes to stop/target prices.</p> <code>SignalBias</code> <p>Signal directional bias.</p> <code>SignalCategory</code> <p>Signal categorization types.</p> <code>SignalMetadata</code> <p>Complete signal metadata with change tracking and serialization.</p> <code>SignalStatus</code> <p>Signal lifecycle status.</p>"},{"location":"reference/thestrat/signals/#thestrat.signals.PriceChange","title":"PriceChange  <code>dataclass</code>","text":"<pre><code>PriceChange(\n    field_name: str,\n    from_value: float,\n    to_value: float,\n    timestamp: datetime,\n    reason: str | None = None,\n)\n</code></pre> <p>Track changes to stop/target prices.</p>"},{"location":"reference/thestrat/signals/#thestrat.signals.SignalBias","title":"SignalBias","text":"<p>               Bases: <code>Enum</code></p> <p>Signal directional bias.</p>"},{"location":"reference/thestrat/signals/#thestrat.signals.SignalCategory","title":"SignalCategory","text":"<p>               Bases: <code>Enum</code></p> <p>Signal categorization types.</p>"},{"location":"reference/thestrat/signals/#thestrat.signals.SignalMetadata","title":"SignalMetadata  <code>dataclass</code>","text":"<pre><code>SignalMetadata(\n    pattern: str,\n    category: SignalCategory,\n    bias: SignalBias,\n    bar_count: int,\n    entry_bar_index: int,\n    trigger_bar_index: int,\n    entry_price: float,\n    stop_price: float,\n    timestamp: datetime,\n    signal_id: str = (lambda: str(uuid4()))(),\n    target_bar_index: int | None = None,\n    target_price: float | None = None,\n    status: SignalStatus = PENDING,\n    triggered_at: datetime | None = None,\n    closed_at: datetime | None = None,\n    close_reason: str | None = None,\n    change_history: list[PriceChange] = list(),\n    symbol: str | None = None,\n    timeframe: str | None = None,\n    risk_amount: float | None = None,\n    reward_amount: float | None = None,\n    risk_reward_ratio: float | None = None,\n    entry_filled_price: float | None = None,\n    exit_price: float | None = None,\n    pnl: float | None = None,\n    max_favorable_excursion: float | None = None,\n    max_adverse_excursion: float | None = None,\n)\n</code></pre> <p>Complete signal metadata with change tracking and serialization.</p> <p>Methods:</p> Name Description <code>__post_init__</code> <p>Store original values and calculate metrics.</p> <code>from_dict</code> <p>Reconstruct SignalMetadata from dictionary.</p> <code>from_json</code> <p>Deserialize from JSON string.</p> <code>to_dict</code> <p>Convert to dictionary for JSON serialization.</p> <code>to_json</code> <p>Serialize to JSON string.</p> <code>trail_stop</code> <p>Trail stop loss, only allowing favorable moves.</p> <code>update_stop</code> <p>Update stop with change tracking.</p> <code>update_target</code> <p>Update target with change tracking.</p>"},{"location":"reference/thestrat/signals/#thestrat.signals.SignalMetadata.__post_init__","title":"__post_init__","text":"<pre><code>__post_init__()\n</code></pre> <p>Store original values and calculate metrics.</p> Source code in <code>thestrat/signals.py</code> <pre><code>def __post_init__(self):\n    \"\"\"Store original values and calculate metrics.\"\"\"\n    self.original_stop = self.stop_price\n    self.original_target = self.target_price\n    self._calculate_risk_metrics()\n</code></pre>"},{"location":"reference/thestrat/signals/#thestrat.signals.SignalMetadata.from_dict","title":"from_dict  <code>classmethod</code>","text":"<pre><code>from_dict(data: dict[str, Any]) -&gt; SignalMetadata\n</code></pre> <p>Reconstruct SignalMetadata from dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict[str, Any]</code> <p>Dictionary representation from <code>to_dict()</code></p> required <p>Returns:</p> Type Description <code>SignalMetadata</code> <p>SignalMetadata instance with original values and metrics recalculated</p> Source code in <code>thestrat/signals.py</code> <pre><code>@classmethod\ndef from_dict(cls, data: dict[str, Any]) -&gt; \"SignalMetadata\":\n    \"\"\"\n    Reconstruct SignalMetadata from dictionary.\n\n    Args:\n        data: Dictionary representation from `to_dict()`\n\n    Returns:\n        SignalMetadata instance with original values and metrics recalculated\n    \"\"\"\n    # Make a copy to avoid modifying the original\n    data = data.copy()\n\n    # Convert strings back to enums\n    data[\"category\"] = SignalCategory(data[\"category\"])\n    data[\"bias\"] = SignalBias(data[\"bias\"])\n    data[\"status\"] = SignalStatus(data[\"status\"])\n\n    # Convert ISO strings to datetime\n    data[\"timestamp\"] = datetime.fromisoformat(data[\"timestamp\"])\n\n    if data.get(\"triggered_at\"):\n        data[\"triggered_at\"] = datetime.fromisoformat(data[\"triggered_at\"])\n    if data.get(\"closed_at\"):\n        data[\"closed_at\"] = datetime.fromisoformat(data[\"closed_at\"])\n\n    # Reconstruct change history\n    data[\"change_history\"] = [\n        PriceChange(**{**ch, \"timestamp\": datetime.fromisoformat(ch[\"timestamp\"])})\n        for ch in data.get(\"change_history\", [])\n    ]\n\n    # Convert string prices back to floats\n    float_fields = [\n        \"entry_price\",\n        \"stop_price\",\n        \"target_price\",\n        \"original_stop\",\n        \"original_target\",\n        \"risk_amount\",\n        \"reward_amount\",\n        \"risk_reward_ratio\",\n        \"entry_filled_price\",\n        \"exit_price\",\n        \"pnl\",\n        \"max_favorable_excursion\",\n        \"max_adverse_excursion\",\n    ]\n\n    for float_field in float_fields:\n        if data.get(float_field) is not None and isinstance(data[float_field], str):\n            data[float_field] = float(data[float_field])\n\n    # Remove fields that are calculated in __post_init__ and shouldn't be passed to constructor\n    calculated_fields = [\"original_stop\", \"original_target\", \"risk_amount\", \"reward_amount\", \"risk_reward_ratio\"]\n    for calc_field in calculated_fields:\n        data.pop(calc_field, None)\n\n    # Create the object (original values and metrics will be recalculated in __post_init__)\n    return cls(**data)\n</code></pre>"},{"location":"reference/thestrat/signals/#thestrat.signals.SignalMetadata.from_json","title":"from_json  <code>classmethod</code>","text":"<pre><code>from_json(json_str: str) -&gt; SignalMetadata\n</code></pre> <p>Deserialize from JSON string.</p> <p>Parameters:</p> Name Type Description Default <code>json_str</code> <code>str</code> <p>JSON string from <code>to_json()</code></p> required <p>Returns:</p> Type Description <code>SignalMetadata</code> <p>SignalMetadata instance reconstructed from JSON</p> Source code in <code>thestrat/signals.py</code> <pre><code>@classmethod\ndef from_json(cls, json_str: str) -&gt; \"SignalMetadata\":\n    \"\"\"\n    Deserialize from JSON string.\n\n    Args:\n        json_str: JSON string from `to_json()`\n\n    Returns:\n        SignalMetadata instance reconstructed from JSON\n    \"\"\"\n    return cls.from_dict(json.loads(json_str))\n</code></pre>"},{"location":"reference/thestrat/signals/#thestrat.signals.SignalMetadata.to_dict","title":"to_dict","text":"<pre><code>to_dict() -&gt; dict[str, Any]\n</code></pre> <p>Convert to dictionary for JSON serialization.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary representation with all fields serializable to JSON</p> Source code in <code>thestrat/signals.py</code> <pre><code>def to_dict(self) -&gt; dict[str, Any]:\n    \"\"\"\n    Convert to dictionary for JSON serialization.\n\n    Returns:\n        Dictionary representation with all fields serializable to JSON\n    \"\"\"\n    data = asdict(self)\n\n    # Convert enums to strings\n    data[\"category\"] = self.category.value\n    data[\"bias\"] = self.bias.value\n    data[\"status\"] = self.status.value\n\n    # Convert datetime to ISO format\n    data[\"timestamp\"] = self.timestamp.isoformat()\n\n    if self.triggered_at:\n        data[\"triggered_at\"] = self.triggered_at.isoformat()\n    if self.closed_at:\n        data[\"closed_at\"] = self.closed_at.isoformat()\n\n    # Convert change history\n    data[\"change_history\"] = [\n        {**asdict(change), \"timestamp\": change.timestamp.isoformat()} for change in self.change_history\n    ]\n\n    # Convert floats to strings for precision (optional)\n    float_fields = [\n        \"entry_price\",\n        \"stop_price\",\n        \"target_price\",\n        \"original_stop\",\n        \"original_target\",\n        \"risk_amount\",\n        \"reward_amount\",\n        \"risk_reward_ratio\",\n        \"entry_filled_price\",\n        \"exit_price\",\n        \"pnl\",\n        \"max_favorable_excursion\",\n        \"max_adverse_excursion\",\n    ]\n\n    for float_field in float_fields:\n        if data.get(float_field) is not None:\n            data[float_field] = str(data[float_field])\n\n    return data\n</code></pre>"},{"location":"reference/thestrat/signals/#thestrat.signals.SignalMetadata.to_json","title":"to_json","text":"<pre><code>to_json() -&gt; str\n</code></pre> <p>Serialize to JSON string.</p> <p>Returns:</p> Type Description <code>str</code> <p>JSON string representation of the signal metadata</p> Source code in <code>thestrat/signals.py</code> <pre><code>def to_json(self) -&gt; str:\n    \"\"\"\n    Serialize to JSON string.\n\n    Returns:\n        JSON string representation of the signal metadata\n    \"\"\"\n    return json.dumps(self.to_dict(), default=str)\n</code></pre>"},{"location":"reference/thestrat/signals/#thestrat.signals.SignalMetadata.trail_stop","title":"trail_stop","text":"<pre><code>trail_stop(new_stop: float, reason: str = 'trailing_stop') -&gt; bool\n</code></pre> <p>Trail stop loss, only allowing favorable moves.</p> <p>Parameters:</p> Name Type Description Default <code>new_stop</code> <code>float</code> <p>Proposed new stop price</p> required <code>reason</code> <code>str</code> <p>Reason for trailing (default: \"trailing_stop\")</p> <code>'trailing_stop'</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if stop was trailed, False if move was unfavorable and rejected</p> Source code in <code>thestrat/signals.py</code> <pre><code>def trail_stop(self, new_stop: float, reason: str = \"trailing_stop\") -&gt; bool:\n    \"\"\"\n    Trail stop loss, only allowing favorable moves.\n\n    Args:\n        new_stop: Proposed new stop price\n        reason: Reason for trailing (default: \"trailing_stop\")\n\n    Returns:\n        True if stop was trailed, False if move was unfavorable and rejected\n    \"\"\"\n    if self.bias == SignalBias.LONG:\n        # For long trades, only trail up\n        if new_stop &gt; self.stop_price:\n            self.update_stop(new_stop, reason)\n            return True\n    else:\n        # For short trades, only trail down\n        if new_stop &lt; self.stop_price:\n            self.update_stop(new_stop, reason)\n            return True\n    return False\n</code></pre>"},{"location":"reference/thestrat/signals/#thestrat.signals.SignalMetadata.update_stop","title":"update_stop","text":"<pre><code>update_stop(new_stop: float, reason: str = None) -&gt; None\n</code></pre> <p>Update stop with change tracking.</p> <p>Parameters:</p> Name Type Description Default <code>new_stop</code> <code>float</code> <p>New stop loss price</p> required <code>reason</code> <code>str</code> <p>Optional reason for the update (e.g., \"trailing_stop\", \"manual_adjustment\")</p> <code>None</code> Source code in <code>thestrat/signals.py</code> <pre><code>def update_stop(self, new_stop: float, reason: str = None) -&gt; None:\n    \"\"\"\n    Update stop with change tracking.\n\n    Args:\n        new_stop: New stop loss price\n        reason: Optional reason for the update (e.g., \"trailing_stop\", \"manual_adjustment\")\n    \"\"\"\n    if new_stop == self.stop_price:\n        return\n\n    change = PriceChange(\n        field_name=\"stop_price\",\n        from_value=self.stop_price,\n        to_value=new_stop,\n        timestamp=datetime.now(),\n        reason=reason,\n    )\n    self.change_history.append(change)\n    self.stop_price = new_stop\n    self._calculate_risk_metrics()\n</code></pre>"},{"location":"reference/thestrat/signals/#thestrat.signals.SignalMetadata.update_target","title":"update_target","text":"<pre><code>update_target(new_target: float, reason: str = None) -&gt; None\n</code></pre> <p>Update target with change tracking.</p> <p>Parameters:</p> Name Type Description Default <code>new_target</code> <code>float</code> <p>New target price</p> required <code>reason</code> <code>str</code> <p>Optional reason for the update (e.g., \"manual_adjustment\", \"scale_out\")</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If called on continuation signals (they have no target)</p> Source code in <code>thestrat/signals.py</code> <pre><code>def update_target(self, new_target: float, reason: str = None) -&gt; None:\n    \"\"\"\n    Update target with change tracking.\n\n    Args:\n        new_target: New target price\n        reason: Optional reason for the update (e.g., \"manual_adjustment\", \"scale_out\")\n\n    Raises:\n        ValueError: If called on continuation signals (they have no target)\n    \"\"\"\n    if self.category == SignalCategory.CONTINUATION:\n        raise ValueError(\"Continuation signals have no target\")\n\n    if new_target == self.target_price:\n        return\n\n    change = PriceChange(\n        field_name=\"target_price\",\n        from_value=self.target_price,\n        to_value=new_target,\n        timestamp=datetime.now(),\n        reason=reason,\n    )\n    self.change_history.append(change)\n    self.target_price = new_target\n    self._calculate_risk_metrics()\n</code></pre>"},{"location":"reference/thestrat/signals/#thestrat.signals.SignalStatus","title":"SignalStatus","text":"<p>               Bases: <code>Enum</code></p> <p>Signal lifecycle status.</p>"},{"location":"user-guide/","title":"User Guide","text":"<p>Welcome to the TheStrat user guide. This section provides comprehensive documentation for using the TheStrat Python module in your trading applications.</p>"},{"location":"user-guide/#what-is-thestrat","title":"What is #TheStrat?","text":""},{"location":"user-guide/#thestrat-is-a-technical-analysis-methodology-that-focuses-on-understanding-market-structure-through-the-identification-of-specific-bar-patterns-and-their-relationships-across-multiple-timeframes","title":"TheStrat is a technical analysis methodology that focuses on understanding market structure through the identification of specific bar patterns and their relationships across multiple timeframes.","text":""},{"location":"user-guide/#guide-structure","title":"Guide Structure","text":"<p>This user guide is organized into the following sections:</p>"},{"location":"user-guide/#installation","title":"Installation","text":"<p>How to install and set up the TheStrat module in your environment.</p>"},{"location":"user-guide/#quick-start","title":"Quick Start","text":"<p>Get up and running quickly with basic examples and common use cases.</p>"},{"location":"user-guide/#examples","title":"Examples","text":"<p>Detailed examples showing how to use each component and feature.</p>"},{"location":"user-guide/#asset-classes","title":"Asset Classes","text":"<p>Understanding how different asset classes work within the framework.</p>"},{"location":"user-guide/#prerequisites","title":"Prerequisites","text":"<p>Before using TheStrat, you should have:</p> <ul> <li>Python 3.11 or higher installed</li> <li>Basic understanding of financial markets and OHLCV data</li> <li>Familiarity with Python data structures (pandas/polars DataFrames)</li> </ul>"},{"location":"user-guide/#key-concepts","title":"Key Concepts","text":""},{"location":"user-guide/#timeframe-aggregation","title":"Timeframe Aggregation","text":"<p>TheStrat works across multiple timeframes. The aggregation component handles converting your base timeframe data (e.g., 1-minute bars) into higher timeframes (e.g., 5-minute, 15-minute, hourly).</p>"},{"location":"user-guide/#inside-and-outside-bars","title":"Inside and Outside Bars","text":"<p>Core to #TheStrat methodology: - Inside Bar: High \u2264 previous high AND Low \u2265 previous low - Outside Bar: High &gt; previous high AND Low &lt; previous low</p>"},{"location":"user-guide/#signals-and-pivots","title":"Signals and Pivots","text":"<p>The indicators component identifies key market structure points and generates actionable signals based on TheStrat rules.</p>"},{"location":"user-guide/#getting-help","title":"Getting Help","text":"<p>If you need assistance:</p> <ol> <li>Check the Examples section for similar use cases</li> <li>Review the API Reference for detailed method documentation</li> <li>Contact the maintainer for private module support</li> </ol> <p>Let's get started with Installation!</p>"},{"location":"user-guide/asset-classes/","title":"Asset Classes","text":"<p>TheStrat supports multiple asset classes, each with specific market characteristics and trading hours. This guide explains how to configure and work with different asset classes effectively.</p>"},{"location":"user-guide/asset-classes/#overview","title":"Overview","text":"<p>Asset classes in TheStrat determine:</p> <ul> <li>Trading hours and session handling</li> <li>Timezone requirements and defaults</li> <li>Gap handling for market opens/closes</li> <li>Aggregation behavior for weekends and holidays</li> </ul>"},{"location":"user-guide/asset-classes/#supported-asset-classes","title":"Supported Asset Classes","text":"<p>TheStrat currently supports three major asset classes: crypto, equities, and fx. Each has been optimized for their specific market characteristics.</p>"},{"location":"user-guide/asset-classes/#crypto-247-trading","title":"Crypto (24/7 Trading)","text":"<p>Cryptocurrency markets trade continuously without breaks.</p> <p>Configuration: <pre><code>from thestrat.schemas import FactoryConfig, AggregationConfig, IndicatorsConfig\n\ncrypto_config = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"1h\"],\n        asset_class=\"crypto\",\n        timezone=\"UTC\"  # Always UTC for crypto\n    )\n)\n</code></pre></p> <p>Characteristics: - Trading Hours: 24/7/365 continuous - Timezone: UTC (required) - Session Handling: No sessions or gaps - Weekend Behavior: Trades through weekends</p> <p>Example Usage: <pre><code>from thestrat import Factory\nfrom thestrat.schemas import (\n    FactoryConfig, AggregationConfig, IndicatorsConfig,\n    TimeframeItemConfig, SwingPointsConfig\n)\n\n# Bitcoin hourly analysis\nbtc_config = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"4h\"],\n        asset_class=\"crypto\",\n        timezone=\"UTC\"\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"all\"],\n                swing_points=SwingPointsConfig(\n                    window=6,           # Longer window for 4h timeframe\n                    threshold=4.0       # Higher threshold for crypto volatility\n                )\n            )\n        ]\n    )\n)\n\npipeline = Factory.create_all(btc_config)\n</code></pre></p> <p>Best Practices: - Use higher volatility thresholds (3-5%) - Consider larger swing windows due to 24/7 nature - Include incomplete bars for real-time analysis</p>"},{"location":"user-guide/asset-classes/#equities-market-hours","title":"Equities (Market Hours)","text":"<p>Traditional stock markets with defined trading sessions.</p> <p>Configuration: <pre><code>from thestrat.schemas import FactoryConfig, AggregationConfig\n\nequity_config = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"5min\"],\n        asset_class=\"equities\",\n        timezone=\"US/Eastern\"  # NYSE/NASDAQ\n    )\n)\n</code></pre></p> <p>Characteristics: - Trading Hours: 9:30 AM - 4:00 PM ET (regular session) - Timezone: US/Eastern (default), configurable - Session Handling: Pre-market, regular, after-hours - Weekend Behavior: No trading weekends/holidays</p> <p>Market Sessions:</p> <p>TheStrat automatically handles market hours for equities. You can configure different timeframes for different analysis needs:</p> <pre><code># Short-term intraday analysis\nshort_term_config = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"1m\"],\n        asset_class=\"equities\",\n        timezone=\"US/Eastern\"\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"all\"],\n                swing_points=SwingPointsConfig(window=3, threshold=1.0)\n            )\n        ]\n    )\n)\n\n# Regular session analysis\nregular_config = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"5m\"],\n        asset_class=\"equities\",\n        timezone=\"US/Eastern\"\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"all\"],\n                swing_points=SwingPointsConfig(window=5, threshold=2.0)\n            )\n        ]\n    )\n)\n\n# Create pipelines\nshort_pipeline = Factory.create_all(short_term_config)\nregular_pipeline = Factory.create_all(regular_config)\n</code></pre> <p>International Equities: <pre><code># London Stock Exchange\nlse_config = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"15m\"],\n        asset_class=\"equities\",\n        timezone=\"Europe/London\"  # 8:00-16:30 GMT\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"all\"],\n                swing_points=SwingPointsConfig(window=5, threshold=2.0)\n            )\n        ]\n    )\n)\n\n# Tokyo Stock Exchange\ntse_config = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"30m\"],\n        asset_class=\"equities\",\n        timezone=\"Asia/Tokyo\"    # 9:00-15:00 JST\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"all\"],\n                swing_points=SwingPointsConfig(window=5, threshold=2.0)\n            )\n        ]\n    )\n)\n</code></pre></p>"},{"location":"user-guide/asset-classes/#forex-245-trading","title":"Forex (24/5 Trading)","text":"<p>Foreign exchange markets trade 24/5 from Sunday 5 PM to Friday 5 PM ET.</p> <p>Configuration: <pre><code>from thestrat.schemas import FactoryConfig, AggregationConfig\n\nfx_config = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"1h\"],\n        asset_class=\"fx\",\n        timezone=\"UTC\"  # Always UTC for FX\n    )\n)\n</code></pre></p> <p>Characteristics: - Trading Hours: Sun 5 PM - Fri 5 PM ET (24/5) - Timezone: UTC (required) - Session Handling: Asian, London, New York sessions - Weekend Behavior: Gap handling for weekend closes</p> <p>Major FX Sessions: <pre><code>def analyze_fx_sessions(eurusd_data):\n    \"\"\"Analyze EUR/USD across major FX sessions.\"\"\"\n\n    sessions = {\n        \"asian\": FactoryConfig(\n            aggregation=AggregationConfig(\n                target_timeframes=[\"1h\"],\n                asset_class=\"fx\",\n                timezone=\"UTC\"  # Asian session: 10 PM - 8 AM UTC\n            )\n        ),\n        \"london\": FactoryConfig(\n            aggregation=AggregationConfig(\n                target_timeframes=[\"30min\"],\n                asset_class=\"fx\",\n                timezone=\"UTC\"  # London session: 7 AM - 4 PM UTC\n            )\n        ),\n        \"newyork\": FactoryConfig(\n            aggregation=AggregationConfig(\n                target_timeframes=[\"15min\"],\n                asset_class=\"fx\",\n                timezone=\"UTC\"  # New York session: 12 PM - 9 PM UTC\n            )\n        )\n    }\n\n    results = {}\n    for session, config in sessions.items():\n        pipeline = Factory.create_all(config)\n        analyzed = pipeline[\"indicators\"].process(\n            pipeline[\"aggregation\"].process(eurusd_data)\n        )\n        results[session] = analyzed\n\n    return results\n</code></pre></p> <p>Currency-Specific Examples: <pre><code># Major pairs with different characteristics\npairs = {\n    \"EURUSD\": {\"threshold\": 0.3, \"window\": 5},   # Lower volatility\n    \"GBPJPY\": {\"threshold\": 0.8, \"window\": 4},   # Higher volatility\n    \"AUDUSD\": {\"threshold\": 0.4, \"window\": 6},   # Commodity currency\n    \"USDCAD\": {\"threshold\": 0.5, \"window\": 5}    # Oil correlation\n}\n\nfor pair, params in pairs.items():\n    config = FactoryConfig(\n        aggregation=AggregationConfig(\n            target_timeframes=[\"4h\"],\n            asset_class=\"fx\",\n            timezone=\"UTC\"\n        ),\n        indicators=IndicatorsConfig(\n            timeframe_configs=[\n                TimeframeItemConfig(\n                    timeframes=[\"all\"],\n                    swing_points=SwingPointsConfig(**params)\n                )\n            ]\n        )\n    )\n    # Process each pair...\n</code></pre></p>"},{"location":"user-guide/asset-classes/#asset-class-comparison","title":"Asset Class Comparison","text":"Asset Class Trading Hours Timezone Gap Handling Volatility Recommended Timeframes Crypto 24/7 UTC None High 1h, 4h, 1d Equities 9:30-16:00 ET US/Eastern Daily gaps Medium 1m, 5m, 15m, 1h Forex 24/5 UTC Weekend gaps Medium 15m, 1h, 4h"},{"location":"user-guide/asset-classes/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"user-guide/asset-classes/#custom-market-configuration","title":"Custom Market Configuration","text":"<pre><code># Define custom market behavior using supported parameters\ncustom_config = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"15m\"],  # Use supported timeframe\n        asset_class=\"equities\",     # Base on existing class\n        timezone=\"US/Pacific\",      # Custom timezone\n        session_start=\"06:30\"       # Custom session start\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"all\"],\n                swing_points=SwingPointsConfig(window=5, threshold=2.0)\n            )\n        ]\n    )\n)\n</code></pre>"},{"location":"user-guide/asset-classes/#multi-asset-portfolio","title":"Multi-Asset Portfolio","text":"<pre><code>def analyze_multi_asset_portfolio(assets):\n    \"\"\"Analyze multiple asset classes in one portfolio.\"\"\"\n\n    results = {}\n\n    for asset_name, (data, asset_class) in assets.items():\n        # Get appropriate config for asset class\n        base_config = {\n            \"crypto\": {\"target_timeframes\": [\"4h\"], \"timezone\": \"UTC\", \"threshold\": 3.0},\n            \"equities\": {\"target_timeframes\": [\"15min\"], \"timezone\": \"US/Eastern\", \"threshold\": 1.5},\n            \"fx\": {\"target_timeframes\": [\"1h\"], \"timezone\": \"UTC\", \"threshold\": 0.5}\n        }\n\n        if asset_class in base_config:\n            config = FactoryConfig(\n                aggregation=AggregationConfig(\n                    asset_class=asset_class,\n                    target_timeframes=base_config[asset_class][\"target_timeframes\"],\n                    timezone=base_config[asset_class][\"timezone\"]\n                ),\n                indicators=IndicatorsConfig(\n                    timeframe_configs=[\n                        TimeframeItemConfig(\n                            timeframes=[\"all\"],\n                            swing_points=SwingPointsConfig(\n                                window=5,\n                                threshold=base_config[asset_class][\"threshold\"]\n                            )\n                        )\n                    ]\n                )\n            )\n\n            pipeline = Factory.create_all(config)\n            aggregated = pipeline[\"aggregation\"].process(data)\n            analyzed = pipeline[\"indicators\"].process(aggregated)\n\n            results[asset_name] = {\n                'asset_class': asset_class,\n                'data': analyzed,\n                'inside_bars': analyzed['inside_bar'].sum(),\n                'outside_bars': analyzed['outside_bar'].sum()\n            }\n\n    return results\n\n# Example usage\nportfolio = {\n    'BTC': (btc_data, 'crypto'),\n    'AAPL': (aapl_data, 'equities'),\n    'EURUSD': (eurusd_data, 'fx')\n}\n\nportfolio_analysis = analyze_multi_asset_portfolio(portfolio)\n</code></pre>"},{"location":"user-guide/asset-classes/#best-practices-by-asset-class","title":"Best Practices by Asset Class","text":""},{"location":"user-guide/asset-classes/#crypto","title":"Crypto","text":"<ul> <li>Use UTC timezone exclusively</li> <li>Higher volatility thresholds (3-5%)</li> <li>Consider 24/7 nature in signal interpretation</li> <li>Include incomplete bars for real-time analysis</li> </ul>"},{"location":"user-guide/asset-classes/#equities","title":"Equities","text":"<ul> <li>Respect market hours and gaps</li> <li>Lower volatility thresholds (1-2%)</li> <li>Consider pre/post market sessions separately</li> <li>Account for earnings and announcement gaps</li> </ul>"},{"location":"user-guide/asset-classes/#forex","title":"Forex","text":"<ul> <li>Use UTC timezone for consistency</li> <li>Medium volatility thresholds (0.5-1%)</li> <li>Consider major session overlaps</li> <li>Handle weekend gaps appropriately</li> </ul> <p>Choose the asset class configuration that matches your data and trading requirements. The framework handles the complex details of market hours, timezone conversions, and gap handling automatically.</p>"},{"location":"user-guide/configuration/","title":"Configuration Reference","text":"<p>Configuration documentation will be generated during build.</p>"},{"location":"user-guide/dataframe-schema/","title":"DataFrame Schema Usage","text":"<p>The <code>IndicatorSchema</code> class provides comprehensive DataFrame validation and schema information for TheStrat processing pipeline. This is essential for database integration and data validation workflows.</p>"},{"location":"user-guide/dataframe-schema/#quick-start","title":"Quick Start","text":"<pre><code>from thestrat import IndicatorSchema\nimport polars as pl\nfrom datetime import datetime\n\n# Validate input DataFrame\ndata = {\n    \"timestamp\": [datetime.now()],\n    \"open\": [100.0], \"high\": [105.0], \"low\": [95.0], \"close\": [102.0],\n    \"symbol\": [\"AAPL\"], \"volume\": [1000000.0], \"timeframe\": [\"5min\"]\n}\n\ndf = pl.DataFrame(data, schema=IndicatorSchema.get_polars_dtypes())\nresult = IndicatorSchema.validate_dataframe(df)\n\nprint(f\"Valid: {result['valid']}\")\nprint(f\"Missing columns: {result['missing_required']}\")\n</code></pre>"},{"location":"user-guide/dataframe-schema/#database-schema-generation","title":"Database Schema Generation","text":""},{"location":"user-guide/dataframe-schema/#sql-table-creation","title":"SQL Table Creation","text":"<pre><code># Get column types and descriptions\ndescriptions = IndicatorSchema.get_column_descriptions()\npolars_types = IndicatorSchema.get_polars_dtypes()\n\n# Map Polars types to SQL types\ntype_mapping = {\n    pl.Datetime: \"TIMESTAMP\",\n    pl.Float64: \"DOUBLE PRECISION\",\n    pl.String: \"VARCHAR(50)\",\n    pl.Boolean: \"BOOLEAN\",\n    pl.Int32: \"INTEGER\"\n}\n\n# Generate CREATE TABLE statement\ndef generate_sql_schema(table_name: str) -&gt; str:\n    lines = [f\"CREATE TABLE {table_name} (\"]\n\n    for col, polars_type in polars_types.items():\n        sql_type = type_mapping.get(polars_type, \"TEXT\")\n        description = descriptions.get(col, \"\").replace(\"'\", \"''\")\n        lines.append(f\"  {col} {sql_type}, -- {description}\")\n\n    lines.append(\"  PRIMARY KEY (timestamp, symbol, timeframe)\")\n    lines.append(\");\")\n    return \"\\n\".join(lines)\n\nschema_sql = generate_sql_schema(\"thestrat_indicators\")\n</code></pre>"},{"location":"user-guide/dataframe-schema/#column-categories","title":"Column Categories","text":"<p>Organize columns by functionality for targeted database operations:</p> <pre><code>categories = IndicatorSchema.get_column_categories()\n\n# Create separate tables by category\nfor category, columns in categories.items():\n    if category == \"base_ohlc\":\n        # Core market data table\n        create_base_table(columns)\n    elif category == \"signals\":\n        # Trading signals table with indexes\n        create_signals_table(columns)\n    elif category == \"swing_points\":\n        # Technical analysis table\n        create_analysis_table(columns)\n</code></pre>"},{"location":"user-guide/dataframe-schema/#input-validation","title":"Input Validation","text":""},{"location":"user-guide/dataframe-schema/#required-columns-check","title":"Required Columns Check","text":"<pre><code>def validate_input_data(df) -&gt; dict:\n    \"\"\"Validate DataFrame before processing.\"\"\"\n    result = IndicatorSchema.validate_dataframe(df)\n\n    if not result['valid']:\n        errors = []\n        if result['missing_required']:\n            errors.append(f\"Missing: {result['missing_required']}\")\n        if result['type_issues']:\n            errors.append(f\"Type errors: {result['type_issues']}\")\n\n        raise ValueError(f\"Invalid DataFrame: {'; '.join(errors)}\")\n\n    return result['converted_df'] if result['conversion_performed'] else df\n</code></pre>"},{"location":"user-guide/dataframe-schema/#auto-conversion-from-pandas","title":"Auto-conversion from Pandas","text":"<pre><code>import pandas as pd\n\n# Pandas DataFrame automatically converts\ndf_pandas = pd.DataFrame(data)\ndf_pandas['timestamp'] = pd.to_datetime(df_pandas['timestamp'])\n\nresult = IndicatorSchema.validate_dataframe(df_pandas)\n# result['converted_df'] contains Polars DataFrame\n</code></pre>"},{"location":"user-guide/dataframe-schema/#column-documentation","title":"Column Documentation","text":""},{"location":"user-guide/dataframe-schema/#get-field-information","title":"Get Field Information","text":"<pre><code># Column descriptions for documentation\ndescriptions = IndicatorSchema.get_column_descriptions()\npolars_types = IndicatorSchema.get_polars_dtypes()\n\n# Generate documentation\nfor col in [\"swing_high\", \"continuity\", \"signal\"]:\n    print(f\"**{col}**: {descriptions[col]}\")\n    print(f\"Type: `{polars_types[col].__name__}`\\n\")\n</code></pre>"},{"location":"user-guide/dataframe-schema/#category-based-operations","title":"Category-based Operations","text":"<pre><code>categories = IndicatorSchema.get_column_categories()\n\n# Process only price analysis columns\nprice_cols = categories['price_analysis']\ndf_prices = df.select(price_cols)\n\n# Extract signal columns for trading system\nsignal_cols = categories['signals']\ndf_signals = df.select(signal_cols)\n</code></pre>"},{"location":"user-guide/dataframe-schema/#integration-patterns","title":"Integration Patterns","text":""},{"location":"user-guide/dataframe-schema/#database-insert-with-validation","title":"Database Insert with Validation","text":"<pre><code>def insert_thestrat_data(df, connection):\n    \"\"\"Insert validated DataFrame into database.\"\"\"\n    # Validate first\n    validated_df = validate_input_data(df)\n\n    # Get column info for proper insertion\n    polars_types = IndicatorSchema.get_polars_dtypes()\n\n    # Insert with proper type handling\n    for row in validated_df.iter_rows(named=True):\n        insert_row(connection, row, polars_types)\n\ndef insert_row(conn, row_data, type_info):\n    \"\"\"Insert single row with type conversion.\"\"\"\n    columns = list(row_data.keys())\n    placeholders = \", \".join([\"?\" for _ in columns])\n\n    # Convert values based on schema\n    values = []\n    for col, value in row_data.items():\n        if col in type_info and type_info[col] == pl.Datetime:\n            values.append(value.isoformat() if value else None)\n        else:\n            values.append(value)\n\n    query = f\"INSERT INTO thestrat_indicators ({', '.join(columns)}) VALUES ({placeholders})\"\n    conn.execute(query, values)\n</code></pre>"},{"location":"user-guide/dataframe-schema/#api-response-validation","title":"API Response Validation","text":"<pre><code>def validate_api_response(json_data: list) -&gt; pl.DataFrame:\n    \"\"\"Convert and validate API data.\"\"\"\n    df = pl.DataFrame(json_data)\n\n    # Validate structure\n    result = IndicatorSchema.validate_dataframe(df)\n    if not result['valid']:\n        raise ValueError(f\"API data invalid: {result}\")\n\n    return result.get('converted_df', df)\n</code></pre>"},{"location":"user-guide/dataframe-schema/#best-practices","title":"Best Practices","text":"<ul> <li>Always validate input data before processing</li> <li>Use column categories to organize database tables efficiently</li> <li>Leverage auto-conversion for Pandas compatibility</li> <li>Check type_issues for data quality problems</li> <li>Use descriptions for database comments and API documentation</li> </ul>"},{"location":"user-guide/examples/","title":"Examples","text":"<p>This section provides comprehensive examples of using TheStrat for various trading scenarios and asset classes.</p>"},{"location":"user-guide/examples/#basic-examples","title":"Basic Examples","text":""},{"location":"user-guide/examples/#simple-5-minute-analysis","title":"Simple 5-Minute Analysis","text":"<pre><code>import pandas as pd\nfrom thestrat import Factory\nfrom thestrat.schemas import (\n    FactoryConfig, AggregationConfig, IndicatorsConfig,\n    TimeframeItemConfig, SwingPointsConfig\n)\n\n# Sample market data\ndata = pd.DataFrame({\n    'timestamp': pd.date_range('2024-01-01 09:30', periods=300, freq='1min'),\n    'open': [100 + i*0.1 for i in range(300)],\n    'high': [100.5 + i*0.1 for i in range(300)],\n    'low': [99.5 + i*0.1 for i in range(300)],\n    'close': [100.2 + i*0.1 for i in range(300)],\n    'volume': [1000 + i*10 for i in range(300)]\n})\n\n# Configure for 5-minute equity analysis with Pydantic models\nconfig = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"5m\"],\n        asset_class=\"equities\",\n        timezone=\"US/Eastern\"\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"all\"],\n                swing_points=SwingPointsConfig(window=5, threshold=2.0)\n            )\n        ]\n    )\n)\n\n# Process the data\npipeline = Factory.create_all(config)\naggregated = pipeline[\"aggregation\"].process(data)\nanalyzed = pipeline[\"indicators\"].process(aggregated)\n\n# Display results\nprint(f\"Converted {len(data)} 1-minute bars to {len(aggregated)} 5-minute bars\")\nprint(f\"Found {analyzed['inside_bar'].sum()} inside bars\")\nprint(f\"Found {analyzed['outside_bar'].sum()} outside bars\")\n</code></pre>"},{"location":"user-guide/examples/#multi-timeframe-analysis","title":"Multi-Timeframe Analysis","text":"<pre><code>from thestrat import Factory\nfrom thestrat.schemas import (\n    FactoryConfig, AggregationConfig, IndicatorsConfig,\n    TimeframeItemConfig, SwingPointsConfig\n)\nimport pandas as pd\n\ndef analyze_multiple_timeframes(data, timeframes=['5m', '15m', '1h']):\n    \"\"\"Analyze data across multiple timeframes using Pydantic models.\"\"\"\n    # Single configuration for multiple timeframes using models\n    config = FactoryConfig(\n        aggregation=AggregationConfig(\n            target_timeframes=timeframes,  # Process all timeframes together\n            asset_class=\"equities\",\n            timezone=\"US/Eastern\"\n        ),\n        indicators=IndicatorsConfig(\n            timeframe_configs=[\n                TimeframeItemConfig(\n                    timeframes=[\"5m\"],\n                    swing_points=SwingPointsConfig(window=3, threshold=1.5)  # Short-term settings\n                ),\n                TimeframeItemConfig(\n                    timeframes=[\"15m\", \"1h\"],\n                    swing_points=SwingPointsConfig(window=7, threshold=2.5)  # Long-term settings\n                )\n            ]\n        )\n    )\n\n    # Single pipeline processes all timeframes\n    pipeline = Factory.create_all(config)\n    aggregated = pipeline[\"aggregation\"].process(data)\n    analyzed = pipeline[\"indicators\"].process(aggregated)\n\n    # Extract results by timeframe from normalized output\n    results = {}\n    for tf in timeframes:\n        tf_data = analyzed[analyzed['timeframe'] == tf]\n        results[tf] = {\n            'data': tf_data,\n            'inside_bars': tf_data['inside_bar'].sum(),\n            'outside_bars': tf_data['outside_bar'].sum(),\n            'pivot_highs': tf_data['pivot_high'].sum() if 'pivot_high' in tf_data.columns else 0,\n            'pivot_lows': tf_data['pivot_low'].sum() if 'pivot_low' in tf_data.columns else 0\n        }\n\n    return results, analyzed  # Return both summary and full data\n\n# Use with your data\nmulti_tf_analysis, full_data = analyze_multiple_timeframes(sample_data)\n\n# Display summary\nfor tf, result in multi_tf_analysis.items():\n    print(f\"{tf}: {result['inside_bars']} inside, {result['outside_bars']} outside\")\n\nprint(f\"Total processed: {len(full_data)} bars across {len(full_data['timeframe'].unique())} timeframes\")\n</code></pre>"},{"location":"user-guide/examples/#asset-class-specific-examples","title":"Asset Class Specific Examples","text":""},{"location":"user-guide/examples/#cryptocurrency-247-trading","title":"Cryptocurrency (24/7 Trading)","text":"<pre><code># Bitcoin/crypto configuration with Pydantic models\ncrypto_config = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"1h\"],\n        asset_class=\"crypto\",\n        timezone=\"UTC\"  # Always UTC for crypto\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"all\"],\n                swing_points=SwingPointsConfig(\n                    window=6,  # Slightly larger window for hourly\n                    threshold=3.0  # Higher threshold for crypto volatility\n                )\n            )\n        ]\n    )\n)\n\ncrypto_pipeline = Factory.create_all(crypto_config)\n\n# Process crypto data (note: no market hours restrictions)\ncrypto_analyzed = crypto_pipeline[\"aggregation\"].process(btc_data)\ncrypto_signals = crypto_pipeline[\"indicators\"].process(crypto_analyzed)\n\nprint(f\"Crypto analysis: 24/7 trading, {len(crypto_signals)} hourly bars\")\n</code></pre>"},{"location":"user-guide/examples/#forex-245-trading","title":"Forex (24/5 Trading)","text":"<pre><code># EUR/USD analysis with Pydantic models\nfx_config = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"4h\"],\n        asset_class=\"fx\",\n        timezone=\"UTC\"\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"all\"],\n                swing_points=SwingPointsConfig(\n                    window=4,\n                    threshold=0.5  # Lower threshold for FX (measured in %)\n                )\n            )\n        ]\n    )\n)\n\nfx_pipeline = Factory.create_all(fx_config)\n\n# FX data processing handles weekend gaps automatically\neurusd_aggregated = fx_pipeline[\"aggregation\"].process(eurusd_1m_data)\neurusd_analyzed = fx_pipeline[\"indicators\"].process(eurusd_aggregated)\n\n# Find major swing points (check for boolean columns indicating new pivots)\nmajor_swings = eurusd_analyzed[\n    (eurusd_analyzed.get('new_pivot_high', False) == True) |\n    (eurusd_analyzed.get('new_pivot_low', False) == True)\n] if 'new_pivot_high' in eurusd_analyzed.columns or 'new_pivot_low' in eurusd_analyzed.columns else []\nprint(f\"Found {len(major_swings)} major swing points in EUR/USD\")\n</code></pre>"},{"location":"user-guide/examples/#multi-timeframe-examples","title":"Multi-Timeframe Examples","text":""},{"location":"user-guide/examples/#single-request-multi-timeframe-analysis","title":"Single Request Multi-Timeframe Analysis","text":"<pre><code>from thestrat import Factory\n\n# Process multiple timeframes with different configurations using Pydantic models\nconfig = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"5m\", \"15m\", \"1h\", \"1d\"],  # All timeframes together\n        asset_class=\"equities\",\n        timezone=\"US/Eastern\"\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"5m\"],  # Short-term aggressive settings\n                swing_points=SwingPointsConfig(window=3, threshold=1.0)\n            ),\n            TimeframeItemConfig(\n                timeframes=[\"15m\"],  # Medium-term balanced settings\n                swing_points=SwingPointsConfig(window=5, threshold=2.0)\n            ),\n            TimeframeItemConfig(\n                timeframes=[\"1h\", \"1d\"],  # Long-term conservative settings\n                swing_points=SwingPointsConfig(window=10, threshold=3.0)\n            )\n        ]\n    )\n)\n\npipeline = Factory.create_all(config)\naggregated = pipeline[\"aggregation\"].process(market_data)\nanalyzed = pipeline[\"indicators\"].process(aggregated)\n\n# Extract results for each timeframe from normalized output\nfor tf in [\"5m\", \"15m\", \"1h\", \"1d\"]:\n    tf_data = analyzed[analyzed['timeframe'] == tf]\n    print(f\"{tf}: {len(tf_data)} bars, {tf_data['inside_bar'].sum()} inside bars\")\n\nprint(f\"Total: {len(analyzed)} bars across {len(analyzed['timeframe'].unique())} timeframes\")\n</code></pre>"},{"location":"user-guide/examples/#cross-timeframe-signal-correlation","title":"Cross-Timeframe Signal Correlation","text":"<pre><code>def analyze_cross_timeframe_signals(data):\n    \"\"\"Analyze signal correlation across multiple timeframes.\"\"\"\n    config = FactoryConfig(\n        aggregation=AggregationConfig(\n            target_timeframes=[\"5m\", \"15m\", \"1h\"],\n            asset_class=\"equities\"\n        ),\n        indicators=IndicatorsConfig(\n            timeframe_configs=[\n                TimeframeItemConfig(\n                    timeframes=[\"all\"],\n                    swing_points=SwingPointsConfig(window=5, threshold=2.0)\n                )\n            ]\n        )\n    )\n\n    pipeline = Factory.create_all(config)\n    aggregated = pipeline[\"aggregation\"].process(data)\n    analyzed = pipeline[\"indicators\"].process(aggregated)\n\n    # Find synchronized signals across timeframes\n    synchronized_signals = []\n\n    # Get latest bar for each timeframe\n    latest_by_tf = {}\n    for tf in [\"5m\", \"15m\", \"1h\"]:\n        tf_data = analyzed[analyzed['timeframe'] == tf]\n        if len(tf_data) &gt; 0:\n            latest_by_tf[tf] = tf_data.iloc[-1]\n\n    # Check for signal alignment\n    if all(bar.get('outside_bar', False) for bar in latest_by_tf.values()):\n        synchronized_signals.append({\n            'type': 'multi_timeframe_breakout',\n            'timeframes': list(latest_by_tf.keys()),\n            'timestamp': list(latest_by_tf.values())[0]['timestamp']\n        })\n\n    return synchronized_signals, analyzed\n\n# Example usage\nsignals, full_analysis = analyze_cross_timeframe_signals(sample_data)\nprint(f\"Found {len(signals)} synchronized signals across multiple timeframes\")\n</code></pre>"},{"location":"user-guide/examples/#advanced-analysis-examples","title":"Advanced Analysis Examples","text":""},{"location":"user-guide/examples/#custom-signal-detection","title":"Custom Signal Detection","text":"<pre><code>def detect_strat_patterns(data):\n    \"\"\"Detect common TheStrat patterns.\"\"\"\n    patterns = []\n\n    for i in range(2, len(data)):\n        current = data.iloc[i]\n        prev1 = data.iloc[i-1]\n        prev2 = data.iloc[i-2]\n\n        # Inside bar followed by breakout (2-1-2 Continuation)\n        if (prev2['outside_bar'] and\n            prev1['inside_bar'] and\n            current['close'] &gt; prev2['high']):\n            patterns.append({\n                'timestamp': current['timestamp'],\n                'pattern': '2-1-2_bullish_continuation',\n                'entry_price': prev2['high'],\n                'target': current['close'] + (current['close'] - prev2['low']) * 0.5\n            })\n\n        # Outside bar reversal\n        if (current['outside_bar'] and\n            prev1['close'] &gt; prev1['open'] and  # Previous bar was bullish\n            current['close'] &lt; current['open']):  # Current bar is bearish\n            patterns.append({\n                'timestamp': current['timestamp'],\n                'pattern': 'outside_bar_reversal',\n                'entry_price': current['low'],\n                'stop_loss': current['high']\n            })\n\n    return patterns\n\n# Apply pattern detection\npatterns = detect_strat_patterns(analyzed_data)\nprint(f\"Detected {len(patterns)} TheStrat patterns\")\n\n# Display recent patterns\nfor pattern in patterns[-5:]:\n    print(f\"{pattern['timestamp']}: {pattern['pattern']} @ {pattern['entry_price']}\")\n</code></pre>"},{"location":"user-guide/examples/#risk-management-integration","title":"Risk Management Integration","text":"<pre><code>def calculate_position_sizes(signals, account_balance, risk_percent=2.0):\n    \"\"\"Calculate position sizes based on TheStrat signals.\"\"\"\n    positions = []\n\n    for signal in signals:\n        if 'entry_price' in signal and 'stop_loss' in signal:\n            # Calculate risk per share\n            risk_per_share = abs(signal['entry_price'] - signal['stop_loss'])\n\n            # Calculate position size\n            risk_amount = account_balance * (risk_percent / 100)\n            position_size = int(risk_amount / risk_per_share) if risk_per_share &gt; 0 else 0\n\n            positions.append({\n                **signal,\n                'position_size': position_size,\n                'risk_amount': risk_amount,\n                'risk_per_share': risk_per_share\n            })\n\n    return positions\n\n# Example usage\naccount_balance = 100000  # $100k account\nrisk_per_trade = 2.0      # 2% risk per trade\n\nsized_positions = calculate_position_sizes(patterns, account_balance, risk_per_trade)\n\nfor pos in sized_positions:\n    if pos['position_size'] &gt; 0:\n        print(f\"Signal: {pos['pattern']}\")\n        print(f\"Entry: ${pos['entry_price']:.2f}\")\n        print(f\"Size: {pos['position_size']} shares\")\n        print(f\"Risk: ${pos['risk_amount']:.2f}\")\n        print(\"---\")\n</code></pre>"},{"location":"user-guide/examples/#real-time-analysis-simulation","title":"Real-Time Analysis Simulation","text":"<pre><code>import time\nfrom datetime import datetime\n\ndef simulate_real_time_analysis(historical_data, interval_seconds=60):\n    \"\"\"Simulate real-time TheStrat analysis with Pydantic models.\"\"\"\n\n    config = FactoryConfig(\n        aggregation=AggregationConfig(target_timeframes=[\"5m\"], asset_class=\"equities\"),\n        indicators=IndicatorsConfig(\n            timeframe_configs=[\n                TimeframeItemConfig(\n                    timeframes=[\"all\"],\n                    swing_points=SwingPointsConfig(window=5, threshold=2.0)\n                )\n            ]\n        )\n    )\n\n    pipeline = Factory.create_all(config)\n\n    # Simulate streaming data\n    for i in range(50, len(historical_data), 5):  # Add 5 bars at a time\n        current_data = historical_data.iloc[:i]\n\n        # Process latest data\n        aggregated = pipeline[\"aggregation\"].process(current_data)\n        analyzed = pipeline[\"indicators\"].process(aggregated)\n\n        # Check for new signals (last bar)\n        if len(analyzed) &gt; 0:\n            latest = analyzed.iloc[-1]\n\n            if latest['inside_bar']:\n                print(f\"{datetime.now()}: Inside bar detected @ {latest['close']:.2f}\")\n            elif latest['outside_bar']:\n                print(f\"{datetime.now()}: Outside bar detected @ {latest['close']:.2f}\")\n\n            # Check for pivot points\n            if latest.get('new_pivot_high', False):\n                print(f\"{datetime.now()}: New Pivot HIGH @ {latest['high']:.2f}\")\n            elif latest.get('new_pivot_low', False):\n                print(f\"{datetime.now()}: New Pivot LOW @ {latest['low']:.2f}\")\n\n        time.sleep(interval_seconds)\n\n# Run simulation (comment out for docs)\n# simulate_real_time_analysis(sample_data, interval_seconds=2)\n</code></pre>"},{"location":"user-guide/examples/#performance-optimization-examples","title":"Performance Optimization Examples","text":""},{"location":"user-guide/examples/#batch-processing","title":"Batch Processing","text":"<pre><code>def batch_process_symbols(symbol_data_dict, config_template):\n    \"\"\"Process multiple symbols efficiently with new API.\"\"\"\n    results = {}\n\n    # Create pipeline once - supports multiple timeframes per symbol\n    pipeline = Factory.create_all(config_template)\n\n    for symbol, data in symbol_data_dict.items():\n        try:\n            # Process each symbol - now handles multiple timeframes\n            aggregated = pipeline[\"aggregation\"].process(data)\n            analyzed = pipeline[\"indicators\"].process(aggregated)\n\n            # Store results with timeframe breakdown\n            results[symbol] = {\n                'data': analyzed,\n                'timeframes': analyzed['timeframe'].unique().tolist(),\n                'inside_bars': analyzed['inside_bar'].sum(),\n                'outside_bars': analyzed['outside_bar'].sum(),\n                'last_price': analyzed.iloc[-1]['close'],\n                'total_bars': len(analyzed)\n            }\n\n            print(f\"Processed {symbol}: {len(analyzed)} bars across {len(analyzed['timeframe'].unique())} timeframes\")\n\n        except Exception as e:\n            print(f\"Error processing {symbol}: {e}\")\n            results[symbol] = None\n\n    return results\n\n# Example usage\nsymbols_data = {\n    'AAPL': aapl_data,\n    'MSFT': msft_data,\n    'GOOGL': googl_data\n}\n\nbatch_results = batch_process_symbols(symbols_data, config)\n</code></pre>"},{"location":"user-guide/examples/#memory-efficient-processing","title":"Memory Efficient Processing","text":"<pre><code>def process_large_dataset(data, chunk_size=1000):\n    \"\"\"Process large datasets in chunks to manage memory with new API.\"\"\"\n\n    config = FactoryConfig(\n        aggregation=AggregationConfig(\n            target_timeframes=[\"5m\"],\n            asset_class=\"equities\"\n        ),\n        indicators=IndicatorsConfig(\n            timeframe_configs=[\n                TimeframeItemConfig(\n                    timeframes=[\"all\"],\n                    swing_points=SwingPointsConfig(window=5)\n                )\n            ]\n        )\n    )\n\n    pipeline = Factory.create_all(config)\n    results = []\n\n    # Process in chunks\n    for start_idx in range(0, len(data), chunk_size):\n        end_idx = min(start_idx + chunk_size, len(data))\n        chunk = data.iloc[start_idx:end_idx]\n\n        # Include overlap for continuity\n        if start_idx &gt; 0:\n            overlap = data.iloc[max(0, start_idx-100):start_idx]\n            chunk = pd.concat([overlap, chunk])\n\n        # Process chunk\n        aggregated = pipeline[\"aggregation\"].process(chunk)\n        analyzed = pipeline[\"indicators\"].process(aggregated)\n\n        # Store results (excluding overlap)\n        if start_idx &gt; 0:\n            analyzed = analyzed.iloc[20:]  # Remove overlap portion\n\n        results.append(analyzed)\n        print(f\"Processed chunk {start_idx//chunk_size + 1}\")\n\n    # Combine results\n    final_result = pd.concat(results, ignore_index=True)\n    return final_result\n</code></pre>"},{"location":"user-guide/examples/#integration-examples","title":"Integration Examples","text":""},{"location":"user-guide/examples/#with-popular-trading-libraries","title":"With Popular Trading Libraries","text":"<pre><code># Integration with backtrader\nimport backtrader as bt\n\nclass TheStratStrategy(bt.Strategy):\n    def __init__(self):\n        self.thestrat_config = FactoryConfig(\n            aggregation=AggregationConfig(\n                target_timeframes=[\"5m\"],\n                asset_class=\"equities\"\n            ),\n            indicators=IndicatorsConfig(\n                timeframe_configs=[\n                    TimeframeItemConfig(\n                        timeframes=[\"all\"],\n                        swing_points=SwingPointsConfig(window=5, threshold=2.0)\n                    )\n                ]\n            )\n        )\n        self.pipeline = Factory.create_all(self.thestrat_config)\n\n    def next(self):\n        # Convert backtrader data to DataFrame\n        data = self.convert_bt_data()\n\n        # Apply TheStrat analysis\n        analyzed = self.pipeline[\"indicators\"].process(\n            self.pipeline[\"aggregation\"].process(data)\n        )\n\n        # Trading logic based on TheStrat signals\n        if analyzed.iloc[-1]['outside_bar'] and not self.position:\n            self.buy()\n        elif analyzed.iloc[-1]['inside_bar'] and self.position:\n            self.close()\n\n# Integration with zipline\nfrom zipline.api import order, record, symbol\n\ndef thestrat_zipline_algo(context, data):\n    # Get price data\n    prices = data.history(symbol('AAPL'), ['open', 'high', 'low', 'close'], 100, '1d')\n\n    # Apply TheStrat with new API\n    config = FactoryConfig(\n        aggregation=AggregationConfig(target_timeframes=[\"1d\"]),\n        indicators=IndicatorsConfig(\n            timeframe_configs=[\n                TimeframeItemConfig(\n                    timeframes=[\"all\"],\n                    swing_points=SwingPointsConfig(window=5)\n                )\n            ]\n        )\n    )\n    pipeline = Factory.create_all(config)\n    aggregated = pipeline[\"aggregation\"].process(prices.reset_index())\n    analyzed = pipeline[\"indicators\"].process(aggregated)\n\n    # Trading decisions\n    if analyzed.iloc[-1]['outside_bar']:\n        order(symbol('AAPL'), 100)\n\n    record(inside_bars=analyzed['inside_bar'].sum())\n</code></pre> <p>These examples demonstrate the flexibility and power of TheStrat for various trading scenarios. Adapt the configurations and logic to match your specific trading strategy and requirements.</p>"},{"location":"user-guide/installation/","title":"Installation","text":"<p>This guide covers how to install the TheStrat module in different environments and scenarios.</p>"},{"location":"user-guide/installation/#prerequisites","title":"Prerequisites","text":"<p>Before installing TheStrat, ensure you have:</p> <ul> <li>Python 3.11 or higher</li> <li>uv package manager (recommended) or pip</li> <li>Git (for development installation)</li> </ul>"},{"location":"user-guide/installation/#installing-uv-recommended","title":"Installing uv (Recommended)","text":"<p>If you don't have <code>uv</code> installed, it's the fastest Python package installer:</p> <pre><code># On macOS and Linux\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# On Windows\npowershell -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n\n# Or with pip\npip install uv\n</code></pre>"},{"location":"user-guide/installation/#installation-options","title":"Installation Options","text":""},{"location":"user-guide/installation/#option-1-direct-installation-recommended","title":"Option 1: Direct Installation (Recommended)","text":"<p>Install directly from the GitHub repository:</p> Install TheStrat<pre><code>uv add git+https://github.com/jlixfeld/thestrat.git\n</code></pre>"},{"location":"user-guide/installation/#option-2-development-installation","title":"Option 2: Development Installation","text":"<p>For development work or to run tests:</p> Development Setup<pre><code># Clone the repository\ngit clone https://github.com/jlixfeld/thestrat.git\ncd thestrat\n\n# Install with development dependencies\nuv sync --extra test --extra dev --extra docs\n</code></pre>"},{"location":"user-guide/installation/#option-3-using-pip","title":"Option 3: Using pip","text":"<p>If you prefer using pip:</p> <pre><code>pip install git+https://github.com/jlixfeld/thestrat.git\n</code></pre>"},{"location":"user-guide/installation/#verify-installation","title":"Verify Installation","text":"<p>Test your installation by importing the module:</p> Verify Installation<pre><code>import thestrat\nprint(f\"TheStrat version: {thestrat.__version__}\")  # Dynamic version from package\n\n# Test basic functionality with Pydantic models\nfrom thestrat import Factory\nfrom thestrat.schemas import (\n    FactoryConfig, AggregationConfig, IndicatorsConfig,\n    TimeframeItemConfig, SwingPointsConfig\n)\n\nconfig = FactoryConfig(\n    aggregation=AggregationConfig(target_timeframes=[\"5m\"]),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"all\"],\n                swing_points=SwingPointsConfig(window=5, threshold=2.0)\n            )\n        ]\n    )\n)\n\ncomponents = Factory.create_all(config)\nprint(\"Installation successful!\")\n</code></pre>"},{"location":"user-guide/installation/#development-setup","title":"Development Setup","text":"<p>If you're planning to contribute or modify the code:</p>"},{"location":"user-guide/installation/#1-clone-and-install","title":"1. Clone and Install","text":"<pre><code>git clone https://github.com/jlixfeld/thestrat.git\ncd thestrat\nuv sync --extra test --extra dev --extra docs\n</code></pre>"},{"location":"user-guide/installation/#2-verify-development-environment","title":"2. Verify Development Environment","text":"<pre><code># Run tests\nuv run pytest\n\n# Check code formatting\nuv run ruff check .\n\n# Format code\nuv run ruff format .\n\n# Build documentation\nuv run mkdocs serve\n</code></pre>"},{"location":"user-guide/installation/#3-run-development-tests","title":"3. Run Development Tests","text":"<p>Verify your development environment:</p> <pre><code># Run all tests\nuv run pytest\n\n# Check code quality\nuv run ruff check .\n</code></pre>"},{"location":"user-guide/installation/#dependencies","title":"Dependencies","text":"<p>TheStrat has the following dependencies:</p>"},{"location":"user-guide/installation/#core-dependencies","title":"Core Dependencies","text":"<ul> <li>polars[timezone] \u22651.0.0 - High-performance data processing</li> <li>pandas \u22651.5.0 - Data manipulation and analysis</li> <li>numpy \u22651.21.0 - Numerical computing</li> <li>pytz \u22652022.1 - Timezone handling</li> </ul>"},{"location":"user-guide/installation/#development-dependencies","title":"Development Dependencies","text":"<ul> <li>pytest \u22656.0 - Testing framework</li> <li>ruff ==0.11.13 - Linting and formatting</li> <li>pytest-cov \u22652.0 - Coverage reporting</li> </ul>"},{"location":"user-guide/installation/#documentation-dependencies","title":"Documentation Dependencies","text":"<ul> <li>mkdocs-material \u22659.4.0 - Documentation theme</li> <li>mkdocstrings[python] \u22650.24.0 - API documentation generation</li> </ul>"},{"location":"user-guide/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-guide/installation/#common-issues","title":"Common Issues","text":"<p>Import Error: <code>ModuleNotFoundError: No module named 'thestrat'</code> :   Ensure you've activated the correct Python environment and the module is installed.</p> <p>Version Conflicts: Dependency resolution errors :   Use <code>uv</code> which has better dependency resolution than pip:     <pre><code>uv add git+https://github.com/jlixfeld/thestrat.git\n</code></pre></p> <p>Permission Errors: Cannot write to installation directory :   Use a virtual environment or user installation:     <pre><code># Create virtual environment\nuv venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\nuv add git+https://github.com/jlixfeld/thestrat.git\n</code></pre></p> <p>Test Failures: Tests failing during development setup :   Ensure you have the test dependencies:     <pre><code>uv sync --extra test\nuv run pytest -v\n</code></pre></p>"},{"location":"user-guide/installation/#getting-help","title":"Getting Help","text":"<p>If you encounter issues not covered here:</p> <ol> <li>Check that all prerequisites are installed</li> <li>Verify your Python version: <code>python --version</code></li> <li>Try creating a fresh virtual environment</li> <li>Contact the maintainer with error details</li> </ol>"},{"location":"user-guide/installation/#next-steps","title":"Next Steps","text":"<p>Once installation is complete, proceed to the Quick Start guide to begin using TheStrat in your applications.</p>"},{"location":"user-guide/quickstart/","title":"Quick Start","text":"<p>Get up and running with TheStrat in just a few minutes. This guide assumes you have already installed the module.</p>"},{"location":"user-guide/quickstart/#basic-workflow","title":"Basic Workflow","text":"<p>TheStrat follows a simple workflow:</p> <ol> <li>Configure your components using the Factory pattern</li> <li>Aggregate your data to the desired timeframe</li> <li>Analyze with TheStrat indicators</li> <li>Extract signals and insights</li> </ol>"},{"location":"user-guide/quickstart/#your-first-thestrat-analysis","title":"Your First TheStrat Analysis","text":"<p>Let's start with a complete example using sample market data:</p> <pre><code>import pandas as pd\nfrom thestrat import Factory\nfrom thestrat.schemas import (\n    FactoryConfig, AggregationConfig, IndicatorsConfig,\n    TimeframeItemConfig, SwingPointsConfig\n)\n\n# Sample OHLCV data (1-minute bars)\nsample_data = pd.DataFrame({\n    'timestamp': pd.date_range('2024-01-01 09:30', periods=100, freq='1min'),\n    'open': [100.0] * 100,\n    'high': [101.0] * 100,\n    'low': [99.0] * 100,\n    'close': [100.5] * 100,\n    'volume': [1000] * 100\n})\n\n# Configure TheStrat components with Pydantic models\nconfig = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"5m\"],  # Aggregate to 5-minute bars (now supports multiple)\n        asset_class=\"equities\",    # US equity market\n        timezone=\"US/Eastern\"      # Eastern timezone\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"all\"],    # Apply to all target timeframes\n                swing_points=SwingPointsConfig(\n                    window=5,            # 5-period swing detection\n                    threshold=2.0        # 2% threshold for significance\n                )\n            )\n        ]\n    )\n)\n\n# Create components using Factory\npipeline = Factory.create_all(config)\n\n# Process the data - now returns normalized output with timeframe column\naggregated_data = pipeline[\"aggregation\"].process(sample_data)\nanalyzed_data = pipeline[\"indicators\"].process(aggregated_data)\n\nprint(f\"Original bars: {len(sample_data)}\")\nprint(f\"Aggregated bars: {len(aggregated_data)}\")\nprint(f\"Analysis complete: {len(analyzed_data)} bars with TheStrat indicators\")\nprint(f\"Timeframes processed: {analyzed_data['timeframe'].unique()}\")\n</code></pre>"},{"location":"user-guide/quickstart/#step-by-step-breakdown","title":"Step-by-Step Breakdown","text":""},{"location":"user-guide/quickstart/#step-1-configure-components","title":"Step 1: Configure Components","text":"<p>The Factory pattern centralizes configuration:</p> <pre><code>from thestrat import Factory\nfrom thestrat.schemas import (\n    FactoryConfig, AggregationConfig, IndicatorsConfig,\n    TimeframeItemConfig, SwingPointsConfig\n)\n\n# Minimal configuration using models\nsimple_config = FactoryConfig(\n    aggregation=AggregationConfig(target_timeframes=[\"5m\"]),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(timeframes=[\"all\"])\n        ]\n    )\n)\n\n# Full configuration with all options\nfull_config = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"5m\", \"15m\"],  # Multiple timeframes supported\n        asset_class=\"equities\",\n        timezone=\"US/Eastern\"\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"5m\"],\n                swing_points=SwingPointsConfig(window=5, threshold=2.0)\n            ),\n            TimeframeItemConfig(\n                timeframes=[\"15m\"],\n                swing_points=SwingPointsConfig(window=7, threshold=3.0)\n            )\n        ]\n    )\n)\n\ncomponents = Factory.create_all(full_config)\n</code></pre>"},{"location":"user-guide/quickstart/#step-2-timeframe-aggregation","title":"Step 2: Timeframe Aggregation","text":"<p>Transform your base timeframe data:</p> <pre><code># Get the aggregation component\naggregator = components[\"aggregation\"]\n\n# Process your 1-minute data into 5-minute bars\nfive_min_bars = aggregator.process(one_minute_data)\n\n# The aggregated data maintains OHLCV structure and includes timeframe column\nprint(five_min_bars.columns)\n# ['timestamp', 'open', 'high', 'low', 'close', 'volume', 'timeframe']\n</code></pre>"},{"location":"user-guide/quickstart/#step-3-apply-thestrat-indicators","title":"Step 3: Apply TheStrat Indicators","text":"<p>Analyze market structure:</p> <pre><code># Get the indicators component\nindicators = components[\"indicators\"]\n\n# Apply TheStrat analysis\nanalyzed = indicators.process(five_min_bars)\n\n# New columns are added for TheStrat metrics\nprint(analyzed.columns)\n# Original OHLCV + TheStrat indicators like:\n# 'inside_bar', 'outside_bar', 'pivot_high', 'pivot_low', etc.\n</code></pre>"},{"location":"user-guide/quickstart/#step-4-extract-insights","title":"Step 4: Extract Insights","text":"<p>Work with the results:</p> <pre><code># Find inside bars\ninside_bars = analyzed[analyzed['inside_bar'] == True]\nprint(f\"Found {len(inside_bars)} inside bars\")\n\n# Find pivot points (pivot_high and pivot_low contain price values, not booleans)\npivot_highs = analyzed[analyzed['new_pivot_high'] == True] if 'new_pivot_high' in analyzed.columns else []\npivot_lows = analyzed[analyzed['new_pivot_low'] == True] if 'new_pivot_low' in analyzed.columns else []\n\nprint(f\"Pivot highs: {len(pivot_highs) if hasattr(pivot_highs, '__len__') else 0}\")\nprint(f\"Pivot lows: {len(pivot_lows) if hasattr(pivot_lows, '__len__') else 0}\")\n\n# Get the latest signals\nlatest_signals = analyzed.tail(10)[['timestamp', 'inside_bar', 'outside_bar']]\nprint(latest_signals)\n</code></pre>"},{"location":"user-guide/quickstart/#asset-class-examples","title":"Asset Class Examples","text":"<p>Different asset classes require different configurations:</p>"},{"location":"user-guide/quickstart/#crypto-247-trading","title":"Crypto (24/7 Trading)","text":"<pre><code>crypto_config = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"1h\"],\n        asset_class=\"crypto\",\n        timezone=\"UTC\"  # Always UTC for crypto\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"all\"],\n                swing_points=SwingPointsConfig(window=5, threshold=2.0)\n            )\n        ]\n    )\n)\n\ncrypto_pipeline = Factory.create_all(crypto_config)\n</code></pre>"},{"location":"user-guide/quickstart/#forex-245-trading","title":"Forex (24/5 Trading)","text":"<pre><code>fx_config = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"4h\"],\n        asset_class=\"fx\",\n        timezone=\"UTC\"  # Always UTC for FX\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"all\"],\n                swing_points=SwingPointsConfig(window=5, threshold=1.0)\n            )\n        ]\n    )\n)\n\nfx_pipeline = Factory.create_all(fx_config)\n</code></pre>"},{"location":"user-guide/quickstart/#common-patterns","title":"Common Patterns","text":""},{"location":"user-guide/quickstart/#multiple-timeframe-analysis","title":"Multiple Timeframe Analysis","text":"<pre><code># Analyze multiple timeframes in a single operation using Pydantic models\nconfig = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"5m\", \"15m\", \"1h\"],  # Process all timeframes together\n        asset_class=\"equities\"\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"5m\"],\n                swing_points=SwingPointsConfig(window=3, threshold=1.5)  # Aggressive for short timeframe\n            ),\n            TimeframeItemConfig(\n                timeframes=[\"15m\", \"1h\"],\n                swing_points=SwingPointsConfig(window=7, threshold=2.5)  # Conservative for longer timeframes\n            )\n        ]\n    )\n)\n\npipeline = Factory.create_all(config)\naggregated = pipeline[\"aggregation\"].process(raw_data)\nanalyzed = pipeline[\"indicators\"].process(aggregated)\n\n# Filter results by timeframe using the normalized output\nfor tf in [\"5m\", \"15m\", \"1h\"]:\n    tf_data = analyzed[analyzed['timeframe'] == tf]\n    print(f\"{tf}: {len(tf_data)} bars, {tf_data['inside_bar'].sum()} inside bars\")\n\nprint(f\"Total analysis: {len(analyzed)} bars across {len(analyzed['timeframe'].unique())} timeframes\")\n</code></pre>"},{"location":"user-guide/quickstart/#signal-detection","title":"Signal Detection","text":"<pre><code># Custom signal detection\ndef find_breakouts(data):\n    \"\"\"Find potential breakout signals\"\"\"\n    breakouts = []\n\n    for i in range(1, len(data)):\n        current = data.iloc[i]\n        previous = data.iloc[i-1]\n\n        # Outside bar followed by continuation\n        if (previous['outside_bar'] and\n            current['close'] &gt; previous['high']):\n            breakouts.append({\n                'timestamp': current['timestamp'],\n                'type': 'bullish_breakout',\n                'price': current['close']\n            })\n\n    return breakouts\n\n# Apply to your analyzed data\nsignals = find_breakouts(analyzed_data)\nprint(f\"Found {len(signals)} breakout signals\")\n</code></pre>"},{"location":"user-guide/quickstart/#next-steps","title":"Next Steps","text":"<p>Now that you understand the basics:</p> <ol> <li>Explore Examples - More detailed use cases and advanced features</li> <li>Review Asset Classes - Understand market-specific behaviors</li> <li>Check API Reference - Detailed documentation of all methods and parameters</li> </ol>"},{"location":"user-guide/quickstart/#common-questions","title":"Common Questions","text":"<p>Q: What timeframes are supported? A: Standard timeframes: 1m, 5m, 15m, 30m, 1h, 4h, 1d. Custom intervals can be configured.</p> <p>Q: Can I use my own data format? A: Yes, as long as it has OHLCV columns and a timestamp. The data will be automatically standardized.</p> <p>Q: How do I handle missing data? A: TheStrat includes built-in handling for gaps and missing bars appropriate to each asset class.</p> <p>Q: Can I backtest strategies? A: TheStrat provides the analysis foundation. You'll need to combine it with your backtesting framework.</p>"}]}