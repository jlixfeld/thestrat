{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"TheStrat Documentation","text":"<p>A Python module for financial data aggregation and technical analysis using #TheStrat methodology.</p> <p>Primary Focus: US Equities</p> <p>This library is primarily developed and tested for US Equities analysis. While crypto, forex, and futures are supported via configuration, they are not actively tested or used in production. All examples and documentation focus on US Equities use cases.</p>"},{"location":"#overview","title":"Overview","text":"<p>TheStrat provides a comprehensive framework for implementing the #TheStrat trading methodology in Python. It offers high-performance timeframe aggregation, complete technical indicators, and robust support for multiple asset classes.</p>"},{"location":"#key-features","title":"Key Features","text":"<p> Multi-Timeframe Aggregation</p> <p>OHLCV data aggregation across multiple timeframes simultaneously with timezone handling</p> <p> #TheStrat Indicators</p> <p>Complete implementation of TheStrat technical indicators with per-timeframe configurations</p> <p> Multi-Asset Support</p> <p>US Equities (primary focus), with additional support for crypto and FX timezone alignment</p> <p> Factory Pattern</p> <p>Clean component creation and configuration management</p> <p> High Performance</p> <p>Vectorized operations using Polars and Pandas for optimal speed</p> <p> Comprehensive Testing</p> <p>High test coverage with 190+ tests ensuring reliability</p>"},{"location":"#quick-example","title":"Quick Example","text":"Basic TheStrat Usage with Pydantic Models<pre><code>from thestrat import Factory\nfrom thestrat.schemas import (\n    FactoryConfig, AggregationConfig, IndicatorsConfig,\n    TimeframeItemConfig, SwingPointsConfig\n)\n\n# Configure your pipeline with Pydantic models\nconfig = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"5min\", \"15min\"],  # Multiple timeframes supported\n        asset_class=\"equities\",\n        timezone=\"US/Eastern\"\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"5min\"],\n                swing_points=SwingPointsConfig(window=3, threshold=1.5)  # Short-term settings\n            ),\n            TimeframeItemConfig(\n                timeframes=[\"15min\"],\n                swing_points=SwingPointsConfig(window=7, threshold=2.5)  # Long-term settings\n            )\n        ]\n    )\n)\n\n# Create and use components\npipeline = Factory.create_all(config)\naggregated = pipeline[\"aggregation\"].process(market_data)\nanalyzed = pipeline[\"indicators\"].process(aggregated)\n\nprint(f\"Processed {len(analyzed)} bars with TheStrat indicators\")\nprint(f\"Timeframes: {analyzed['timeframe'].unique()}\")\n</code></pre>"},{"location":"#core-components","title":"Core Components","text":"Component Purpose Features Aggregation OHLCV timeframe aggregation Timezone handling, simultaneous multi-timeframe processing Indicators TheStrat technical indicators Inside/Outside bars, Swing points, per-timeframe configurations Factory Component creation Validation, configuration management Schemas Configuration models Pydantic validation, comprehensive documentation"},{"location":"#supported-markets","title":"Supported Markets","text":"Equities (Primary)Crypto (Supported)Forex (Supported) <ul> <li>US Equities (actively tested and used)</li> <li>Session-aligned aggregation via configurable <code>session_start</code> offset</li> <li>Configurable timezones (default: US/Eastern)</li> <li>Note: No explicit pre/post-market gating or holiday calendars</li> </ul> <ul> <li>24/7 trading support</li> <li>UTC timezone enforcement</li> <li>Continuous aggregation</li> <li>Not actively tested - treat as illustrative</li> </ul> <ul> <li>24/5 alignment with UTC</li> <li>UTC timezone enforcement</li> <li>Weekend gaps appear in price data as-is</li> <li>Not actively tested - treat as illustrative</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<p>Ready to implement #TheStrat in your trading system?</p> <p>Get Started with Installation View API Reference</p>"},{"location":"#project-status","title":"Project Status","text":"<p>This project is under active development with comprehensive test coverage and strict code quality standards.</p>"},{"location":"developer-guide/","title":"Developer Guide","text":"<p>Welcome to the TheStrat developer guide. This section provides comprehensive information for contributors and developers working with the TheStrat codebase.</p>"},{"location":"developer-guide/#for-maintainers","title":"For Maintainers","text":"<p>This project is currently private. Contact the author for access and contribution guidelines.</p>"},{"location":"developer-guide/#architecture-overview","title":"Architecture Overview","text":"<p>TheStrat follows a modular design with clear separation of concerns:</p>"},{"location":"developer-guide/#core-components","title":"Core Components","text":"<ul> <li>Factory - Component creation and configuration management</li> <li>Aggregation - OHLCV timeframe data processing</li> <li>Indicators - TheStrat technical analysis implementation</li> <li>Schemas - Configuration models and validation</li> </ul>"},{"location":"developer-guide/#design-patterns","title":"Design Patterns","text":"<ul> <li>Factory Pattern - Centralized component creation with validation</li> <li>Abstract Base Classes - Consistent interfaces across components</li> <li>Configuration-Driven - Flexible behavior through configuration objects</li> <li>Functional Programming - Immutable data transformations where possible</li> </ul>"},{"location":"developer-guide/#quick-development-setup","title":"Quick Development Setup","text":"<pre><code># Clone repository\ngit clone https://github.com/jlixfeld/thestrat.git\ncd thestrat\n\n# Install all development dependencies\nuv sync --extra test --extra dev --extra docs\n\n# Verify installation\nuv run pytest\nuv run ruff check .\nuv run mkdocs serve\n</code></pre>"},{"location":"developer-guide/#guide-sections","title":"Guide Sections","text":""},{"location":"developer-guide/#contributing","title":"Contributing","text":"<p>Guidelines for making contributions, code style, and pull request process.</p>"},{"location":"developer-guide/#development-workflow","title":"Development Workflow","text":"<ol> <li>Setup - Install dependencies and verify environment</li> <li>Development - Write code following project conventions</li> <li>Testing - Ensure comprehensive test coverage</li> <li>Documentation - Update docs for any API changes</li> <li>Quality - Run linting and formatting tools</li> <li>Review - Submit changes for review</li> </ol>"},{"location":"developer-guide/#code-quality-standards","title":"Code Quality Standards","text":"<ul> <li>Test Coverage: Maintain &gt;95% coverage</li> <li>Code Formatting: Automated with Ruff</li> <li>Type Hints: Required for all public APIs</li> <li>Documentation: Comprehensive docstrings</li> <li>Performance: Benchmarked critical paths</li> </ul>"},{"location":"developer-guide/#technology-stack","title":"Technology Stack","text":"<ul> <li>Python 3.11+ - Modern Python features</li> <li>Polars - High-performance data processing</li> <li>Pandas - Legacy support and interoperability</li> <li>Pytest - Testing framework</li> <li>Ruff - Linting and formatting</li> <li>MkDocs Material - Documentation</li> </ul>"},{"location":"developer-guide/#getting-help","title":"Getting Help","text":"<p>For development questions:</p> <ol> <li>Check existing documentation</li> <li>Review test cases for examples</li> <li>Contact the maintainer directly</li> </ol>"},{"location":"developer-guide/#project-status","title":"Project Status","text":"<p>Version: 1.0.1 - Production/Stable Maintenance: Active development License: Private - All rights reserved</p>"},{"location":"developer-guide/contributing/","title":"Contributing","text":"<p>Thank you for your interest in contributing to TheStrat! This guide outlines the process for making contributions to this private project.</p>"},{"location":"developer-guide/contributing/#getting-access","title":"Getting Access","text":"<p>This is a private module. Contact the author at <code>nominal_choroid0y@icloud.com</code> for:</p> <ul> <li>Access to the repository</li> <li>Contribution guidelines</li> <li>Development discussions</li> <li>Feature requests</li> </ul>"},{"location":"developer-guide/contributing/#development-setup","title":"Development Setup","text":"<p>Once you have access, set up your development environment:</p>"},{"location":"developer-guide/contributing/#1-clone-and-install","title":"1. Clone and Install","text":"<pre><code>git clone https://github.com/jlixfeld/thestrat.git\ncd thestrat\n\n# Install with all extras\nuv sync --extra test --extra dev --extra docs\n</code></pre>"},{"location":"developer-guide/contributing/#2-verify-setup","title":"2. Verify Setup","text":"<pre><code># Run tests\nuv run pytest\n\n# Check formatting\nuv run ruff format --check .\n\n# Check linting\nuv run ruff check .\n\n# Test documentation build\nuv run mkdocs serve\n</code></pre>"},{"location":"developer-guide/contributing/#3-run-quality-checks","title":"3. Run Quality Checks","text":"<pre><code># Check code quality\nuv run ruff check .\nuv run ruff format --check .\n</code></pre>"},{"location":"developer-guide/contributing/#code-standards","title":"Code Standards","text":""},{"location":"developer-guide/contributing/#code-style","title":"Code Style","text":"<p>We use Ruff for both linting and formatting:</p> <pre><code># Format code\nuv run ruff format .\n\n# Check linting\nuv run ruff check .\n\n# Auto-fix issues\nuv run ruff check --fix .\n</code></pre> <p>Configuration (already in <code>pyproject.toml</code>): - Line length: 120 characters - Quote style: Double quotes - Python target: 3.11+</p>"},{"location":"developer-guide/contributing/#type-hints","title":"Type Hints","text":"<p>All public APIs must include type hints:</p> <pre><code># Good\ndef process_data(data: PandasDataFrame, config: dict) -&gt; PandasDataFrame:\n    \"\"\"Process market data with configuration.\"\"\"\n    return data\n\n# Bad\ndef process_data(data, config):\n    return data\n</code></pre>"},{"location":"developer-guide/contributing/#documentation","title":"Documentation","text":"<p>Docstring Style: Use Google-style docstrings:</p> <pre><code>def aggregate_timeframe(data: PandasDataFrame, timeframe: str) -&gt; PandasDataFrame:\n    \"\"\"Aggregate OHLCV data to specified timeframe.\n\n    Args:\n        data: Input OHLCV DataFrame with required columns\n        timeframe: Target timeframe (e.g., '5m', '1h', '1d')\n\n    Returns:\n        Aggregated DataFrame with same schema as input\n\n    Raises:\n        ValueError: If required columns are missing\n\n    Example:\n        &gt;&gt;&gt; data = PandasDataFrame(...)\n        &gt;&gt;&gt; result = aggregate_timeframe(data, '5m')\n        &gt;&gt;&gt; len(result) &lt; len(data)  # Fewer bars after aggregation\n        True\n    \"\"\"\n</code></pre> <p>API Documentation: All public methods need comprehensive docstrings that will be included in the generated API documentation.</p>"},{"location":"developer-guide/contributing/#testing-requirements","title":"Testing Requirements","text":""},{"location":"developer-guide/contributing/#test-coverage","title":"Test Coverage","text":"<p>Maintain &gt;95% test coverage:</p> <pre><code># Run with coverage\nuv run pytest --cov=thestrat --cov-report=html\n\n# View coverage report\nopen htmlcov/index.html\n</code></pre>"},{"location":"developer-guide/contributing/#test-categories","title":"Test Categories","text":"<p>We use pytest markers to categorize tests:</p> <pre><code>import pytest\n\n@pytest.mark.unit\ndef test_aggregation_logic():\n    \"\"\"Unit test for aggregation logic.\"\"\"\n    pass\n\n@pytest.mark.integration\ndef test_full_pipeline():\n    \"\"\"Integration test for complete pipeline.\"\"\"\n    pass\n</code></pre> <p>Run specific categories:</p> <pre><code># Unit tests only\nuv run pytest -m unit\n\n# Integration tests only\nuv run pytest -m integration\n\n# All tests\nuv run pytest\n</code></pre>"},{"location":"developer-guide/contributing/#writing-tests","title":"Writing Tests","text":"<p>Test Structure: Follow the Arrange-Act-Assert pattern:</p> <pre><code>def test_timeframe_aggregation():\n    # Arrange\n    input_data = create_sample_ohlcv_data()\n    expected_bars = 20\n\n    # Act\n    result = aggregate_timeframe(input_data, '5m')\n\n    # Assert\n    assert len(result) == expected_bars\n    assert all(col in result.columns for col in REQUIRED_COLUMNS)\n</code></pre> <p>Test Data: Use fixtures for reusable test data:</p> <pre><code>@pytest.fixture\ndef sample_ohlcv():\n    \"\"\"Sample OHLCV data for testing.\"\"\"\n    return PandasDataFrame({\n        'timestamp': pd.date_range('2024-01-01', periods=100, freq='1min'),\n        'open': [100.0] * 100,\n        'high': [101.0] * 100,\n        'low': [99.0] * 100,\n        'close': [100.5] * 100,\n        'volume': [1000] * 100,\n        'timeframe': ['1min'] * 100\n    })\n</code></pre>"},{"location":"developer-guide/contributing/#contribution-workflow","title":"Contribution Workflow","text":""},{"location":"developer-guide/contributing/#1-create-feature-branch","title":"1. Create Feature Branch","text":"<pre><code># From main branch\ngit checkout main\ngit pull origin main\n\n# Create feature branch\ngit checkout -b feature/your-feature-name\n</code></pre>"},{"location":"developer-guide/contributing/#2-make-changes","title":"2. Make Changes","text":"<ul> <li>Write code following our standards</li> <li>Add comprehensive tests</li> <li>Update documentation if needed</li> <li>Ensure all tests pass</li> </ul>"},{"location":"developer-guide/contributing/#3-quality-checks","title":"3. Quality Checks","text":"<p>Before committing, run full quality checks:</p> <pre><code># Format code\nuv run ruff format .\n\n# Check linting\nuv run ruff check .\n\n# Run full test suite\nuv run pytest --cov=thestrat\n\n# Test documentation\nuv run mkdocs build\n</code></pre>"},{"location":"developer-guide/contributing/#4-commit-changes","title":"4. Commit Changes","text":"<p>Use conventional commit messages:</p> <pre><code># Feature\ngit commit -m \"feat: add multi-timeframe aggregation support\"\n\n# Bug fix\ngit commit -m \"fix: handle missing volume data in aggregation\"\n\n# Documentation\ngit commit -m \"docs: add examples for forex analysis\"\n\n# Tests\ngit commit -m \"test: add integration tests for factory pattern\"\n</code></pre>"},{"location":"developer-guide/contributing/#5-push-and-create-pr","title":"5. Push and Create PR","text":"<pre><code>git push origin feature/your-feature-name\n</code></pre> <p>Then create a pull request with: - Clear description of changes - Link to any related issues - Test coverage report - Documentation updates</p>"},{"location":"developer-guide/contributing/#review-process","title":"Review Process","text":"<p>All contributions go through code review:</p> <ol> <li>Automated Checks: CI runs tests, linting, coverage</li> <li>Manual Review: Code quality, design, documentation</li> <li>Testing: Functionality and edge cases</li> <li>Documentation: API docs and user guides updated</li> </ol>"},{"location":"developer-guide/contributing/#areas-for-contribution","title":"Areas for Contribution","text":"<p>Current focus areas (contact maintainer for details):</p> <ul> <li>Performance Optimization: Polars-first implementations</li> <li>Additional Indicators: Extended TheStrat patterns</li> <li>Asset Class Support: New market types</li> <li>Testing: Edge cases and integration scenarios</li> <li>Documentation: More examples and tutorials</li> </ul>"},{"location":"developer-guide/contributing/#release-process","title":"Release Process","text":"<p>Releases follow semantic versioning:</p> <ul> <li>Patch (1.0.1): Bug fixes, documentation</li> <li>Minor (1.1.0): New features, backwards compatible</li> <li>Major (2.0.0): Breaking changes</li> </ul>"},{"location":"developer-guide/contributing/#getting-help","title":"Getting Help","text":"<p>For contribution questions:</p> <ol> <li>Documentation: Check existing docs and examples</li> <li>Issues: Search existing issues and discussions</li> <li>Contact: Email the maintainer directly</li> <li>Code Review: Learn from existing PR reviews</li> </ol>"},{"location":"developer-guide/contributing/#license","title":"License","text":"<p>All contributions are subject to the project's private license. By contributing, you agree that your contributions will be licensed under the same terms.</p> <p>Thank you for helping make TheStrat better!</p>"},{"location":"reference/","title":"API Reference","text":"<p>Complete API documentation for all TheStrat components.</p>"},{"location":"reference/#core-modules","title":"Core Modules","text":"Module Description aggregation OHLCV timeframe aggregation indicators TheStrat technical indicators signals Signal processing and metadata factory Component creation with factory pattern schemas Pydantic configuration schemas base Abstract base classes"},{"location":"reference/#quick-navigation","title":"Quick Navigation","text":"<ul> <li>Factory - Start here for component creation</li> <li>Schemas - Configuration models and validation</li> <li>Aggregation - Timeframe data processing</li> <li>Indicators - TheStrat analysis functions</li> <li>Base - Abstract base classes</li> </ul>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>thestrat<ul> <li>aggregation</li> <li>indicators</li> <li>signals</li> <li>factory</li> <li>schemas</li> <li>base</li> </ul> </li> </ul>"},{"location":"reference/thestrat/","title":"Thestrat","text":"<p>TheStrat package root</p>"},{"location":"reference/thestrat/#thestrat","title":"thestrat","text":"<p>TheStrat Python Module</p> <p>Standalone module for vectorized Strat technical analysis and OHLC timeframe aggregation. Supports historical and real-time market data processing across all asset classes.</p> <p>Modules:</p> Name Description <code>aggregation</code> <p>OHLC timeframe aggregation with precise time boundary control.</p> <code>base</code> <p>Base component classes for TheStrat module.</p> <code>factory</code> <p>Factory pattern for TheStrat component creation and configuration.</p> <code>indicators</code> <p>Vectorized Strat technical indicators implementation.</p> <code>precision</code> <p>Security-aware precision utilities for indicator field rounding.</p> <code>schemas</code> <p>Pydantic schema models for TheStrat configuration validation.</p> <code>signals</code> <p>Signal metadata implementation for TheStrat trading system.</p> <p>Classes:</p> Name Description <code>Aggregation</code> <p>Convert OHLC data between timeframes with precise time boundary control.</p> <code>AggregationConfig</code> <p>Complete configuration for aggregation component with market-aware settings.</p> <code>Component</code> <p>Base class for all TheStrat components.</p> <code>Factory</code> <p>Factory class for creating TheStrat components.</p> <code>FactoryConfig</code> <p>Root configuration for Factory.create_all method with complete pipeline setup.</p> <code>GapDetectionConfig</code> <p>Configuration for gap detection with comprehensive threshold documentation.</p> <code>IndicatorSchema</code> <p>Complete Indicator Schema</p> <code>Indicators</code> <p>Vectorized implementation of all Strat technical indicators.</p> <code>IndicatorsConfig</code> <p>Complete configuration for indicators component with per-timeframe settings.</p> <code>PrecisionError</code> <p>Raised when precision cannot be determined.</p> <code>PriceChange</code> <p>Track changes to stop/target prices.</p> <code>SignalBias</code> <p>Signal directional bias.</p> <code>SignalCategory</code> <p>Signal categorization types.</p> <code>SignalMetadata</code> <p>Complete signal metadata with change tracking and serialization.</p> <code>SignalStatus</code> <p>Signal lifecycle status.</p> <code>SwingPointsConfig</code> <p>Configuration for swing point detection with comprehensive parameter documentation.</p> <code>TimeframeItemConfig</code> <p>Configuration for a single timeframe item with flexible timeframe targeting.</p> <p>Functions:</p> Name Description <code>apply_precision</code> <p>Apply security-aware precision rounding to indicator DataFrame.</p> <code>get_comparison_tolerance</code> <p>Get comparison tolerance for a field based on its precision.</p> <code>get_field_decimal_places</code> <p>Get decimal places for a field based on its precision type.</p> <code>get_field_precision_type</code> <p>Get precision type for a field from IndicatorSchema metadata.</p>"},{"location":"reference/thestrat/#thestrat.Aggregation","title":"Aggregation","text":"<pre><code>Aggregation(config: AggregationConfig)\n</code></pre> <p>               Bases: <code>Component</code></p> <p>Convert OHLC data between timeframes with precise time boundary control.</p> Features <ul> <li>Time Boundary Control: hour_boundary flag for hourly+ aggregation alignment</li> <li>Session Control: session_start parameter for sub-hourly alignment</li> <li>Asset Class Support: Crypto, equities, FX, futures with timezone handling</li> <li>Vectorized Processing: Pure Polars operations for maximum performance</li> </ul> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>AggregationConfig</code> <p>Validated AggregationConfig containing all configuration settings</p> required <p>Methods:</p> Name Description <code>normalize_timezone</code> <p>Convert timestamps to target timezone.</p> <code>process</code> <p>Convert OHLC data to target timeframes with boundary alignment.</p> <code>validate_input</code> <p>Validate input data format.</p> <code>validate_input_timezones</code> <p>Validate and log timezone information for input data.</p> Source code in <code>thestrat/aggregation.py</code> <pre><code>def __init__(self, config: AggregationConfig):\n    \"\"\"\n    Initialize aggregation component with validated configuration.\n\n    Args:\n        config: Validated AggregationConfig containing all configuration settings\n    \"\"\"\n    super().__init__()\n\n    # Store the validated Pydantic config\n    self.config = config\n\n    # Extract commonly used values for convenience\n    self.target_timeframes = config.target_timeframes.copy()\n    self.asset_class = config.asset_class\n\n    # These fields are guaranteed to be non-None after model validation\n    assert config.timezone is not None\n    assert config.session_start is not None\n    assert config.hour_boundary is not None\n\n    self.timezone = config.timezone\n    self.session_start = config.session_start\n    self.hour_boundary = config.hour_boundary\n\n    # Validate all timeframes\n    from .schemas import TimeframeConfig\n\n    for tf in self.target_timeframes:\n        if not TimeframeConfig.validate_timeframe(tf):\n            raise ValueError(\n                f\"Invalid timeframe '{tf}'. Supported timeframes: {sorted(TimeframeConfig.TIMEFRAME_METADATA.keys())}\"\n            )\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Aggregation.normalize_timezone","title":"normalize_timezone","text":"<pre><code>normalize_timezone(data: DataFrame) -&gt; DataFrame\n</code></pre> <p>Convert timestamps to target timezone.</p> <p>Handles both naive and timezone-aware timestamps: - Naive: Assumes already in target timezone, adds timezone awareness - Aware (different): Converts from current timezone to target timezone - Aware (same): No conversion needed</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>Input DataFrame with timestamp column</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with timezone-aware timestamps in target timezone</p> Source code in <code>thestrat/aggregation.py</code> <pre><code>def normalize_timezone(self, data: PolarsDataFrame) -&gt; PolarsDataFrame:\n    \"\"\"\n    Convert timestamps to target timezone.\n\n    Handles both naive and timezone-aware timestamps:\n    - Naive: Assumes already in target timezone, adds timezone awareness\n    - Aware (different): Converts from current timezone to target timezone\n    - Aware (same): No conversion needed\n\n    Args:\n        data: Input DataFrame with timestamp column\n\n    Returns:\n        DataFrame with timezone-aware timestamps in target timezone\n    \"\"\"\n    df = data.clone()\n\n    ts_dtype = df.schema[\"timestamp\"]\n\n    # Extract timezone from dtype metadata (None if naive)\n    current_tz = ts_dtype.time_zone if hasattr(ts_dtype, \"time_zone\") else None\n\n    if current_tz is None:\n        # Naive timestamps - assume already in target timezone, add awareness\n        df = df.with_columns([col(\"timestamp\").dt.replace_time_zone(self.timezone)])\n    elif current_tz != self.timezone:\n        # Timezone-aware but different - CONVERT to target timezone\n        df = df.with_columns([col(\"timestamp\").dt.convert_time_zone(self.timezone)])\n    # else: Already in target timezone, no conversion needed\n\n    return df\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Aggregation.process","title":"process","text":"<pre><code>process(data: DataFrame | DataFrame) -&gt; DataFrame\n</code></pre> <p>Convert OHLC data to target timeframes with boundary alignment.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | DataFrame</code> <p>Input DataFrame with OHLC data including MANDATORY timeframe column</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>Aggregated OHLC DataFrame with consistent column ordering</p> Source code in <code>thestrat/aggregation.py</code> <pre><code>def process(self, data: PolarsDataFrame | PandasDataFrame) -&gt; PolarsDataFrame:\n    \"\"\"\n    Convert OHLC data to target timeframes with boundary alignment.\n\n    Args:\n        data: Input DataFrame with OHLC data including MANDATORY timeframe column\n\n    Returns:\n        Aggregated OHLC DataFrame with consistent column ordering\n    \"\"\"\n    if not self.validate_input(data):\n        raise ValueError(\"Input data validation failed\")\n\n    df = self._convert_to_polars(data)\n\n    # Validate and log timezone information\n    self.validate_input_timezones(df)\n\n    # Convert timestamps to target timezone\n    df = self.normalize_timezone(df)\n\n    # Process the timeframe data (timeframe column is mandatory)\n    return self._process_timeframes(df)\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Aggregation.validate_input","title":"validate_input","text":"<pre><code>validate_input(data: DataFrame | DataFrame) -&gt; bool\n</code></pre> <p>Validate input data format.</p> Source code in <code>thestrat/aggregation.py</code> <pre><code>def validate_input(self, data: PolarsDataFrame | PandasDataFrame) -&gt; bool:\n    \"\"\"Validate input data format.\"\"\"\n    df = self._convert_to_polars(data)\n\n    from .schemas import IndicatorSchema, TimeframeConfig\n\n    # Check all required columns (including mandatory timeframe)\n    required_cols = IndicatorSchema.get_required_input_columns()\n    missing_cols = [col for col in required_cols if col not in df.columns]\n\n    if missing_cols:\n        print(f\"ERROR: Missing required columns: {missing_cols}\")\n        return False\n\n    # Validate timeframe values\n    unique_timeframes = df[\"timeframe\"].unique().to_list()\n    for tf in unique_timeframes:\n        if not TimeframeConfig.validate_timeframe(tf):\n            print(f\"ERROR: Invalid timeframe '{tf}'\")\n            return False\n\n    # Check for minimum data points\n    if len(df) &lt; 2:\n        print(f\"ERROR: Insufficient data points ({len(df)} &lt; 2)\")\n        return False\n\n    return True\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Aggregation.validate_input_timezones","title":"validate_input_timezones","text":"<pre><code>validate_input_timezones(data: DataFrame) -&gt; None\n</code></pre> <p>Validate and log timezone information for input data.</p> <p>Performs O(1) timezone detection using Polars dtype metadata and logs helpful warnings/guidance for users about timezone handling.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>Input DataFrame with timestamp column</p> required Note <p>This method uses Polars schema metadata (O(1)) rather than scanning rows, as Polars enforces homogeneous column types - all timestamps in a column share the same timezone (or all are naive).</p> Source code in <code>thestrat/aggregation.py</code> <pre><code>def validate_input_timezones(self, data: PolarsDataFrame) -&gt; None:\n    \"\"\"\n    Validate and log timezone information for input data.\n\n    Performs O(1) timezone detection using Polars dtype metadata and logs\n    helpful warnings/guidance for users about timezone handling.\n\n    Args:\n        data: Input DataFrame with timestamp column\n\n    Note:\n        This method uses Polars schema metadata (O(1)) rather than scanning\n        rows, as Polars enforces homogeneous column types - all timestamps\n        in a column share the same timezone (or all are naive).\n    \"\"\"\n    ts_dtype = data.schema[\"timestamp\"]\n\n    # Extract timezone from dtype metadata (None if naive)\n    current_tz = ts_dtype.time_zone if hasattr(ts_dtype, \"time_zone\") else None\n\n    if current_tz is None:\n        # Naive timestamps - warn user and provide conversion example\n        first_row_preview = data[0] if len(data) &gt; 0 else \"No data\"\n        logging.warning(\n            f\"Naive timestamps detected - assuming data is already in {self.timezone}\\n\"\n            f\"First row: {first_row_preview}\\n\"\n            f\"If your data is UTC from database, convert before feeding to Factory:\\n\"\n            f\"  df = df.with_columns(\\n\"\n            f\"      pl.col('timestamp')\\n\"\n            f\"        .dt.replace_time_zone('UTC')\\n\"\n            f\"        .dt.convert_time_zone('{self.timezone}')\\n\"\n            f\"  )\"\n        )\n    elif current_tz != self.timezone:\n        # Timezone-aware but different from target - will be converted\n        first_row_preview = data[0] if len(data) &gt; 0 else \"No data\"\n        logging.info(f\"Converting timestamps from {current_tz} to {self.timezone}\\nFirst row: {first_row_preview}\")\n</code></pre>"},{"location":"reference/thestrat/#thestrat.AggregationConfig","title":"AggregationConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Complete configuration for aggregation component with market-aware settings.</p> <p>Methods:</p> Name Description <code>apply_asset_class_defaults</code> <p>Apply AssetClassConfig defaults for timezone, hour_boundary, and session_start.</p> <code>validate_and_expand_target_timeframes</code> <p>Validate target_timeframes field and expand 'all' keyword.</p>"},{"location":"reference/thestrat/#thestrat.AggregationConfig.apply_asset_class_defaults","title":"apply_asset_class_defaults  <code>classmethod</code>","text":"<pre><code>apply_asset_class_defaults(data: Any) -&gt; Any\n</code></pre> <p>Apply AssetClassConfig defaults for timezone, hour_boundary, and session_start.</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@model_validator(mode=\"before\")\n@classmethod\ndef apply_asset_class_defaults(cls, data: Any) -&gt; Any:\n    \"\"\"Apply AssetClassConfig defaults for timezone, hour_boundary, and session_start.\"\"\"\n    if not isinstance(data, dict):\n        return data\n\n    # Get asset class, default to \"equities\"\n    asset_class = data.get(\"asset_class\", \"equities\")\n    asset_config = AssetClassConfig.get_config(asset_class)\n\n    # Force UTC timezone for crypto and fx regardless of input\n    if asset_class in [\"crypto\", \"fx\"]:\n        data[\"timezone\"] = \"UTC\"\n    elif \"timezone\" not in data or data[\"timezone\"] is None:\n        data[\"timezone\"] = asset_config.timezone\n\n    # Apply other defaults only if fields are not provided or are None\n    if \"hour_boundary\" not in data or data[\"hour_boundary\"] is None:\n        data[\"hour_boundary\"] = asset_config.hour_boundary\n    if \"session_start\" not in data or data[\"session_start\"] is None:\n        data[\"session_start\"] = asset_config.session_start\n\n    return data\n</code></pre>"},{"location":"reference/thestrat/#thestrat.AggregationConfig.validate_and_expand_target_timeframes","title":"validate_and_expand_target_timeframes  <code>classmethod</code>","text":"<pre><code>validate_and_expand_target_timeframes(\n    target_timeframes: list[str],\n) -&gt; list[str]\n</code></pre> <p>Validate target_timeframes field and expand 'all' keyword.</p> <p>This Pydantic field validator is automatically called when AggregationConfig is instantiated. It validates individual timeframes and expands ['all'] to all supported timeframes.</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@field_validator(\"target_timeframes\")\n@classmethod\ndef validate_and_expand_target_timeframes(cls, target_timeframes: list[str]) -&gt; list[str]:\n    \"\"\"\n    Validate target_timeframes field and expand 'all' keyword.\n\n    This Pydantic field validator is automatically called when AggregationConfig\n    is instantiated. It validates individual timeframes and expands ['all'] to\n    all supported timeframes.\n    \"\"\"\n    if not target_timeframes:\n        raise ValueError(\"target_timeframes cannot be empty\")\n\n    # Check for 'all' keyword\n    if \"all\" in target_timeframes:\n        if len(target_timeframes) &gt; 1:\n            raise ValueError(\"'all' cannot be combined with specific timeframes\")\n        # Expand to all supported timeframes\n        return list(TimeframeConfig.TIMEFRAME_METADATA.keys())\n\n    # Validate each specific timeframe\n    for i, timeframe in enumerate(target_timeframes):\n        if not isinstance(timeframe, str) or not timeframe.strip():\n            raise ValueError(f\"target_timeframes[{i}] must be a non-empty string\")\n\n        # Validate timeframe format using TimeframeConfig\n        if not TimeframeConfig.validate_timeframe(timeframe):\n            raise ValueError(f\"Invalid timeframe '{timeframe}'\")\n\n    return target_timeframes\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Component","title":"Component","text":"<pre><code>Component()\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Base class for all TheStrat components.</p> <p>Methods:</p> Name Description <code>process</code> <p>Process data and return Polars DataFrame results.</p> <code>validate_input</code> <p>Validate input data format.</p> Source code in <code>thestrat/base.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize base component with metadata tracking.\"\"\"\n    from datetime import datetime\n\n    self._created_at = datetime.now()\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Component.process","title":"process  <code>abstractmethod</code>","text":"<pre><code>process(data: DataFrame | DataFrame) -&gt; DataFrame\n</code></pre> <p>Process data and return Polars DataFrame results.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | DataFrame</code> <p>Input DataFrame (Polars or Pandas)</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>Processed PolarsDataFrame with results</p> Source code in <code>thestrat/base.py</code> <pre><code>@abstractmethod\ndef process(self, data: PolarsDataFrame | PandasDataFrame) -&gt; PolarsDataFrame:\n    \"\"\"\n    Process data and return Polars DataFrame results.\n\n    Args:\n        data: Input DataFrame (Polars or Pandas)\n\n    Returns:\n        Processed PolarsDataFrame with results\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Component.validate_input","title":"validate_input  <code>abstractmethod</code>","text":"<pre><code>validate_input(data: DataFrame | DataFrame) -&gt; None\n</code></pre> <p>Validate input data format.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | DataFrame</code> <p>Input DataFrame to validate</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If data format is invalid, with specific error message</p> Source code in <code>thestrat/base.py</code> <pre><code>@abstractmethod\ndef validate_input(self, data: PolarsDataFrame | PandasDataFrame) -&gt; None:\n    \"\"\"\n    Validate input data format.\n\n    Args:\n        data: Input DataFrame to validate\n\n    Raises:\n        ValueError: If data format is invalid, with specific error message\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Factory","title":"Factory","text":"<p>Factory class for creating TheStrat components.</p> <p>Provides static methods for creating individual components and class methods for creating complete processing pipelines. All methods accept validated Pydantic configuration models.</p> <p>Methods:</p> Name Description <code>create_aggregation</code> <p>Create aggregation component from validated configuration.</p> <code>create_all</code> <p>Create complete processing pipeline with aggregation and indicators.</p> <code>create_indicators</code> <p>Create indicators component from validated configuration.</p> <code>get_asset_class_config</code> <p>Get default configuration for specific asset class.</p> <code>get_supported_asset_classes</code> <p>Get list of supported asset classes.</p> <code>get_supported_timeframes</code> <p>Get list of all supported timeframes in chronological order.</p> <code>get_timeframe_metadata</code> <p>Get detailed metadata for a specific timeframe.</p>"},{"location":"reference/thestrat/#thestrat.Factory.create_aggregation","title":"create_aggregation  <code>staticmethod</code>","text":"<pre><code>create_aggregation(config: AggregationConfig) -&gt; Aggregation\n</code></pre> <p>Create aggregation component from validated configuration.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>AggregationConfig</code> <p>Validated AggregationConfig containing: - <code>target_timeframes</code>: Target timeframes list (e.g., [\"1H\", \"5m\", \"1D\"]) - <code>asset_class</code>: Asset class type (crypto, equities, fx, futures, commodities) - <code>timezone</code>: Timezone override (UTC asset classes always use UTC;            non-UTC uses priority: specified &gt; system &gt; asset_class default) - <code>hour_boundary</code>: Align to hour boundaries (auto-determined if None) - <code>session_start</code>: Session start time (asset class default if None)</p> required <p>Returns:</p> Type Description <code>Aggregation</code> <p>Configured Aggregation component</p> Example <p>from thestrat.schemas import AggregationConfig config = AggregationConfig( ...     target_timeframes=[\"5m\", \"1H\"], ...     asset_class=\"crypto\", ...     timezone=\"UTC\" ... ) aggregation = Factory.create_aggregation(config)</p> Source code in <code>thestrat/factory.py</code> <pre><code>@staticmethod\ndef create_aggregation(config: AggregationConfig) -&gt; Aggregation:\n    \"\"\"\n    Create aggregation component from validated configuration.\n\n    Args:\n        config: Validated AggregationConfig containing:\n            - `target_timeframes`: Target timeframes list (e.g., [\"1H\", \"5m\", \"1D\"])\n            - `asset_class`: Asset class type (crypto, equities, fx, futures, commodities)\n            - `timezone`: Timezone override (UTC asset classes always use UTC;\n                       non-UTC uses priority: specified &gt; system &gt; asset_class default)\n            - `hour_boundary`: Align to hour boundaries (auto-determined if None)\n            - `session_start`: Session start time (asset class default if None)\n\n    Returns:\n        Configured Aggregation component\n\n    Example:\n        &gt;&gt;&gt; from thestrat.schemas import AggregationConfig\n        &gt;&gt;&gt; config = AggregationConfig(\n        ...     target_timeframes=[\"5m\", \"1H\"],\n        ...     asset_class=\"crypto\",\n        ...     timezone=\"UTC\"\n        ... )\n        &gt;&gt;&gt; aggregation = Factory.create_aggregation(config)\n    \"\"\"\n    return Aggregation(config)\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Factory.create_all","title":"create_all  <code>classmethod</code>","text":"<pre><code>create_all(config: FactoryConfig) -&gt; ComponentDict\n</code></pre> <p>Create complete processing pipeline with aggregation and indicators.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>FactoryConfig</code> <p>Validated FactoryConfig containing: <code>aggregation</code>: AggregationConfig with target timeframes and settings <code>indicators</code>: IndicatorsConfig with per-timeframe configurations</p> required <p>Returns:</p> Type Description <code>ComponentDict</code> <p>Dictionary containing created components:</p> <code>ComponentDict</code> <p>{ \"aggregation\": Aggregation, \"indicators\": Indicators</p> <code>ComponentDict</code> <p>}</p> Example <p>from thestrat.schemas import FactoryConfig, AggregationConfig, IndicatorsConfig, TimeframeItemConfig config = FactoryConfig( ...     aggregation=AggregationConfig(target_timeframes=[\"5m\"]), ...     indicators=IndicatorsConfig( ...         timeframe_configs=[TimeframeItemConfig(timeframes=[\"all\"])] ...     ) ... ) components = Factory.create_all(config)</p> Source code in <code>thestrat/factory.py</code> <pre><code>@classmethod\ndef create_all(cls, config: FactoryConfig) -&gt; ComponentDict:\n    \"\"\"\n    Create complete processing pipeline with aggregation and indicators.\n\n    Args:\n        config: Validated FactoryConfig containing:\n            `aggregation`: AggregationConfig with target timeframes and settings\n            `indicators`: IndicatorsConfig with per-timeframe configurations\n\n    Returns:\n        Dictionary containing created components:\n        {\n            \"aggregation\": Aggregation,\n            \"indicators\": Indicators\n        }\n\n    Example:\n        &gt;&gt;&gt; from thestrat.schemas import FactoryConfig, AggregationConfig, IndicatorsConfig, TimeframeItemConfig\n        &gt;&gt;&gt; config = FactoryConfig(\n        ...     aggregation=AggregationConfig(target_timeframes=[\"5m\"]),\n        ...     indicators=IndicatorsConfig(\n        ...         timeframe_configs=[TimeframeItemConfig(timeframes=[\"all\"])]\n        ...     )\n        ... )\n        &gt;&gt;&gt; components = Factory.create_all(config)\n    \"\"\"\n    return {\n        \"aggregation\": cls.create_aggregation(config.aggregation),\n        \"indicators\": cls.create_indicators(config.indicators),\n    }\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Factory.create_indicators","title":"create_indicators  <code>staticmethod</code>","text":"<pre><code>create_indicators(config: IndicatorsConfig) -&gt; Indicators\n</code></pre> <p>Create indicators component from validated configuration.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>IndicatorsConfig</code> <p>Validated IndicatorsConfig containing per-timeframe configurations using Pydantic models</p> required <p>Returns:</p> Type Description <code>Indicators</code> <p>Configured Indicators component</p> Example <p>from thestrat.schemas import IndicatorsConfig, TimeframeItemConfig, SwingPointsConfig config = IndicatorsConfig( ...     timeframe_configs=[ ...         TimeframeItemConfig( ...             timeframes=[\"5m\", \"15m\"], ...             swing_points=SwingPointsConfig(window=7, threshold=3.0) ...         ) ...     ] ... ) indicators = Factory.create_indicators(config)</p> Source code in <code>thestrat/factory.py</code> <pre><code>@staticmethod\ndef create_indicators(config: IndicatorsConfig) -&gt; Indicators:\n    \"\"\"\n    Create indicators component from validated configuration.\n\n    Args:\n        config: Validated IndicatorsConfig containing per-timeframe configurations\n            using Pydantic models\n\n    Returns:\n        Configured Indicators component\n\n    Example:\n        &gt;&gt;&gt; from thestrat.schemas import IndicatorsConfig, TimeframeItemConfig, SwingPointsConfig\n        &gt;&gt;&gt; config = IndicatorsConfig(\n        ...     timeframe_configs=[\n        ...         TimeframeItemConfig(\n        ...             timeframes=[\"5m\", \"15m\"],\n        ...             swing_points=SwingPointsConfig(window=7, threshold=3.0)\n        ...         )\n        ...     ]\n        ... )\n        &gt;&gt;&gt; indicators = Factory.create_indicators(config)\n    \"\"\"\n    return Indicators(config)\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Factory.get_asset_class_config","title":"get_asset_class_config  <code>staticmethod</code>","text":"<pre><code>get_asset_class_config(asset_class: str) -&gt; dict[str, Any]\n</code></pre> <p>Get default configuration for specific asset class.</p> <p>Parameters:</p> Name Type Description Default <code>asset_class</code> <code>str</code> <p>Asset class type</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary with default <code>timezone</code> and <code>session_start</code></p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If asset_class is not supported</p> Source code in <code>thestrat/factory.py</code> <pre><code>@staticmethod\ndef get_asset_class_config(asset_class: str) -&gt; dict[str, Any]:\n    \"\"\"\n    Get default configuration for specific asset class.\n\n    Args:\n        asset_class: Asset class type\n\n    Returns:\n        Dictionary with default `timezone` and `session_start`\n\n    Raises:\n        ValueError: If asset_class is not supported\n    \"\"\"\n    from .schemas import AssetClassConfig\n\n    if asset_class not in Factory.get_supported_asset_classes():\n        raise ValueError(f\"Unsupported asset class: {asset_class}\")\n\n    return AssetClassConfig.REGISTRY[asset_class].model_dump()\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Factory.get_supported_asset_classes","title":"get_supported_asset_classes  <code>staticmethod</code>","text":"<pre><code>get_supported_asset_classes() -&gt; list[str]\n</code></pre> <p>Get list of supported asset classes.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of supported asset class strings</p> Source code in <code>thestrat/factory.py</code> <pre><code>@staticmethod\ndef get_supported_asset_classes() -&gt; list[str]:\n    \"\"\"\n    Get list of supported asset classes.\n\n    Returns:\n        List of supported asset class strings\n    \"\"\"\n    from .schemas import AssetClassConfig\n\n    return list(AssetClassConfig.REGISTRY.keys())\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Factory.get_supported_timeframes","title":"get_supported_timeframes  <code>cached</code> <code>staticmethod</code>","text":"<pre><code>get_supported_timeframes() -&gt; list[str]\n</code></pre> <p>Get list of all supported timeframes in chronological order.</p> <p>Returns a chronologically ordered list of timeframe strings that can be used with the aggregation and indicators components. These timeframes are validated when creating configurations.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>Chronologically ordered list of supported timeframe strings (shortest to longest)</p> Example <p>from thestrat import Factory timeframes = Factory.get_supported_timeframes() print(timeframes) ['1min', '5min', '15min', '30min', '1h', '4h', '6h', '12h', '1d', '1w', '1m', '1q', '1y']</p> Note <p>The timeframes are ordered by duration (shortest to longest) and follow standard conventions: - Minutes: <code>1min</code>, <code>5min</code>, <code>15min</code>, <code>30min</code> - Hours: <code>1h</code>, <code>4h</code>, <code>6h</code>, <code>12h</code> - Days/Weeks/Months: <code>1d</code>, <code>1w</code>, <code>1m</code> (month), <code>1q</code> (quarter), <code>1y</code></p> Source code in <code>thestrat/factory.py</code> <pre><code>@staticmethod\n@lru_cache(maxsize=1)\ndef get_supported_timeframes() -&gt; list[str]:\n    \"\"\"\n    Get list of all supported timeframes in chronological order.\n\n    Returns a chronologically ordered list of timeframe strings that can be used with\n    the aggregation and indicators components. These timeframes are\n    validated when creating configurations.\n\n    Returns:\n        Chronologically ordered list of supported timeframe strings (shortest to longest)\n\n    Example:\n        &gt;&gt;&gt; from thestrat import Factory\n        &gt;&gt;&gt; timeframes = Factory.get_supported_timeframes()\n        &gt;&gt;&gt; print(timeframes)\n        ['1min', '5min', '15min', '30min', '1h', '4h', '6h', '12h', '1d', '1w', '1m', '1q', '1y']\n\n        &gt;&gt;&gt; # Use in configuration\n        &gt;&gt;&gt; from thestrat.schemas import AggregationConfig\n        &gt;&gt;&gt; available_timeframes = Factory.get_supported_timeframes()\n        &gt;&gt;&gt; config = AggregationConfig(\n        ...     target_timeframes=[available_timeframes[0], available_timeframes[1]],\n        ...     asset_class=\"equities\"\n        ... )\n\n    Note:\n        The timeframes are ordered by duration (shortest to longest) and follow standard conventions:\n        - Minutes: `1min`, `5min`, `15min`, `30min`\n        - Hours: `1h`, `4h`, `6h`, `12h`\n        - Days/Weeks/Months: `1d`, `1w`, `1m` (month), `1q` (quarter), `1y`\n    \"\"\"\n    from .schemas import TimeframeConfig\n\n    # Pre-compute timeframes with their durations for efficient sorting\n    timeframes_with_duration = [\n        (tf, TimeframeConfig.TIMEFRAME_METADATA.get(tf, {}).get(\"seconds\", float(\"inf\")))\n        for tf in TimeframeConfig.TIMEFRAME_METADATA.keys()\n    ]\n\n    # Sort by duration and return just the timeframe strings\n    return [tf for tf, _ in sorted(timeframes_with_duration, key=lambda x: x[1])]\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Factory.get_supported_timeframes--use-in-configuration","title":"Use in configuration","text":"<p>from thestrat.schemas import AggregationConfig available_timeframes = Factory.get_supported_timeframes() config = AggregationConfig( ...     target_timeframes=[available_timeframes[0], available_timeframes[1]], ...     asset_class=\"equities\" ... )</p>"},{"location":"reference/thestrat/#thestrat.Factory.get_timeframe_metadata","title":"get_timeframe_metadata  <code>staticmethod</code>","text":"<pre><code>get_timeframe_metadata(timeframe: str) -&gt; dict[str, Any]\n</code></pre> <p>Get detailed metadata for a specific timeframe.</p> <p>Provides comprehensive information about a timeframe including its category, duration in seconds, description, and typical use cases. This is useful for understanding the characteristics and appropriate applications of different timeframes.</p> <p>Parameters:</p> Name Type Description Default <code>timeframe</code> <code>str</code> <p>Timeframe string to get metadata for (e.g., \"5min\", \"1h\", \"1d\")</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary containing:</p> <code>dict[str, Any]</code> <ul> <li><code>category</code>: Timeframe category (e.g., \"sub-hourly\", \"hourly\", \"daily\")</li> </ul> <code>dict[str, Any]</code> <ul> <li><code>seconds</code>: Duration in seconds</li> </ul> <code>dict[str, Any]</code> <ul> <li><code>description</code>: Human-readable description</li> </ul> <code>dict[str, Any]</code> <ul> <li><code>typical_use</code>: Common use cases for this timeframe</li> </ul> <code>dict[str, Any]</code> <ul> <li><code>data_volume</code>: Expected data volume level</li> </ul> <p>Raises:</p> Type Description <code>ValueError</code> <p>If timeframe is not supported</p> Example <p>from thestrat import Factory metadata = Factory.get_timeframe_metadata(\"1h\") print(metadata) {     'category': 'hourly',     'seconds': 3600,     'description': '1-hour bars for daily structure analysis',     'typical_use': 'Day trading context, hourly levels',     'data_volume': 'low' }</p> See Also <ul> <li>:meth:<code>get_supported_timeframes</code>: Get list of all supported timeframes</li> <li>:meth:<code>validate_timeframe_format</code>: Validate a timeframe string</li> </ul> Source code in <code>thestrat/factory.py</code> <pre><code>@staticmethod\ndef get_timeframe_metadata(timeframe: str) -&gt; dict[str, Any]:\n    \"\"\"\n    Get detailed metadata for a specific timeframe.\n\n    Provides comprehensive information about a timeframe including its\n    category, duration in seconds, description, and typical use cases.\n    This is useful for understanding the characteristics and appropriate\n    applications of different timeframes.\n\n    Args:\n        timeframe: Timeframe string to get metadata for (e.g., \"5min\", \"1h\", \"1d\")\n\n    Returns:\n        Dictionary containing:\n        - `category`: Timeframe category (e.g., \"sub-hourly\", \"hourly\", \"daily\")\n        - `seconds`: Duration in seconds\n        - `description`: Human-readable description\n        - `typical_use`: Common use cases for this timeframe\n        - `data_volume`: Expected data volume level\n\n    Raises:\n        ValueError: If timeframe is not supported\n\n    Example:\n        &gt;&gt;&gt; from thestrat import Factory\n        &gt;&gt;&gt; metadata = Factory.get_timeframe_metadata(\"1h\")\n        &gt;&gt;&gt; print(metadata)\n        {\n            'category': 'hourly',\n            'seconds': 3600,\n            'description': '1-hour bars for daily structure analysis',\n            'typical_use': 'Day trading context, hourly levels',\n            'data_volume': 'low'\n        }\n\n        &gt;&gt;&gt; # Check if a timeframe is suitable for day trading\n        &gt;&gt;&gt; metadata = Factory.get_timeframe_metadata(\"5min\")\n        &gt;&gt;&gt; if \"day trading\" in metadata[\"typical_use\"].lower():\n        ...     print(f\"5min is suitable for day trading\")\n\n        &gt;&gt;&gt; # Get all intraday timeframes\n        &gt;&gt;&gt; all_timeframes = Factory.get_supported_timeframes()\n        &gt;&gt;&gt; intraday = []\n        &gt;&gt;&gt; for tf in all_timeframes:\n        ...     meta = Factory.get_timeframe_metadata(tf)\n        ...     if meta[\"category\"] in [\"sub-hourly\", \"hourly\"]:\n        ...         intraday.append(tf)\n\n    See Also:\n        - :meth:`get_supported_timeframes`: Get list of all supported timeframes\n        - :meth:`validate_timeframe_format`: Validate a timeframe string\n    \"\"\"\n    # Use cached helper method to get metadata efficiently\n    metadata = Factory._get_cached_timeframe_metadata(timeframe)\n    return metadata.copy()  # Return a copy to prevent modification\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Factory.get_timeframe_metadata--check-if-a-timeframe-is-suitable-for-day-trading","title":"Check if a timeframe is suitable for day trading","text":"<p>metadata = Factory.get_timeframe_metadata(\"5min\") if \"day trading\" in metadata[\"typical_use\"].lower(): ...     print(f\"5min is suitable for day trading\")</p>"},{"location":"reference/thestrat/#thestrat.Factory.get_timeframe_metadata--get-all-intraday-timeframes","title":"Get all intraday timeframes","text":"<p>all_timeframes = Factory.get_supported_timeframes() intraday = [] for tf in all_timeframes: ...     meta = Factory.get_timeframe_metadata(tf) ...     if meta[\"category\"] in [\"sub-hourly\", \"hourly\"]: ...         intraday.append(tf)</p>"},{"location":"reference/thestrat/#thestrat.FactoryConfig","title":"FactoryConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Root configuration for Factory.create_all method with complete pipeline setup.</p> <p>Methods:</p> Name Description <code>validate_configuration_consistency</code> <p>Validate consistency between aggregation and indicators configurations.</p>"},{"location":"reference/thestrat/#thestrat.FactoryConfig.validate_configuration_consistency","title":"validate_configuration_consistency","text":"<pre><code>validate_configuration_consistency() -&gt; Self\n</code></pre> <p>Validate consistency between aggregation and indicators configurations.</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@model_validator(mode=\"after\")\ndef validate_configuration_consistency(self) -&gt; Self:\n    \"\"\"Validate consistency between aggregation and indicators configurations.\"\"\"\n    # Future enhancement: Could validate that indicator timeframes are compatible\n    # with aggregation target timeframes, but this is not currently enforced\n    # in the existing system\n    return self\n</code></pre>"},{"location":"reference/thestrat/#thestrat.GapDetectionConfig","title":"GapDetectionConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for gap detection with comprehensive threshold documentation.</p>"},{"location":"reference/thestrat/#thestrat.IndicatorSchema","title":"IndicatorSchema","text":"<p>               Bases: <code>BaseModel</code></p> <p>Complete Indicator Schema</p> <p>Defines all columns that are created by TheStrat processing pipeline. All columns are required as the indicators component creates them all.</p> <p>Methods:</p> Name Description <code>get_all_input_columns</code> <p>Get list of all input columns (required + optional).</p> <code>get_column_categories</code> <p>Get columns organized by functional categories.</p> <code>get_column_descriptions</code> <p>Get descriptions for all possible DataFrame columns.</p> <code>get_field_metadata</code> <p>Get json_schema_extra metadata for a field, safely handling missing data.</p> <code>get_optional_input_columns</code> <p>Get list of optional input columns based on schema definition.</p> <code>get_output_columns</code> <p>Get list of all output columns based on schema definition.</p> <code>get_polars_dtypes</code> <p>Get Polars data types for all DataFrame columns.</p> <code>get_precision_metadata</code> <p>Get precision metadata for all fields.</p> <code>get_required_input_columns</code> <p>Get list of required input columns based on schema definition.</p> <code>get_standard_column_order</code> <p>Get the standard column ordering for aggregation output.</p> <code>validate_dataframe</code> <p>Validate input DataFrame columns and data types against IndicatorSchema input requirements.</p>"},{"location":"reference/thestrat/#thestrat.IndicatorSchema.get_all_input_columns","title":"get_all_input_columns  <code>classmethod</code>","text":"<pre><code>get_all_input_columns() -&gt; list[str]\n</code></pre> <p>Get list of all input columns (required + optional).</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of all input column names</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_all_input_columns(cls) -&gt; list[str]:\n    \"\"\"\n    Get list of all input columns (required + optional).\n\n    Returns:\n        List of all input column names\n    \"\"\"\n    return sorted(cls.get_required_input_columns() + cls.get_optional_input_columns())\n</code></pre>"},{"location":"reference/thestrat/#thestrat.IndicatorSchema.get_column_categories","title":"get_column_categories  <code>classmethod</code>","text":"<pre><code>get_column_categories() -&gt; dict[str, list[str]]\n</code></pre> <p>Get columns organized by functional categories.</p> <p>Dynamically extracts categories from the IndicatorSchema metadata.</p> <p>Returns:</p> Type Description <code>dict[str, list[str]]</code> <p>Dictionary mapping category names to lists of column names</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_column_categories(cls) -&gt; dict[str, list[str]]:\n    \"\"\"\n    Get columns organized by functional categories.\n\n    Dynamically extracts categories from the IndicatorSchema metadata.\n\n    Returns:\n        Dictionary mapping category names to lists of column names\n    \"\"\"\n    categories: dict[str, list[str]] = {}\n\n    for field_name, field_info in cls.model_fields.items():\n        json_extra = getattr(field_info, \"json_schema_extra\", {})\n        if isinstance(json_extra, dict) and \"category\" in json_extra:\n            category = json_extra[\"category\"]\n            if category not in categories:\n                categories[category] = []\n            categories[category].append(field_name)\n\n    # Sort columns within each category for consistent output\n    for category in categories:\n        categories[category].sort()\n\n    return categories\n</code></pre>"},{"location":"reference/thestrat/#thestrat.IndicatorSchema.get_column_descriptions","title":"get_column_descriptions  <code>classmethod</code>","text":"<pre><code>get_column_descriptions() -&gt; dict[str, str]\n</code></pre> <p>Get descriptions for all possible DataFrame columns.</p> <p>Returns:</p> Type Description <code>dict[str, str]</code> <p>Dictionary mapping column names to their descriptions</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_column_descriptions(cls) -&gt; dict[str, str]:\n    \"\"\"\n    Get descriptions for all possible DataFrame columns.\n\n    Returns:\n        Dictionary mapping column names to their descriptions\n    \"\"\"\n    descriptions = {}\n\n    # Get descriptions from the schema\n    for field_name, field_info in cls.model_fields.items():\n        if field_info.description:\n            descriptions[field_name] = field_info.description\n\n    return descriptions\n</code></pre>"},{"location":"reference/thestrat/#thestrat.IndicatorSchema.get_field_metadata","title":"get_field_metadata  <code>classmethod</code>","text":"<pre><code>get_field_metadata(field_name: str) -&gt; dict[str, Any]\n</code></pre> <p>Get json_schema_extra metadata for a field, safely handling missing data.</p> <p>Parameters:</p> Name Type Description Default <code>field_name</code> <code>str</code> <p>Name of the field to get metadata for</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary of metadata from json_schema_extra, empty dict if not found</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_field_metadata(cls, field_name: str) -&gt; dict[str, Any]:\n    \"\"\"\n    Get json_schema_extra metadata for a field, safely handling missing data.\n\n    Args:\n        field_name: Name of the field to get metadata for\n\n    Returns:\n        Dictionary of metadata from json_schema_extra, empty dict if not found\n    \"\"\"\n    field_info = cls.model_fields.get(field_name)\n    if not field_info:\n        return {}\n    return getattr(field_info, \"json_schema_extra\", {}) or {}\n</code></pre>"},{"location":"reference/thestrat/#thestrat.IndicatorSchema.get_optional_input_columns","title":"get_optional_input_columns  <code>classmethod</code>","text":"<pre><code>get_optional_input_columns() -&gt; list[str]\n</code></pre> <p>Get list of optional input columns based on schema definition.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of column names that are optional for input data</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_optional_input_columns(cls) -&gt; list[str]:\n    \"\"\"\n    Get list of optional input columns based on schema definition.\n\n    Returns:\n        List of column names that are optional for input data\n    \"\"\"\n    from pydantic_core import PydanticUndefined\n\n    optional_columns = []\n    for field_name, field_info in cls.model_fields.items():\n        json_extra = getattr(field_info, \"json_schema_extra\", {}) or {}\n        if (\n            json_extra.get(\"input\") is True  # Is an input column\n            and (\n                json_extra.get(\"optional\", False)  # Marked as optional\n                or getattr(field_info, \"default\", PydanticUndefined) is not PydanticUndefined\n            )  # Has default value\n        ):\n            optional_columns.append(field_name)\n    return sorted(optional_columns)\n</code></pre>"},{"location":"reference/thestrat/#thestrat.IndicatorSchema.get_output_columns","title":"get_output_columns  <code>classmethod</code>","text":"<pre><code>get_output_columns() -&gt; list[str]\n</code></pre> <p>Get list of all output columns based on schema definition.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of column names marked as output in schema metadata</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_output_columns(cls) -&gt; list[str]:\n    \"\"\"\n    Get list of all output columns based on schema definition.\n\n    Returns:\n        List of column names marked as output in schema metadata\n    \"\"\"\n    output_columns = []\n    for field_name, field_info in cls.model_fields.items():\n        json_extra = getattr(field_info, \"json_schema_extra\", {}) or {}\n        if json_extra.get(\"output\") is True:\n            output_columns.append(field_name)\n    return sorted(output_columns)\n</code></pre>"},{"location":"reference/thestrat/#thestrat.IndicatorSchema.get_polars_dtypes","title":"get_polars_dtypes  <code>classmethod</code>","text":"<pre><code>get_polars_dtypes() -&gt; dict[str, Any]\n</code></pre> <p>Get Polars data types for all DataFrame columns.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary mapping column names to their Polars data types</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_polars_dtypes(cls) -&gt; dict[str, Any]:\n    \"\"\"\n    Get Polars data types for all DataFrame columns.\n\n    Returns:\n        Dictionary mapping column names to their Polars data types\n    \"\"\"\n    types = {}\n\n    for field_name, field_info in cls.model_fields.items():\n        json_extra = getattr(field_info, \"json_schema_extra\", {})\n        if isinstance(json_extra, dict) and \"polars_dtype\" in json_extra:\n            types[field_name] = json_extra[\"polars_dtype\"]\n\n    return types\n</code></pre>"},{"location":"reference/thestrat/#thestrat.IndicatorSchema.get_precision_metadata","title":"get_precision_metadata  <code>classmethod</code>","text":"<pre><code>get_precision_metadata() -&gt; dict[str, dict[str, Any]]\n</code></pre> <p>Get precision metadata for all fields.</p> <p>Returns:</p> Type Description <code>dict[str, dict[str, Any]]</code> <p>Dict mapping field_name \u2192 {'precision_type': str, 'decimal_places': int | None}</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_precision_metadata(cls) -&gt; dict[str, dict[str, Any]]:\n    \"\"\"\n    Get precision metadata for all fields.\n\n    Returns:\n        Dict mapping field_name \u2192 {'precision_type': str, 'decimal_places': int | None}\n    \"\"\"\n    metadata = {}\n\n    for field_name, field_info in cls.model_fields.items():\n        json_extra = getattr(field_info, \"json_schema_extra\", {}) or {}\n        if \"precision_type\" in json_extra:\n            metadata[field_name] = {\n                \"precision_type\": json_extra[\"precision_type\"],\n                \"decimal_places\": json_extra.get(\"decimal_places\"),\n            }\n\n    return metadata\n</code></pre>"},{"location":"reference/thestrat/#thestrat.IndicatorSchema.get_required_input_columns","title":"get_required_input_columns  <code>classmethod</code>","text":"<pre><code>get_required_input_columns() -&gt; list[str]\n</code></pre> <p>Get list of required input columns based on schema definition.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of column names that are required for input data</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_required_input_columns(cls) -&gt; list[str]:\n    \"\"\"\n    Get list of required input columns based on schema definition.\n\n    Returns:\n        List of column names that are required for input data\n    \"\"\"\n    from pydantic_core import PydanticUndefined\n\n    required_columns = []\n    for field_name, field_info in cls.model_fields.items():\n        json_extra = getattr(field_info, \"json_schema_extra\", {}) or {}\n        if (\n            json_extra.get(\"input\") is True  # Is an input column\n            and not json_extra.get(\"optional\", False)  # Not marked as optional\n            and getattr(field_info, \"default\", PydanticUndefined)\n            is PydanticUndefined  # No default value (required)\n        ):\n            required_columns.append(field_name)\n    return sorted(required_columns)\n</code></pre>"},{"location":"reference/thestrat/#thestrat.IndicatorSchema.get_standard_column_order","title":"get_standard_column_order  <code>classmethod</code>","text":"<pre><code>get_standard_column_order() -&gt; list[str]\n</code></pre> <p>Get the standard column ordering for aggregation output.</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_standard_column_order(cls) -&gt; list[str]:\n    \"\"\"Get the standard column ordering for aggregation output.\"\"\"\n    return [\"timestamp\", \"symbol\", \"timeframe\", \"open\", \"high\", \"low\", \"close\", \"volume\"]\n</code></pre>"},{"location":"reference/thestrat/#thestrat.IndicatorSchema.validate_dataframe","title":"validate_dataframe  <code>classmethod</code>","text":"<pre><code>validate_dataframe(df) -&gt; dict[str, Any]\n</code></pre> <p>Validate input DataFrame columns and data types against IndicatorSchema input requirements.</p> <p>Automatically converts Pandas DataFrames to Polars for consistent validation.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <p>Polars or Pandas DataFrame to validate</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary with validation results including missing/extra columns, type issues,</p> <code>dict[str, Any]</code> <p>and the converted Polars DataFrame if conversion occurred</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef validate_dataframe(cls, df) -&gt; dict[str, Any]:\n    \"\"\"\n    Validate input DataFrame columns and data types against IndicatorSchema input requirements.\n\n    Automatically converts Pandas DataFrames to Polars for consistent validation.\n\n    Args:\n        df: Polars or Pandas DataFrame to validate\n\n    Returns:\n        Dictionary with validation results including missing/extra columns, type issues,\n        and the converted Polars DataFrame if conversion occurred\n    \"\"\"\n    from polars import from_pandas\n\n    # Detect DataFrame type and convert if necessary\n    df_type = \"unknown\"\n    converted_df = None\n    conversion_errors = []\n\n    if hasattr(df, \"columns\"):\n        # Check if it's a Pandas DataFrame\n        if hasattr(df, \"dtypes\") and not hasattr(df, \"schema\"):\n            df_type = \"pandas\"\n            try:\n                # Convert Pandas to Polars\n                converted_df = from_pandas(df)\n                df = converted_df  # Use converted DataFrame for validation\n            except Exception as e:\n                conversion_errors.append(f\"Failed to convert Pandas to Polars: {str(e)}\")\n                # Fall back to column-only validation\n                df_columns = list(df.columns)\n                return {\n                    \"valid\": False,\n                    \"conversion_error\": conversion_errors[0],\n                    \"df_type\": df_type,\n                    \"columns\": df_columns,\n                    \"message\": \"Could not convert Pandas DataFrame to Polars for full validation\",\n                }\n        # Check if it's already a Polars DataFrame\n        elif hasattr(df, \"schema\"):\n            df_type = \"polars\"\n        else:\n            raise ValueError(\"Unknown DataFrame type - must be Pandas or Polars DataFrame\")\n\n        df_columns = list(df.columns)\n    else:\n        raise ValueError(\"Input must be a DataFrame with .columns attribute\")\n\n    required_fields = []\n    optional_fields = []\n    expected_types = {}\n\n    # Extract input field requirements from schema\n    for field_name, field_info in cls.model_fields.items():\n        json_extra = getattr(field_info, \"json_schema_extra\", {})\n        if isinstance(json_extra, dict) and json_extra.get(\"input\"):\n            if field_info.is_required():\n                required_fields.append(field_name)\n            else:\n                optional_fields.append(field_name)\n\n            # Store expected Polars type for validation\n            if \"polars_dtype\" in json_extra:\n                expected_types[field_name] = json_extra[\"polars_dtype\"]\n\n    # Check for missing and extra columns\n    missing_required = [col for col in required_fields if col not in df_columns]\n    missing_optional = [col for col in optional_fields if col not in df_columns]\n    extra_columns = [col for col in df_columns if col not in required_fields + optional_fields]\n\n    # Check data types for present columns (now guaranteed to be Polars)\n    type_issues = []\n    if hasattr(df, \"schema\"):  # Polars DataFrame\n        for col_name, expected_type in expected_types.items():\n            if col_name in df_columns:\n                actual_type = df.schema[col_name]\n                if actual_type != expected_type:\n                    type_issues.append(\n                        {\n                            \"column\": col_name,\n                            \"expected\": expected_type.__name__\n                            if hasattr(expected_type, \"__name__\")\n                            else str(expected_type),\n                            \"actual\": str(actual_type),\n                        }\n                    )\n\n    result = {\n        \"valid\": len(missing_required) == 0 and len(type_issues) == 0,\n        \"missing_required\": missing_required,\n        \"missing_optional\": missing_optional,\n        \"extra_columns\": extra_columns,\n        \"type_issues\": type_issues,\n        \"required_fields\": required_fields,\n        \"optional_fields\": optional_fields,\n        \"expected_types\": {k: v.__name__ if hasattr(v, \"__name__\") else str(v) for k, v in expected_types.items()},\n        \"df_type\": df_type,\n    }\n\n    # Include converted DataFrame if conversion occurred\n    if converted_df is not None:\n        result[\"converted_df\"] = converted_df\n        result[\"conversion_performed\"] = True\n    else:\n        result[\"conversion_performed\"] = False\n\n    return result\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Indicators","title":"Indicators","text":"<pre><code>Indicators(config: IndicatorsConfig)\n</code></pre> <p>               Bases: <code>Component</code></p> <p>Vectorized implementation of all Strat technical indicators.</p> <p>Provides comprehensive technical analysis including swing point detection, market structure analysis, pattern recognition, and gap detection optimized for TheStrat methodology.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>IndicatorsConfig</code> <p>Validated IndicatorsConfig containing per-timeframe configurations</p> required <p>Methods:</p> Name Description <code>get_signal_object</code> <p>Create SignalMetadata object from single-row DataFrame.</p> <code>process</code> <p>Calculate all Strat indicators for OHLC data.</p> <code>validate_input</code> <p>Validate input data format.</p> Source code in <code>thestrat/indicators.py</code> <pre><code>def __init__(self, config: IndicatorsConfig):\n    \"\"\"\n    Initialize indicators component with validated configuration.\n\n    Args:\n        config: Validated IndicatorsConfig containing per-timeframe configurations\n    \"\"\"\n    super().__init__()\n\n    # Store the validated Pydantic config\n    self.config = config\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Indicators.get_signal_object","title":"get_signal_object  <code>classmethod</code>","text":"<pre><code>get_signal_object(df: DataFrame) -&gt; SignalMetadata\n</code></pre> <p>Create SignalMetadata object from single-row DataFrame.</p> <p>Decoupled from pipeline - can be called standalone with database query results. Expects DataFrame with exactly 1 row containing signal data with pre-calculated entry/stop prices and targets.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame with exactly 1 row containing signal data</p> required <p>Returns:</p> Type Description <code>SignalMetadata</code> <p>SignalMetadata object with targets parsed from DataFrame</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If df doesn't have exactly 1 row or missing required columns</p> Example Source code in <code>thestrat/indicators.py</code> <pre><code>@classmethod\ndef get_signal_object(cls, df: PolarsDataFrame) -&gt; \"SignalMetadata\":\n    \"\"\"\n    Create SignalMetadata object from single-row DataFrame.\n\n    Decoupled from pipeline - can be called standalone with database query results.\n    Expects DataFrame with exactly 1 row containing signal data with pre-calculated\n    entry/stop prices and targets.\n\n    Args:\n        df: DataFrame with exactly 1 row containing signal data\n\n    Returns:\n        SignalMetadata object with targets parsed from DataFrame\n\n    Raises:\n        ValueError: If df doesn't have exactly 1 row or missing required columns\n\n    Example:\n        # Query database for specific signal\n        signal_df = db.query(\\\"\\\"\\\"\n            SELECT * FROM signals\n            WHERE symbol='AAPL' AND timestamp='2024-01-15 10:30:00'\n        \\\"\\\"\\\")\n\n        # Create signal object (no pipeline needed)\n        signal = Indicators.get_signal_object(signal_df)\n    \"\"\"\n    if df.shape[0] != 1:\n        raise ValueError(\n            f\"get_signal_object() expects DataFrame with exactly 1 row, got {df.shape[0]} rows. \"\n            \"Query database to filter to specific signal first.\"\n        )\n\n    from .signals import SIGNALS, SignalBias, SignalCategory, SignalMetadata, TargetLevel\n\n    # Extract row data\n    row = df.row(0, named=True)\n\n    # Validate required columns exist\n    if \"entry_price\" not in row or \"stop_price\" not in row:\n        raise ValueError(\n            \"DataFrame missing required 'entry_price' and/or 'stop_price' columns. \"\n            \"These columns must be calculated during signal detection in the full pipeline. \"\n            \"Run the complete Indicators.process() pipeline to generate these columns.\"\n        )\n\n    # Parse target_prices from native list (not JSON)\n    target_prices = []\n    if row.get(\"target_prices\") is not None:\n        # target_prices is List[Float64] from database\n        target_list = row[\"target_prices\"]\n        target_prices = [TargetLevel(price=price) for price in target_list]\n\n    # Get signal configuration\n    pattern = row[\"signal\"]\n    config = SIGNALS.get(pattern, {})\n\n    # Use pre-calculated entry/stop prices from setup bar\n    entry_price = float(row[\"entry_price\"]) if row[\"entry_price\"] is not None else None\n    stop_price = float(row[\"stop_price\"]) if row[\"stop_price\"] is not None else None\n\n    if entry_price is None or stop_price is None:\n        raise ValueError(\n            f\"Signal has null entry_price or stop_price. Pattern: {pattern}, \"\n            f\"entry_price: {entry_price}, stop_price: {stop_price}. \"\n            \"This indicates the signal was detected without sufficient historical data for setup bar lookup.\"\n        )\n\n    # Create SignalMetadata\n    signal = SignalMetadata(\n        pattern=pattern,\n        category=SignalCategory(row[\"type\"]),\n        bias=SignalBias(row[\"bias\"]),\n        bar_count=config.get(\"bar_count\", 2),\n        entry_price=entry_price,\n        stop_price=stop_price,\n        target_prices=target_prices,\n        timestamp=row[\"timestamp\"],\n        symbol=row.get(\"symbol\"),\n        timeframe=row.get(\"timeframe\"),\n    )\n\n    return signal\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Indicators.get_signal_object--query-database-for-specific-signal","title":"Query database for specific signal","text":"<p>signal_df = db.query(\"\"\"     SELECT * FROM signals     WHERE symbol='AAPL' AND timestamp='2024-01-15 10:30:00' \"\"\")</p>"},{"location":"reference/thestrat/#thestrat.Indicators.get_signal_object--create-signal-object-no-pipeline-needed","title":"Create signal object (no pipeline needed)","text":"<p>signal = Indicators.get_signal_object(signal_df)</p>"},{"location":"reference/thestrat/#thestrat.Indicators.process","title":"process","text":"<pre><code>process(data: DataFrame | DataFrame) -&gt; DataFrame\n</code></pre> <p>Calculate all Strat indicators for OHLC data.</p> <p>Performs comprehensive technical analysis including swing point detection, market structure analysis, pattern recognition, and gap detection. Calculations run sequentially due to data dependencies between indicators.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | DataFrame</code> <p>Input DataFrame with OHLC data</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with all Strat indicators added</p> Source code in <code>thestrat/indicators.py</code> <pre><code>def process(self, data: PolarsDataFrame | PandasDataFrame) -&gt; PolarsDataFrame:\n    \"\"\"\n    Calculate all Strat indicators for OHLC data.\n\n    Performs comprehensive technical analysis including swing point detection, market structure\n    analysis, pattern recognition, and gap detection. Calculations run sequentially due to\n    data dependencies between indicators.\n\n    Args:\n        data: Input DataFrame with OHLC data\n\n    Returns:\n        DataFrame with all Strat indicators added\n    \"\"\"\n    self.validate_input(data)\n\n    # Convert to Polars if needed\n    df = self._convert_to_polars(data)\n\n    # Ensure optional schema columns are present\n    if \"symbol\" not in df.columns:\n        df = df.with_columns(lit(None, dtype=String).alias(\"symbol\"))\n\n    # Check if data has timeframe column for per-timeframe processing\n    if \"timeframe\" in df.columns:\n        # ALWAYS partition by timeframe to prevent cross-timeframe pollution in rolling/cumulative operations\n        # This ensures market structure calculations only consider bars from the same timeframe\n        timeframe_groups = df.partition_by(\"timeframe\", as_dict=True)\n        processed_groups = []\n\n        # Check if \"all\" timeframe is configured\n        has_all_config = any(\"all\" in tf_config.timeframes for tf_config in self.config.timeframe_configs)\n\n        for timeframe_key, timeframe_data in timeframe_groups.items():\n            # Extract timeframe string from tuple key\n            timeframe = timeframe_key[0] if isinstance(timeframe_key, tuple) else timeframe_key\n\n            # Get config for this timeframe\n            # If \"all\" config exists, use it for every timeframe; otherwise use timeframe-specific config\n            if has_all_config:\n                tf_config = self._get_config_for_timeframe(\"any_timeframe_will_get_all_config\")\n            else:\n                tf_config = self._get_config_for_timeframe(timeframe)\n\n            # Process this timeframe with its specific config\n            processed_data = self._process_single_timeframe(timeframe_data, tf_config)\n            processed_groups.append(processed_data)\n\n        # Combine all processed groups\n        df = processed_groups[0]\n        for group in processed_groups[1:]:\n            df = df.vstack(group)\n\n        # Sort by original order (symbol, timeframe, timestamp)\n        sort_cols = []\n        if \"symbol\" in df.columns:\n            sort_cols.append(\"symbol\")\n        sort_cols.extend([\"timeframe\", \"timestamp\"])\n        df = df.sort(sort_cols)\n    else:\n        # No timeframe column - must have \"all\" configuration\n        has_all_config = any(\"all\" in tf_config.timeframes for tf_config in self.config.timeframe_configs)\n        if not has_all_config:\n            raise ValueError(\"Data without timeframe column requires an 'all' timeframe configuration.\")\n\n        all_config = self._get_config_for_timeframe(\"any_timeframe_will_get_all_config\")\n        df = self._process_single_timeframe(df, all_config)\n\n    return df\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Indicators.validate_input","title":"validate_input","text":"<pre><code>validate_input(data: DataFrame | DataFrame) -&gt; None\n</code></pre> <p>Validate input data format.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If data format is invalid, with specific error message</p> Source code in <code>thestrat/indicators.py</code> <pre><code>def validate_input(self, data: PolarsDataFrame | PandasDataFrame) -&gt; None:\n    \"\"\"\n    Validate input data format.\n\n    Raises:\n        ValueError: If data format is invalid, with specific error message\n    \"\"\"\n    df = self._convert_to_polars(data)\n\n    # Check required columns\n    required_cols = [\"timestamp\", \"open\", \"high\", \"low\", \"close\"]\n    missing_cols = [col for col in required_cols if col not in df.columns]\n    if missing_cols:\n        raise ValueError(f\"Missing required columns: {missing_cols}\")\n\n    # Note: Minimum data point validation removed as _calculate_swing_points\n    # now handles small datasets gracefully with proper safeguards\n\n    # Verify price data integrity\n    validations = df.select(\n        [\n            (col(\"high\") &gt;= col(\"low\")).all().alias(\"high_gte_low\"),\n            (col(\"high\") &gt;= col(\"open\")).all().alias(\"high_gte_open\"),\n            (col(\"high\") &gt;= col(\"close\")).all().alias(\"high_gte_close\"),\n            (col(\"low\") &lt;= col(\"open\")).all().alias(\"low_lte_open\"),\n            (col(\"low\") &lt;= col(\"close\")).all().alias(\"low_lte_close\"),\n        ]\n    )\n\n    validation_results = validations.to_numpy().flatten()\n    validation_names = [\"high &gt;= low\", \"high &gt;= open\", \"high &gt;= close\", \"low &lt;= open\", \"low &lt;= close\"]\n\n    failed_validations = [\n        name for name, result in zip(validation_names, validation_results, strict=False) if not result\n    ]\n    if failed_validations:\n        raise ValueError(f\"Invalid price data: failed validations: {failed_validations}\")\n</code></pre>"},{"location":"reference/thestrat/#thestrat.IndicatorsConfig","title":"IndicatorsConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Complete configuration for indicators component with per-timeframe settings.</p>"},{"location":"reference/thestrat/#thestrat.PrecisionError","title":"PrecisionError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when precision cannot be determined.</p>"},{"location":"reference/thestrat/#thestrat.PriceChange","title":"PriceChange  <code>dataclass</code>","text":"<pre><code>PriceChange(\n    field_name: str,\n    from_value: float,\n    to_value: float,\n    timestamp: datetime,\n    reason: str | None = None,\n)\n</code></pre> <p>Track changes to stop/target prices.</p>"},{"location":"reference/thestrat/#thestrat.SignalBias","title":"SignalBias","text":"<p>               Bases: <code>Enum</code></p> <p>Signal directional bias.</p>"},{"location":"reference/thestrat/#thestrat.SignalCategory","title":"SignalCategory","text":"<p>               Bases: <code>Enum</code></p> <p>Signal categorization types.</p>"},{"location":"reference/thestrat/#thestrat.SignalMetadata","title":"SignalMetadata  <code>dataclass</code>","text":"<pre><code>SignalMetadata(\n    pattern: str,\n    category: SignalCategory,\n    bias: SignalBias,\n    bar_count: int,\n    entry_price: float,\n    stop_price: float,\n    timestamp: datetime,\n    signal_id: str = (lambda: str(uuid4()))(),\n    target_prices: list[TargetLevel] = list(),\n    status: SignalStatus = PENDING,\n    triggered_at: datetime | None = None,\n    closed_at: datetime | None = None,\n    close_reason: str | None = None,\n    change_history: list[PriceChange] = list(),\n    symbol: str | None = None,\n    timeframe: str | None = None,\n    risk_amount: float | None = None,\n    reward_amount: float | None = None,\n    risk_reward_ratio: float | None = None,\n    entry_filled_price: float | None = None,\n    exit_price: float | None = None,\n    pnl: float | None = None,\n    max_favorable_excursion: float | None = None,\n    max_adverse_excursion: float | None = None,\n)\n</code></pre> <p>Complete signal metadata with change tracking and serialization.</p> <p>Methods:</p> Name Description <code>__post_init__</code> <p>Store original values and calculate metrics.</p> <code>trail_stop</code> <p>Trail stop loss, only allowing favorable moves.</p> <code>update_stop</code> <p>Update stop with change tracking.</p>"},{"location":"reference/thestrat/#thestrat.SignalMetadata.__post_init__","title":"__post_init__","text":"<pre><code>__post_init__()\n</code></pre> <p>Store original values and calculate metrics.</p> Source code in <code>thestrat/signals.py</code> <pre><code>def __post_init__(self):\n    \"\"\"Store original values and calculate metrics.\"\"\"\n    self.original_stop = self.stop_price\n    self._calculate_risk_metrics()\n</code></pre>"},{"location":"reference/thestrat/#thestrat.SignalMetadata.trail_stop","title":"trail_stop","text":"<pre><code>trail_stop(new_stop: float, reason: str = 'trailing_stop') -&gt; bool\n</code></pre> <p>Trail stop loss, only allowing favorable moves.</p> <p>Parameters:</p> Name Type Description Default <code>new_stop</code> <code>float</code> <p>Proposed new stop price</p> required <code>reason</code> <code>str</code> <p>Reason for trailing (default: \"trailing_stop\")</p> <code>'trailing_stop'</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if stop was trailed, False if move was unfavorable and rejected</p> Source code in <code>thestrat/signals.py</code> <pre><code>def trail_stop(self, new_stop: float, reason: str = \"trailing_stop\") -&gt; bool:\n    \"\"\"\n    Trail stop loss, only allowing favorable moves.\n\n    Args:\n        new_stop: Proposed new stop price\n        reason: Reason for trailing (default: \"trailing_stop\")\n\n    Returns:\n        True if stop was trailed, False if move was unfavorable and rejected\n    \"\"\"\n    if self.bias == SignalBias.LONG:\n        # For long trades, only trail up\n        if new_stop &gt; self.stop_price:\n            self.update_stop(new_stop, reason)\n            return True\n    else:\n        # For short trades, only trail down\n        if new_stop &lt; self.stop_price:\n            self.update_stop(new_stop, reason)\n            return True\n    return False\n</code></pre>"},{"location":"reference/thestrat/#thestrat.SignalMetadata.update_stop","title":"update_stop","text":"<pre><code>update_stop(new_stop: float, reason: str = None) -&gt; None\n</code></pre> <p>Update stop with change tracking.</p> <p>Parameters:</p> Name Type Description Default <code>new_stop</code> <code>float</code> <p>New stop loss price</p> required <code>reason</code> <code>str</code> <p>Optional reason for the update (e.g., \"trailing_stop\", \"manual_adjustment\")</p> <code>None</code> Source code in <code>thestrat/signals.py</code> <pre><code>def update_stop(self, new_stop: float, reason: str = None) -&gt; None:\n    \"\"\"\n    Update stop with change tracking.\n\n    Args:\n        new_stop: New stop loss price\n        reason: Optional reason for the update (e.g., \"trailing_stop\", \"manual_adjustment\")\n    \"\"\"\n    if new_stop == self.stop_price:\n        return\n\n    change = PriceChange(\n        field_name=\"stop_price\",\n        from_value=self.stop_price,\n        to_value=new_stop,\n        timestamp=datetime.now(),\n        reason=reason,\n    )\n    self.change_history.append(change)\n    self.stop_price = new_stop\n    self._calculate_risk_metrics()\n</code></pre>"},{"location":"reference/thestrat/#thestrat.SignalStatus","title":"SignalStatus","text":"<p>               Bases: <code>Enum</code></p> <p>Signal lifecycle status.</p>"},{"location":"reference/thestrat/#thestrat.SwingPointsConfig","title":"SwingPointsConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for swing point detection with comprehensive parameter documentation.</p>"},{"location":"reference/thestrat/#thestrat.TimeframeItemConfig","title":"TimeframeItemConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for a single timeframe item with flexible timeframe targeting.</p> <p>Methods:</p> Name Description <code>validate_timeframe_combinations</code> <p>Validate that 'all' is not mixed with specific timeframes.</p>"},{"location":"reference/thestrat/#thestrat.TimeframeItemConfig.validate_timeframe_combinations","title":"validate_timeframe_combinations","text":"<pre><code>validate_timeframe_combinations() -&gt; Self\n</code></pre> <p>Validate that 'all' is not mixed with specific timeframes.</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@model_validator(mode=\"after\")\ndef validate_timeframe_combinations(self) -&gt; Self:\n    \"\"\"Validate that 'all' is not mixed with specific timeframes.\"\"\"\n    if \"all\" in self.timeframes and len(self.timeframes) &gt; 1:\n        raise ValueError(\"'all' cannot be combined with specific timeframes\")\n    return self\n</code></pre>"},{"location":"reference/thestrat/#thestrat.apply_precision","title":"apply_precision","text":"<pre><code>apply_precision(\n    df: DataFrame,\n    security_precision_map: Dict[str, int],\n    symbol_column: str = \"symbol\",\n) -&gt; DataFrame\n</code></pre> <p>Apply security-aware precision rounding to indicator DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame with indicator columns</p> required <code>security_precision_map</code> <code>Dict[str, int]</code> <p>Dict mapping symbol \u2192 decimal places (from IBKR minTick)</p> required <code>symbol_column</code> <code>str</code> <p>Column name containing symbols (default: 'symbol')</p> <code>'symbol'</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with rounded values</p> <p>Raises:</p> Type Description <code>PrecisionError</code> <p>If a symbol in df is not in security_precision_map</p> Example <pre><code># Precision from IBKR: {'AAPL': 2, 'EURUSD': 5, 'BTC': 8}\nrounded_df = apply_precision(indicators_df, precision_map)\n</code></pre> Source code in <code>thestrat/precision.py</code> <pre><code>def apply_precision(\n    df: pl.DataFrame, security_precision_map: Dict[str, int], symbol_column: str = \"symbol\"\n) -&gt; pl.DataFrame:\n    \"\"\"\n    Apply security-aware precision rounding to indicator DataFrame.\n\n    Args:\n        df: DataFrame with indicator columns\n        security_precision_map: Dict mapping symbol \u2192 decimal places (from IBKR minTick)\n        symbol_column: Column name containing symbols (default: 'symbol')\n\n    Returns:\n        DataFrame with rounded values\n\n    Raises:\n        PrecisionError: If a symbol in df is not in security_precision_map\n\n    Example:\n        ```python\n        # Precision from IBKR: {'AAPL': 2, 'EURUSD': 5, 'BTC': 8}\n        rounded_df = apply_precision(indicators_df, precision_map)\n        ```\n    \"\"\"\n    # Validate all symbols have precision\n    df_symbols = df[symbol_column].unique().to_list()\n    missing_symbols = set(df_symbols) - set(security_precision_map.keys())\n\n    if missing_symbols:\n        raise PrecisionError(\n            f\"Missing precision for symbols: {sorted(missing_symbols)}. \"\n            f\"All symbols must have precision fetched from IBKR before applying.\"\n        )\n\n    # Process each symbol group separately\n    result_parts = []\n\n    for symbol_tuple, group_df in df.group_by(symbol_column, maintain_order=True):\n        symbol = symbol_tuple[0] if isinstance(symbol_tuple, tuple) else symbol_tuple\n        security_precision = security_precision_map[symbol]\n\n        # Round each field based on its precision type\n        for field_name in group_df.columns:\n            try:\n                decimal_places = get_field_decimal_places(field_name, security_precision)\n\n                if decimal_places is not None and field_name in group_df.columns:\n                    # Handle list columns (target_prices)\n                    if group_df.schema[field_name] == pl.List(pl.Float64):\n                        group_df = group_df.with_columns(\n                            pl.col(field_name).list.eval(pl.element().round(decimal_places))\n                        )\n                    else:\n                        # Regular float columns\n                        group_df = group_df.with_columns(pl.col(field_name).round(decimal_places))\n            except PrecisionError:\n                # Field not in schema or no precision metadata - skip\n                continue\n\n        result_parts.append(group_df)\n\n    return pl.concat(result_parts)\n</code></pre>"},{"location":"reference/thestrat/#thestrat.get_comparison_tolerance","title":"get_comparison_tolerance","text":"<pre><code>get_comparison_tolerance(field_name: str, security_precision: int = 2) -&gt; float\n</code></pre> <p>Get comparison tolerance for a field based on its precision.</p> <p>Parameters:</p> Name Type Description Default <code>field_name</code> <code>str</code> <p>Field to compare</p> required <code>security_precision</code> <code>int</code> <p>Precision for the security (from IBKR minTick)</p> <code>2</code> <p>Returns:</p> Type Description <code>float</code> <p>Tolerance value (10^-decimal_places) or 0 for exact comparison</p> Example <pre><code># For percent_close_from_high (2 decimals): returns 0.01\ntolerance = get_comparison_tolerance('percent_close_from_high', 2)\n\n# For ath with security_precision=5: returns 0.00001\ntolerance = get_comparison_tolerance('ath', 5)\n\n# For target_count (integer): returns 0 (exact comparison)\ntolerance = get_comparison_tolerance('target_count', 2)\n</code></pre> Source code in <code>thestrat/precision.py</code> <pre><code>def get_comparison_tolerance(field_name: str, security_precision: int = 2) -&gt; float:\n    \"\"\"\n    Get comparison tolerance for a field based on its precision.\n\n    Args:\n        field_name: Field to compare\n        security_precision: Precision for the security (from IBKR minTick)\n\n    Returns:\n        Tolerance value (10^-decimal_places) or 0 for exact comparison\n\n    Example:\n        ```python\n        # For percent_close_from_high (2 decimals): returns 0.01\n        tolerance = get_comparison_tolerance('percent_close_from_high', 2)\n\n        # For ath with security_precision=5: returns 0.00001\n        tolerance = get_comparison_tolerance('ath', 5)\n\n        # For target_count (integer): returns 0 (exact comparison)\n        tolerance = get_comparison_tolerance('target_count', 2)\n        ```\n    \"\"\"\n    try:\n        decimal_places = get_field_decimal_places(field_name, security_precision)\n\n        if decimal_places is not None:\n            return 10 ** (-decimal_places)\n        else:\n            # Integer fields - exact comparison\n            return 0\n    except PrecisionError:\n        # Unknown field - use small epsilon\n        return 1e-6\n</code></pre>"},{"location":"reference/thestrat/#thestrat.get_field_decimal_places","title":"get_field_decimal_places","text":"<pre><code>get_field_decimal_places(\n    field_name: str, security_precision: int = 2\n) -&gt; int | None\n</code></pre> <p>Get decimal places for a field based on its precision type.</p> <p>Parameters:</p> Name Type Description Default <code>field_name</code> <code>str</code> <p>Name of the indicator field</p> required <code>security_precision</code> <code>int</code> <p>Decimal places for this security (from IBKR minTick)</p> <code>2</code> <p>Returns:</p> Type Description <code>int | None</code> <p>Number of decimal places, or None for integer fields</p> <p>Raises:</p> Type Description <code>PrecisionError</code> <p>If field not found or precision_type missing</p> Source code in <code>thestrat/precision.py</code> <pre><code>def get_field_decimal_places(field_name: str, security_precision: int = 2) -&gt; int | None:\n    \"\"\"\n    Get decimal places for a field based on its precision type.\n\n    Args:\n        field_name: Name of the indicator field\n        security_precision: Decimal places for this security (from IBKR minTick)\n\n    Returns:\n        Number of decimal places, or None for integer fields\n\n    Raises:\n        PrecisionError: If field not found or precision_type missing\n    \"\"\"\n    metadata = IndicatorSchema.get_field_metadata(field_name)\n\n    if not metadata:\n        raise PrecisionError(f\"Field '{field_name}' not found in IndicatorSchema\")\n\n    precision_type = metadata.get(\"precision_type\")\n\n    if precision_type is None:\n        raise PrecisionError(f\"Field '{field_name}' missing 'precision_type' in json_schema_extra\")\n\n    if precision_type == PRECISION_TYPE_PERCENTAGE:\n        return 2  # Percentages always 2 decimals\n    elif precision_type == PRECISION_TYPE_PRICE:\n        return security_precision  # Use security's precision from IBKR\n    elif precision_type == PRECISION_TYPE_INTEGER:\n        return None  # No rounding for integers\n    else:\n        raise PrecisionError(f\"Unknown precision_type '{precision_type}' for field '{field_name}'\")\n</code></pre>"},{"location":"reference/thestrat/#thestrat.get_field_precision_type","title":"get_field_precision_type","text":"<pre><code>get_field_precision_type(field_name: str) -&gt; str | None\n</code></pre> <p>Get precision type for a field from IndicatorSchema metadata.</p> <p>Parameters:</p> Name Type Description Default <code>field_name</code> <code>str</code> <p>Name of the indicator field</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>Precision type: 'percentage', 'price', 'integer', or None</p> Source code in <code>thestrat/precision.py</code> <pre><code>def get_field_precision_type(field_name: str) -&gt; str | None:\n    \"\"\"\n    Get precision type for a field from IndicatorSchema metadata.\n\n    Args:\n        field_name: Name of the indicator field\n\n    Returns:\n        Precision type: 'percentage', 'price', 'integer', or None\n    \"\"\"\n    metadata = IndicatorSchema.get_field_metadata(field_name)\n    return metadata.get(\"precision_type\")\n</code></pre>"},{"location":"reference/thestrat/aggregation/","title":"Aggregation","text":"<p>OHLCV timeframe aggregation</p> <p>OHLC timeframe aggregation with precise time boundary control.</p> <p>This module provides vectorized OHLC aggregation across different timeframes with support for asset class-specific timezone handling and boundary alignment.</p> <p>Classes:</p> Name Description <code>Aggregation</code> <p>Convert OHLC data between timeframes with precise time boundary control.</p>"},{"location":"reference/thestrat/aggregation/#thestrat.aggregation.Aggregation","title":"Aggregation","text":"<pre><code>Aggregation(config: AggregationConfig)\n</code></pre> <p>               Bases: <code>Component</code></p> <p>Convert OHLC data between timeframes with precise time boundary control.</p> Features <ul> <li>Time Boundary Control: hour_boundary flag for hourly+ aggregation alignment</li> <li>Session Control: session_start parameter for sub-hourly alignment</li> <li>Asset Class Support: Crypto, equities, FX, futures with timezone handling</li> <li>Vectorized Processing: Pure Polars operations for maximum performance</li> </ul> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>AggregationConfig</code> <p>Validated AggregationConfig containing all configuration settings</p> required <p>Methods:</p> Name Description <code>normalize_timezone</code> <p>Convert timestamps to target timezone.</p> <code>process</code> <p>Convert OHLC data to target timeframes with boundary alignment.</p> <code>validate_input</code> <p>Validate input data format.</p> <code>validate_input_timezones</code> <p>Validate and log timezone information for input data.</p> Source code in <code>thestrat/aggregation.py</code> <pre><code>def __init__(self, config: AggregationConfig):\n    \"\"\"\n    Initialize aggregation component with validated configuration.\n\n    Args:\n        config: Validated AggregationConfig containing all configuration settings\n    \"\"\"\n    super().__init__()\n\n    # Store the validated Pydantic config\n    self.config = config\n\n    # Extract commonly used values for convenience\n    self.target_timeframes = config.target_timeframes.copy()\n    self.asset_class = config.asset_class\n\n    # These fields are guaranteed to be non-None after model validation\n    assert config.timezone is not None\n    assert config.session_start is not None\n    assert config.hour_boundary is not None\n\n    self.timezone = config.timezone\n    self.session_start = config.session_start\n    self.hour_boundary = config.hour_boundary\n\n    # Validate all timeframes\n    from .schemas import TimeframeConfig\n\n    for tf in self.target_timeframes:\n        if not TimeframeConfig.validate_timeframe(tf):\n            raise ValueError(\n                f\"Invalid timeframe '{tf}'. Supported timeframes: {sorted(TimeframeConfig.TIMEFRAME_METADATA.keys())}\"\n            )\n</code></pre>"},{"location":"reference/thestrat/aggregation/#thestrat.aggregation.Aggregation.normalize_timezone","title":"normalize_timezone","text":"<pre><code>normalize_timezone(data: DataFrame) -&gt; DataFrame\n</code></pre> <p>Convert timestamps to target timezone.</p> <p>Handles both naive and timezone-aware timestamps: - Naive: Assumes already in target timezone, adds timezone awareness - Aware (different): Converts from current timezone to target timezone - Aware (same): No conversion needed</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>Input DataFrame with timestamp column</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with timezone-aware timestamps in target timezone</p> Source code in <code>thestrat/aggregation.py</code> <pre><code>def normalize_timezone(self, data: PolarsDataFrame) -&gt; PolarsDataFrame:\n    \"\"\"\n    Convert timestamps to target timezone.\n\n    Handles both naive and timezone-aware timestamps:\n    - Naive: Assumes already in target timezone, adds timezone awareness\n    - Aware (different): Converts from current timezone to target timezone\n    - Aware (same): No conversion needed\n\n    Args:\n        data: Input DataFrame with timestamp column\n\n    Returns:\n        DataFrame with timezone-aware timestamps in target timezone\n    \"\"\"\n    df = data.clone()\n\n    ts_dtype = df.schema[\"timestamp\"]\n\n    # Extract timezone from dtype metadata (None if naive)\n    current_tz = ts_dtype.time_zone if hasattr(ts_dtype, \"time_zone\") else None\n\n    if current_tz is None:\n        # Naive timestamps - assume already in target timezone, add awareness\n        df = df.with_columns([col(\"timestamp\").dt.replace_time_zone(self.timezone)])\n    elif current_tz != self.timezone:\n        # Timezone-aware but different - CONVERT to target timezone\n        df = df.with_columns([col(\"timestamp\").dt.convert_time_zone(self.timezone)])\n    # else: Already in target timezone, no conversion needed\n\n    return df\n</code></pre>"},{"location":"reference/thestrat/aggregation/#thestrat.aggregation.Aggregation.process","title":"process","text":"<pre><code>process(data: DataFrame | DataFrame) -&gt; DataFrame\n</code></pre> <p>Convert OHLC data to target timeframes with boundary alignment.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | DataFrame</code> <p>Input DataFrame with OHLC data including MANDATORY timeframe column</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>Aggregated OHLC DataFrame with consistent column ordering</p> Source code in <code>thestrat/aggregation.py</code> <pre><code>def process(self, data: PolarsDataFrame | PandasDataFrame) -&gt; PolarsDataFrame:\n    \"\"\"\n    Convert OHLC data to target timeframes with boundary alignment.\n\n    Args:\n        data: Input DataFrame with OHLC data including MANDATORY timeframe column\n\n    Returns:\n        Aggregated OHLC DataFrame with consistent column ordering\n    \"\"\"\n    if not self.validate_input(data):\n        raise ValueError(\"Input data validation failed\")\n\n    df = self._convert_to_polars(data)\n\n    # Validate and log timezone information\n    self.validate_input_timezones(df)\n\n    # Convert timestamps to target timezone\n    df = self.normalize_timezone(df)\n\n    # Process the timeframe data (timeframe column is mandatory)\n    return self._process_timeframes(df)\n</code></pre>"},{"location":"reference/thestrat/aggregation/#thestrat.aggregation.Aggregation.validate_input","title":"validate_input","text":"<pre><code>validate_input(data: DataFrame | DataFrame) -&gt; bool\n</code></pre> <p>Validate input data format.</p> Source code in <code>thestrat/aggregation.py</code> <pre><code>def validate_input(self, data: PolarsDataFrame | PandasDataFrame) -&gt; bool:\n    \"\"\"Validate input data format.\"\"\"\n    df = self._convert_to_polars(data)\n\n    from .schemas import IndicatorSchema, TimeframeConfig\n\n    # Check all required columns (including mandatory timeframe)\n    required_cols = IndicatorSchema.get_required_input_columns()\n    missing_cols = [col for col in required_cols if col not in df.columns]\n\n    if missing_cols:\n        print(f\"ERROR: Missing required columns: {missing_cols}\")\n        return False\n\n    # Validate timeframe values\n    unique_timeframes = df[\"timeframe\"].unique().to_list()\n    for tf in unique_timeframes:\n        if not TimeframeConfig.validate_timeframe(tf):\n            print(f\"ERROR: Invalid timeframe '{tf}'\")\n            return False\n\n    # Check for minimum data points\n    if len(df) &lt; 2:\n        print(f\"ERROR: Insufficient data points ({len(df)} &lt; 2)\")\n        return False\n\n    return True\n</code></pre>"},{"location":"reference/thestrat/aggregation/#thestrat.aggregation.Aggregation.validate_input_timezones","title":"validate_input_timezones","text":"<pre><code>validate_input_timezones(data: DataFrame) -&gt; None\n</code></pre> <p>Validate and log timezone information for input data.</p> <p>Performs O(1) timezone detection using Polars dtype metadata and logs helpful warnings/guidance for users about timezone handling.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>Input DataFrame with timestamp column</p> required Note <p>This method uses Polars schema metadata (O(1)) rather than scanning rows, as Polars enforces homogeneous column types - all timestamps in a column share the same timezone (or all are naive).</p> Source code in <code>thestrat/aggregation.py</code> <pre><code>def validate_input_timezones(self, data: PolarsDataFrame) -&gt; None:\n    \"\"\"\n    Validate and log timezone information for input data.\n\n    Performs O(1) timezone detection using Polars dtype metadata and logs\n    helpful warnings/guidance for users about timezone handling.\n\n    Args:\n        data: Input DataFrame with timestamp column\n\n    Note:\n        This method uses Polars schema metadata (O(1)) rather than scanning\n        rows, as Polars enforces homogeneous column types - all timestamps\n        in a column share the same timezone (or all are naive).\n    \"\"\"\n    ts_dtype = data.schema[\"timestamp\"]\n\n    # Extract timezone from dtype metadata (None if naive)\n    current_tz = ts_dtype.time_zone if hasattr(ts_dtype, \"time_zone\") else None\n\n    if current_tz is None:\n        # Naive timestamps - warn user and provide conversion example\n        first_row_preview = data[0] if len(data) &gt; 0 else \"No data\"\n        logging.warning(\n            f\"Naive timestamps detected - assuming data is already in {self.timezone}\\n\"\n            f\"First row: {first_row_preview}\\n\"\n            f\"If your data is UTC from database, convert before feeding to Factory:\\n\"\n            f\"  df = df.with_columns(\\n\"\n            f\"      pl.col('timestamp')\\n\"\n            f\"        .dt.replace_time_zone('UTC')\\n\"\n            f\"        .dt.convert_time_zone('{self.timezone}')\\n\"\n            f\"  )\"\n        )\n    elif current_tz != self.timezone:\n        # Timezone-aware but different from target - will be converted\n        first_row_preview = data[0] if len(data) &gt; 0 else \"No data\"\n        logging.info(f\"Converting timestamps from {current_tz} to {self.timezone}\\nFirst row: {first_row_preview}\")\n</code></pre>"},{"location":"reference/thestrat/base/","title":"Base","text":"<p>Abstract base classes</p> <p>Base component classes for TheStrat module.</p> <p>This module provides the abstract base class and core functionality for all TheStrat components.</p> <p>Classes:</p> Name Description <code>Component</code> <p>Base class for all TheStrat components.</p>"},{"location":"reference/thestrat/base/#thestrat.base.Component","title":"Component","text":"<pre><code>Component()\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Base class for all TheStrat components.</p> <p>Methods:</p> Name Description <code>process</code> <p>Process data and return Polars DataFrame results.</p> <code>validate_input</code> <p>Validate input data format.</p> Source code in <code>thestrat/base.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize base component with metadata tracking.\"\"\"\n    from datetime import datetime\n\n    self._created_at = datetime.now()\n</code></pre>"},{"location":"reference/thestrat/base/#thestrat.base.Component.process","title":"process  <code>abstractmethod</code>","text":"<pre><code>process(data: DataFrame | DataFrame) -&gt; DataFrame\n</code></pre> <p>Process data and return Polars DataFrame results.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | DataFrame</code> <p>Input DataFrame (Polars or Pandas)</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>Processed PolarsDataFrame with results</p> Source code in <code>thestrat/base.py</code> <pre><code>@abstractmethod\ndef process(self, data: PolarsDataFrame | PandasDataFrame) -&gt; PolarsDataFrame:\n    \"\"\"\n    Process data and return Polars DataFrame results.\n\n    Args:\n        data: Input DataFrame (Polars or Pandas)\n\n    Returns:\n        Processed PolarsDataFrame with results\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/thestrat/base/#thestrat.base.Component.validate_input","title":"validate_input  <code>abstractmethod</code>","text":"<pre><code>validate_input(data: DataFrame | DataFrame) -&gt; None\n</code></pre> <p>Validate input data format.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | DataFrame</code> <p>Input DataFrame to validate</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If data format is invalid, with specific error message</p> Source code in <code>thestrat/base.py</code> <pre><code>@abstractmethod\ndef validate_input(self, data: PolarsDataFrame | PandasDataFrame) -&gt; None:\n    \"\"\"\n    Validate input data format.\n\n    Args:\n        data: Input DataFrame to validate\n\n    Raises:\n        ValueError: If data format is invalid, with specific error message\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/thestrat/factory/","title":"Factory","text":"<p>Component creation with factory pattern</p> <p>Factory pattern for TheStrat component creation and configuration.</p> <p>This module provides clean factory methods for creating and configuring TheStrat components with Pydantic schema validation.</p> <p>Classes:</p> Name Description <code>ComponentDict</code> <p>Type definition for component dictionary returned by Factory.create_all().</p> <code>Factory</code> <p>Factory class for creating TheStrat components.</p>"},{"location":"reference/thestrat/factory/#thestrat.factory.ComponentDict","title":"ComponentDict","text":"<p>               Bases: <code>TypedDict</code></p> <p>Type definition for component dictionary returned by Factory.create_all().</p>"},{"location":"reference/thestrat/factory/#thestrat.factory.Factory","title":"Factory","text":"<p>Factory class for creating TheStrat components.</p> <p>Provides static methods for creating individual components and class methods for creating complete processing pipelines. All methods accept validated Pydantic configuration models.</p> <p>Methods:</p> Name Description <code>create_aggregation</code> <p>Create aggregation component from validated configuration.</p> <code>create_all</code> <p>Create complete processing pipeline with aggregation and indicators.</p> <code>create_indicators</code> <p>Create indicators component from validated configuration.</p> <code>get_asset_class_config</code> <p>Get default configuration for specific asset class.</p> <code>get_supported_asset_classes</code> <p>Get list of supported asset classes.</p> <code>get_supported_timeframes</code> <p>Get list of all supported timeframes in chronological order.</p> <code>get_timeframe_metadata</code> <p>Get detailed metadata for a specific timeframe.</p>"},{"location":"reference/thestrat/factory/#thestrat.factory.Factory.create_aggregation","title":"create_aggregation  <code>staticmethod</code>","text":"<pre><code>create_aggregation(config: AggregationConfig) -&gt; Aggregation\n</code></pre> <p>Create aggregation component from validated configuration.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>AggregationConfig</code> <p>Validated AggregationConfig containing: - <code>target_timeframes</code>: Target timeframes list (e.g., [\"1H\", \"5m\", \"1D\"]) - <code>asset_class</code>: Asset class type (crypto, equities, fx, futures, commodities) - <code>timezone</code>: Timezone override (UTC asset classes always use UTC;            non-UTC uses priority: specified &gt; system &gt; asset_class default) - <code>hour_boundary</code>: Align to hour boundaries (auto-determined if None) - <code>session_start</code>: Session start time (asset class default if None)</p> required <p>Returns:</p> Type Description <code>Aggregation</code> <p>Configured Aggregation component</p> Example <p>from thestrat.schemas import AggregationConfig config = AggregationConfig( ...     target_timeframes=[\"5m\", \"1H\"], ...     asset_class=\"crypto\", ...     timezone=\"UTC\" ... ) aggregation = Factory.create_aggregation(config)</p> Source code in <code>thestrat/factory.py</code> <pre><code>@staticmethod\ndef create_aggregation(config: AggregationConfig) -&gt; Aggregation:\n    \"\"\"\n    Create aggregation component from validated configuration.\n\n    Args:\n        config: Validated AggregationConfig containing:\n            - `target_timeframes`: Target timeframes list (e.g., [\"1H\", \"5m\", \"1D\"])\n            - `asset_class`: Asset class type (crypto, equities, fx, futures, commodities)\n            - `timezone`: Timezone override (UTC asset classes always use UTC;\n                       non-UTC uses priority: specified &gt; system &gt; asset_class default)\n            - `hour_boundary`: Align to hour boundaries (auto-determined if None)\n            - `session_start`: Session start time (asset class default if None)\n\n    Returns:\n        Configured Aggregation component\n\n    Example:\n        &gt;&gt;&gt; from thestrat.schemas import AggregationConfig\n        &gt;&gt;&gt; config = AggregationConfig(\n        ...     target_timeframes=[\"5m\", \"1H\"],\n        ...     asset_class=\"crypto\",\n        ...     timezone=\"UTC\"\n        ... )\n        &gt;&gt;&gt; aggregation = Factory.create_aggregation(config)\n    \"\"\"\n    return Aggregation(config)\n</code></pre>"},{"location":"reference/thestrat/factory/#thestrat.factory.Factory.create_all","title":"create_all  <code>classmethod</code>","text":"<pre><code>create_all(config: FactoryConfig) -&gt; ComponentDict\n</code></pre> <p>Create complete processing pipeline with aggregation and indicators.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>FactoryConfig</code> <p>Validated FactoryConfig containing: <code>aggregation</code>: AggregationConfig with target timeframes and settings <code>indicators</code>: IndicatorsConfig with per-timeframe configurations</p> required <p>Returns:</p> Type Description <code>ComponentDict</code> <p>Dictionary containing created components:</p> <code>ComponentDict</code> <p>{ \"aggregation\": Aggregation, \"indicators\": Indicators</p> <code>ComponentDict</code> <p>}</p> Example <p>from thestrat.schemas import FactoryConfig, AggregationConfig, IndicatorsConfig, TimeframeItemConfig config = FactoryConfig( ...     aggregation=AggregationConfig(target_timeframes=[\"5m\"]), ...     indicators=IndicatorsConfig( ...         timeframe_configs=[TimeframeItemConfig(timeframes=[\"all\"])] ...     ) ... ) components = Factory.create_all(config)</p> Source code in <code>thestrat/factory.py</code> <pre><code>@classmethod\ndef create_all(cls, config: FactoryConfig) -&gt; ComponentDict:\n    \"\"\"\n    Create complete processing pipeline with aggregation and indicators.\n\n    Args:\n        config: Validated FactoryConfig containing:\n            `aggregation`: AggregationConfig with target timeframes and settings\n            `indicators`: IndicatorsConfig with per-timeframe configurations\n\n    Returns:\n        Dictionary containing created components:\n        {\n            \"aggregation\": Aggregation,\n            \"indicators\": Indicators\n        }\n\n    Example:\n        &gt;&gt;&gt; from thestrat.schemas import FactoryConfig, AggregationConfig, IndicatorsConfig, TimeframeItemConfig\n        &gt;&gt;&gt; config = FactoryConfig(\n        ...     aggregation=AggregationConfig(target_timeframes=[\"5m\"]),\n        ...     indicators=IndicatorsConfig(\n        ...         timeframe_configs=[TimeframeItemConfig(timeframes=[\"all\"])]\n        ...     )\n        ... )\n        &gt;&gt;&gt; components = Factory.create_all(config)\n    \"\"\"\n    return {\n        \"aggregation\": cls.create_aggregation(config.aggregation),\n        \"indicators\": cls.create_indicators(config.indicators),\n    }\n</code></pre>"},{"location":"reference/thestrat/factory/#thestrat.factory.Factory.create_indicators","title":"create_indicators  <code>staticmethod</code>","text":"<pre><code>create_indicators(config: IndicatorsConfig) -&gt; Indicators\n</code></pre> <p>Create indicators component from validated configuration.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>IndicatorsConfig</code> <p>Validated IndicatorsConfig containing per-timeframe configurations using Pydantic models</p> required <p>Returns:</p> Type Description <code>Indicators</code> <p>Configured Indicators component</p> Example <p>from thestrat.schemas import IndicatorsConfig, TimeframeItemConfig, SwingPointsConfig config = IndicatorsConfig( ...     timeframe_configs=[ ...         TimeframeItemConfig( ...             timeframes=[\"5m\", \"15m\"], ...             swing_points=SwingPointsConfig(window=7, threshold=3.0) ...         ) ...     ] ... ) indicators = Factory.create_indicators(config)</p> Source code in <code>thestrat/factory.py</code> <pre><code>@staticmethod\ndef create_indicators(config: IndicatorsConfig) -&gt; Indicators:\n    \"\"\"\n    Create indicators component from validated configuration.\n\n    Args:\n        config: Validated IndicatorsConfig containing per-timeframe configurations\n            using Pydantic models\n\n    Returns:\n        Configured Indicators component\n\n    Example:\n        &gt;&gt;&gt; from thestrat.schemas import IndicatorsConfig, TimeframeItemConfig, SwingPointsConfig\n        &gt;&gt;&gt; config = IndicatorsConfig(\n        ...     timeframe_configs=[\n        ...         TimeframeItemConfig(\n        ...             timeframes=[\"5m\", \"15m\"],\n        ...             swing_points=SwingPointsConfig(window=7, threshold=3.0)\n        ...         )\n        ...     ]\n        ... )\n        &gt;&gt;&gt; indicators = Factory.create_indicators(config)\n    \"\"\"\n    return Indicators(config)\n</code></pre>"},{"location":"reference/thestrat/factory/#thestrat.factory.Factory.get_asset_class_config","title":"get_asset_class_config  <code>staticmethod</code>","text":"<pre><code>get_asset_class_config(asset_class: str) -&gt; dict[str, Any]\n</code></pre> <p>Get default configuration for specific asset class.</p> <p>Parameters:</p> Name Type Description Default <code>asset_class</code> <code>str</code> <p>Asset class type</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary with default <code>timezone</code> and <code>session_start</code></p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If asset_class is not supported</p> Source code in <code>thestrat/factory.py</code> <pre><code>@staticmethod\ndef get_asset_class_config(asset_class: str) -&gt; dict[str, Any]:\n    \"\"\"\n    Get default configuration for specific asset class.\n\n    Args:\n        asset_class: Asset class type\n\n    Returns:\n        Dictionary with default `timezone` and `session_start`\n\n    Raises:\n        ValueError: If asset_class is not supported\n    \"\"\"\n    from .schemas import AssetClassConfig\n\n    if asset_class not in Factory.get_supported_asset_classes():\n        raise ValueError(f\"Unsupported asset class: {asset_class}\")\n\n    return AssetClassConfig.REGISTRY[asset_class].model_dump()\n</code></pre>"},{"location":"reference/thestrat/factory/#thestrat.factory.Factory.get_supported_asset_classes","title":"get_supported_asset_classes  <code>staticmethod</code>","text":"<pre><code>get_supported_asset_classes() -&gt; list[str]\n</code></pre> <p>Get list of supported asset classes.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of supported asset class strings</p> Source code in <code>thestrat/factory.py</code> <pre><code>@staticmethod\ndef get_supported_asset_classes() -&gt; list[str]:\n    \"\"\"\n    Get list of supported asset classes.\n\n    Returns:\n        List of supported asset class strings\n    \"\"\"\n    from .schemas import AssetClassConfig\n\n    return list(AssetClassConfig.REGISTRY.keys())\n</code></pre>"},{"location":"reference/thestrat/factory/#thestrat.factory.Factory.get_supported_timeframes","title":"get_supported_timeframes  <code>cached</code> <code>staticmethod</code>","text":"<pre><code>get_supported_timeframes() -&gt; list[str]\n</code></pre> <p>Get list of all supported timeframes in chronological order.</p> <p>Returns a chronologically ordered list of timeframe strings that can be used with the aggregation and indicators components. These timeframes are validated when creating configurations.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>Chronologically ordered list of supported timeframe strings (shortest to longest)</p> Example <p>from thestrat import Factory timeframes = Factory.get_supported_timeframes() print(timeframes) ['1min', '5min', '15min', '30min', '1h', '4h', '6h', '12h', '1d', '1w', '1m', '1q', '1y']</p> Note <p>The timeframes are ordered by duration (shortest to longest) and follow standard conventions: - Minutes: <code>1min</code>, <code>5min</code>, <code>15min</code>, <code>30min</code> - Hours: <code>1h</code>, <code>4h</code>, <code>6h</code>, <code>12h</code> - Days/Weeks/Months: <code>1d</code>, <code>1w</code>, <code>1m</code> (month), <code>1q</code> (quarter), <code>1y</code></p> Source code in <code>thestrat/factory.py</code> <pre><code>@staticmethod\n@lru_cache(maxsize=1)\ndef get_supported_timeframes() -&gt; list[str]:\n    \"\"\"\n    Get list of all supported timeframes in chronological order.\n\n    Returns a chronologically ordered list of timeframe strings that can be used with\n    the aggregation and indicators components. These timeframes are\n    validated when creating configurations.\n\n    Returns:\n        Chronologically ordered list of supported timeframe strings (shortest to longest)\n\n    Example:\n        &gt;&gt;&gt; from thestrat import Factory\n        &gt;&gt;&gt; timeframes = Factory.get_supported_timeframes()\n        &gt;&gt;&gt; print(timeframes)\n        ['1min', '5min', '15min', '30min', '1h', '4h', '6h', '12h', '1d', '1w', '1m', '1q', '1y']\n\n        &gt;&gt;&gt; # Use in configuration\n        &gt;&gt;&gt; from thestrat.schemas import AggregationConfig\n        &gt;&gt;&gt; available_timeframes = Factory.get_supported_timeframes()\n        &gt;&gt;&gt; config = AggregationConfig(\n        ...     target_timeframes=[available_timeframes[0], available_timeframes[1]],\n        ...     asset_class=\"equities\"\n        ... )\n\n    Note:\n        The timeframes are ordered by duration (shortest to longest) and follow standard conventions:\n        - Minutes: `1min`, `5min`, `15min`, `30min`\n        - Hours: `1h`, `4h`, `6h`, `12h`\n        - Days/Weeks/Months: `1d`, `1w`, `1m` (month), `1q` (quarter), `1y`\n    \"\"\"\n    from .schemas import TimeframeConfig\n\n    # Pre-compute timeframes with their durations for efficient sorting\n    timeframes_with_duration = [\n        (tf, TimeframeConfig.TIMEFRAME_METADATA.get(tf, {}).get(\"seconds\", float(\"inf\")))\n        for tf in TimeframeConfig.TIMEFRAME_METADATA.keys()\n    ]\n\n    # Sort by duration and return just the timeframe strings\n    return [tf for tf, _ in sorted(timeframes_with_duration, key=lambda x: x[1])]\n</code></pre>"},{"location":"reference/thestrat/factory/#thestrat.factory.Factory.get_supported_timeframes--use-in-configuration","title":"Use in configuration","text":"<p>from thestrat.schemas import AggregationConfig available_timeframes = Factory.get_supported_timeframes() config = AggregationConfig( ...     target_timeframes=[available_timeframes[0], available_timeframes[1]], ...     asset_class=\"equities\" ... )</p>"},{"location":"reference/thestrat/factory/#thestrat.factory.Factory.get_timeframe_metadata","title":"get_timeframe_metadata  <code>staticmethod</code>","text":"<pre><code>get_timeframe_metadata(timeframe: str) -&gt; dict[str, Any]\n</code></pre> <p>Get detailed metadata for a specific timeframe.</p> <p>Provides comprehensive information about a timeframe including its category, duration in seconds, description, and typical use cases. This is useful for understanding the characteristics and appropriate applications of different timeframes.</p> <p>Parameters:</p> Name Type Description Default <code>timeframe</code> <code>str</code> <p>Timeframe string to get metadata for (e.g., \"5min\", \"1h\", \"1d\")</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary containing:</p> <code>dict[str, Any]</code> <ul> <li><code>category</code>: Timeframe category (e.g., \"sub-hourly\", \"hourly\", \"daily\")</li> </ul> <code>dict[str, Any]</code> <ul> <li><code>seconds</code>: Duration in seconds</li> </ul> <code>dict[str, Any]</code> <ul> <li><code>description</code>: Human-readable description</li> </ul> <code>dict[str, Any]</code> <ul> <li><code>typical_use</code>: Common use cases for this timeframe</li> </ul> <code>dict[str, Any]</code> <ul> <li><code>data_volume</code>: Expected data volume level</li> </ul> <p>Raises:</p> Type Description <code>ValueError</code> <p>If timeframe is not supported</p> Example <p>from thestrat import Factory metadata = Factory.get_timeframe_metadata(\"1h\") print(metadata) {     'category': 'hourly',     'seconds': 3600,     'description': '1-hour bars for daily structure analysis',     'typical_use': 'Day trading context, hourly levels',     'data_volume': 'low' }</p> See Also <ul> <li>:meth:<code>get_supported_timeframes</code>: Get list of all supported timeframes</li> <li>:meth:<code>validate_timeframe_format</code>: Validate a timeframe string</li> </ul> Source code in <code>thestrat/factory.py</code> <pre><code>@staticmethod\ndef get_timeframe_metadata(timeframe: str) -&gt; dict[str, Any]:\n    \"\"\"\n    Get detailed metadata for a specific timeframe.\n\n    Provides comprehensive information about a timeframe including its\n    category, duration in seconds, description, and typical use cases.\n    This is useful for understanding the characteristics and appropriate\n    applications of different timeframes.\n\n    Args:\n        timeframe: Timeframe string to get metadata for (e.g., \"5min\", \"1h\", \"1d\")\n\n    Returns:\n        Dictionary containing:\n        - `category`: Timeframe category (e.g., \"sub-hourly\", \"hourly\", \"daily\")\n        - `seconds`: Duration in seconds\n        - `description`: Human-readable description\n        - `typical_use`: Common use cases for this timeframe\n        - `data_volume`: Expected data volume level\n\n    Raises:\n        ValueError: If timeframe is not supported\n\n    Example:\n        &gt;&gt;&gt; from thestrat import Factory\n        &gt;&gt;&gt; metadata = Factory.get_timeframe_metadata(\"1h\")\n        &gt;&gt;&gt; print(metadata)\n        {\n            'category': 'hourly',\n            'seconds': 3600,\n            'description': '1-hour bars for daily structure analysis',\n            'typical_use': 'Day trading context, hourly levels',\n            'data_volume': 'low'\n        }\n\n        &gt;&gt;&gt; # Check if a timeframe is suitable for day trading\n        &gt;&gt;&gt; metadata = Factory.get_timeframe_metadata(\"5min\")\n        &gt;&gt;&gt; if \"day trading\" in metadata[\"typical_use\"].lower():\n        ...     print(f\"5min is suitable for day trading\")\n\n        &gt;&gt;&gt; # Get all intraday timeframes\n        &gt;&gt;&gt; all_timeframes = Factory.get_supported_timeframes()\n        &gt;&gt;&gt; intraday = []\n        &gt;&gt;&gt; for tf in all_timeframes:\n        ...     meta = Factory.get_timeframe_metadata(tf)\n        ...     if meta[\"category\"] in [\"sub-hourly\", \"hourly\"]:\n        ...         intraday.append(tf)\n\n    See Also:\n        - :meth:`get_supported_timeframes`: Get list of all supported timeframes\n        - :meth:`validate_timeframe_format`: Validate a timeframe string\n    \"\"\"\n    # Use cached helper method to get metadata efficiently\n    metadata = Factory._get_cached_timeframe_metadata(timeframe)\n    return metadata.copy()  # Return a copy to prevent modification\n</code></pre>"},{"location":"reference/thestrat/factory/#thestrat.factory.Factory.get_timeframe_metadata--check-if-a-timeframe-is-suitable-for-day-trading","title":"Check if a timeframe is suitable for day trading","text":"<p>metadata = Factory.get_timeframe_metadata(\"5min\") if \"day trading\" in metadata[\"typical_use\"].lower(): ...     print(f\"5min is suitable for day trading\")</p>"},{"location":"reference/thestrat/factory/#thestrat.factory.Factory.get_timeframe_metadata--get-all-intraday-timeframes","title":"Get all intraday timeframes","text":"<p>all_timeframes = Factory.get_supported_timeframes() intraday = [] for tf in all_timeframes: ...     meta = Factory.get_timeframe_metadata(tf) ...     if meta[\"category\"] in [\"sub-hourly\", \"hourly\"]: ...         intraday.append(tf)</p>"},{"location":"reference/thestrat/indicators/","title":"Indicators","text":"<p>TheStrat technical indicators</p> <p>Vectorized Strat technical indicators implementation.</p> <p>This module provides comprehensive Strat pattern analysis with high-performance vectorized calculations using Polars operations.</p> <p>Classes:</p> Name Description <code>Indicators</code> <p>Vectorized implementation of all Strat technical indicators.</p>"},{"location":"reference/thestrat/indicators/#thestrat.indicators.Indicators","title":"Indicators","text":"<pre><code>Indicators(config: IndicatorsConfig)\n</code></pre> <p>               Bases: <code>Component</code></p> <p>Vectorized implementation of all Strat technical indicators.</p> <p>Provides comprehensive technical analysis including swing point detection, market structure analysis, pattern recognition, and gap detection optimized for TheStrat methodology.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>IndicatorsConfig</code> <p>Validated IndicatorsConfig containing per-timeframe configurations</p> required <p>Methods:</p> Name Description <code>get_signal_object</code> <p>Create SignalMetadata object from single-row DataFrame.</p> <code>process</code> <p>Calculate all Strat indicators for OHLC data.</p> <code>validate_input</code> <p>Validate input data format.</p> Source code in <code>thestrat/indicators.py</code> <pre><code>def __init__(self, config: IndicatorsConfig):\n    \"\"\"\n    Initialize indicators component with validated configuration.\n\n    Args:\n        config: Validated IndicatorsConfig containing per-timeframe configurations\n    \"\"\"\n    super().__init__()\n\n    # Store the validated Pydantic config\n    self.config = config\n</code></pre>"},{"location":"reference/thestrat/indicators/#thestrat.indicators.Indicators.get_signal_object","title":"get_signal_object  <code>classmethod</code>","text":"<pre><code>get_signal_object(df: DataFrame) -&gt; SignalMetadata\n</code></pre> <p>Create SignalMetadata object from single-row DataFrame.</p> <p>Decoupled from pipeline - can be called standalone with database query results. Expects DataFrame with exactly 1 row containing signal data with pre-calculated entry/stop prices and targets.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame with exactly 1 row containing signal data</p> required <p>Returns:</p> Type Description <code>SignalMetadata</code> <p>SignalMetadata object with targets parsed from DataFrame</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If df doesn't have exactly 1 row or missing required columns</p> Example Source code in <code>thestrat/indicators.py</code> <pre><code>@classmethod\ndef get_signal_object(cls, df: PolarsDataFrame) -&gt; \"SignalMetadata\":\n    \"\"\"\n    Create SignalMetadata object from single-row DataFrame.\n\n    Decoupled from pipeline - can be called standalone with database query results.\n    Expects DataFrame with exactly 1 row containing signal data with pre-calculated\n    entry/stop prices and targets.\n\n    Args:\n        df: DataFrame with exactly 1 row containing signal data\n\n    Returns:\n        SignalMetadata object with targets parsed from DataFrame\n\n    Raises:\n        ValueError: If df doesn't have exactly 1 row or missing required columns\n\n    Example:\n        # Query database for specific signal\n        signal_df = db.query(\\\"\\\"\\\"\n            SELECT * FROM signals\n            WHERE symbol='AAPL' AND timestamp='2024-01-15 10:30:00'\n        \\\"\\\"\\\")\n\n        # Create signal object (no pipeline needed)\n        signal = Indicators.get_signal_object(signal_df)\n    \"\"\"\n    if df.shape[0] != 1:\n        raise ValueError(\n            f\"get_signal_object() expects DataFrame with exactly 1 row, got {df.shape[0]} rows. \"\n            \"Query database to filter to specific signal first.\"\n        )\n\n    from .signals import SIGNALS, SignalBias, SignalCategory, SignalMetadata, TargetLevel\n\n    # Extract row data\n    row = df.row(0, named=True)\n\n    # Validate required columns exist\n    if \"entry_price\" not in row or \"stop_price\" not in row:\n        raise ValueError(\n            \"DataFrame missing required 'entry_price' and/or 'stop_price' columns. \"\n            \"These columns must be calculated during signal detection in the full pipeline. \"\n            \"Run the complete Indicators.process() pipeline to generate these columns.\"\n        )\n\n    # Parse target_prices from native list (not JSON)\n    target_prices = []\n    if row.get(\"target_prices\") is not None:\n        # target_prices is List[Float64] from database\n        target_list = row[\"target_prices\"]\n        target_prices = [TargetLevel(price=price) for price in target_list]\n\n    # Get signal configuration\n    pattern = row[\"signal\"]\n    config = SIGNALS.get(pattern, {})\n\n    # Use pre-calculated entry/stop prices from setup bar\n    entry_price = float(row[\"entry_price\"]) if row[\"entry_price\"] is not None else None\n    stop_price = float(row[\"stop_price\"]) if row[\"stop_price\"] is not None else None\n\n    if entry_price is None or stop_price is None:\n        raise ValueError(\n            f\"Signal has null entry_price or stop_price. Pattern: {pattern}, \"\n            f\"entry_price: {entry_price}, stop_price: {stop_price}. \"\n            \"This indicates the signal was detected without sufficient historical data for setup bar lookup.\"\n        )\n\n    # Create SignalMetadata\n    signal = SignalMetadata(\n        pattern=pattern,\n        category=SignalCategory(row[\"type\"]),\n        bias=SignalBias(row[\"bias\"]),\n        bar_count=config.get(\"bar_count\", 2),\n        entry_price=entry_price,\n        stop_price=stop_price,\n        target_prices=target_prices,\n        timestamp=row[\"timestamp\"],\n        symbol=row.get(\"symbol\"),\n        timeframe=row.get(\"timeframe\"),\n    )\n\n    return signal\n</code></pre>"},{"location":"reference/thestrat/indicators/#thestrat.indicators.Indicators.get_signal_object--query-database-for-specific-signal","title":"Query database for specific signal","text":"<p>signal_df = db.query(\"\"\"     SELECT * FROM signals     WHERE symbol='AAPL' AND timestamp='2024-01-15 10:30:00' \"\"\")</p>"},{"location":"reference/thestrat/indicators/#thestrat.indicators.Indicators.get_signal_object--create-signal-object-no-pipeline-needed","title":"Create signal object (no pipeline needed)","text":"<p>signal = Indicators.get_signal_object(signal_df)</p>"},{"location":"reference/thestrat/indicators/#thestrat.indicators.Indicators.process","title":"process","text":"<pre><code>process(data: DataFrame | DataFrame) -&gt; DataFrame\n</code></pre> <p>Calculate all Strat indicators for OHLC data.</p> <p>Performs comprehensive technical analysis including swing point detection, market structure analysis, pattern recognition, and gap detection. Calculations run sequentially due to data dependencies between indicators.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | DataFrame</code> <p>Input DataFrame with OHLC data</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with all Strat indicators added</p> Source code in <code>thestrat/indicators.py</code> <pre><code>def process(self, data: PolarsDataFrame | PandasDataFrame) -&gt; PolarsDataFrame:\n    \"\"\"\n    Calculate all Strat indicators for OHLC data.\n\n    Performs comprehensive technical analysis including swing point detection, market structure\n    analysis, pattern recognition, and gap detection. Calculations run sequentially due to\n    data dependencies between indicators.\n\n    Args:\n        data: Input DataFrame with OHLC data\n\n    Returns:\n        DataFrame with all Strat indicators added\n    \"\"\"\n    self.validate_input(data)\n\n    # Convert to Polars if needed\n    df = self._convert_to_polars(data)\n\n    # Ensure optional schema columns are present\n    if \"symbol\" not in df.columns:\n        df = df.with_columns(lit(None, dtype=String).alias(\"symbol\"))\n\n    # Check if data has timeframe column for per-timeframe processing\n    if \"timeframe\" in df.columns:\n        # ALWAYS partition by timeframe to prevent cross-timeframe pollution in rolling/cumulative operations\n        # This ensures market structure calculations only consider bars from the same timeframe\n        timeframe_groups = df.partition_by(\"timeframe\", as_dict=True)\n        processed_groups = []\n\n        # Check if \"all\" timeframe is configured\n        has_all_config = any(\"all\" in tf_config.timeframes for tf_config in self.config.timeframe_configs)\n\n        for timeframe_key, timeframe_data in timeframe_groups.items():\n            # Extract timeframe string from tuple key\n            timeframe = timeframe_key[0] if isinstance(timeframe_key, tuple) else timeframe_key\n\n            # Get config for this timeframe\n            # If \"all\" config exists, use it for every timeframe; otherwise use timeframe-specific config\n            if has_all_config:\n                tf_config = self._get_config_for_timeframe(\"any_timeframe_will_get_all_config\")\n            else:\n                tf_config = self._get_config_for_timeframe(timeframe)\n\n            # Process this timeframe with its specific config\n            processed_data = self._process_single_timeframe(timeframe_data, tf_config)\n            processed_groups.append(processed_data)\n\n        # Combine all processed groups\n        df = processed_groups[0]\n        for group in processed_groups[1:]:\n            df = df.vstack(group)\n\n        # Sort by original order (symbol, timeframe, timestamp)\n        sort_cols = []\n        if \"symbol\" in df.columns:\n            sort_cols.append(\"symbol\")\n        sort_cols.extend([\"timeframe\", \"timestamp\"])\n        df = df.sort(sort_cols)\n    else:\n        # No timeframe column - must have \"all\" configuration\n        has_all_config = any(\"all\" in tf_config.timeframes for tf_config in self.config.timeframe_configs)\n        if not has_all_config:\n            raise ValueError(\"Data without timeframe column requires an 'all' timeframe configuration.\")\n\n        all_config = self._get_config_for_timeframe(\"any_timeframe_will_get_all_config\")\n        df = self._process_single_timeframe(df, all_config)\n\n    return df\n</code></pre>"},{"location":"reference/thestrat/indicators/#thestrat.indicators.Indicators.validate_input","title":"validate_input","text":"<pre><code>validate_input(data: DataFrame | DataFrame) -&gt; None\n</code></pre> <p>Validate input data format.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If data format is invalid, with specific error message</p> Source code in <code>thestrat/indicators.py</code> <pre><code>def validate_input(self, data: PolarsDataFrame | PandasDataFrame) -&gt; None:\n    \"\"\"\n    Validate input data format.\n\n    Raises:\n        ValueError: If data format is invalid, with specific error message\n    \"\"\"\n    df = self._convert_to_polars(data)\n\n    # Check required columns\n    required_cols = [\"timestamp\", \"open\", \"high\", \"low\", \"close\"]\n    missing_cols = [col for col in required_cols if col not in df.columns]\n    if missing_cols:\n        raise ValueError(f\"Missing required columns: {missing_cols}\")\n\n    # Note: Minimum data point validation removed as _calculate_swing_points\n    # now handles small datasets gracefully with proper safeguards\n\n    # Verify price data integrity\n    validations = df.select(\n        [\n            (col(\"high\") &gt;= col(\"low\")).all().alias(\"high_gte_low\"),\n            (col(\"high\") &gt;= col(\"open\")).all().alias(\"high_gte_open\"),\n            (col(\"high\") &gt;= col(\"close\")).all().alias(\"high_gte_close\"),\n            (col(\"low\") &lt;= col(\"open\")).all().alias(\"low_lte_open\"),\n            (col(\"low\") &lt;= col(\"close\")).all().alias(\"low_lte_close\"),\n        ]\n    )\n\n    validation_results = validations.to_numpy().flatten()\n    validation_names = [\"high &gt;= low\", \"high &gt;= open\", \"high &gt;= close\", \"low &lt;= open\", \"low &lt;= close\"]\n\n    failed_validations = [\n        name for name, result in zip(validation_names, validation_results, strict=False) if not result\n    ]\n    if failed_validations:\n        raise ValueError(f\"Invalid price data: failed validations: {failed_validations}\")\n</code></pre>"},{"location":"reference/thestrat/schemas/","title":"Schemas","text":"<p>Pydantic configuration schemas</p> <p>Pydantic schema models for TheStrat configuration validation.</p> <p>This module provides comprehensive validation schemas that replace all manual validation logic in the Factory class. Models use Pydantic v2 features for maximum performance, type safety, and detailed error reporting.</p> <p>Classes:</p> Name Description <code>AggregationConfig</code> <p>Complete configuration for aggregation component with market-aware settings.</p> <code>AssetClassConfig</code> <p>Configuration for a specific asset class with comprehensive market metadata.</p> <code>FactoryConfig</code> <p>Root configuration for Factory.create_all method with complete pipeline setup.</p> <code>GapDetectionConfig</code> <p>Configuration for gap detection with comprehensive threshold documentation.</p> <code>IndicatorSchema</code> <p>Complete Indicator Schema</p> <code>IndicatorsConfig</code> <p>Complete configuration for indicators component with per-timeframe settings.</p> <code>SwingPointsConfig</code> <p>Configuration for swing point detection with comprehensive parameter documentation.</p> <code>TargetConfig</code> <p>Configuration for multi-target detection.</p> <code>TimeframeConfig</code> <p>Configuration and validation for timeframes with comprehensive metadata.</p> <code>TimeframeItemConfig</code> <p>Configuration for a single timeframe item with flexible timeframe targeting.</p>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.AggregationConfig","title":"AggregationConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Complete configuration for aggregation component with market-aware settings.</p> <p>Methods:</p> Name Description <code>apply_asset_class_defaults</code> <p>Apply AssetClassConfig defaults for timezone, hour_boundary, and session_start.</p> <code>validate_and_expand_target_timeframes</code> <p>Validate target_timeframes field and expand 'all' keyword.</p>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.AggregationConfig.apply_asset_class_defaults","title":"apply_asset_class_defaults  <code>classmethod</code>","text":"<pre><code>apply_asset_class_defaults(data: Any) -&gt; Any\n</code></pre> <p>Apply AssetClassConfig defaults for timezone, hour_boundary, and session_start.</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@model_validator(mode=\"before\")\n@classmethod\ndef apply_asset_class_defaults(cls, data: Any) -&gt; Any:\n    \"\"\"Apply AssetClassConfig defaults for timezone, hour_boundary, and session_start.\"\"\"\n    if not isinstance(data, dict):\n        return data\n\n    # Get asset class, default to \"equities\"\n    asset_class = data.get(\"asset_class\", \"equities\")\n    asset_config = AssetClassConfig.get_config(asset_class)\n\n    # Force UTC timezone for crypto and fx regardless of input\n    if asset_class in [\"crypto\", \"fx\"]:\n        data[\"timezone\"] = \"UTC\"\n    elif \"timezone\" not in data or data[\"timezone\"] is None:\n        data[\"timezone\"] = asset_config.timezone\n\n    # Apply other defaults only if fields are not provided or are None\n    if \"hour_boundary\" not in data or data[\"hour_boundary\"] is None:\n        data[\"hour_boundary\"] = asset_config.hour_boundary\n    if \"session_start\" not in data or data[\"session_start\"] is None:\n        data[\"session_start\"] = asset_config.session_start\n\n    return data\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.AggregationConfig.validate_and_expand_target_timeframes","title":"validate_and_expand_target_timeframes  <code>classmethod</code>","text":"<pre><code>validate_and_expand_target_timeframes(\n    target_timeframes: list[str],\n) -&gt; list[str]\n</code></pre> <p>Validate target_timeframes field and expand 'all' keyword.</p> <p>This Pydantic field validator is automatically called when AggregationConfig is instantiated. It validates individual timeframes and expands ['all'] to all supported timeframes.</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@field_validator(\"target_timeframes\")\n@classmethod\ndef validate_and_expand_target_timeframes(cls, target_timeframes: list[str]) -&gt; list[str]:\n    \"\"\"\n    Validate target_timeframes field and expand 'all' keyword.\n\n    This Pydantic field validator is automatically called when AggregationConfig\n    is instantiated. It validates individual timeframes and expands ['all'] to\n    all supported timeframes.\n    \"\"\"\n    if not target_timeframes:\n        raise ValueError(\"target_timeframes cannot be empty\")\n\n    # Check for 'all' keyword\n    if \"all\" in target_timeframes:\n        if len(target_timeframes) &gt; 1:\n            raise ValueError(\"'all' cannot be combined with specific timeframes\")\n        # Expand to all supported timeframes\n        return list(TimeframeConfig.TIMEFRAME_METADATA.keys())\n\n    # Validate each specific timeframe\n    for i, timeframe in enumerate(target_timeframes):\n        if not isinstance(timeframe, str) or not timeframe.strip():\n            raise ValueError(f\"target_timeframes[{i}] must be a non-empty string\")\n\n        # Validate timeframe format using TimeframeConfig\n        if not TimeframeConfig.validate_timeframe(timeframe):\n            raise ValueError(f\"Invalid timeframe '{timeframe}'\")\n\n    return target_timeframes\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.AssetClassConfig","title":"AssetClassConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for a specific asset class with comprehensive market metadata.</p> <p>Methods:</p> Name Description <code>get_config</code> <p>Get configuration for specific asset class.</p>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.AssetClassConfig.get_config","title":"get_config  <code>classmethod</code>","text":"<pre><code>get_config(asset_class: str) -&gt; AssetClassConfig\n</code></pre> <p>Get configuration for specific asset class.</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_config(cls, asset_class: str) -&gt; \"AssetClassConfig\":\n    \"\"\"Get configuration for specific asset class.\"\"\"\n    return cls.REGISTRY.get(asset_class, cls.REGISTRY[\"equities\"])\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.FactoryConfig","title":"FactoryConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Root configuration for Factory.create_all method with complete pipeline setup.</p> <p>Methods:</p> Name Description <code>validate_configuration_consistency</code> <p>Validate consistency between aggregation and indicators configurations.</p>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.FactoryConfig.validate_configuration_consistency","title":"validate_configuration_consistency","text":"<pre><code>validate_configuration_consistency() -&gt; Self\n</code></pre> <p>Validate consistency between aggregation and indicators configurations.</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@model_validator(mode=\"after\")\ndef validate_configuration_consistency(self) -&gt; Self:\n    \"\"\"Validate consistency between aggregation and indicators configurations.\"\"\"\n    # Future enhancement: Could validate that indicator timeframes are compatible\n    # with aggregation target timeframes, but this is not currently enforced\n    # in the existing system\n    return self\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.GapDetectionConfig","title":"GapDetectionConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for gap detection with comprehensive threshold documentation.</p>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.IndicatorSchema","title":"IndicatorSchema","text":"<p>               Bases: <code>BaseModel</code></p> <p>Complete Indicator Schema</p> <p>Defines all columns that are created by TheStrat processing pipeline. All columns are required as the indicators component creates them all.</p> <p>Methods:</p> Name Description <code>get_all_input_columns</code> <p>Get list of all input columns (required + optional).</p> <code>get_column_categories</code> <p>Get columns organized by functional categories.</p> <code>get_column_descriptions</code> <p>Get descriptions for all possible DataFrame columns.</p> <code>get_field_metadata</code> <p>Get json_schema_extra metadata for a field, safely handling missing data.</p> <code>get_optional_input_columns</code> <p>Get list of optional input columns based on schema definition.</p> <code>get_output_columns</code> <p>Get list of all output columns based on schema definition.</p> <code>get_polars_dtypes</code> <p>Get Polars data types for all DataFrame columns.</p> <code>get_precision_metadata</code> <p>Get precision metadata for all fields.</p> <code>get_required_input_columns</code> <p>Get list of required input columns based on schema definition.</p> <code>get_standard_column_order</code> <p>Get the standard column ordering for aggregation output.</p> <code>validate_dataframe</code> <p>Validate input DataFrame columns and data types against IndicatorSchema input requirements.</p>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.IndicatorSchema.get_all_input_columns","title":"get_all_input_columns  <code>classmethod</code>","text":"<pre><code>get_all_input_columns() -&gt; list[str]\n</code></pre> <p>Get list of all input columns (required + optional).</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of all input column names</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_all_input_columns(cls) -&gt; list[str]:\n    \"\"\"\n    Get list of all input columns (required + optional).\n\n    Returns:\n        List of all input column names\n    \"\"\"\n    return sorted(cls.get_required_input_columns() + cls.get_optional_input_columns())\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.IndicatorSchema.get_column_categories","title":"get_column_categories  <code>classmethod</code>","text":"<pre><code>get_column_categories() -&gt; dict[str, list[str]]\n</code></pre> <p>Get columns organized by functional categories.</p> <p>Dynamically extracts categories from the IndicatorSchema metadata.</p> <p>Returns:</p> Type Description <code>dict[str, list[str]]</code> <p>Dictionary mapping category names to lists of column names</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_column_categories(cls) -&gt; dict[str, list[str]]:\n    \"\"\"\n    Get columns organized by functional categories.\n\n    Dynamically extracts categories from the IndicatorSchema metadata.\n\n    Returns:\n        Dictionary mapping category names to lists of column names\n    \"\"\"\n    categories: dict[str, list[str]] = {}\n\n    for field_name, field_info in cls.model_fields.items():\n        json_extra = getattr(field_info, \"json_schema_extra\", {})\n        if isinstance(json_extra, dict) and \"category\" in json_extra:\n            category = json_extra[\"category\"]\n            if category not in categories:\n                categories[category] = []\n            categories[category].append(field_name)\n\n    # Sort columns within each category for consistent output\n    for category in categories:\n        categories[category].sort()\n\n    return categories\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.IndicatorSchema.get_column_descriptions","title":"get_column_descriptions  <code>classmethod</code>","text":"<pre><code>get_column_descriptions() -&gt; dict[str, str]\n</code></pre> <p>Get descriptions for all possible DataFrame columns.</p> <p>Returns:</p> Type Description <code>dict[str, str]</code> <p>Dictionary mapping column names to their descriptions</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_column_descriptions(cls) -&gt; dict[str, str]:\n    \"\"\"\n    Get descriptions for all possible DataFrame columns.\n\n    Returns:\n        Dictionary mapping column names to their descriptions\n    \"\"\"\n    descriptions = {}\n\n    # Get descriptions from the schema\n    for field_name, field_info in cls.model_fields.items():\n        if field_info.description:\n            descriptions[field_name] = field_info.description\n\n    return descriptions\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.IndicatorSchema.get_field_metadata","title":"get_field_metadata  <code>classmethod</code>","text":"<pre><code>get_field_metadata(field_name: str) -&gt; dict[str, Any]\n</code></pre> <p>Get json_schema_extra metadata for a field, safely handling missing data.</p> <p>Parameters:</p> Name Type Description Default <code>field_name</code> <code>str</code> <p>Name of the field to get metadata for</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary of metadata from json_schema_extra, empty dict if not found</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_field_metadata(cls, field_name: str) -&gt; dict[str, Any]:\n    \"\"\"\n    Get json_schema_extra metadata for a field, safely handling missing data.\n\n    Args:\n        field_name: Name of the field to get metadata for\n\n    Returns:\n        Dictionary of metadata from json_schema_extra, empty dict if not found\n    \"\"\"\n    field_info = cls.model_fields.get(field_name)\n    if not field_info:\n        return {}\n    return getattr(field_info, \"json_schema_extra\", {}) or {}\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.IndicatorSchema.get_optional_input_columns","title":"get_optional_input_columns  <code>classmethod</code>","text":"<pre><code>get_optional_input_columns() -&gt; list[str]\n</code></pre> <p>Get list of optional input columns based on schema definition.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of column names that are optional for input data</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_optional_input_columns(cls) -&gt; list[str]:\n    \"\"\"\n    Get list of optional input columns based on schema definition.\n\n    Returns:\n        List of column names that are optional for input data\n    \"\"\"\n    from pydantic_core import PydanticUndefined\n\n    optional_columns = []\n    for field_name, field_info in cls.model_fields.items():\n        json_extra = getattr(field_info, \"json_schema_extra\", {}) or {}\n        if (\n            json_extra.get(\"input\") is True  # Is an input column\n            and (\n                json_extra.get(\"optional\", False)  # Marked as optional\n                or getattr(field_info, \"default\", PydanticUndefined) is not PydanticUndefined\n            )  # Has default value\n        ):\n            optional_columns.append(field_name)\n    return sorted(optional_columns)\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.IndicatorSchema.get_output_columns","title":"get_output_columns  <code>classmethod</code>","text":"<pre><code>get_output_columns() -&gt; list[str]\n</code></pre> <p>Get list of all output columns based on schema definition.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of column names marked as output in schema metadata</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_output_columns(cls) -&gt; list[str]:\n    \"\"\"\n    Get list of all output columns based on schema definition.\n\n    Returns:\n        List of column names marked as output in schema metadata\n    \"\"\"\n    output_columns = []\n    for field_name, field_info in cls.model_fields.items():\n        json_extra = getattr(field_info, \"json_schema_extra\", {}) or {}\n        if json_extra.get(\"output\") is True:\n            output_columns.append(field_name)\n    return sorted(output_columns)\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.IndicatorSchema.get_polars_dtypes","title":"get_polars_dtypes  <code>classmethod</code>","text":"<pre><code>get_polars_dtypes() -&gt; dict[str, Any]\n</code></pre> <p>Get Polars data types for all DataFrame columns.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary mapping column names to their Polars data types</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_polars_dtypes(cls) -&gt; dict[str, Any]:\n    \"\"\"\n    Get Polars data types for all DataFrame columns.\n\n    Returns:\n        Dictionary mapping column names to their Polars data types\n    \"\"\"\n    types = {}\n\n    for field_name, field_info in cls.model_fields.items():\n        json_extra = getattr(field_info, \"json_schema_extra\", {})\n        if isinstance(json_extra, dict) and \"polars_dtype\" in json_extra:\n            types[field_name] = json_extra[\"polars_dtype\"]\n\n    return types\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.IndicatorSchema.get_precision_metadata","title":"get_precision_metadata  <code>classmethod</code>","text":"<pre><code>get_precision_metadata() -&gt; dict[str, dict[str, Any]]\n</code></pre> <p>Get precision metadata for all fields.</p> <p>Returns:</p> Type Description <code>dict[str, dict[str, Any]]</code> <p>Dict mapping field_name \u2192 {'precision_type': str, 'decimal_places': int | None}</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_precision_metadata(cls) -&gt; dict[str, dict[str, Any]]:\n    \"\"\"\n    Get precision metadata for all fields.\n\n    Returns:\n        Dict mapping field_name \u2192 {'precision_type': str, 'decimal_places': int | None}\n    \"\"\"\n    metadata = {}\n\n    for field_name, field_info in cls.model_fields.items():\n        json_extra = getattr(field_info, \"json_schema_extra\", {}) or {}\n        if \"precision_type\" in json_extra:\n            metadata[field_name] = {\n                \"precision_type\": json_extra[\"precision_type\"],\n                \"decimal_places\": json_extra.get(\"decimal_places\"),\n            }\n\n    return metadata\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.IndicatorSchema.get_required_input_columns","title":"get_required_input_columns  <code>classmethod</code>","text":"<pre><code>get_required_input_columns() -&gt; list[str]\n</code></pre> <p>Get list of required input columns based on schema definition.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of column names that are required for input data</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_required_input_columns(cls) -&gt; list[str]:\n    \"\"\"\n    Get list of required input columns based on schema definition.\n\n    Returns:\n        List of column names that are required for input data\n    \"\"\"\n    from pydantic_core import PydanticUndefined\n\n    required_columns = []\n    for field_name, field_info in cls.model_fields.items():\n        json_extra = getattr(field_info, \"json_schema_extra\", {}) or {}\n        if (\n            json_extra.get(\"input\") is True  # Is an input column\n            and not json_extra.get(\"optional\", False)  # Not marked as optional\n            and getattr(field_info, \"default\", PydanticUndefined)\n            is PydanticUndefined  # No default value (required)\n        ):\n            required_columns.append(field_name)\n    return sorted(required_columns)\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.IndicatorSchema.get_standard_column_order","title":"get_standard_column_order  <code>classmethod</code>","text":"<pre><code>get_standard_column_order() -&gt; list[str]\n</code></pre> <p>Get the standard column ordering for aggregation output.</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_standard_column_order(cls) -&gt; list[str]:\n    \"\"\"Get the standard column ordering for aggregation output.\"\"\"\n    return [\"timestamp\", \"symbol\", \"timeframe\", \"open\", \"high\", \"low\", \"close\", \"volume\"]\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.IndicatorSchema.validate_dataframe","title":"validate_dataframe  <code>classmethod</code>","text":"<pre><code>validate_dataframe(df) -&gt; dict[str, Any]\n</code></pre> <p>Validate input DataFrame columns and data types against IndicatorSchema input requirements.</p> <p>Automatically converts Pandas DataFrames to Polars for consistent validation.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <p>Polars or Pandas DataFrame to validate</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary with validation results including missing/extra columns, type issues,</p> <code>dict[str, Any]</code> <p>and the converted Polars DataFrame if conversion occurred</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef validate_dataframe(cls, df) -&gt; dict[str, Any]:\n    \"\"\"\n    Validate input DataFrame columns and data types against IndicatorSchema input requirements.\n\n    Automatically converts Pandas DataFrames to Polars for consistent validation.\n\n    Args:\n        df: Polars or Pandas DataFrame to validate\n\n    Returns:\n        Dictionary with validation results including missing/extra columns, type issues,\n        and the converted Polars DataFrame if conversion occurred\n    \"\"\"\n    from polars import from_pandas\n\n    # Detect DataFrame type and convert if necessary\n    df_type = \"unknown\"\n    converted_df = None\n    conversion_errors = []\n\n    if hasattr(df, \"columns\"):\n        # Check if it's a Pandas DataFrame\n        if hasattr(df, \"dtypes\") and not hasattr(df, \"schema\"):\n            df_type = \"pandas\"\n            try:\n                # Convert Pandas to Polars\n                converted_df = from_pandas(df)\n                df = converted_df  # Use converted DataFrame for validation\n            except Exception as e:\n                conversion_errors.append(f\"Failed to convert Pandas to Polars: {str(e)}\")\n                # Fall back to column-only validation\n                df_columns = list(df.columns)\n                return {\n                    \"valid\": False,\n                    \"conversion_error\": conversion_errors[0],\n                    \"df_type\": df_type,\n                    \"columns\": df_columns,\n                    \"message\": \"Could not convert Pandas DataFrame to Polars for full validation\",\n                }\n        # Check if it's already a Polars DataFrame\n        elif hasattr(df, \"schema\"):\n            df_type = \"polars\"\n        else:\n            raise ValueError(\"Unknown DataFrame type - must be Pandas or Polars DataFrame\")\n\n        df_columns = list(df.columns)\n    else:\n        raise ValueError(\"Input must be a DataFrame with .columns attribute\")\n\n    required_fields = []\n    optional_fields = []\n    expected_types = {}\n\n    # Extract input field requirements from schema\n    for field_name, field_info in cls.model_fields.items():\n        json_extra = getattr(field_info, \"json_schema_extra\", {})\n        if isinstance(json_extra, dict) and json_extra.get(\"input\"):\n            if field_info.is_required():\n                required_fields.append(field_name)\n            else:\n                optional_fields.append(field_name)\n\n            # Store expected Polars type for validation\n            if \"polars_dtype\" in json_extra:\n                expected_types[field_name] = json_extra[\"polars_dtype\"]\n\n    # Check for missing and extra columns\n    missing_required = [col for col in required_fields if col not in df_columns]\n    missing_optional = [col for col in optional_fields if col not in df_columns]\n    extra_columns = [col for col in df_columns if col not in required_fields + optional_fields]\n\n    # Check data types for present columns (now guaranteed to be Polars)\n    type_issues = []\n    if hasattr(df, \"schema\"):  # Polars DataFrame\n        for col_name, expected_type in expected_types.items():\n            if col_name in df_columns:\n                actual_type = df.schema[col_name]\n                if actual_type != expected_type:\n                    type_issues.append(\n                        {\n                            \"column\": col_name,\n                            \"expected\": expected_type.__name__\n                            if hasattr(expected_type, \"__name__\")\n                            else str(expected_type),\n                            \"actual\": str(actual_type),\n                        }\n                    )\n\n    result = {\n        \"valid\": len(missing_required) == 0 and len(type_issues) == 0,\n        \"missing_required\": missing_required,\n        \"missing_optional\": missing_optional,\n        \"extra_columns\": extra_columns,\n        \"type_issues\": type_issues,\n        \"required_fields\": required_fields,\n        \"optional_fields\": optional_fields,\n        \"expected_types\": {k: v.__name__ if hasattr(v, \"__name__\") else str(v) for k, v in expected_types.items()},\n        \"df_type\": df_type,\n    }\n\n    # Include converted DataFrame if conversion occurred\n    if converted_df is not None:\n        result[\"converted_df\"] = converted_df\n        result[\"conversion_performed\"] = True\n    else:\n        result[\"conversion_performed\"] = False\n\n    return result\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.IndicatorsConfig","title":"IndicatorsConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Complete configuration for indicators component with per-timeframe settings.</p>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.SwingPointsConfig","title":"SwingPointsConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for swing point detection with comprehensive parameter documentation.</p>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.TargetConfig","title":"TargetConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for multi-target detection.</p>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.TimeframeConfig","title":"TimeframeConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration and validation for timeframes with comprehensive metadata.</p> <p>Methods:</p> Name Description <code>get_optimal_source_timeframe</code> <p>Get optimal source timeframe for aggregating to target.</p> <code>get_polars_format</code> <p>Get the Polars format for a timeframe.</p> <code>validate_timeframe</code> <p>Validate that the timeframe is supported (strict mode only).</p>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.TimeframeConfig.get_optimal_source_timeframe","title":"get_optimal_source_timeframe  <code>classmethod</code>","text":"<pre><code>get_optimal_source_timeframe(\n    target_timeframe: str, available_timeframes: list[str]\n) -&gt; str | None\n</code></pre> <p>Get optimal source timeframe for aggregating to target.</p> <p>Parameters:</p> Name Type Description Default <code>target_timeframe</code> <code>str</code> <p>Target timeframe to aggregate to</p> required <code>available_timeframes</code> <code>list[str]</code> <p>List of available source timeframes</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>Optimal source timeframe or None if target already exists or no valid source</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_optimal_source_timeframe(cls, target_timeframe: str, available_timeframes: list[str]) -&gt; str | None:\n    \"\"\"\n    Get optimal source timeframe for aggregating to target.\n\n    Args:\n        target_timeframe: Target timeframe to aggregate to\n        available_timeframes: List of available source timeframes\n\n    Returns:\n        Optimal source timeframe or None if target already exists or no valid source\n    \"\"\"\n    # If target exists, use it directly (pass-through)\n    if target_timeframe in available_timeframes:\n        return target_timeframe\n\n    target_metadata = cls.TIMEFRAME_METADATA.get(target_timeframe)\n    if not target_metadata:\n        return None\n\n    target_seconds = target_metadata[\"seconds\"]\n\n    # Find all mathematically valid sources (those that divide evenly into target)\n    valid_sources = []\n    for source_tf in available_timeframes:\n        source_metadata = cls.TIMEFRAME_METADATA.get(source_tf)\n        if source_metadata:\n            source_seconds = source_metadata[\"seconds\"]\n            if target_seconds % source_seconds == 0:\n                valid_sources.append((source_tf, source_seconds))\n\n    if not valid_sources:\n        return None\n\n    # Return the source with the largest duration (minimize aggregation operations)\n    return max(valid_sources, key=lambda x: x[1])[0]\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.TimeframeConfig.get_polars_format","title":"get_polars_format  <code>classmethod</code>","text":"<pre><code>get_polars_format(timeframe: str) -&gt; str\n</code></pre> <p>Get the Polars format for a timeframe.</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_polars_format(cls, timeframe: str) -&gt; str:\n    \"\"\"Get the Polars format for a timeframe.\"\"\"\n    metadata = cls.TIMEFRAME_METADATA.get(timeframe)\n    if metadata:\n        return metadata.get(\"polars_format\", timeframe)\n    return timeframe\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.TimeframeConfig.validate_timeframe","title":"validate_timeframe  <code>classmethod</code>","text":"<pre><code>validate_timeframe(timeframe: str) -&gt; bool\n</code></pre> <p>Validate that the timeframe is supported (strict mode only).</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef validate_timeframe(cls, timeframe: str) -&gt; bool:\n    \"\"\"Validate that the timeframe is supported (strict mode only).\"\"\"\n    return timeframe in cls.TIMEFRAME_METADATA\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.TimeframeItemConfig","title":"TimeframeItemConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for a single timeframe item with flexible timeframe targeting.</p> <p>Methods:</p> Name Description <code>validate_timeframe_combinations</code> <p>Validate that 'all' is not mixed with specific timeframes.</p>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.TimeframeItemConfig.validate_timeframe_combinations","title":"validate_timeframe_combinations","text":"<pre><code>validate_timeframe_combinations() -&gt; Self\n</code></pre> <p>Validate that 'all' is not mixed with specific timeframes.</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@model_validator(mode=\"after\")\ndef validate_timeframe_combinations(self) -&gt; Self:\n    \"\"\"Validate that 'all' is not mixed with specific timeframes.\"\"\"\n    if \"all\" in self.timeframes and len(self.timeframes) &gt; 1:\n        raise ValueError(\"'all' cannot be combined with specific timeframes\")\n    return self\n</code></pre>"},{"location":"reference/thestrat/signals/","title":"Signals","text":"<p>Signal processing and metadata</p> <p>Signal metadata implementation for TheStrat trading system.</p> <p>This module provides comprehensive signal metadata objects that transform simple pattern strings into rich objects with trading logic, risk management, and change tracking.</p> <p>Classes:</p> Name Description <code>PriceChange</code> <p>Track changes to stop/target prices.</p> <code>SignalBias</code> <p>Signal directional bias.</p> <code>SignalCategory</code> <p>Signal categorization types.</p> <code>SignalMetadata</code> <p>Complete signal metadata with change tracking and serialization.</p> <code>SignalStatus</code> <p>Signal lifecycle status.</p> <code>TargetLevel</code> <p>Individual target level with tracking support.</p>"},{"location":"reference/thestrat/signals/#thestrat.signals.PriceChange","title":"PriceChange  <code>dataclass</code>","text":"<pre><code>PriceChange(\n    field_name: str,\n    from_value: float,\n    to_value: float,\n    timestamp: datetime,\n    reason: str | None = None,\n)\n</code></pre> <p>Track changes to stop/target prices.</p>"},{"location":"reference/thestrat/signals/#thestrat.signals.SignalBias","title":"SignalBias","text":"<p>               Bases: <code>Enum</code></p> <p>Signal directional bias.</p>"},{"location":"reference/thestrat/signals/#thestrat.signals.SignalCategory","title":"SignalCategory","text":"<p>               Bases: <code>Enum</code></p> <p>Signal categorization types.</p>"},{"location":"reference/thestrat/signals/#thestrat.signals.SignalMetadata","title":"SignalMetadata  <code>dataclass</code>","text":"<pre><code>SignalMetadata(\n    pattern: str,\n    category: SignalCategory,\n    bias: SignalBias,\n    bar_count: int,\n    entry_price: float,\n    stop_price: float,\n    timestamp: datetime,\n    signal_id: str = (lambda: str(uuid4()))(),\n    target_prices: list[TargetLevel] = list(),\n    status: SignalStatus = PENDING,\n    triggered_at: datetime | None = None,\n    closed_at: datetime | None = None,\n    close_reason: str | None = None,\n    change_history: list[PriceChange] = list(),\n    symbol: str | None = None,\n    timeframe: str | None = None,\n    risk_amount: float | None = None,\n    reward_amount: float | None = None,\n    risk_reward_ratio: float | None = None,\n    entry_filled_price: float | None = None,\n    exit_price: float | None = None,\n    pnl: float | None = None,\n    max_favorable_excursion: float | None = None,\n    max_adverse_excursion: float | None = None,\n)\n</code></pre> <p>Complete signal metadata with change tracking and serialization.</p> <p>Methods:</p> Name Description <code>__post_init__</code> <p>Store original values and calculate metrics.</p> <code>trail_stop</code> <p>Trail stop loss, only allowing favorable moves.</p> <code>update_stop</code> <p>Update stop with change tracking.</p>"},{"location":"reference/thestrat/signals/#thestrat.signals.SignalMetadata.__post_init__","title":"__post_init__","text":"<pre><code>__post_init__()\n</code></pre> <p>Store original values and calculate metrics.</p> Source code in <code>thestrat/signals.py</code> <pre><code>def __post_init__(self):\n    \"\"\"Store original values and calculate metrics.\"\"\"\n    self.original_stop = self.stop_price\n    self._calculate_risk_metrics()\n</code></pre>"},{"location":"reference/thestrat/signals/#thestrat.signals.SignalMetadata.trail_stop","title":"trail_stop","text":"<pre><code>trail_stop(new_stop: float, reason: str = 'trailing_stop') -&gt; bool\n</code></pre> <p>Trail stop loss, only allowing favorable moves.</p> <p>Parameters:</p> Name Type Description Default <code>new_stop</code> <code>float</code> <p>Proposed new stop price</p> required <code>reason</code> <code>str</code> <p>Reason for trailing (default: \"trailing_stop\")</p> <code>'trailing_stop'</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if stop was trailed, False if move was unfavorable and rejected</p> Source code in <code>thestrat/signals.py</code> <pre><code>def trail_stop(self, new_stop: float, reason: str = \"trailing_stop\") -&gt; bool:\n    \"\"\"\n    Trail stop loss, only allowing favorable moves.\n\n    Args:\n        new_stop: Proposed new stop price\n        reason: Reason for trailing (default: \"trailing_stop\")\n\n    Returns:\n        True if stop was trailed, False if move was unfavorable and rejected\n    \"\"\"\n    if self.bias == SignalBias.LONG:\n        # For long trades, only trail up\n        if new_stop &gt; self.stop_price:\n            self.update_stop(new_stop, reason)\n            return True\n    else:\n        # For short trades, only trail down\n        if new_stop &lt; self.stop_price:\n            self.update_stop(new_stop, reason)\n            return True\n    return False\n</code></pre>"},{"location":"reference/thestrat/signals/#thestrat.signals.SignalMetadata.update_stop","title":"update_stop","text":"<pre><code>update_stop(new_stop: float, reason: str = None) -&gt; None\n</code></pre> <p>Update stop with change tracking.</p> <p>Parameters:</p> Name Type Description Default <code>new_stop</code> <code>float</code> <p>New stop loss price</p> required <code>reason</code> <code>str</code> <p>Optional reason for the update (e.g., \"trailing_stop\", \"manual_adjustment\")</p> <code>None</code> Source code in <code>thestrat/signals.py</code> <pre><code>def update_stop(self, new_stop: float, reason: str = None) -&gt; None:\n    \"\"\"\n    Update stop with change tracking.\n\n    Args:\n        new_stop: New stop loss price\n        reason: Optional reason for the update (e.g., \"trailing_stop\", \"manual_adjustment\")\n    \"\"\"\n    if new_stop == self.stop_price:\n        return\n\n    change = PriceChange(\n        field_name=\"stop_price\",\n        from_value=self.stop_price,\n        to_value=new_stop,\n        timestamp=datetime.now(),\n        reason=reason,\n    )\n    self.change_history.append(change)\n    self.stop_price = new_stop\n    self._calculate_risk_metrics()\n</code></pre>"},{"location":"reference/thestrat/signals/#thestrat.signals.SignalStatus","title":"SignalStatus","text":"<p>               Bases: <code>Enum</code></p> <p>Signal lifecycle status.</p>"},{"location":"reference/thestrat/signals/#thestrat.signals.TargetLevel","title":"TargetLevel  <code>dataclass</code>","text":"<pre><code>TargetLevel(\n    price: float,\n    hit: bool = False,\n    hit_timestamp: datetime | None = None,\n    id: str | None = None,\n)\n</code></pre> <p>Individual target level with tracking support.</p>"},{"location":"user-guide/","title":"User Guide","text":"<p>Welcome to the TheStrat user guide. This section provides comprehensive documentation for using the TheStrat Python module in your trading applications.</p>"},{"location":"user-guide/#what-is-thestrat","title":"What is #TheStrat?","text":""},{"location":"user-guide/#thestrat-is-a-technical-analysis-methodology-that-focuses-on-understanding-market-structure-through-the-identification-of-specific-bar-patterns-and-their-relationships-across-multiple-timeframes","title":"TheStrat is a technical analysis methodology that focuses on understanding market structure through the identification of specific bar patterns and their relationships across multiple timeframes.","text":""},{"location":"user-guide/#guide-structure","title":"Guide Structure","text":"<p>This user guide is organized into the following sections:</p>"},{"location":"user-guide/#installation","title":"Installation","text":"<p>How to install and set up the TheStrat module in your environment.</p>"},{"location":"user-guide/#quick-start","title":"Quick Start","text":"<p>Get up and running quickly with basic examples and common use cases.</p>"},{"location":"user-guide/#examples","title":"Examples","text":"<p>Detailed examples showing how to use each component and feature.</p>"},{"location":"user-guide/#asset-classes","title":"Asset Classes","text":"<p>Understanding how different asset classes work within the framework.</p>"},{"location":"user-guide/#precision-utilities","title":"Precision Utilities","text":"<p>Security-type-aware rounding utilities for consistent precision across trading platforms.</p>"},{"location":"user-guide/#prerequisites","title":"Prerequisites","text":"<p>Before using TheStrat, you should have:</p> <ul> <li>Python 3.11 or higher installed</li> <li>Basic understanding of financial markets and OHLCV data</li> <li>Familiarity with Python data structures (pandas/polars DataFrames)</li> </ul>"},{"location":"user-guide/#key-concepts","title":"Key Concepts","text":""},{"location":"user-guide/#timeframe-aggregation","title":"Timeframe Aggregation","text":"<p>TheStrat works across multiple timeframes. The aggregation component handles converting your base timeframe data (e.g., 1-minute bars) into higher timeframes (e.g., 5-minute, 15-minute, hourly).</p>"},{"location":"user-guide/#inside-and-outside-bars","title":"Inside and Outside Bars","text":"<p>Core to #TheStrat methodology: - Inside Bar: High \u2264 previous high AND Low \u2265 previous low - Outside Bar: High &gt; previous high AND Low &lt; previous low</p>"},{"location":"user-guide/#swing-points-and-market-structure","title":"Swing Points and Market Structure","text":"<p>TheStrat uses precise swing point detection to identify market structure:</p> <ul> <li>Swing High: A price peak that is the highest point within its lookback/lookahead window and meets the percentage threshold compared to the previous swing high</li> <li>Swing Low: A price trough that is the lowest point within its lookback/lookahead window and meets the percentage threshold compared to the previous swing low</li> <li>Higher High (HH): Each new swing high that is higher than the previous swing high (bullish structure)</li> <li>Lower High (LH): Each new swing high that is lower than the previous swing high (bearish structure)</li> <li>Higher Low (HL): Each new swing low that is higher than the previous swing low (bullish structure)</li> <li>Lower Low (LL): Each new swing low that is lower than the previous swing low (bearish structure)</li> </ul>"},{"location":"user-guide/#configuration-parameters","title":"Configuration Parameters","text":"<p>Swing point detection can be configured per timeframe:</p> <ul> <li>Window Size: Number of bars to look back and ahead for peak/valley confirmation (default: 5)</li> <li>Threshold: Minimum percentage change required to confirm a new swing point (default: 2.0%)</li> </ul>"},{"location":"user-guide/#signals-and-patterns","title":"Signals and Patterns","text":"<p>The indicators component identifies key pattern sequences and generates actionable signals based on TheStrat rules.</p>"},{"location":"user-guide/#getting-help","title":"Getting Help","text":"<p>If you need assistance:</p> <ol> <li>Check the Examples section for similar use cases</li> <li>Review the API Reference for detailed method documentation</li> <li>Contact the maintainer for private module support</li> </ol> <p>Let's get started with Installation!</p>"},{"location":"user-guide/asset-classes/","title":"Asset Classes","text":"<p>TheStrat supports multiple asset classes, each with specific market characteristics and trading hours. This guide explains how to configure and work with different asset classes effectively.</p> <p>Primary Focus: US Equities</p> <p>This library is primarily developed and tested for US Equities analysis. While crypto, forex, and futures are supported via configuration, they are not actively tested or used in production.</p>"},{"location":"user-guide/asset-classes/#overview","title":"Overview","text":"<p>Asset classes in TheStrat determine:</p> <ul> <li>Trading hours and session handling</li> <li>Timezone requirements and defaults</li> <li>Gap handling for market opens/closes</li> <li>Aggregation behavior for weekends and holidays</li> </ul>"},{"location":"user-guide/asset-classes/#supported-asset-classes","title":"Supported Asset Classes","text":"<p>TheStrat currently supports three major asset classes: crypto, equities, and fx. Each has been optimized for their specific market characteristics.</p>"},{"location":"user-guide/asset-classes/#crypto-247-trading","title":"Crypto (24/7 Trading)","text":"<p>Cryptocurrency markets trade continuously without breaks.</p> <p>Configuration: <pre><code>from thestrat.schemas import FactoryConfig, AggregationConfig, IndicatorsConfig\n\ncrypto_config = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"1h\"],\n        asset_class=\"crypto\",\n        timezone=\"UTC\"  # Always UTC for crypto\n    )\n)\n</code></pre></p> <p>Characteristics: - Trading Hours: 24/7/365 continuous - Timezone: UTC (required) - Session Handling: No sessions or gaps - Weekend Behavior: Trades through weekends</p> <p>Example Usage: <pre><code>from thestrat import Factory\nfrom thestrat.schemas import (\n    FactoryConfig, AggregationConfig, IndicatorsConfig,\n    TimeframeItemConfig, SwingPointsConfig\n)\n\n# Bitcoin hourly analysis\nbtc_config = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"4h\"],\n        asset_class=\"crypto\",\n        timezone=\"UTC\"\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"all\"],\n                swing_points=SwingPointsConfig(\n                    window=6,           # Longer window for 4h timeframe\n                    threshold=4.0       # Higher threshold for crypto volatility\n                )\n            )\n        ]\n    )\n)\n\npipeline = Factory.create_all(btc_config)\n</code></pre></p> <p>Best Practices: - Use higher volatility thresholds (3-5%) - Consider larger swing windows due to 24/7 nature - Include incomplete bars for real-time analysis</p>"},{"location":"user-guide/asset-classes/#equities-market-hours","title":"Equities (Market Hours)","text":"<p>Traditional stock markets with defined trading sessions.</p> <p>Configuration: <pre><code>from thestrat.schemas import FactoryConfig, AggregationConfig\n\nequity_config = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"5min\"],\n        asset_class=\"equities\",\n        timezone=\"US/Eastern\"  # NYSE/NASDAQ\n    )\n)\n</code></pre></p> <p>Characteristics: - Trading Hours: 9:30 AM - 4:00 PM ET (regular session) - Timezone: US/Eastern (default), configurable - Session Handling: Session-aligned aggregation via configurable session_start offset. No explicit pre/post-market gating or holiday calendars. - Weekend Behavior: No trading weekends/holidays</p> <p>Market Sessions:</p> <p>TheStrat automatically handles market hours for equities. You can configure different timeframes for different analysis needs:</p> <pre><code># Short-term intraday analysis\nshort_term_config = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"1m\"],\n        asset_class=\"equities\",\n        timezone=\"US/Eastern\"\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"all\"],\n                swing_points=SwingPointsConfig(window=3, threshold=1.0)\n            )\n        ]\n    )\n)\n\n# Regular session analysis\nregular_config = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"5m\"],\n        asset_class=\"equities\",\n        timezone=\"US/Eastern\"\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"all\"],\n                swing_points=SwingPointsConfig(window=5, threshold=2.0)\n            )\n        ]\n    )\n)\n\n# Create pipelines\nshort_pipeline = Factory.create_all(short_term_config)\nregular_pipeline = Factory.create_all(regular_config)\n</code></pre> <p>International Equities: <pre><code># London Stock Exchange\nlse_config = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"15m\"],\n        asset_class=\"equities\",\n        timezone=\"Europe/London\"  # 8:00-16:30 GMT\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"all\"],\n                swing_points=SwingPointsConfig(window=5, threshold=2.0)\n            )\n        ]\n    )\n)\n\n# Tokyo Stock Exchange\ntse_config = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"30m\"],\n        asset_class=\"equities\",\n        timezone=\"Asia/Tokyo\"    # 9:00-15:00 JST\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"all\"],\n                swing_points=SwingPointsConfig(window=5, threshold=2.0)\n            )\n        ]\n    )\n)\n</code></pre></p>"},{"location":"user-guide/asset-classes/#forex-245-trading","title":"Forex (24/5 Trading)","text":"<p>Foreign exchange markets trade 24/5 from Sunday 5 PM to Friday 5 PM ET.</p> <p>Configuration: <pre><code>from thestrat.schemas import FactoryConfig, AggregationConfig\n\nfx_config = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"1h\"],\n        asset_class=\"fx\",\n        timezone=\"UTC\"  # Always UTC for FX\n    )\n)\n</code></pre></p> <p>Characteristics: - Trading Hours: Sun 5 PM - Fri 5 PM ET (24/5) - Timezone: UTC (required) - Session Handling: 24/5 alignment with UTC. Weekend gaps appear in price data as-is; no special stitching logic. - Weekend Behavior: Weekend gaps appear in price data as-is</p> <p>Major FX Sessions: <pre><code>def analyze_fx_sessions(eurusd_data):\n    \"\"\"Analyze EUR/USD across major FX sessions.\"\"\"\n\n    sessions = {\n        \"asian\": FactoryConfig(\n            aggregation=AggregationConfig(\n                target_timeframes=[\"1h\"],\n                asset_class=\"fx\",\n                timezone=\"UTC\"  # Asian session: 10 PM - 8 AM UTC\n            )\n        ),\n        \"london\": FactoryConfig(\n            aggregation=AggregationConfig(\n                target_timeframes=[\"30min\"],\n                asset_class=\"fx\",\n                timezone=\"UTC\"  # London session: 7 AM - 4 PM UTC\n            )\n        ),\n        \"newyork\": FactoryConfig(\n            aggregation=AggregationConfig(\n                target_timeframes=[\"15min\"],\n                asset_class=\"fx\",\n                timezone=\"UTC\"  # New York session: 12 PM - 9 PM UTC\n            )\n        )\n    }\n\n    results = {}\n    for session, config in sessions.items():\n        pipeline = Factory.create_all(config)\n        analyzed = pipeline[\"indicators\"].process(\n            pipeline[\"aggregation\"].process(eurusd_data)\n        )\n        results[session] = analyzed\n\n    return results\n</code></pre></p> <p>Currency-Specific Examples: <pre><code># Major pairs with different characteristics\npairs = {\n    \"EURUSD\": {\"threshold\": 0.3, \"window\": 5},   # Lower volatility\n    \"GBPJPY\": {\"threshold\": 0.8, \"window\": 4},   # Higher volatility\n    \"AUDUSD\": {\"threshold\": 0.4, \"window\": 6},   # Commodity currency\n    \"USDCAD\": {\"threshold\": 0.5, \"window\": 5}    # Oil correlation\n}\n\nfor pair, params in pairs.items():\n    config = FactoryConfig(\n        aggregation=AggregationConfig(\n            target_timeframes=[\"4h\"],\n            asset_class=\"fx\",\n            timezone=\"UTC\"\n        ),\n        indicators=IndicatorsConfig(\n            timeframe_configs=[\n                TimeframeItemConfig(\n                    timeframes=[\"all\"],\n                    swing_points=SwingPointsConfig(**params)\n                )\n            ]\n        )\n    )\n    # Process each pair...\n</code></pre></p>"},{"location":"user-guide/asset-classes/#asset-class-comparison","title":"Asset Class Comparison","text":"Asset Class Trading Hours Timezone Gap Handling Volatility Recommended Timeframes Crypto 24/7 UTC None High 1h, 4h, 1d Equities 9:30-16:00 ET US/Eastern Daily gaps Medium 1m, 5m, 15m, 1h Forex 24/5 UTC Weekend gaps Medium 15m, 1h, 4h"},{"location":"user-guide/asset-classes/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"user-guide/asset-classes/#custom-market-configuration","title":"Custom Market Configuration","text":"<pre><code># Define custom market behavior using supported parameters\ncustom_config = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"15m\"],  # Use supported timeframe\n        asset_class=\"equities\",     # Base on existing class\n        timezone=\"US/Pacific\",      # Custom timezone\n        session_start=\"06:30\"       # Custom session start\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"all\"],\n                swing_points=SwingPointsConfig(window=5, threshold=2.0)\n            )\n        ]\n    )\n)\n</code></pre>"},{"location":"user-guide/asset-classes/#multi-asset-portfolio","title":"Multi-Asset Portfolio","text":"<pre><code>def analyze_multi_asset_portfolio(assets):\n    \"\"\"Analyze multiple asset classes in one portfolio.\"\"\"\n\n    results = {}\n\n    for asset_name, (data, asset_class) in assets.items():\n        # Get appropriate config for asset class\n        base_config = {\n            \"crypto\": {\"target_timeframes\": [\"4h\"], \"timezone\": \"UTC\", \"threshold\": 3.0},\n            \"equities\": {\"target_timeframes\": [\"15min\"], \"timezone\": \"US/Eastern\", \"threshold\": 1.5},\n            \"fx\": {\"target_timeframes\": [\"1h\"], \"timezone\": \"UTC\", \"threshold\": 0.5}\n        }\n\n        if asset_class in base_config:\n            config = FactoryConfig(\n                aggregation=AggregationConfig(\n                    asset_class=asset_class,\n                    target_timeframes=base_config[asset_class][\"target_timeframes\"],\n                    timezone=base_config[asset_class][\"timezone\"]\n                ),\n                indicators=IndicatorsConfig(\n                    timeframe_configs=[\n                        TimeframeItemConfig(\n                            timeframes=[\"all\"],\n                            swing_points=SwingPointsConfig(\n                                window=5,\n                                threshold=base_config[asset_class][\"threshold\"]\n                            )\n                        )\n                    ]\n                )\n            )\n\n            pipeline = Factory.create_all(config)\n            aggregated = pipeline[\"aggregation\"].process(data)\n            analyzed = pipeline[\"indicators\"].process(aggregated)\n\n            results[asset_name] = {\n                'asset_class': asset_class,\n                'data': analyzed,\n                'inside_bars': len(analyzed.filter(pl.col('scenario') == \"1\")),\n                'outside_bars': len(analyzed.filter(pl.col('scenario') == \"3\"))\n            }\n\n    return results\n\n# Example usage\nportfolio = {\n    'BTC': (btc_data, 'crypto'),\n    'AAPL': (aapl_data, 'equities'),\n    'EURUSD': (eurusd_data, 'fx')\n}\n\nportfolio_analysis = analyze_multi_asset_portfolio(portfolio)\n</code></pre>"},{"location":"user-guide/asset-classes/#calendar-period-aggregation","title":"Calendar Period Aggregation","text":""},{"location":"user-guide/asset-classes/#timestamp-alignment-for-calendar-periods","title":"Timestamp Alignment for Calendar Periods","text":"<p>When aggregating to calendar-based periods (monthly, quarterly, yearly), TheStrat aligns windows to actual calendar boundaries (1st of month, start of quarter, Jan 1) while applying the session start offset. This ensures calendar periods are comparable across datasets regardless of their start date.</p> <p>Equities Example: <pre><code>from thestrat import Factory\nfrom thestrat.schemas import FactoryConfig, AggregationConfig\n\n# Aggregate daily equities data to monthly\nconfig = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"1m\"],  # Monthly\n        asset_class=\"equities\",\n        timezone=\"US/Eastern\"\n    )\n)\n\npipeline = Factory.create_all(config)\nresult = pipeline[\"aggregation\"].process(daily_data)\n\n# Monthly bars align to 1st of month at 09:30 ET\nprint(result[\"timestamp\"][0])  # 2023-01-01 09:30:00-05:00\n</code></pre></p> <p>Asset Class Behavior:</p> Asset Class Session Start Monthly/Quarterly/Yearly Timestamp Equities 09:30 ET 1st of month/quarter/year at 09:30 ET Crypto 00:00 UTC 1st of month/quarter/year at 00:00 UTC Forex 00:00 UTC 1st of month/quarter/year at 00:00 UTC <p>Why This Matters:</p> <p>Calendar periods anchor to actual calendar boundaries, ensuring: - Monthly bars always start on the 1st of the month - Quarterly bars always start on Jan 1, Apr 1, Jul 1, or Oct 1 - Yearly bars always start on Jan 1 - Consistency across datasets with different start dates</p> <p>The session start offset is applied to these calendar boundaries, so: - Monthly equity bars: 1st of month at 09:30 ET - Monthly crypto bars: 1st of month at 00:00 UTC</p> <p>Supported Calendar Periods: - <code>\"1m\"</code> - Monthly (anchors to 1st of month) - <code>\"1q\"</code> - Quarterly (anchors to Jan/Apr/Jul/Oct 1) - <code>\"1y\"</code> - Yearly (anchors to Jan 1)</p>"},{"location":"user-guide/asset-classes/#best-practices-by-asset-class","title":"Best Practices by Asset Class","text":""},{"location":"user-guide/asset-classes/#crypto","title":"Crypto","text":"<ul> <li>Use UTC timezone exclusively</li> <li>Higher volatility thresholds (3-5%)</li> <li>Consider 24/7 nature in signal interpretation</li> <li>Include incomplete bars for real-time analysis</li> </ul>"},{"location":"user-guide/asset-classes/#equities","title":"Equities","text":"<ul> <li>Respect market hours and gaps</li> <li>Lower volatility thresholds (1-2%)</li> <li>Session-aligned aggregation via configurable session_start offset</li> <li>Account for earnings and announcement gaps</li> </ul>"},{"location":"user-guide/asset-classes/#forex","title":"Forex","text":"<ul> <li>Use UTC timezone for consistency</li> <li>Medium volatility thresholds (0.5-1%)</li> <li>Consider major session overlaps</li> <li>Handle weekend gaps appropriately</li> </ul> <p>Choose the asset class configuration that matches your data and trading requirements. The framework handles the complex details of market hours, timezone conversions, and gap handling automatically.</p>"},{"location":"user-guide/configuration/","title":"Configuration Reference","text":"<p>Configuration documentation will be generated during build.</p>"},{"location":"user-guide/dataframe-schema/","title":"Database Integration Guide","text":"<p>The <code>IndicatorSchema</code> class provides essential schema information for integrating TheStrat output with databases and validation systems. This guide shows how to use the schema to create database tables, validate data, and ensure consistent integration.</p>"},{"location":"user-guide/dataframe-schema/#quick-start","title":"Quick Start","text":"<pre><code>from thestrat import IndicatorSchema\nfrom polars import DataFrame\nfrom datetime import datetime\n\n# Validate input DataFrame\ndata = {\n    \"timestamp\": [datetime.now()],\n    \"open\": [100.0], \"high\": [105.0], \"low\": [95.0], \"close\": [102.0],\n    \"symbol\": [\"AAPL\"], \"volume\": [1000000.0], \"timeframe\": [\"5min\"]\n}\n\ndf = DataFrame(data, schema=IndicatorSchema.get_polars_dtypes())\nresult = IndicatorSchema.validate_dataframe(df)\n\nprint(f\"Valid: {result['valid']}\")\nprint(f\"Missing columns: {result['missing_required']}\")\n</code></pre>"},{"location":"user-guide/dataframe-schema/#database-schema-generation","title":"Database Schema Generation","text":""},{"location":"user-guide/dataframe-schema/#sql-table-creation","title":"SQL Table Creation","text":"<pre><code># Get column types and descriptions\ndescriptions = IndicatorSchema.get_column_descriptions()\npolars_types = IndicatorSchema.get_polars_dtypes()\n\n# Map Polars types to SQL types\nfrom polars import Datetime, Float64, String, Boolean, Int32\n\ntype_mapping = {\n    Datetime: \"TIMESTAMP\",\n    Float64: \"DOUBLE PRECISION\",\n    String: \"VARCHAR(50)\",\n    Boolean: \"BOOLEAN\",\n    Int32: \"INTEGER\"\n}\n\n# Generate CREATE TABLE statement\ndef generate_sql_schema(table_name: str) -&gt; str:\n    lines = [f\"CREATE TABLE {table_name} (\"]\n\n    for col, polars_type in polars_types.items():\n        sql_type = type_mapping.get(polars_type, \"TEXT\")\n        description = descriptions.get(col, \"\").replace(\"'\", \"''\")\n        lines.append(f\"  {col} {sql_type}, -- {description}\")\n\n    lines.append(\"  PRIMARY KEY (timestamp, symbol, timeframe)\")\n    lines.append(\");\")\n    return \"\\n\".join(lines)\n\nschema_sql = generate_sql_schema(\"thestrat_indicators\")\n</code></pre>"},{"location":"user-guide/dataframe-schema/#column-categories","title":"Column Categories","text":"<p>Organize columns by functionality for targeted database operations:</p> <pre><code>categories = IndicatorSchema.get_column_categories()\n\n# Create separate tables by category\nfor category, columns in categories.items():\n    if category == \"base_ohlc\":\n        # Core market data table\n        create_base_table(columns)\n    elif category == \"signals\":\n        # Trading signals table with indexes\n        create_signals_table(columns)\n    elif category == \"market_structure\":\n        # Market structure analysis table\n        create_analysis_table(columns)\n</code></pre>"},{"location":"user-guide/dataframe-schema/#input-validation","title":"Input Validation","text":""},{"location":"user-guide/dataframe-schema/#required-columns-check","title":"Required Columns Check","text":"<pre><code>def validate_input_data(df) -&gt; dict:\n    \"\"\"Validate DataFrame before processing.\"\"\"\n    result = IndicatorSchema.validate_dataframe(df)\n\n    if not result['valid']:\n        errors = []\n        if result['missing_required']:\n            errors.append(f\"Missing: {result['missing_required']}\")\n        if result['type_issues']:\n            errors.append(f\"Type errors: {result['type_issues']}\")\n\n        raise ValueError(f\"Invalid DataFrame: {'; '.join(errors)}\")\n\n    return result['converted_df'] if result['conversion_performed'] else df\n</code></pre>"},{"location":"user-guide/dataframe-schema/#auto-conversion-from-pandas","title":"Auto-conversion from Pandas","text":"<pre><code>from pandas import DataFrame as PandasDataFrame\n\n# Pandas DataFrame automatically converts\ndf_pandas = PandasDataFrame(data)\ndf_pandas['timestamp'] = pd.to_datetime(df_pandas['timestamp'])\n\nresult = IndicatorSchema.validate_dataframe(df_pandas)\n# result['converted_df'] contains Polars DataFrame\n</code></pre>"},{"location":"user-guide/dataframe-schema/#column-documentation","title":"Column Documentation","text":""},{"location":"user-guide/dataframe-schema/#get-field-information","title":"Get Field Information","text":"<pre><code># Column descriptions for documentation\ndescriptions = IndicatorSchema.get_column_descriptions()\npolars_types = IndicatorSchema.get_polars_dtypes()\n\n# Generate documentation\nfor col in [\"swing_high\", \"continuity\", \"signal\"]:\n    print(f\"**{col}**: {descriptions[col]}\")\n    print(f\"Type: `{polars_types[col].__name__}`\\n\")\n</code></pre>"},{"location":"user-guide/dataframe-schema/#category-based-operations","title":"Category-based Operations","text":"<pre><code>categories = IndicatorSchema.get_column_categories()\n\n# Process only price analysis columns\nprice_cols = categories['price_analysis']\ndf_prices = df.select(price_cols)\n\n# Extract signal columns for trading system\nsignal_cols = categories['signals']\ndf_signals = df.select(signal_cols)\n</code></pre>"},{"location":"user-guide/dataframe-schema/#advanced-sql-schema-generation","title":"Advanced SQL Schema Generation","text":"<p>Generate complete SQL DDL with nullable constraints by examining the schema metadata:</p> <pre><code>from thestrat.schemas import IndicatorSchema\n\n# Get schema information\ndescriptions = IndicatorSchema.get_column_descriptions()\npolars_types = IndicatorSchema.get_polars_dtypes()\n\ndef generate_sql_with_constraints(table_name: str) -&gt; str:\n    \"\"\"Generate SQL schema with proper NULL/NOT NULL constraints.\"\"\"\n    lines = [f\"CREATE TABLE {table_name} (\"]\n\n    # Map Polars types to SQL types\n    type_mapping = {\n        \"Datetime\": \"TIMESTAMP\",\n        \"Float64\": \"DOUBLE PRECISION\",\n        \"String\": \"VARCHAR(255)\",\n        \"Boolean\": \"BOOLEAN\",\n        \"Int32\": \"INTEGER\"\n    }\n\n    # Process each field using the new helper method\n    for field_name in IndicatorSchema.model_fields.keys():\n        # Get SQL type from Polars type\n        polars_type = polars_types.get(field_name)\n        polars_type_name = polars_type.__name__ if polars_type and hasattr(polars_type, '__name__') else \"String\"\n        sql_type = type_mapping.get(polars_type_name, \"TEXT\")\n\n        # Get nullable constraint using helper method\n        metadata = IndicatorSchema.get_field_metadata(field_name)\n        nullable = metadata.get('nullable', True)\n        constraint = \"\" if nullable else \" NOT NULL\"\n\n        # Add description as comment\n        description = descriptions.get(field_name, \"\").replace(\"'\", \"''\")\n        lines.append(f\"  {field_name} {sql_type}{constraint}, -- {description}\")\n\n    lines.append(\"  PRIMARY KEY (timestamp, symbol, timeframe)\")\n    lines.append(\");\")\n    return \"\\n\".join(lines)\n\nschema_sql = generate_sql_with_constraints(\"thestrat_indicators\")\nprint(schema_sql)\n</code></pre>"},{"location":"user-guide/dataframe-schema/#field-classification-by-type","title":"Field Classification by Type","text":"<p>Organize columns by input/output type and nullable constraints:</p> <pre><code># Classify fields by their purpose using the helper method\ninput_fields = []\noutput_fields = []\nnullable_fields = []\nrequired_fields = []\n\nfor field_name in IndicatorSchema.model_fields.keys():\n    metadata = IndicatorSchema.get_field_metadata(field_name)\n\n    # Classify by input/output\n    if metadata.get('input', False):\n        input_fields.append(field_name)\n    if metadata.get('output', False):\n        output_fields.append(field_name)\n\n    # Classify by nullable constraint\n    if metadata.get('nullable', True):\n        nullable_fields.append(field_name)\n    else:\n        required_fields.append(field_name)\n\nprint(f\"Input fields ({len(input_fields)}): {input_fields}\")\nprint(f\"Output fields ({len(output_fields)}): {output_fields}\")\nprint(f\"Nullable fields ({len(nullable_fields)}): {nullable_fields}\")\nprint(f\"Required (non-null) fields ({len(required_fields)}): {required_fields}\")\n</code></pre>"},{"location":"user-guide/dataframe-schema/#column-listing-methods","title":"Column Listing Methods","text":"<p>The schema provides convenient methods to programmatically retrieve different sets of columns:</p> <pre><code>from thestrat.schemas import IndicatorSchema\n\n# Get all input columns (required + optional)\ninput_columns = IndicatorSchema.get_all_input_columns()\nprint(f\"Input columns: {input_columns}\")\n# ['close', 'high', 'low', 'open', 'symbol', 'timeframe', 'timestamp', 'volume']\n\n# Get only required input columns\nrequired_inputs = IndicatorSchema.get_required_input_columns()\nprint(f\"Required: {required_inputs}\")\n# ['close', 'high', 'low', 'open', 'timeframe', 'timestamp']\n\n# Get only optional input columns\noptional_inputs = IndicatorSchema.get_optional_input_columns()\nprint(f\"Optional: {optional_inputs}\")\n# ['symbol', 'volume']\n\n# Get all output columns\noutput_columns = IndicatorSchema.get_output_columns()\nprint(f\"Output columns ({len(output_columns)}): {output_columns[:5]}...\")\n# Output columns (33): ['ath', 'atl', 'bias', 'continuity', 'entry_price']...\n</code></pre> <p>Use Cases:</p> <p>Database Column Selection: <pre><code># Select only output columns for downstream processing\noutput_cols = IndicatorSchema.get_output_columns()\nanalysis_df = processed_df.select(output_cols)\n\n# Or exclude output columns to get only input data\ninput_cols = IndicatorSchema.get_all_input_columns()\nraw_data_df = processed_df.select(input_cols)\n</code></pre></p> <p>API Response Filtering: <pre><code>def get_indicator_outputs(df):\n    \"\"\"Extract only indicator output columns for API response.\"\"\"\n    output_cols = IndicatorSchema.get_output_columns()\n    # Add timestamp for context\n    return df.select(['timestamp', 'symbol'] + output_cols)\n</code></pre></p> <p>Data Validation: <pre><code>def validate_minimal_input(df):\n    \"\"\"Ensure DataFrame has all required input columns.\"\"\"\n    required = IndicatorSchema.get_required_input_columns()\n    missing = [col for col in required if col not in df.columns]\n\n    if missing:\n        raise ValueError(f\"Missing required columns: {missing}\")\n\n    return True\n</code></pre></p> <p>Schema Evolution Tracking: <pre><code># Track schema changes over time\ndef document_schema_version():\n    \"\"\"Generate schema documentation for version control.\"\"\"\n    return {\n        \"version\": \"0.0.1a29\",\n        \"input_columns\": IndicatorSchema.get_all_input_columns(),\n        \"output_columns\": IndicatorSchema.get_output_columns(),\n        \"total_columns\": len(IndicatorSchema.model_fields)\n    }\n</code></pre></p>"},{"location":"user-guide/dataframe-schema/#integration-patterns","title":"Integration Patterns","text":""},{"location":"user-guide/dataframe-schema/#database-insert-with-validation","title":"Database Insert with Validation","text":"<pre><code>def insert_thestrat_data(df, connection):\n    \"\"\"Insert validated DataFrame into database.\"\"\"\n    # Validate first\n    validated_df = validate_input_data(df)\n\n    # Get column info for proper insertion\n    polars_types = IndicatorSchema.get_polars_dtypes()\n\n    # Insert with proper type handling\n    for row in validated_df.iter_rows(named=True):\n        insert_row(connection, row, polars_types)\n\ndef insert_row(conn, row_data, type_info):\n    \"\"\"Insert single row with type conversion.\"\"\"\n    columns = list(row_data.keys())\n    placeholders = \", \".join([\"?\" for _ in columns])\n\n    # Convert values based on schema\n    from polars import Datetime\n    values = []\n    for col, value in row_data.items():\n        if col in type_info and type_info[col] == Datetime:\n            values.append(value.isoformat() if value else None)\n        else:\n            values.append(value)\n\n    query = f\"INSERT INTO thestrat_indicators ({', '.join(columns)}) VALUES ({placeholders})\"\n    conn.execute(query, values)\n</code></pre>"},{"location":"user-guide/dataframe-schema/#api-response-validation","title":"API Response Validation","text":"<pre><code>from polars import DataFrame\n\ndef validate_api_response(json_data: list) -&gt; DataFrame:\n    \"\"\"Convert and validate API data.\"\"\"\n    df = DataFrame(json_data)\n\n    # Validate structure\n    result = IndicatorSchema.validate_dataframe(df)\n    if not result['valid']:\n        raise ValueError(f\"API data invalid: {result}\")\n\n    return result.get('converted_df', df)\n</code></pre>"},{"location":"user-guide/dataframe-schema/#volume-data-type-handling","title":"Volume Data Type Handling","text":""},{"location":"user-guide/dataframe-schema/#volume-integer-precision","title":"Volume Integer Precision","text":"<p>During timeframe aggregation, volume values are summed across bars. To prevent floating-point arithmetic from introducing precision errors (like <code>117289485.035470001399517059326171875</code>), all volume values are explicitly cast to <code>Int64</code> after aggregation.</p> <p>Example: <pre><code>from thestrat import Factory\nfrom thestrat.schemas import FactoryConfig, AggregationConfig\n\n# Aggregate 1-minute data to hourly\nconfig = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"1h\"],\n        asset_class=\"crypto\"\n    )\n)\n\npipeline = Factory.create_all(config)\nresult = pipeline[\"aggregation\"].process(minute_data)\n\n# Volume column is Int64, not Float64\nprint(result.schema[\"volume\"])  # Int64\nprint(result[\"volume\"][0])      # 23457897 (exact integer, no decimals)\n</code></pre></p> <p>Benefits: - Exact values: Volume remains as precise integers through all aggregation levels - Database compatibility: Integer volume fields work correctly with SQL INT/BIGINT columns - No precision drift: Multi-level aggregation (1min \u2192 1h \u2192 1d \u2192 1w) maintains exactness</p> <p>Important Notes: - Volume is cast to <code>Int64</code> after aggregation but before returning results - Input data can have volume as <code>Int64</code> or <code>Float64</code> - both work - Multi-level aggregation maintains integer precision at each level - Very large volumes (billions) are supported by <code>Int64</code> type</p>"},{"location":"user-guide/dataframe-schema/#best-practices","title":"Best Practices","text":"<ul> <li>Always validate input data before processing</li> <li>Use column categories to organize database tables efficiently</li> <li>Leverage auto-conversion for Pandas compatibility</li> <li>Check type_issues for data quality problems</li> <li>Use descriptions for database comments and API documentation</li> <li>Expect Int64 volume: Design database schemas with INTEGER/BIGINT for volume columns</li> </ul>"},{"location":"user-guide/examples/","title":"Examples","text":"<p>This section provides comprehensive examples of using TheStrat for various trading scenarios and asset classes.</p>"},{"location":"user-guide/examples/#basic-examples","title":"Basic Examples","text":""},{"location":"user-guide/examples/#simple-5-minute-analysis","title":"Simple 5-Minute Analysis","text":"<pre><code>from pandas import DataFrame as PandasDataFrame\nfrom thestrat import Factory\nfrom thestrat.schemas import (\n    FactoryConfig, AggregationConfig, IndicatorsConfig,\n    TimeframeItemConfig, SwingPointsConfig\n)\n\n# Sample market data\ndata = PandasDataFrame({\n    'timestamp': pd.date_range('2024-01-01 09:30', periods=300, freq='1min'),\n    'open': [100 + i*0.1 for i in range(300)],\n    'high': [100.5 + i*0.1 for i in range(300)],\n    'low': [99.5 + i*0.1 for i in range(300)],\n    'close': [100.2 + i*0.1 for i in range(300)],\n    'volume': [1000 + i*10 for i in range(300)],\n    'timeframe': ['1min'] * 300\n})\n\n# Configure for 5-minute equity analysis with Pydantic models\nconfig = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"5min\"],\n        asset_class=\"equities\",\n        timezone=\"US/Eastern\"\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"all\"],\n                swing_points=SwingPointsConfig(window=5, threshold=2.0)\n            )\n        ]\n    )\n)\n\n# Process the data\npipeline = Factory.create_all(config)\naggregated = pipeline[\"aggregation\"].process(data)\nanalyzed = pipeline[\"indicators\"].process(aggregated)\n\n# Display results\nprint(f\"Converted {len(data)} 1-minute bars to {len(aggregated)} 5-minute bars\")\ninside_bars = len(analyzed.filter(pl.col('scenario') == \"1\"))\noutside_bars = len(analyzed.filter(pl.col('scenario') == \"3\"))\nprint(f\"Found {inside_bars} inside bars\")\nprint(f\"Found {outside_bars} outside bars\")\n</code></pre>"},{"location":"user-guide/examples/#multi-target-configuration","title":"Multi-Target Configuration","text":"<p>Configure multiple target detection for reversal signals with per-timeframe settings:</p> <pre><code>from thestrat import Factory\nfrom thestrat.schemas import (\n    FactoryConfig, AggregationConfig, IndicatorsConfig,\n    TimeframeItemConfig, SwingPointsConfig, TargetConfig\n)\n\n# Configure with target detection\nconfig = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"5min\"],\n        asset_class=\"equities\",\n        timezone=\"US/Eastern\"\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"5min\"],\n                swing_points=SwingPointsConfig(window=5, threshold=2.0),\n                target_config=TargetConfig(\n                    upper_bound=\"higher_high\",    # For long signals - targets until next HH\n                    lower_bound=\"lower_low\",       # For short signals - targets until next LL\n                    merge_threshold_pct=0.02,     # Merge targets within 2% of each other\n                    max_targets=3                  # Limit to 3 targets per signal\n                )\n            )\n        ]\n    )\n)\n\npipeline = Factory.create_all(config)\naggregated = pipeline[\"aggregation\"].process(market_data)\nanalyzed = pipeline[\"indicators\"].process(aggregated)\n\n# Get signal objects with multiple targets\nfrom thestrat.indicators import Indicators\nsignals_with_targets = analyzed.filter(pl.col(\"signal\").is_not_null())\nsignal_objects = [\n    Indicators.get_signal_object(signals_with_targets.slice(i, 1))\n    for i in range(len(signals_with_targets))\n]\n\nfor signal in signal_objects:\n    print(f\"Signal: {signal.pattern} - {signal.bias.value}\")\n    print(f\"Entry: ${signal.entry_price:.2f}, Stop: ${signal.stop_price:.2f}\")\n    if signal.target_prices:\n        for i, target in enumerate(signal.target_prices, 1):\n            print(f\"  Target {i}: ${target.price:.2f}\")\n</code></pre> <p>Key Parameters: - <code>upper_bound</code>: Boundary for long signal targets (<code>higher_high</code>, <code>lower_high</code>) - <code>lower_bound</code>: Boundary for short signal targets (<code>lower_low</code>, <code>higher_low</code>) - <code>merge_threshold_pct</code>: Merge middle targets within threshold (0.02 = 2%). First and last targets are never merged. - <code>max_targets</code>: Maximum targets per signal (None = unlimited)</p>"},{"location":"user-guide/examples/#multi-timeframe-analysis","title":"Multi-Timeframe Analysis","text":"<pre><code>from thestrat import Factory\nfrom thestrat.schemas import (\n    FactoryConfig, AggregationConfig, IndicatorsConfig,\n    TimeframeItemConfig, SwingPointsConfig\n)\nfrom pandas import DataFrame as PandasDataFrame\n\ndef analyze_multiple_timeframes(data, timeframes=['5min', '15min', '1h']):\n    \"\"\"Analyze data across multiple timeframes using Pydantic models.\"\"\"\n    # Single configuration for multiple timeframes using models\n    config = FactoryConfig(\n        aggregation=AggregationConfig(\n            target_timeframes=timeframes,  # Process all timeframes together\n            asset_class=\"equities\",\n            timezone=\"US/Eastern\"\n        ),\n        indicators=IndicatorsConfig(\n            timeframe_configs=[\n                TimeframeItemConfig(\n                    timeframes=[\"5min\"],\n                    swing_points=SwingPointsConfig(window=3, threshold=1.5)  # Short-term settings\n                ),\n                TimeframeItemConfig(\n                    timeframes=[\"15min\", \"1h\"],\n                    swing_points=SwingPointsConfig(window=7, threshold=2.5)  # Long-term settings\n                )\n            ]\n        )\n    )\n\n    # Single pipeline processes all timeframes\n    pipeline = Factory.create_all(config)\n    aggregated = pipeline[\"aggregation\"].process(data)\n    analyzed = pipeline[\"indicators\"].process(aggregated)\n\n    # Extract results by timeframe from normalized output\n    results = {}\n    for tf in timeframes:\n        tf_data = analyzed[analyzed['timeframe'] == tf]\n        results[tf] = {\n            'data': tf_data,\n            'inside_bars': len(tf_data.filter(pl.col('scenario') == \"1\")),\n            'outside_bars': len(tf_data.filter(pl.col('scenario') == \"3\")),\n            'higher_highs': len(tf_data['higher_high'].drop_nulls()),\n            'lower_lows': len(tf_data['lower_low'].drop_nulls())\n        }\n\n    return results, analyzed  # Return both summary and full data\n\n# Use with your data\nmulti_tf_analysis, full_data = analyze_multiple_timeframes(sample_data)\n\n# Display summary\nfor tf, result in multi_tf_analysis.items():\n    print(f\"{tf}: {result['inside_bars']} inside, {result['outside_bars']} outside\")\n\nprint(f\"Total processed: {len(full_data)} bars across {len(full_data['timeframe'].unique())} timeframes\")\n</code></pre>"},{"location":"user-guide/examples/#asset-class-specific-examples","title":"Asset Class Specific Examples","text":""},{"location":"user-guide/examples/#cryptocurrency-247-trading","title":"Cryptocurrency (24/7 Trading)","text":"<p>Not Actively Tested</p> <p>This configuration is illustrative only. Crypto/FX are not actively tested or used in production.</p> <pre><code># Bitcoin/crypto configuration with Pydantic models\ncrypto_config = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"1h\"],\n        asset_class=\"crypto\",\n        timezone=\"UTC\"  # Always UTC for crypto\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"all\"],\n                swing_points=SwingPointsConfig(\n                    window=6,  # Slightly larger window for hourly\n                    threshold=3.0  # Higher threshold for crypto volatility\n                )\n            )\n        ]\n    )\n)\n\ncrypto_pipeline = Factory.create_all(crypto_config)\n\n# Process crypto data (note: no market hours restrictions)\ncrypto_analyzed = crypto_pipeline[\"aggregation\"].process(btc_data)\ncrypto_signals = crypto_pipeline[\"indicators\"].process(crypto_analyzed)\n\nprint(f\"Crypto analysis: 24/7 trading, {len(crypto_signals)} hourly bars\")\n</code></pre>"},{"location":"user-guide/examples/#forex-245-trading","title":"Forex (24/5 Trading)","text":"<p>Not Actively Tested</p> <p>This configuration is illustrative only. Crypto/FX are not actively tested or used in production.</p> <pre><code># EUR/USD analysis with Pydantic models\nfx_config = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"4h\"],\n        asset_class=\"fx\",\n        timezone=\"UTC\"\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"all\"],\n                swing_points=SwingPointsConfig(\n                    window=4,\n                    threshold=0.5  # Lower threshold for FX (measured in %)\n                )\n            )\n        ]\n    )\n)\n\nfx_pipeline = Factory.create_all(fx_config)\n\n# FX data processing handles weekend gaps automatically\neurusd_aggregated = fx_pipeline[\"aggregation\"].process(eurusd_1m_data)\neurusd_analyzed = fx_pipeline[\"indicators\"].process(eurusd_aggregated)\n\n# Find major market structure points\nhigher_highs = len(eurusd_analyzed['higher_high'].drop_nulls())\nlower_lows = len(eurusd_analyzed['lower_low'].drop_nulls())\nprint(f\"Found {higher_highs} HH and {lower_lows} LL in EUR/USD\")\n</code></pre>"},{"location":"user-guide/examples/#multi-timeframe-examples","title":"Multi-Timeframe Examples","text":""},{"location":"user-guide/examples/#single-request-multi-timeframe-analysis","title":"Single Request Multi-Timeframe Analysis","text":"<pre><code>from thestrat import Factory\n\n# Process multiple timeframes with different configurations using Pydantic models\nconfig = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"5min\", \"15min\", \"1h\", \"1d\"],  # All timeframes together\n        asset_class=\"equities\",\n        timezone=\"US/Eastern\"\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"5min\"],  # Short-term aggressive settings\n                swing_points=SwingPointsConfig(window=3, threshold=1.0)\n            ),\n            TimeframeItemConfig(\n                timeframes=[\"15min\"],  # Medium-term balanced settings\n                swing_points=SwingPointsConfig(window=5, threshold=2.0)\n            ),\n            TimeframeItemConfig(\n                timeframes=[\"1h\", \"1d\"],  # Long-term conservative settings\n                swing_points=SwingPointsConfig(window=10, threshold=3.0)\n            )\n        ]\n    )\n)\n\npipeline = Factory.create_all(config)\naggregated = pipeline[\"aggregation\"].process(market_data)\nanalyzed = pipeline[\"indicators\"].process(aggregated)\n\n# Extract results for each timeframe from normalized output\nfor tf in [\"5min\", \"15min\", \"1h\", \"1d\"]:\n    tf_data = analyzed[analyzed['timeframe'] == tf]\n    print(f\"{tf}: {len(tf_data)} bars, {len(tf_data.filter(pl.col('scenario') == '1'))} inside bars\")\n\nprint(f\"Total: {len(analyzed)} bars across {len(analyzed['timeframe'].unique())} timeframes\")\n</code></pre>"},{"location":"user-guide/examples/#swing-point-analysis","title":"Swing Point Analysis","text":""},{"location":"user-guide/examples/#understanding-swing-point-detection","title":"Understanding Swing Point Detection","text":"<p>Swing points are critical for identifying market structure in TheStrat methodology. The implementation uses precise peak/valley detection with configurable parameters.</p> <pre><code>from thestrat import Factory\nfrom thestrat.schemas import (\n    FactoryConfig, AggregationConfig, IndicatorsConfig,\n    TimeframeItemConfig, SwingPointsConfig\n)\nfrom pandas import DataFrame as PandasDataFrame\n\ndef analyze_swing_points(data):\n    \"\"\"Demonstrate swing point detection with different configurations.\"\"\"\n\n    # Configuration with detailed swing point settings\n    config = FactoryConfig(\n        aggregation=AggregationConfig(\n            target_timeframes=[\"5min\"],\n            asset_class=\"equities\",\n            timezone=\"US/Eastern\"\n        ),\n        indicators=IndicatorsConfig(\n            timeframe_configs=[\n                TimeframeItemConfig(\n                    timeframes=[\"all\"],\n                    swing_points=SwingPointsConfig(\n                        window=5,        # Look 5 bars back and ahead\n                        threshold=2.0    # Require 2% price change to confirm\n                    )\n                )\n            ]\n        )\n    )\n\n    # Process the data\n    pipeline = Factory.create_all(config)\n    aggregated = pipeline[\"aggregation\"].process(data)\n    analyzed = pipeline[\"indicators\"].process(aggregated)\n\n    # Market structure analysis\n    higher_highs = len(analyzed['higher_high'].drop_nulls())\n    lower_highs = len(analyzed['lower_high'].drop_nulls())\n    higher_lows = len(analyzed['higher_low'].drop_nulls())\n    lower_lows = len(analyzed['lower_low'].drop_nulls())\n\n    print(f\"Higher highs: {higher_highs} (bullish structure)\")\n    print(f\"Lower lows: {lower_lows} (bearish structure)\")\n    print(f\"Lower lows: {len(lower_lows)} (bearish structure)\")\n\n    return analyzed\n\n# Example usage with trending data\ntrending_data = PandasDataFrame({\n    'timestamp': pd.date_range('2024-01-01 09:30', periods=100, freq='5min'),\n    'open': [100 + i*0.5 + (i%10)*0.2 for i in range(100)],    # Trending up with oscillations\n    'high': [101 + i*0.5 + (i%10)*0.3 for i in range(100)],\n    'low': [99 + i*0.5 + (i%10)*0.1 for i in range(100)],\n    'close': [100.5 + i*0.5 + (i%10)*0.25 for i in range(100)],\n    'volume': [1000 + i*10 for i in range(100)],\n    'timeframe': ['5min'] * 100\n})\n\nresults = analyze_swing_points(trending_data)\n</code></pre>"},{"location":"user-guide/examples/#swing-point-configuration-strategies","title":"Swing Point Configuration Strategies","text":"<p>Different market conditions and trading styles require different swing point settings:</p> <pre><code>def compare_swing_configurations(data):\n    \"\"\"Compare different swing point configurations.\"\"\"\n\n    configurations = [\n        (\"Scalping\", SwingPointsConfig(window=3, threshold=0.5)),     # Very sensitive\n        (\"Day Trading\", SwingPointsConfig(window=5, threshold=1.5)),  # Balanced\n        (\"Swing Trading\", SwingPointsConfig(window=10, threshold=3.0)), # Conservative\n        (\"Position Trading\", SwingPointsConfig(window=20, threshold=5.0)) # Very conservative\n    ]\n\n    results = {}\n\n    for strategy_name, swing_config in configurations:\n        config = FactoryConfig(\n            aggregation=AggregationConfig(\n                target_timeframes=[\"5min\"],\n                asset_class=\"equities\"\n            ),\n            indicators=IndicatorsConfig(\n                timeframe_configs=[\n                    TimeframeItemConfig(\n                        timeframes=[\"all\"],\n                        swing_points=swing_config\n                    )\n                ]\n            )\n        )\n\n        pipeline = Factory.create_all(config)\n        aggregated = pipeline[\"aggregation\"].process(data)\n        analyzed = pipeline[\"indicators\"].process(aggregated)\n\n        # Count market structure points detected\n        structure_count = (len(analyzed['higher_high'].drop_nulls()) +\n                          len(analyzed['lower_high'].drop_nulls()) +\n                          len(analyzed['higher_low'].drop_nulls()) +\n                          len(analyzed['lower_low'].drop_nulls()))\n\n        results[strategy_name] = {\n            'config': swing_config,\n            'swing_points': swing_count,\n            'frequency': f\"{swing_count/len(analyzed)*100:.1f}% of bars\"\n        }\n\n        print(f\"{strategy_name}: {swing_count} swing points ({results[strategy_name]['frequency']})\")\n\n    return results\n\n# Compare configurations\nconfig_results = compare_swing_configurations(trending_data)\n</code></pre>"},{"location":"user-guide/examples/#market-structure-trend-analysis","title":"Market Structure Trend Analysis","text":"<p>Understanding the relationship between swing highs and lows reveals market trends:</p> <pre><code>def analyze_market_structure_trend(analyzed_data):\n    \"\"\"Analyze trend direction using market structure.\"\"\"\n\n    # Get market structure data\n    structure_data = analyzed_data.filter(\n        (analyzed_data['higher_high'].is_not_null()) |\n        (analyzed_data['lower_low'].is_not_null())\n    ).sort('timestamp')\n\n    if len(swing_points) &lt; 4:\n        return \"Insufficient swing points for trend analysis\"\n\n    # Count recent structure patterns\n    recent_data = analyzed_data.tail(50)  # Last 50 bars\n\n    hh_count = len(recent_data['higher_high'].drop_nulls())\n    hl_count = len(recent_data['higher_low'].drop_nulls())\n    lh_count = len(recent_data['lower_high'].drop_nulls())\n    ll_count = len(recent_data['lower_low'].drop_nulls())\n\n    bullish_signals = hh_count + hl_count\n    bearish_signals = lh_count + ll_count\n\n    print(f\"Recent Market Structure (last 50 bars):\")\n    print(f\"  Higher Highs: {hh_count}\")\n    print(f\"  Higher Lows: {hl_count}\")\n    print(f\"  Lower Highs: {lh_count}\")\n    print(f\"  Lower Lows: {ll_count}\")\n    print(f\"  Bullish signals: {bullish_signals}\")\n    print(f\"  Bearish signals: {bearish_signals}\")\n\n    if bullish_signals &gt; bearish_signals * 1.5:\n        trend = \"Strong Uptrend\"\n    elif bearish_signals &gt; bullish_signals * 1.5:\n        trend = \"Strong Downtrend\"\n    elif bullish_signals &gt; bearish_signals:\n        trend = \"Weak Uptrend\"\n    elif bearish_signals &gt; bullish_signals:\n        trend = \"Weak Downtrend\"\n    else:\n        trend = \"Sideways/Consolidation\"\n\n    print(f\"  Trend Assessment: {trend}\")\n    return trend\n\n# Analyze the trend\ntrend_assessment = analyze_market_structure_trend(results)\n</code></pre>"},{"location":"user-guide/examples/#performance-considerations","title":"Performance Considerations","text":"<p>TheStrat's swing point detection is fully vectorized for optimal performance:</p> <pre><code>import time\n\ndef benchmark_swing_detection(data_size=10000):\n    \"\"\"Benchmark swing point detection performance.\"\"\"\n\n    # Generate large dataset\n    large_data = PandasDataFrame({\n        'timestamp': pd.date_range('2024-01-01', periods=data_size, freq='1min'),\n        'open': [100 + i*0.01 + (i%100)*0.1 for i in range(data_size)],\n        'high': [100.5 + i*0.01 + (i%100)*0.15 for i in range(data_size)],\n        'low': [99.5 + i*0.01 + (i%100)*0.05 for i in range(data_size)],\n        'close': [100.2 + i*0.01 + (i%100)*0.12 for i in range(data_size)],\n        'volume': [1000 + i for i in range(data_size)],\n        'timeframe': ['1min'] * data_size\n    })\n\n    config = FactoryConfig(\n        aggregation=AggregationConfig(\n            target_timeframes=[\"5min\"],\n            asset_class=\"equities\"\n        ),\n        indicators=IndicatorsConfig(\n            timeframe_configs=[\n                TimeframeItemConfig(\n                    timeframes=[\"all\"],\n                    swing_points=SwingPointsConfig(window=5, threshold=2.0)\n                )\n            ]\n        )\n    )\n\n    pipeline = Factory.create_all(config)\n\n    # Benchmark aggregation\n    start_time = time.time()\n    aggregated = pipeline[\"aggregation\"].process(large_data)\n    agg_time = time.time() - start_time\n\n    # Benchmark indicators (including swing points)\n    start_time = time.time()\n    analyzed = pipeline[\"indicators\"].process(aggregated)\n    indicator_time = time.time() - start_time\n\n    print(f\"Performance Benchmark ({data_size:,} input rows):\")\n    print(f\"  Aggregation: {agg_time:.3f}s ({len(large_data)/agg_time:,.0f} rows/sec)\")\n    print(f\"  Indicators: {indicator_time:.3f}s ({len(aggregated)/indicator_time:,.0f} rows/sec)\")\n    print(f\"  Total: {agg_time + indicator_time:.3f}s\")\n    print(f\"  Output: {len(analyzed)} bars with full indicator analysis\")\n\n# Run performance benchmark\nbenchmark_swing_detection(10000)\n</code></pre>"},{"location":"user-guide/examples/#cross-timeframe-signal-correlation","title":"Cross-Timeframe Signal Correlation","text":"<pre><code>def analyze_cross_timeframe_signals(data):\n    \"\"\"Analyze signal correlation across multiple timeframes.\"\"\"\n    config = FactoryConfig(\n        aggregation=AggregationConfig(\n            target_timeframes=[\"5min\", \"15min\", \"1h\"],\n            asset_class=\"equities\"\n        ),\n        indicators=IndicatorsConfig(\n            timeframe_configs=[\n                TimeframeItemConfig(\n                    timeframes=[\"all\"],\n                    swing_points=SwingPointsConfig(window=5, threshold=2.0)\n                )\n            ]\n        )\n    )\n\n    pipeline = Factory.create_all(config)\n    aggregated = pipeline[\"aggregation\"].process(data)\n    analyzed = pipeline[\"indicators\"].process(aggregated)\n\n    # Find synchronized signals across timeframes\n    synchronized_signals = []\n\n    # Get latest bar for each timeframe\n    latest_by_tf = {}\n    for tf in [\"5min\", \"15min\", \"1h\"]:\n        tf_data = analyzed[analyzed['timeframe'] == tf]\n        if len(tf_data) &gt; 0:\n            latest_by_tf[tf] = tf_data.iloc[-1]\n\n    # Check for signal alignment\n    if all(bar.get('scenario') == \"3\" for bar in latest_by_tf.values()):\n        synchronized_signals.append({\n            'type': 'multi_timeframe_breakout',\n            'timeframes': list(latest_by_tf.keys()),\n            'timestamp': list(latest_by_tf.values())[0]['timestamp']\n        })\n\n    return synchronized_signals, analyzed\n\n# Example usage\nsignals, full_analysis = analyze_cross_timeframe_signals(sample_data)\nprint(f\"Found {len(signals)} synchronized signals across multiple timeframes\")\n</code></pre>"},{"location":"user-guide/examples/#advanced-analysis-examples","title":"Advanced Analysis Examples","text":""},{"location":"user-guide/examples/#custom-signal-detection","title":"Custom Signal Detection","text":"<pre><code>def detect_strat_patterns(data):\n    \"\"\"Detect common TheStrat patterns.\"\"\"\n    patterns = []\n\n    for i in range(2, len(data)):\n        current = data.iloc[i]\n        prev1 = data.iloc[i-1]\n        prev2 = data.iloc[i-2]\n\n        # Inside bar followed by breakout (2-1-2 Continuation)\n        if (prev2['scenario'] == \"3\" and\n            prev1['scenario'] == \"1\" and\n            current['close'] &gt; prev2['high']):\n            patterns.append({\n                'timestamp': current['timestamp'],\n                'pattern': '2-1-2_bullish_continuation',\n                'entry_price': prev2['high'],\n                'target': current['close'] + (current['close'] - prev2['low']) * 0.5\n            })\n\n        # Outside bar reversal\n        if (current['scenario'] == \"3\" and\n            prev1['close'] &gt; prev1['open'] and  # Previous bar was bullish\n            current['close'] &lt; current['open']):  # Current bar is bearish\n            patterns.append({\n                'timestamp': current['timestamp'],\n                'pattern': 'outside_bar_reversal',\n                'entry_price': current['low'],\n                'stop_loss': current['high']\n            })\n\n    return patterns\n\n# Apply pattern detection\npatterns = detect_strat_patterns(analyzed_data)\nprint(f\"Detected {len(patterns)} TheStrat patterns\")\n\n# Display recent patterns\nfor pattern in patterns[-5:]:\n    print(f\"{pattern['timestamp']}: {pattern['pattern']} @ {pattern['entry_price']}\")\n</code></pre>"},{"location":"user-guide/examples/#risk-management-integration","title":"Risk Management Integration","text":"<pre><code>def calculate_position_sizes(signals, account_balance, risk_percent=2.0):\n    \"\"\"Calculate position sizes based on TheStrat signals.\"\"\"\n    positions = []\n\n    for signal in signals:\n        if 'entry_price' in signal and 'stop_loss' in signal:\n            # Calculate risk per share\n            risk_per_share = abs(signal['entry_price'] - signal['stop_loss'])\n\n            # Calculate position size\n            risk_amount = account_balance * (risk_percent / 100)\n            position_size = int(risk_amount / risk_per_share) if risk_per_share &gt; 0 else 0\n\n            positions.append({\n                **signal,\n                'position_size': position_size,\n                'risk_amount': risk_amount,\n                'risk_per_share': risk_per_share\n            })\n\n    return positions\n\n# Example usage\naccount_balance = 100000  # $100k account\nrisk_per_trade = 2.0      # 2% risk per trade\n\nsized_positions = calculate_position_sizes(patterns, account_balance, risk_per_trade)\n\nfor pos in sized_positions:\n    if pos['position_size'] &gt; 0:\n        print(f\"Signal: {pos['pattern']}\")\n        print(f\"Entry: ${pos['entry_price']:.2f}\")\n        print(f\"Size: {pos['position_size']} shares\")\n        print(f\"Risk: ${pos['risk_amount']:.2f}\")\n        print(\"---\")\n</code></pre>"},{"location":"user-guide/examples/#real-time-analysis-simulation","title":"Real-Time Analysis Simulation","text":"<pre><code>import time\nfrom datetime import datetime\n\ndef simulate_real_time_analysis(historical_data, interval_seconds=60):\n    \"\"\"Simulate real-time TheStrat analysis with Pydantic models.\"\"\"\n\n    config = FactoryConfig(\n        aggregation=AggregationConfig(target_timeframes=[\"5min\"], asset_class=\"equities\"),\n        indicators=IndicatorsConfig(\n            timeframe_configs=[\n                TimeframeItemConfig(\n                    timeframes=[\"all\"],\n                    swing_points=SwingPointsConfig(window=5, threshold=2.0)\n                )\n            ]\n        )\n    )\n\n    pipeline = Factory.create_all(config)\n\n    # Simulate streaming data\n    for i in range(50, len(historical_data), 5):  # Add 5 bars at a time\n        current_data = historical_data.iloc[:i]\n\n        # Process latest data\n        aggregated = pipeline[\"aggregation\"].process(current_data)\n        analyzed = pipeline[\"indicators\"].process(aggregated)\n\n        # Check for new signals (last bar)\n        if len(analyzed) &gt; 0:\n            latest = analyzed.iloc[-1]\n\n            if latest['scenario'] == \"1\":\n                print(f\"{datetime.now()}: Inside bar detected @ {latest['close']:.2f}\")\n            elif latest['scenario'] == \"3\":\n                print(f\"{datetime.now()}: Outside bar detected @ {latest['close']:.2f}\")\n\n            # Check for market structure changes\n            if latest.get('higher_high') is not None:\n                print(f\"{datetime.now()}: Higher High @ {latest['higher_high']:.2f}\")\n            elif latest.get('lower_low') is not None:\n                print(f\"{datetime.now()}: Lower Low @ {latest['lower_low']:.2f}\")\n\n        time.sleep(interval_seconds)\n\n# Run simulation (comment out for docs)\n# simulate_real_time_analysis(sample_data, interval_seconds=2)\n</code></pre>"},{"location":"user-guide/examples/#performance-optimization-examples","title":"Performance Optimization Examples","text":""},{"location":"user-guide/examples/#batch-processing","title":"Batch Processing","text":"<pre><code>def batch_process_symbols(symbol_data_dict, config_template):\n    \"\"\"Process multiple symbols efficiently with new API.\"\"\"\n    results = {}\n\n    # Create pipeline once - supports multiple timeframes per symbol\n    pipeline = Factory.create_all(config_template)\n\n    for symbol, data in symbol_data_dict.items():\n        try:\n            # Process each symbol - now handles multiple timeframes\n            aggregated = pipeline[\"aggregation\"].process(data)\n            analyzed = pipeline[\"indicators\"].process(aggregated)\n\n            # Store results with timeframe breakdown\n            results[symbol] = {\n                'data': analyzed,\n                'timeframes': analyzed['timeframe'].unique().tolist(),\n                'inside_bars': len(analyzed.filter(pl.col('scenario') == \"1\")),\n                'outside_bars': len(analyzed.filter(pl.col('scenario') == \"3\")),\n                'last_price': analyzed.iloc[-1]['close'],\n                'total_bars': len(analyzed)\n            }\n\n            print(f\"Processed {symbol}: {len(analyzed)} bars across {len(analyzed['timeframe'].unique())} timeframes\")\n\n        except Exception as e:\n            print(f\"Error processing {symbol}: {e}\")\n            results[symbol] = None\n\n    return results\n\n# Example usage\nsymbols_data = {\n    'AAPL': aapl_data,\n    'MSFT': msft_data,\n    'GOOGL': googl_data\n}\n\nbatch_results = batch_process_symbols(symbols_data, config)\n</code></pre>"},{"location":"user-guide/examples/#memory-efficient-processing","title":"Memory Efficient Processing","text":"<pre><code>def process_large_dataset(data, chunk_size=1000):\n    \"\"\"Process large datasets in chunks to manage memory with new API.\"\"\"\n\n    config = FactoryConfig(\n        aggregation=AggregationConfig(\n            target_timeframes=[\"5min\"],\n            asset_class=\"equities\"\n        ),\n        indicators=IndicatorsConfig(\n            timeframe_configs=[\n                TimeframeItemConfig(\n                    timeframes=[\"all\"],\n                    swing_points=SwingPointsConfig(window=5)\n                )\n            ]\n        )\n    )\n\n    pipeline = Factory.create_all(config)\n    results = []\n\n    # Process in chunks\n    for start_idx in range(0, len(data), chunk_size):\n        end_idx = min(start_idx + chunk_size, len(data))\n        chunk = data.iloc[start_idx:end_idx]\n\n        # Include overlap for continuity\n        if start_idx &gt; 0:\n            overlap = data.iloc[max(0, start_idx-100):start_idx]\n            chunk = pd.concat([overlap, chunk])\n\n        # Process chunk\n        aggregated = pipeline[\"aggregation\"].process(chunk)\n        analyzed = pipeline[\"indicators\"].process(aggregated)\n\n        # Store results (excluding overlap)\n        if start_idx &gt; 0:\n            analyzed = analyzed.iloc[20:]  # Remove overlap portion\n\n        results.append(analyzed)\n        print(f\"Processed chunk {start_idx//chunk_size + 1}\")\n\n    # Combine results\n    final_result = pd.concat(results, ignore_index=True)\n    return final_result\n</code></pre>"},{"location":"user-guide/examples/#integration-examples","title":"Integration Examples","text":""},{"location":"user-guide/examples/#with-popular-trading-libraries","title":"With Popular Trading Libraries","text":"<pre><code># Integration with backtrader\nimport backtrader as bt\n\nclass TheStratStrategy(bt.Strategy):\n    def __init__(self):\n        self.thestrat_config = FactoryConfig(\n            aggregation=AggregationConfig(\n                target_timeframes=[\"5min\"],\n                asset_class=\"equities\"\n            ),\n            indicators=IndicatorsConfig(\n                timeframe_configs=[\n                    TimeframeItemConfig(\n                        timeframes=[\"all\"],\n                        swing_points=SwingPointsConfig(window=5, threshold=2.0)\n                    )\n                ]\n            )\n        )\n        self.pipeline = Factory.create_all(self.thestrat_config)\n\n    def next(self):\n        # Convert backtrader data to DataFrame\n        data = self.convert_bt_data()\n\n        # Apply TheStrat analysis\n        analyzed = self.pipeline[\"indicators\"].process(\n            self.pipeline[\"aggregation\"].process(data)\n        )\n\n        # Trading logic based on TheStrat signals\n        if analyzed.iloc[-1]['scenario'] == \"3\" and not self.position:\n            self.buy()\n        elif analyzed.iloc[-1]['scenario'] == \"1\" and self.position:\n            self.close()\n\n# Integration with zipline\nfrom zipline.api import order, record, symbol\n\ndef thestrat_zipline_algo(context, data):\n    # Get price data\n    prices = data.history(symbol('AAPL'), ['open', 'high', 'low', 'close'], 100, '1d')\n\n    # Apply TheStrat with new API\n    config = FactoryConfig(\n        aggregation=AggregationConfig(target_timeframes=[\"1d\"]),\n        indicators=IndicatorsConfig(\n            timeframe_configs=[\n                TimeframeItemConfig(\n                    timeframes=[\"all\"],\n                    swing_points=SwingPointsConfig(window=5)\n                )\n            ]\n        )\n    )\n    pipeline = Factory.create_all(config)\n    aggregated = pipeline[\"aggregation\"].process(prices.reset_index())\n    analyzed = pipeline[\"indicators\"].process(aggregated)\n\n    # Trading decisions\n    if analyzed.iloc[-1]['scenario'] == \"3\":\n        order(symbol('AAPL'), 100)\n\n    record(inside_bars=len(analyzed.filter(pl.col('scenario') == \"1\")))\n</code></pre> <p>These examples demonstrate the flexibility and power of TheStrat for various trading scenarios. Adapt the configurations and logic to match your specific trading strategy and requirements.</p>"},{"location":"user-guide/installation/","title":"Installation","text":"<p>This guide covers how to install the TheStrat module in different environments and scenarios.</p>"},{"location":"user-guide/installation/#prerequisites","title":"Prerequisites","text":"<p>Before installing TheStrat, ensure you have:</p> <ul> <li>Python 3.11 or higher</li> <li>uv package manager (recommended) or pip</li> <li>Git (for development installation)</li> </ul>"},{"location":"user-guide/installation/#installing-uv-recommended","title":"Installing uv (Recommended)","text":"<p>If you don't have <code>uv</code> installed, it's the fastest Python package installer:</p> <pre><code># On macOS and Linux\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# On Windows\npowershell -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n\n# Or with pip\npip install uv\n</code></pre>"},{"location":"user-guide/installation/#installation-options","title":"Installation Options","text":""},{"location":"user-guide/installation/#option-1-direct-installation-recommended","title":"Option 1: Direct Installation (Recommended)","text":"<p>Install directly from the GitHub repository:</p> Install TheStrat<pre><code>uv add git+https://github.com/jlixfeld/thestrat.git\n</code></pre>"},{"location":"user-guide/installation/#option-2-development-installation","title":"Option 2: Development Installation","text":"<p>For development work or to run tests:</p> Development Setup<pre><code># Clone the repository\ngit clone https://github.com/jlixfeld/thestrat.git\ncd thestrat\n\n# Install with development dependencies\nuv sync --extra test --extra dev --extra docs\n</code></pre>"},{"location":"user-guide/installation/#option-3-using-pip","title":"Option 3: Using pip","text":"<p>If you prefer using pip:</p> <pre><code>pip install git+https://github.com/jlixfeld/thestrat.git\n</code></pre>"},{"location":"user-guide/installation/#verify-installation","title":"Verify Installation","text":"<p>Test your installation by importing the module:</p> Verify Installation<pre><code>import thestrat\nprint(f\"TheStrat version: {thestrat.__version__}\")  # Dynamic version from package\n\n# Test basic functionality with Pydantic models\nfrom thestrat import Factory\nfrom thestrat.schemas import (\n    FactoryConfig, AggregationConfig, IndicatorsConfig,\n    TimeframeItemConfig, SwingPointsConfig\n)\n\nconfig = FactoryConfig(\n    aggregation=AggregationConfig(target_timeframes=[\"5m\"]),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"all\"],\n                swing_points=SwingPointsConfig(window=5, threshold=2.0)\n            )\n        ]\n    )\n)\n\ncomponents = Factory.create_all(config)\nprint(\"Installation successful!\")\n</code></pre>"},{"location":"user-guide/installation/#development-setup","title":"Development Setup","text":"<p>If you're planning to contribute or modify the code:</p>"},{"location":"user-guide/installation/#1-clone-and-install","title":"1. Clone and Install","text":"<pre><code>git clone https://github.com/jlixfeld/thestrat.git\ncd thestrat\nuv sync --extra test --extra dev --extra docs\n</code></pre>"},{"location":"user-guide/installation/#2-verify-development-environment","title":"2. Verify Development Environment","text":"<pre><code># Run tests\nuv run pytest\n\n# Check code formatting\nuv run ruff check .\n\n# Format code\nuv run ruff format .\n\n# Build documentation\nuv run mkdocs serve\n</code></pre>"},{"location":"user-guide/installation/#3-run-development-tests","title":"3. Run Development Tests","text":"<p>Verify your development environment:</p> <pre><code># Run all tests\nuv run pytest\n\n# Check code quality\nuv run ruff check .\n</code></pre>"},{"location":"user-guide/installation/#dependencies","title":"Dependencies","text":"<p>TheStrat has the following dependencies:</p>"},{"location":"user-guide/installation/#core-dependencies","title":"Core Dependencies","text":"<ul> <li>polars[timezone] \u22651.0.0 - High-performance data processing</li> <li>pandas \u22651.5.0 - Data manipulation and analysis</li> <li>numpy \u22651.21.0 - Numerical computing</li> <li>pytz \u22652022.1 - Timezone handling</li> </ul>"},{"location":"user-guide/installation/#development-dependencies","title":"Development Dependencies","text":"<ul> <li>pytest \u22656.0 - Testing framework</li> <li>ruff ==0.11.13 - Linting and formatting</li> <li>pytest-cov \u22652.0 - Coverage reporting</li> </ul>"},{"location":"user-guide/installation/#documentation-dependencies","title":"Documentation Dependencies","text":"<ul> <li>mkdocs-material \u22659.4.0 - Documentation theme</li> <li>mkdocstrings[python] \u22650.24.0 - API documentation generation</li> </ul>"},{"location":"user-guide/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-guide/installation/#common-issues","title":"Common Issues","text":"<p>Import Error: <code>ModuleNotFoundError: No module named 'thestrat'</code> :   Ensure you've activated the correct Python environment and the module is installed.</p> <p>Version Conflicts: Dependency resolution errors :   Use <code>uv</code> which has better dependency resolution than pip:     <pre><code>uv add git+https://github.com/jlixfeld/thestrat.git\n</code></pre></p> <p>Permission Errors: Cannot write to installation directory :   Use a virtual environment or user installation:     <pre><code># Create virtual environment\nuv venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\nuv add git+https://github.com/jlixfeld/thestrat.git\n</code></pre></p> <p>Test Failures: Tests failing during development setup :   Ensure you have the test dependencies:     <pre><code>uv sync --extra test\nuv run pytest -v\n</code></pre></p>"},{"location":"user-guide/installation/#getting-help","title":"Getting Help","text":"<p>If you encounter issues not covered here:</p> <ol> <li>Check that all prerequisites are installed</li> <li>Verify your Python version: <code>python --version</code></li> <li>Try creating a fresh virtual environment</li> <li>Contact the maintainer with error details</li> </ol>"},{"location":"user-guide/installation/#next-steps","title":"Next Steps","text":"<p>Once installation is complete, proceed to the Quick Start guide to begin using TheStrat in your applications.</p>"},{"location":"user-guide/pattern-terminology/","title":"Pattern Terminology and Visual Guide","text":"<p>This guide establishes clear terminology for TheStrat patterns and provides visual diagrams for all reversal and continuation signals.</p>"},{"location":"user-guide/pattern-terminology/#core-terminology","title":"Core Terminology","text":""},{"location":"user-guide/pattern-terminology/#scenarios","title":"Scenarios","text":"<p>TheStrat classifies individual bars based on their relationship to the previous bar:</p> <p>Scenario \"1\" - Inside Bar - Current bar's high \u2264 previous bar's high AND low \u2265 previous bar's low - Consolidation/consolidation - bar is completely contained within previous bar's range - Creates potential for breakout in either direction</p> <p>Scenario \"2U\" - Directional Up - Current bar makes a higher high but doesn't make a lower low - Upward directional move - Labeled \"2U\" in pattern names</p> <p>Scenario \"2D\" - Directional Down - Current bar makes a lower low but doesn't make a higher high - Downward directional move - Labeled \"2D\" in pattern names</p> <p>Scenario \"3\" - Outside Bar (Expansion or Broadening formation on a lower timeframe) - Current bar makes both a higher high AND lower low - Expansion - completely engulfs previous bar's range - Labeled \"3\" in pattern names</p> <p>All TheStrat patterns are built from combinations of these scenarios (e.g., \"2D-2U\", \"2D-1-2U\", \"3-2U\").</p>"},{"location":"user-guide/pattern-terminology/#bar-roles","title":"Bar Roles","text":"<p>Setup Bar</p> <ul> <li>The bar being broken (reversals) or continued (continuations)</li> <li>Provides the entry and stop price levels</li> <li>Always the bar immediately before the trigger bar (regardless of pattern type)</li> <li>In 2-bar patterns (e.g., 2D-2U): The first directional bar (2D)</li> <li>In 3-bar patterns (e.g., 2D-1-2U): The inside bar (1)</li> </ul> <p>Trigger Bar</p> <ul> <li>The bar that completes and confirms the pattern</li> <li>Where the signal is detected in the DataFrame</li> <li>Always the final bar of the pattern (regardless of pattern type)</li> <li>In 2-bar patterns (e.g., 2D-2U): The second directional bar (2U)</li> <li>In 3-bar patterns (e.g., 2D-1-2U): The final directional bar (2U)</li> </ul>"},{"location":"user-guide/pattern-terminology/#price-levels","title":"Price Levels","text":"<p>Entry Price</p> <ul> <li>Breakout/breakdown level from setup bar</li> <li>Long signals: Setup bar high (breakout above)</li> <li>Short signals: Setup bar low (breakdown below)</li> </ul> <p>Stop Price</p> <ul> <li>Invalidation level from setup bar</li> <li>Long signals: Setup bar low (invalidation if broken)</li> <li>Short signals: Setup bar high (invalidation if broken)</li> </ul> <p>Target Ladder</p> <ul> <li>Series of target price levels extending to structural bounds</li> <li>Detected from historical bars before the setup bar (or before inside bar for 1-2-2 rev-strats)</li> <li>Long signals: Ascending ladder of highs (each target higher than previous) extending to <code>higher_high</code> or <code>lower_high</code> bound</li> <li>Short signals: Descending ladder of lows (each target lower than previous) extending to <code>lower_low</code> or <code>higher_low</code> bound</li> <li>First target must be beyond the setup bar's breakout level (entry price)</li> </ul>"},{"location":"user-guide/pattern-terminology/#visual-pattern-guide","title":"Visual Pattern Guide","text":""},{"location":"user-guide/pattern-terminology/#inside-bar-reversals","title":"Inside Bar Reversals","text":"<p>Patterns: 2d-1-2u, 2u-1-2d, 3-1-2u, 3-1-2d</p> <ul> <li>Yellow candle = Inside bar (consolidation), also the setup bar</li> <li>Setup bar provides entry/stop levels</li> <li>Targets extend from historical bars beyond trigger bar</li> </ul>"},{"location":"user-guide/pattern-terminology/#2-bar-reversals","title":"2-Bar Reversals","text":"<p>Patterns: 2d-2u, 2u-2d</p> <ul> <li>Two bars form the reversal pattern</li> <li>Setup bar provides entry/stop levels</li> <li>Targets extend from historical bars beyond trigger bar</li> </ul>"},{"location":"user-guide/pattern-terminology/#rev-strat-patterns","title":"Rev-Strat Patterns","text":"<p>Patterns: 1-3u, 1-3d, 1-2d-2u, 1-2u-2d</p> <ul> <li>Pattern starts with inside bar (1)</li> <li>Setup bar provides entry/stop levels</li> <li>Targets extend from historical bars beyond trigger bar</li> </ul>"},{"location":"user-guide/pattern-terminology/#3-2-context-reversals","title":"3-2 Context Reversals","text":"<p>Patterns: 3-2u, 3-2d</p> <ul> <li>Context-dependent patterns (require continuity analysis)</li> <li>Scenario 3 in one direction countered by a scenario 2 in the other</li> <li>Reversal determined by previous trend context</li> </ul>"},{"location":"user-guide/pattern-terminology/#inside-bar-continuations","title":"Inside Bar Continuations","text":"<p>Patterns: 2u-1-2u, 2d-1-2d</p> <ul> <li>Yellow candle = Inside bar</li> <li>Green line = Entry level (setup bar high/low)</li> <li>No targets stored for continuations (trend-following)</li> </ul>"},{"location":"user-guide/pattern-terminology/#pattern-anatomy-example","title":"Pattern Anatomy Example","text":"<p>Detailed 2D-2U Example showing:</p> <ul> <li>Setup Bar (2D) provides entry at high, stop at low</li> <li>Trigger Bar (2U) completes the pattern</li> <li>Target ladder detected from historical bars</li> <li>Targets extend to higher_high bound</li> <li>Actual price levels from real market data</li> </ul>"},{"location":"user-guide/pattern-terminology/#price-level-rules","title":"Price Level Rules","text":""},{"location":"user-guide/pattern-terminology/#long-reversals-eg-2d-2u-2d-1-2u","title":"Long Reversals (e.g., 2D-2U, 2D-1-2U)","text":"<ul> <li>Entry: Setup bar high</li> <li>Stop: Setup bar low</li> <li>Targets: Ascending ladder of historical highs extending to <code>higher_high</code> or <code>lower_high</code> bound</li> <li>First target must be above trigger bar high</li> <li>Each subsequent target higher than previous (ascending values: target_1 &lt; target_2 &lt; ...)</li> <li>Maximum targets determined by <code>max_targets</code> config</li> <li>Relationship: <code>stop &lt; entry</code> and <code>trigger_high &lt; target_1 &lt; target_2 &lt; ... \u2264 bound</code></li> </ul>"},{"location":"user-guide/pattern-terminology/#short-reversals-eg-2u-2d-2u-1-2d","title":"Short Reversals (e.g., 2U-2D, 2U-1-2D)","text":"<ul> <li>Entry: Setup bar low</li> <li>Stop: Setup bar high</li> <li>Targets: Descending ladder of historical lows extending to <code>lower_low</code> or <code>higher_low</code> bound</li> <li>First target must be below trigger bar low</li> <li>Each subsequent target lower than previous (descending values: target_1 &gt; target_2 &gt; ...)</li> <li>Maximum targets determined by <code>max_targets</code> config</li> <li>Relationship: <code>stop &gt; entry</code> and <code>trigger_low &gt; target_1 &gt; target_2 &gt; ... \u2265 bound</code></li> </ul>"},{"location":"user-guide/pattern-terminology/#continuations-all-patterns","title":"Continuations (All patterns)","text":"<ul> <li>Entry: Setup bar high (long) or low (short)</li> <li>Stop: Setup bar low (long) or high (short)</li> <li>Targets: None (trend-following, no target ladder)</li> </ul>"},{"location":"user-guide/pattern-terminology/#all-pattern-names-reference","title":"All Pattern Names Reference","text":""},{"location":"user-guide/pattern-terminology/#reversal-patterns-long-bias","title":"Reversal Patterns - Long Bias","text":"<p>2-Bar Patterns:</p> <ul> <li><code>2D-2U</code> - Down bar followed by up bar (simple reversal)</li> <li><code>3-2U</code> - Outside bar followed by a reversal in the opposite direction.</li> </ul> <p>3-Bar Patterns:</p> <ul> <li><code>1-2D-2U</code> - Inside, down, up (Rev Strat)</li> <li><code>3-1-2U</code> - Outside, inside, up</li> <li><code>3-2D-2U</code> - Outside, down, up</li> <li><code>2D-1-2U</code> - Down, inside, up</li> </ul>"},{"location":"user-guide/pattern-terminology/#reversal-patterns-short-bias","title":"Reversal Patterns - Short Bias","text":"<p>2-Bar Patterns:</p> <ul> <li><code>2U-2D</code> - Up bar followed by down bar (simple reversal)</li> <li><code>3-2D</code> - Outside bar followed by a reversal in the opposite direction.</li> </ul> <p>3-Bar Patterns:</p> <ul> <li><code>1-2U-2D</code> - Inside, up, down (Rev Strat)</li> <li><code>3-1-2D</code> - Outside, inside, down</li> <li><code>3-2U-2D</code> - Outside, up, down</li> <li><code>2U-1-2D</code> - Up, inside, down</li> </ul>"},{"location":"user-guide/pattern-terminology/#continuation-patterns-long-bias","title":"Continuation Patterns - Long Bias","text":"<p>2-Bar Patterns:</p> <ul> <li><code>2U-2U</code> - Up bar followed by up bar (continuation)</li> </ul> <p>3-Bar Patterns:</p> <ul> <li><code>2U-1-2U</code> - Up, inside, up</li> </ul>"},{"location":"user-guide/pattern-terminology/#continuation-patterns-short-bias","title":"Continuation Patterns - Short Bias","text":"<p>2-Bar Patterns:</p> <ul> <li><code>2D-2D</code> - Down bar followed by down bar (continuation)</li> </ul> <p>3-Bar Patterns:</p> <ul> <li><code>2D-1-2D</code> - Down, inside, down</li> </ul>"},{"location":"user-guide/pattern-terminology/#implementation-reference","title":"Implementation Reference","text":""},{"location":"user-guide/pattern-terminology/#code-locations","title":"Code Locations","text":"<p>Signal Detection: <code>thestrat/indicators.py</code></p> <p>Signal Objects: <code>thestrat/signals.py</code></p> <p>Configuration: <code>thestrat/schemas.py</code></p>"},{"location":"user-guide/pattern-terminology/#related-documentation","title":"Related Documentation","text":"<ul> <li>Signal Metadata Guide - Complete field documentation</li> <li>DataFrame Schema - Output column specifications</li> <li>Asset Classes - Timezone and session configuration</li> <li>Examples - Real-world usage examples</li> </ul>"},{"location":"user-guide/precision/","title":"Precision Utilities","text":"<p>The precision utilities provide security-type-aware rounding for indicator fields to ensure consistent behavior between live trading and backtesting platforms.</p>"},{"location":"user-guide/precision/#overview","title":"Overview","text":"<p>Different securities have different price precision requirements: - Equities (AAPL, TSLA): 2 decimal places ($150.12) - Forex (EURUSD): 5 decimal places (1.23457) - Crypto (BTC): 8 decimal places (42358.12345678)</p> <p>The precision module automatically handles these differences for all indicator fields.</p>"},{"location":"user-guide/precision/#quick-start","title":"Quick Start","text":"<pre><code>from thestrat import apply_precision, IndicatorSchema\nimport polars as pl\n\n# Your indicator DataFrame\ndf = pl.DataFrame({\n    \"symbol\": [\"AAPL\", \"EURUSD\", \"BTC\"],\n    \"open\": [150.123456, 1.234567890, 42358.12345678901],\n    \"close\": [151.987654, 1.987654321, 42500.98765432109],\n    \"percent_close_from_high\": [45.123456, 67.987654, 23.456789],\n})\n\n# Define precision per security (from IBKR minTick)\nprecision_map = {\n    \"AAPL\": 2,      # $0.01 minimum tick\n    \"EURUSD\": 5,    # 0.00001 minimum tick\n    \"BTC\": 8,       # 0.00000001 minimum tick\n}\n\n# Apply precision rounding\nrounded_df = apply_precision(df, precision_map)\n\n# Results:\n# AAPL:   open=150.12, close=151.99, percent=45.12\n# EURUSD: open=1.23457, close=1.98765, percent=67.99\n# BTC:    open=42358.12345678, close=42500.98765432, percent=23.46\n</code></pre>"},{"location":"user-guide/precision/#field-types","title":"Field Types","text":"<p>All indicator fields have precision metadata defining how they should be rounded:</p>"},{"location":"user-guide/precision/#percentage-fields-always-2-decimals","title":"Percentage Fields (Always 2 Decimals)","text":"<p>Percentage fields are always rounded to 2 decimal places, regardless of security:</p> <pre><code>from thestrat import get_field_decimal_places\n\n# Percentage fields always return 2\nget_field_decimal_places(\"percent_close_from_high\", security_precision=2)  # \u2192 2\nget_field_decimal_places(\"percent_close_from_high\", security_precision=5)  # \u2192 2\nget_field_decimal_places(\"percent_close_from_high\", security_precision=8)  # \u2192 2\n</code></pre> <p>Fields: - <code>percent_close_from_high</code> - <code>percent_close_from_low</code></p>"},{"location":"user-guide/precision/#price-fields-security-dependent","title":"Price Fields (Security-Dependent)","text":"<p>Price fields use the security's precision from IBKR minTick:</p> <pre><code># Price fields use security_precision parameter\nget_field_decimal_places(\"open\", security_precision=2)  # \u2192 2 (equities)\nget_field_decimal_places(\"close\", security_precision=5)  # \u2192 5 (forex)\nget_field_decimal_places(\"ath\", security_precision=8)    # \u2192 8 (crypto)\n</code></pre> <p>Fields: - OHLC: <code>open</code>, <code>high</code>, <code>low</code>, <code>close</code> - Price levels: <code>ath</code>, <code>atl</code> - Market structure: <code>higher_high</code>, <code>lower_high</code>, <code>higher_low</code>, <code>lower_low</code> - Signal prices: <code>entry_price</code>, <code>stop_price</code>, <code>target_prices</code>, <code>f23_trigger</code></p>"},{"location":"user-guide/precision/#integerboolean-fields-no-rounding","title":"Integer/Boolean Fields (No Rounding)","text":"<p>Integer and boolean fields are never rounded:</p> <pre><code># Integer fields return None (no rounding)\nget_field_decimal_places(\"target_count\", security_precision=2)  # \u2192 None\nget_field_decimal_places(\"continuity\", security_precision=5)    # \u2192 None\n</code></pre> <p>Fields: - Integers: <code>target_count</code>, <code>continuity</code>, <code>gapper</code>, <code>kicker</code>, <code>pmg</code> - Booleans: <code>new_ath</code>, <code>new_atl</code>, <code>in_force</code>, <code>hammer</code>, <code>shooter</code>, <code>f23</code>, etc. - Strings: <code>signal</code>, <code>type</code>, <code>bias</code>, <code>scenario</code>, <code>f23x</code></p>"},{"location":"user-guide/precision/#api-reference","title":"API Reference","text":""},{"location":"user-guide/precision/#apply_precision","title":"apply_precision()","text":"<p>Apply security-aware precision rounding to an entire DataFrame:</p> <pre><code>from thestrat import apply_precision\n\nrounded_df = apply_precision(\n    df,                      # DataFrame with indicator columns\n    security_precision_map,  # Dict[str, int]: symbol \u2192 decimal places\n    symbol_column=\"symbol\"   # Column containing symbols (default: \"symbol\")\n)\n</code></pre> <p>Parameters: - <code>df</code>: Polars DataFrame with indicator columns - <code>security_precision_map</code>: Dictionary mapping symbol to decimal places - <code>symbol_column</code>: Name of column containing symbols (default: <code>\"symbol\"</code>)</p> <p>Returns: DataFrame with all fields rounded according to their precision type</p> <p>Raises: <code>PrecisionError</code> if any symbol in the DataFrame is missing from the precision map</p> <p>Features: - Handles list columns (<code>target_prices</code>) element-wise - Preserves null values - Maintains column order - Processes multiple symbols in single DataFrame</p>"},{"location":"user-guide/precision/#get_field_decimal_places","title":"get_field_decimal_places()","text":"<p>Get decimal places for a specific field:</p> <pre><code>from thestrat import get_field_decimal_places\n\ndecimal_places = get_field_decimal_places(\n    field_name,              # Name of indicator field\n    security_precision=2     # Decimal places for security (default: 2)\n)\n</code></pre> <p>Returns: - <code>int</code>: Number of decimal places (for percentage/price fields) - <code>None</code>: No rounding needed (for integer/boolean/string fields)</p> <p>Raises: <code>PrecisionError</code> if field not found or missing precision metadata</p>"},{"location":"user-guide/precision/#get_field_precision_type","title":"get_field_precision_type()","text":"<p>Get the precision type for a field:</p> <pre><code>from thestrat import get_field_precision_type\n\nprecision_type = get_field_precision_type(\"open\")  # \u2192 \"price\"\nprecision_type = get_field_precision_type(\"percent_close_from_high\")  # \u2192 \"percentage\"\nprecision_type = get_field_precision_type(\"target_count\")  # \u2192 \"integer\"\n</code></pre> <p>Returns: - <code>\"percentage\"</code>: Always 2 decimals - <code>\"price\"</code>: Security-dependent decimals - <code>\"integer\"</code>: No rounding - <code>None</code>: Field not in schema</p>"},{"location":"user-guide/precision/#get_comparison_tolerance","title":"get_comparison_tolerance()","text":"<p>Get comparison tolerance for floating-point comparisons:</p> <pre><code>from thestrat import get_comparison_tolerance\n\n# For assertions/tests: value1 \u2248 value2 within tolerance\ntolerance = get_comparison_tolerance(\n    field_name,              # Field to compare\n    security_precision=2     # Security precision (default: 2)\n)\n</code></pre> <p>Returns: - <code>10^(-decimal_places)</code> for percentage/price fields - <code>0</code> for integer fields (exact comparison) - <code>1e-6</code> for unknown fields (small epsilon)</p> <p>Example: <pre><code># Percentage field (2 decimals) \u2192 0.01 tolerance\nassert abs(value1 - value2) &lt; get_comparison_tolerance(\"percent_close_from_high\")\n\n# Price field with 5 decimals \u2192 0.00001 tolerance\nassert abs(price1 - price2) &lt; get_comparison_tolerance(\"close\", security_precision=5)\n\n# Integer field \u2192 0 (exact comparison)\nassert value1 == value2  # get_comparison_tolerance(\"target_count\") == 0\n</code></pre></p>"},{"location":"user-guide/precision/#indicatorschemaget_precision_metadata","title":"IndicatorSchema.get_precision_metadata()","text":"<p>Get precision metadata for all fields:</p> <pre><code>from thestrat import IndicatorSchema\n\nmetadata = IndicatorSchema.get_precision_metadata()\n\n# Returns: dict[str, dict[str, Any]]\n# {\n#     \"percent_close_from_high\": {\"precision_type\": \"percentage\", \"decimal_places\": 2},\n#     \"open\": {\"precision_type\": \"price\", \"decimal_places\": None},\n#     \"target_count\": {\"precision_type\": \"integer\", \"decimal_places\": None},\n#     ...\n# }\n</code></pre>"},{"location":"user-guide/precision/#advanced-usage","title":"Advanced Usage","text":""},{"location":"user-guide/precision/#multi-symbol-dataframes","title":"Multi-Symbol DataFrames","text":"<p>The <code>apply_precision()</code> function handles multiple symbols with different precisions:</p> <pre><code>import polars as pl\nfrom thestrat import apply_precision\n\n# Mixed symbols in one DataFrame\ndf = pl.DataFrame({\n    \"symbol\": [\"AAPL\", \"EURUSD\", \"AAPL\", \"EURUSD\"],\n    \"timestamp\": [...],\n    \"open\": [150.123456, 1.234567890, 151.987654, 1.987654321],\n})\n\n# Different precision per symbol\nprecision_map = {\"AAPL\": 2, \"EURUSD\": 5}\n\n# Automatically groups by symbol and applies correct precision\nresult = apply_precision(df, precision_map)\n</code></pre>"},{"location":"user-guide/precision/#list-columns-target_prices","title":"List Columns (target_prices)","text":"<p>List columns are automatically handled element-wise:</p> <pre><code>df = pl.DataFrame({\n    \"symbol\": [\"AAPL\"],\n    \"target_prices\": [[150.123456, 151.987654, 153.555555]],\n})\n\nresult = apply_precision(df, {\"AAPL\": 2})\n# result[\"target_prices\"][0] \u2192 [150.12, 151.99, 153.56]\n</code></pre>"},{"location":"user-guide/precision/#database-integration","title":"Database Integration","text":"<p>Round before storing to ensure consistent precision:</p> <pre><code>from thestrat import apply_precision\n\ndef store_indicators(df, precision_map, connection):\n    \"\"\"Store indicator data with proper precision.\"\"\"\n    # Round all fields\n    rounded_df = apply_precision(df, precision_map)\n\n    # Write to database\n    rounded_df.write_database(\"indicators\", connection)\n</code></pre>"},{"location":"user-guide/precision/#backtesting-consistency","title":"Backtesting Consistency","text":"<p>Ensure backtests match live trading precision:</p> <pre><code>from thestrat import Factory, apply_precision\n\n# Process indicators\npipeline = Factory.create_all(config)\nindicators = pipeline[\"indicators\"].process(data)\n\n# Apply same precision as live trading\n# (precision_map fetched from IBKR contract details)\nrounded = apply_precision(indicators, precision_map)\n\n# Now backtest results match live trading behavior\nbacktest_results = run_backtest(rounded)\n</code></pre>"},{"location":"user-guide/precision/#error-handling","title":"Error Handling","text":""},{"location":"user-guide/precision/#missing-symbol-precision","title":"Missing Symbol Precision","text":"<pre><code>from thestrat import apply_precision, PrecisionError\n\ndf = pl.DataFrame({\n    \"symbol\": [\"AAPL\", \"TSLA\"],\n    \"open\": [150.12, 250.34],\n})\n\nprecision_map = {\"AAPL\": 2}  # Missing TSLA\n\ntry:\n    apply_precision(df, precision_map)\nexcept PrecisionError as e:\n    print(e)  # \"Missing precision for symbols: ['TSLA']\"\n</code></pre>"},{"location":"user-guide/precision/#invalid-field-name","title":"Invalid Field Name","text":"<pre><code>from thestrat import get_field_decimal_places, PrecisionError\n\ntry:\n    get_field_decimal_places(\"invalid_field\")\nexcept PrecisionError as e:\n    print(e)  # \"Field 'invalid_field' not found in IndicatorSchema\"\n</code></pre>"},{"location":"user-guide/precision/#best-practices","title":"Best Practices","text":"<ol> <li>Fetch precision from IBKR: Use contract details to get the correct minTick for each security</li> <li>Apply before storage: Round data before writing to database to ensure consistency</li> <li>Apply before backtesting: Use same precision in backtests as live trading</li> <li>Cache precision map: Build precision map once and reuse across processing runs</li> <li>Validate symbols: Ensure all symbols have precision before processing</li> </ol>"},{"location":"user-guide/precision/#integration-example","title":"Integration Example","text":"<p>Complete example integrating precision utilities with strattrader:</p> <pre><code>from thestrat import Factory, apply_precision, IndicatorSchema\nfrom thestrat.schemas import FactoryConfig, AggregationConfig, IndicatorsConfig\nimport polars as pl\n\n# 1. Fetch precision from IBKR\ndef get_ibkr_precision(symbols):\n    \"\"\"Get precision from IBKR contract details.\"\"\"\n    precision_map = {}\n    for symbol in symbols:\n        contract = ib.reqContractDetails(symbol)\n        min_tick = contract.minTick  # e.g., 0.01, 0.00001, 0.00000001\n\n        # Convert minTick to decimal places\n        decimal_places = len(str(min_tick).split('.')[-1])\n        precision_map[symbol] = decimal_places\n\n    return precision_map\n\n# 2. Process indicators\nconfig = FactoryConfig(\n    aggregation=AggregationConfig(target_timeframes=[\"5min\"], asset_class=\"equities\"),\n    indicators=IndicatorsConfig(timeframe_configs=[...])\n)\n\npipeline = Factory.create_all(config)\naggregated = pipeline[\"aggregation\"].process(raw_data)\nindicators = pipeline[\"indicators\"].process(aggregated)\n\n# 3. Get precision for all symbols\nsymbols = indicators[\"symbol\"].unique().to_list()\nprecision_map = get_ibkr_precision(symbols)\n\n# 4. Apply precision\nrounded_indicators = apply_precision(indicators, precision_map)\n\n# 5. Store with consistent precision\nrounded_indicators.write_database(\"indicators\", connection)\n</code></pre>"},{"location":"user-guide/precision/#see-also","title":"See Also","text":"<ul> <li>DataFrame Schema - Complete schema documentation</li> <li>Examples - Working code examples</li> <li>API Reference - Detailed function signatures</li> </ul>"},{"location":"user-guide/quickstart/","title":"Quick Start","text":"<p>Get up and running with TheStrat in just a few minutes. This guide assumes you have already installed the module.</p>"},{"location":"user-guide/quickstart/#basic-workflow","title":"Basic Workflow","text":"<p>TheStrat follows a simple workflow:</p> <ol> <li>Configure your components using the Factory pattern</li> <li>Aggregate your data to the desired timeframe</li> <li>Analyze with TheStrat indicators</li> <li>Extract signals and insights</li> </ol>"},{"location":"user-guide/quickstart/#data-format-requirements","title":"Data Format Requirements","text":"<p>TheStrat requires specific columns in your input data. All data must include a <code>timeframe</code> column that specifies the timeframe of each data point.</p>"},{"location":"user-guide/quickstart/#required-columns","title":"Required Columns","text":"<p>Required columns (all mandatory): - <code>timestamp</code> - datetime column for each bar/candle - <code>timeframe</code> - timeframe of the data (e.g., '1min', '5min', '1h') - <code>open</code> - opening price (float, &gt; 0) - <code>high</code> - highest price (float, &gt; 0) - <code>low</code> - lowest price (float, &gt; 0) - <code>close</code> - closing price (float, &gt; 0)</p> <p>Optional columns: - <code>symbol</code> - trading symbol/ticker (string) - <code>volume</code> - trading volume (float, \u2265 0)</p>"},{"location":"user-guide/quickstart/#data-format-example","title":"Data Format Example","text":"<p>All input data must include the <code>timeframe</code> column:</p> <pre><code># Example input data\ndata = pd.DataFrame({\n    'timestamp': [...],  # datetime\n    'timeframe': ['1min', '1min', '5min', '5min', ...],  # MANDATORY\n    'open': [...],       # float\n    'high': [...],       # float\n    'low': [...],        # float\n    'close': [...],      # float\n    'symbol': [...],     # optional string\n    'volume': [...]      # optional float\n})\n</code></pre> <p>Data type support: - Accepts both Polars and Pandas DataFrames (auto-converts Pandas to Polars) - Timestamps can be timezone-naive (converted using config timezone) or timezone-aware - Minimum 2 data points required</p>"},{"location":"user-guide/quickstart/#your-first-thestrat-analysis","title":"Your First TheStrat Analysis","text":"<p>Let's start with a complete example using sample market data:</p> <pre><code>from pandas import DataFrame as PandasDataFrame\nfrom thestrat import Factory\nfrom thestrat.schemas import (\n    FactoryConfig, AggregationConfig, IndicatorsConfig,\n    TimeframeItemConfig, SwingPointsConfig\n)\n\n# Sample OHLCV data (1-minute bars)\nsample_data = PandasDataFrame({\n    'timestamp': pd.date_range('2024-01-01 09:30', periods=100, freq='1min'),\n    'open': [100.0] * 100,\n    'high': [101.0] * 100,\n    'low': [99.0] * 100,\n    'close': [100.5] * 100,\n    'volume': [1000] * 100,\n    'timeframe': ['1min'] * 100\n})\n\n# Configure TheStrat components with Pydantic models\nconfig = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"5min\"],  # Aggregate to 5-minute bars (now supports multiple)\n        asset_class=\"equities\",      # US equity market\n        timezone=\"US/Eastern\"        # Eastern timezone\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"all\"],    # Apply to all target timeframes\n                swing_points=SwingPointsConfig(\n                    window=5,            # 5-period swing detection\n                    threshold=2.0        # 2% threshold for significance\n                )\n            )\n        ]\n    )\n)\n\n# Create components using Factory\npipeline = Factory.create_all(config)\n\n# Process the data - now returns normalized output with timeframe column\naggregated_data = pipeline[\"aggregation\"].process(sample_data)\nanalyzed_data = pipeline[\"indicators\"].process(aggregated_data)\n\nprint(f\"Original bars: {len(sample_data)}\")\nprint(f\"Aggregated bars: {len(aggregated_data)}\")\nprint(f\"Analysis complete: {len(analyzed_data)} bars with TheStrat indicators\")\nprint(f\"Timeframes processed: {analyzed_data['timeframe'].unique()}\")\n</code></pre>"},{"location":"user-guide/quickstart/#step-by-step-breakdown","title":"Step-by-Step Breakdown","text":""},{"location":"user-guide/quickstart/#step-1-configure-components","title":"Step 1: Configure Components","text":"<p>The Factory pattern centralizes configuration:</p> <pre><code>from thestrat import Factory\nfrom thestrat.schemas import (\n    FactoryConfig, AggregationConfig, IndicatorsConfig,\n    TimeframeItemConfig, SwingPointsConfig\n)\n\n# Minimal configuration using models\nsimple_config = FactoryConfig(\n    aggregation=AggregationConfig(target_timeframes=[\"5min\"]),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(timeframes=[\"all\"])\n        ]\n    )\n)\n\n# Full configuration with all options\nfull_config = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"5min\", \"15min\"],  # Multiple timeframes supported\n        asset_class=\"equities\",\n        timezone=\"US/Eastern\"\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"5min\"],\n                swing_points=SwingPointsConfig(window=5, threshold=2.0)\n            ),\n            TimeframeItemConfig(\n                timeframes=[\"15min\"],\n                swing_points=SwingPointsConfig(window=7, threshold=3.0)\n            )\n        ]\n    )\n)\n\ncomponents = Factory.create_all(full_config)\n</code></pre>"},{"location":"user-guide/quickstart/#step-2-timeframe-aggregation","title":"Step 2: Timeframe Aggregation","text":"<p>Transform your base timeframe data:</p> <pre><code># Get the aggregation component\naggregator = components[\"aggregation\"]\n\n# Process your 1-minute data into 5-minute bars\nfive_min_bars = aggregator.process(one_minute_data)\n\n# The aggregated data maintains OHLCV structure and includes timeframe column\nprint(five_min_bars.columns)\n# ['timestamp', 'open', 'high', 'low', 'close', 'volume', 'timeframe']\n</code></pre>"},{"location":"user-guide/quickstart/#step-3-apply-thestrat-indicators","title":"Step 3: Apply TheStrat Indicators","text":"<p>Analyze market structure:</p> <pre><code># Get the indicators component\nindicators = components[\"indicators\"]\n\n# Apply TheStrat analysis\nanalyzed = indicators.process(five_min_bars)\n\n# New columns are added for TheStrat metrics\nprint(analyzed.columns)\n# Original OHLCV + TheStrat indicators like:\n# 'scenario', 'higher_high', 'lower_low', 'signal', etc.\n</code></pre>"},{"location":"user-guide/quickstart/#step-4-extract-insights","title":"Step 4: Extract Insights","text":"<p>Work with the results:</p> <pre><code># Find inside bars (scenario == \"1\")\ninside_bars = analyzed.filter(pl.col('scenario') == \"1\")\nprint(f\"Found {len(inside_bars)} inside bars\")\n\n# Find outside bars (scenario == \"3\")\noutside_bars = analyzed.filter(pl.col('scenario') == \"3\")\nprint(f\"Found {len(outside_bars)} outside bars\")\n\n# Find market structure points\nhigher_highs = len(analyzed['higher_high'].drop_nulls())\nlower_lows = len(analyzed['lower_low'].drop_nulls())\n\nprint(f\"Higher highs: {higher_highs}\")\nprint(f\"Lower lows: {lower_lows}\")\n\n# Get the latest signals\nlatest_signals = analyzed.tail(10).select(['timestamp', 'scenario', 'signal'])\nprint(latest_signals)\n</code></pre>"},{"location":"user-guide/quickstart/#asset-class-examples","title":"Asset Class Examples","text":"<p>Different asset classes require different configurations:</p>"},{"location":"user-guide/quickstart/#crypto-247-trading","title":"Crypto (24/7 Trading)","text":"<p>Not Actively Tested</p> <p>Crypto support is illustrative. This configuration is not actively tested or used in production.</p> <pre><code>crypto_config = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"1h\"],\n        asset_class=\"crypto\",\n        timezone=\"UTC\"  # Always UTC for crypto\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"all\"],\n                swing_points=SwingPointsConfig(window=5, threshold=2.0)\n            )\n        ]\n    )\n)\n\ncrypto_pipeline = Factory.create_all(crypto_config)\n</code></pre>"},{"location":"user-guide/quickstart/#forex-245-trading","title":"Forex (24/5 Trading)","text":"<p>Not Actively Tested</p> <p>Forex support is illustrative. This configuration is not actively tested or used in production.</p> <pre><code>fx_config = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"4h\"],\n        asset_class=\"fx\",\n        timezone=\"UTC\"  # Always UTC for FX\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"all\"],\n                swing_points=SwingPointsConfig(window=5, threshold=1.0)\n            )\n        ]\n    )\n)\n\nfx_pipeline = Factory.create_all(fx_config)\n</code></pre>"},{"location":"user-guide/quickstart/#common-patterns","title":"Common Patterns","text":""},{"location":"user-guide/quickstart/#multiple-timeframe-analysis","title":"Multiple Timeframe Analysis","text":"<pre><code># Analyze multiple timeframes in a single operation using Pydantic models\nconfig = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"5min\", \"15min\", \"1h\"],  # Process all timeframes together\n        asset_class=\"equities\"\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"5min\"],\n                swing_points=SwingPointsConfig(window=3, threshold=1.5)  # Aggressive for short timeframe\n            ),\n            TimeframeItemConfig(\n                timeframes=[\"15min\", \"1h\"],\n                swing_points=SwingPointsConfig(window=7, threshold=2.5)  # Conservative for longer timeframes\n            )\n        ]\n    )\n)\n\npipeline = Factory.create_all(config)\naggregated = pipeline[\"aggregation\"].process(raw_data)\nanalyzed = pipeline[\"indicators\"].process(aggregated)\n\n# Filter results by timeframe using the normalized output\nfor tf in [\"5min\", \"15min\", \"1h\"]:\n    tf_data = analyzed.filter(pl.col('timeframe') == tf)\n    inside_bars = len(tf_data.filter(pl.col('scenario') == \"1\"))\n    print(f\"{tf}: {len(tf_data)} bars, {inside_bars} inside bars\")\n\nprint(f\"Total analysis: {len(analyzed)} bars across {len(analyzed['timeframe'].unique())} timeframes\")\n</code></pre>"},{"location":"user-guide/quickstart/#signal-detection","title":"Signal Detection","text":"<pre><code># Custom signal detection\ndef find_breakouts(data):\n    \"\"\"Find potential breakout signals\"\"\"\n    breakouts = []\n\n    for i in range(1, len(data)):\n        current = data.row(i, named=True)\n        previous = data.row(i-1, named=True)\n\n        # Outside bar (scenario == \"3\") followed by continuation\n        if (previous['scenario'] == \"3\" and\n            current['close'] &gt; previous['high']):\n            breakouts.append({\n                'timestamp': current['timestamp'],\n                'type': 'bullish_breakout',\n                'price': current['close']\n            })\n\n    return breakouts\n\n# Apply to your analyzed data\nsignals = find_breakouts(analyzed_data)\nprint(f\"Found {len(signals)} breakout signals\")\n</code></pre>"},{"location":"user-guide/quickstart/#next-steps","title":"Next Steps","text":"<p>Now that you understand the basics:</p> <ol> <li>Explore Examples - More detailed use cases and advanced features</li> <li>Review Asset Classes - Understand market-specific behaviors</li> <li>Check API Reference - Detailed documentation of all methods and parameters</li> </ol>"},{"location":"user-guide/quickstart/#common-questions","title":"Common Questions","text":"<p>Q: What timeframes are supported? A: Supported timeframes: 1min, 5min, 15min, 30min, 1h, 4h, 6h, 12h, 1d, 1w, 1m (month), 1q, 1y. These are the only valid timeframe strings.</p> <p>Q: Can I use my own data format? A: Yes, as long as it has the required columns including the mandatory <code>timeframe</code> column. TheStrat accepts both Pandas and Polars DataFrames and will automatically standardize the data.</p> <p>Q: What if I have data from multiple symbols? A: Include a <code>symbol</code> column and TheStrat will process each symbol separately while maintaining proper grouping in the aggregation.</p> <p>Q: Why is the timeframe column mandatory? A: The timeframe column ensures TheStrat knows exactly what timeframe your data represents, preventing errors and enabling optimal aggregation strategies. This makes the API explicit and prevents silent failures.</p> <p>Q: How do I migrate existing data to include the timeframe column? A: Add the timeframe column to your existing DataFrames. Here's how:</p> <pre><code># If you have existing data without timeframe column\nexisting_data = pd.DataFrame({\n    'timestamp': pd.date_range('2024-01-01 09:30', periods=100, freq='1min'),\n    'open': [100.0] * 100,\n    'high': [101.0] * 100,\n    'low': [99.0] * 100,\n    'close': [100.5] * 100,\n    'volume': [1000] * 100\n})\n\n# Add the timeframe column (1min data in this example)\nexisting_data['timeframe'] = '1min'\n\n# Or for multiple timeframes, determine based on your data frequency\ndef determine_timeframe(freq_minutes):\n    if freq_minutes == 1:\n        return '1min'\n    elif freq_minutes == 5:\n        return '5min'\n    elif freq_minutes == 60:\n        return '1h'\n    # Add more mappings as needed\n\n# Now your data is ready for TheStrat\npipeline = Factory.create_all(config)\nresult = pipeline[\"aggregation\"].process(existing_data)\n</code></pre> <p>Q: How do I handle missing data? A: TheStrat includes built-in handling for gaps and missing bars appropriate to each asset class.</p> <p>Q: Can I backtest strategies? A: TheStrat provides the analysis foundation. You'll need to combine it with your backtesting framework.</p>"},{"location":"user-guide/signal-metadata/","title":"Signal Metadata","text":"<p>Complete guide to signal metadata objects, examples, and database integration</p> <p>\ud83d\udcd6 New to TheStrat patterns? See the Pattern Terminology and Visual Guide for definitions and diagrams of all reversal and continuation patterns.</p> <p>TheStrat signals return rich metadata objects that provide comprehensive trading information including entry/stop/target levels, risk management data, and change tracking capabilities.</p>"},{"location":"user-guide/signal-metadata/#overview","title":"Overview","text":"<p>When TheStrat indicators detect trading patterns, they generate signals with detailed metadata through the <code>SignalMetadata</code> class. This metadata transforms simple pattern strings into actionable trading objects with:</p> <ul> <li>Price levels: Entry and stop prices, with multiple target levels for reversals</li> <li>Target tracking: <code>TargetLevel</code> objects with hit status, timestamps, and broker fill IDs</li> <li>Risk management: Risk/reward ratios and position sizing data</li> <li>State tracking: Signal lifecycle and execution status</li> <li>Change history: Audit trail for stop price adjustments</li> <li>DataFrame integration: Native List[Float64] type for database storage with eager evaluation</li> </ul>"},{"location":"user-guide/signal-metadata/#basic-signal-example","title":"Basic Signal Example","text":"<pre><code>from datetime import datetime\nfrom thestrat.signals import SignalMetadata, SignalCategory, SignalBias, TargetLevel\n\n# Create a reversal signal with multiple targets\nsignal = SignalMetadata(\n    pattern=\"3-2U\",\n    category=SignalCategory.REVERSAL,\n    bias=SignalBias.LONG,\n    bar_count=2,\n    entry_price=150.0,\n    stop_price=148.0,\n    target_prices=[\n        TargetLevel(price=155.0),\n        TargetLevel(price=158.0),\n        TargetLevel(price=160.0)\n    ],\n    timestamp=datetime.now(),\n    symbol=\"AAPL\",\n    timeframe=\"5min\"\n)\n\nprint(f\"Signal: {signal.pattern}\")\nprint(f\"Entry: ${signal.entry_price}\")\nprint(f\"Stop: ${signal.stop_price}\")\nprint(f\"Targets: {[t.price for t in signal.target_prices]}\")\nprint(f\"Risk/Reward (first target): {signal.risk_reward_ratio:.2f}\")\n</code></pre> <p>Output: <pre><code>Signal: 3-2U\nEntry: $150.0\nStop: $148.0\nTargets: [155.0, 158.0, 160.0]\nRisk/Reward (first target): 2.50\n</code></pre></p>"},{"location":"user-guide/signal-metadata/#signal-categories-and-examples","title":"Signal Categories and Examples","text":""},{"location":"user-guide/signal-metadata/#reversal-signals","title":"Reversal Signals","text":""},{"location":"user-guide/signal-metadata/#understanding-reversal-signal-price-levels","title":"Understanding Reversal Signal Price Levels","text":"<p>For reversal signals, price levels come from the setup bar (the bar being reversed):</p> <ul> <li>Entry Price: Setup bar high (long) or low (short) - the breakout/breakdown level</li> <li>Stop Price: Setup bar low (long) or high (short) - the invalidation level</li> <li>First Target: Setup bar high (long) or low (short) - same as entry, what's being broken</li> <li>Additional Targets: Ladder of highs/lows extending to structural bounds</li> </ul> <p>See Pattern Terminology for visual diagrams and detailed explanations.</p>"},{"location":"user-guide/signal-metadata/#code-examples","title":"Code Examples","text":"<p>Reversal signals have entry, stop, and multiple target prices:</p> <pre><code># Long reversal signal with multiple targets\nlong_reversal = SignalMetadata(\n    pattern=\"2D-2U\",\n    category=SignalCategory.REVERSAL,\n    bias=SignalBias.LONG,\n    bar_count=2,\n    entry_price=125.50,    # Setup bar (2D) high\n    stop_price=123.75,     # Setup bar (2D) low\n    target_prices=[\n        TargetLevel(price=125.50),  # First target: setup bar high\n        TargetLevel(price=129.00),  # Additional ladder targets\n        TargetLevel(price=131.50),  # extending to higher_high\n        TargetLevel(price=134.00)   # structural bound\n    ],\n    timestamp=datetime.now()\n)\n\n# Short reversal signal with multiple targets\nshort_reversal = SignalMetadata(\n    pattern=\"2U-2D\",\n    category=SignalCategory.REVERSAL,\n    bias=SignalBias.SHORT,\n    bar_count=2,\n    entry_price=98.25,     # Setup bar (2U) low\n    stop_price=99.50,      # Setup bar (2U) high\n    target_prices=[\n        TargetLevel(price=98.25),  # First target: setup bar low\n        TargetLevel(price=95.00),  # Additional ladder targets\n        TargetLevel(price=93.50),  # descending to lower_low\n        TargetLevel(price=92.00)   # structural bound\n    ],\n    timestamp=datetime.now()\n)\n</code></pre>"},{"location":"user-guide/signal-metadata/#continuation-signals","title":"Continuation Signals","text":"<p>Continuation signals have no targets (trend-following):</p> <pre><code># Long continuation signal\ncontinuation = SignalMetadata(\n    pattern=\"2U-2U\",\n    category=SignalCategory.CONTINUATION,\n    bias=SignalBias.LONG,\n    bar_count=2,\n    entry_price=87.50,\n    stop_price=85.25,\n    timestamp=datetime.now()\n)\n\n# Note: target_prices is empty for continuation signals\nassert len(continuation.target_prices) == 0\nassert continuation.reward_amount is None\n</code></pre>"},{"location":"user-guide/signal-metadata/#risk-management-data","title":"Risk Management Data","text":"<p>All signals automatically calculate risk metrics using the first target:</p> <pre><code>signal = SignalMetadata(\n    pattern=\"3-1-2U\",\n    category=SignalCategory.REVERSAL,\n    bias=SignalBias.LONG,\n    bar_count=3,\n    entry_price=100.0,\n    stop_price=97.0,\n    target_prices=[\n        TargetLevel(price=106.0),\n        TargetLevel(price=109.0),\n        TargetLevel(price=112.0)\n    ],\n    timestamp=datetime.now()\n)\n\n# Automatic risk calculations (based on first target)\nprint(f\"Risk Amount: ${signal.risk_amount}\")      # $3.00 (100 - 97)\nprint(f\"Reward Amount: ${signal.reward_amount}\")  # $6.00 (106 - 100, first target)\nprint(f\"R/R Ratio: {signal.risk_reward_ratio}\")   # 2.0 (6 / 3)\n\n# Original stop preserved for tracking\nprint(f\"Original Stop: ${signal.original_stop}\")  # $97.0\n</code></pre>"},{"location":"user-guide/signal-metadata/#stop-loss-management","title":"Stop Loss Management","text":""},{"location":"user-guide/signal-metadata/#adjusting-stop-loss","title":"Adjusting Stop Loss","text":"<pre><code># Trail stop loss (with change tracking)\nsignal.update_stop(98.0, \"trailing_stop\")\n\nprint(f\"New Stop: ${signal.stop_price}\")           # $98.0\nprint(f\"Updated Risk: ${signal.risk_amount}\")      # $2.0 (100 - 98)\nprint(f\"New R/R: {signal.risk_reward_ratio}\")      # 3.0 (6 / 2)\n\n# Check change history\nchange = signal.change_history[0]\nprint(f\"Change: {change.field_name} from ${change.from_value} to ${change.to_value}\")\nprint(f\"Reason: {change.reason}\")\nprint(f\"Time: {change.timestamp}\")\n</code></pre>"},{"location":"user-guide/signal-metadata/#smart-trailing","title":"Smart Trailing","text":"<p>The <code>trail_stop()</code> method only allows favorable moves:</p> <pre><code># For long signals, only trails stop UP\nresult = signal.trail_stop(99.0)  # Move stop from 98 to 99\nprint(f\"Trailed successfully: {result}\")  # True\n\nresult = signal.trail_stop(96.0)  # Try to move stop DOWN\nprint(f\"Trailed successfully: {result}\")  # False (rejected)\nprint(f\"Stop unchanged: ${signal.stop_price}\")  # Still $99.0\n\n# For short signals, only trails stop DOWN\nshort_signal.trail_stop(95.0)  # Move stop from 99.50 to 95.0 \u2713\nshort_signal.trail_stop(101.0) # Try to move stop UP \u2717 (rejected)\n</code></pre>"},{"location":"user-guide/signal-metadata/#multiple-target-tracking","title":"Multiple Target Tracking","text":""},{"location":"user-guide/signal-metadata/#target-hit-management","title":"Target Hit Management","text":"<p>Track when each target level is reached:</p> <pre><code># Check target status\nfor i, target in enumerate(signal.target_prices):\n    print(f\"Target {i+1}: ${target.price} - Hit: {target.hit}\")\n\n# Mark first target as hit (typically done by brokerage integration)\nsignal.target_prices[0].hit = True\nsignal.target_prices[0].hit_timestamp = datetime.now()\nsignal.target_prices[0].id = \"BROKER_FILL_12345\"  # Broker's fill ID for tracking\n\n# Scale out or adjust stops based on targets hit\nhit_count = sum(1 for t in signal.target_prices if t.hit)\nprint(f\"Targets hit: {hit_count}/{len(signal.target_prices)}\")\n\n# Adjust stop to breakeven after first target\nif signal.target_prices[0].hit:\n    signal.trail_stop(signal.entry_price, \"breakeven_after_target_1\")\n</code></pre>"},{"location":"user-guide/signal-metadata/#target-merge-threshold","title":"Target Merge Threshold","text":"<p>The <code>merge_threshold_pct</code> parameter in <code>TargetConfig</code> controls how closely-spaced target levels are consolidated. This feature helps reduce target clutter while preserving TheStrat's core principles.</p> <p>Key Behavior: - First target (T1) is never merged - always represents nearest resistance/support - Last target (TN) is never merged - always represents the structure bound - Middle targets can be merged if within the threshold percentage - Merge only applies when 3+ targets exist (need middle targets to merge)</p> <p>Example Configuration: <pre><code>from thestrat.schemas import TargetConfig\n\ntarget_config = TargetConfig(\n    upper_bound=\"higher_high\",\n    lower_bound=\"lower_low\",\n    merge_threshold_pct=0.01,  # Merge middle targets within 1%\n    max_targets=None\n)\n</code></pre></p> <p>Real-World Example (MSFT):</p> <p>Setup: Long signal at $336.11, potential targets at $340.12, $342.08, $351.47</p> <pre><code># Without merging (merge_threshold_pct=0.0)\ntargets = [340.12, 342.08, 351.47]  # All 3 targets preserved\n\n# With 1% merging (merge_threshold_pct=0.01)\n# $340.12 and $342.08 are ~0.57% apart (within 1% threshold)\ntargets = [340.12, 342.08, 351.47]  # Still 3 targets\n# First (340.12) and last (351.47) never merge\n# Middle target (342.08) preserved since it's distinct from both\n\n# With 5% merging (merge_threshold_pct=0.05)\n# $340.12 to $342.08 = 0.57% (would merge if middle)\n# But first/last never merge, so middle targets between them might consolidate\ntargets = [340.12, 351.47]  # First and last preserved\n</code></pre> <p>Why This Matters:</p> <p>In TheStrat, T1 represents the immediate resistance/support being broken, and TN represents the structure bound. These are fundamental to the pattern and should never be merged regardless of proximity. Only intermediate targets can be consolidated for cleaner risk management.</p> <p>Best Practices: - Use <code>0.01</code> (1%) for tight clustering control - Use <code>0.02</code> (2%) for moderate consolidation - Use <code>0.05</code> (5%) for aggressive reduction - Set <code>0.0</code> to disable merging entirely</p>"},{"location":"user-guide/signal-metadata/#database-integration","title":"Database Integration","text":""},{"location":"user-guide/signal-metadata/#dataframe-schema","title":"DataFrame Schema","text":"<p>TheStrat indicators output signal data as DataFrame columns with eager evaluation - targets are calculated during <code>process()</code> and immediately available in the DataFrame:</p> <pre><code>from thestrat import Factory, FactoryConfig, AggregationConfig, IndicatorsConfig\nfrom thestrat.schemas import TimeframeItemConfig, SwingPointsConfig, TargetConfig\n\n# Process data through TheStrat with target configuration\nconfig = FactoryConfig(\n    aggregation=AggregationConfig(target_timeframes=[\"5min\"], asset_class=\"equities\"),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"5min\"],\n                swing_points=SwingPointsConfig(window=5, threshold=2.0),\n                target_config=TargetConfig(\n                    upper_bound=\"higher_high\",  # For long signals\n                    lower_bound=\"lower_low\",    # For short signals\n                    max_targets=3\n                )\n            )\n        ]\n    )\n)\n\npipeline = Factory.create_all(config)\naggregated = pipeline[\"aggregation\"].process(raw_data)\nanalyzed = pipeline[\"indicators\"].process(aggregated)  # Targets calculated here (eager)\n\n# Signal data is available in DataFrame columns\nsignals_df = analyzed.filter(analyzed[\"signal\"].is_not_null())\n\n# Key columns for database storage:\n# - signal: Pattern string (e.g., \"2D-2U\")\n# - type: Signal category (\"reversal\" or \"continuation\")\n# - bias: Direction (\"long\" or \"short\")\n# - target_prices: Native List[Float64] (e.g., [155.0, 158.0, 160.0]) - NOT JSON strings\n# - target_count: Integer count of targets\n\nprint(signals_df.select([\"timestamp\", \"symbol\", \"signal\", \"type\", \"bias\", \"target_prices\", \"target_count\"]))\n</code></pre>"},{"location":"user-guide/signal-metadata/#database-storage-example","title":"Database Storage Example","text":"<p>PostgreSQL (Recommended - supports native ARRAY type):</p> <pre><code>import psycopg2\nimport polars as pl\n\n# Create database table with native ARRAY type\nconn = psycopg2.connect(\"dbname=trading user=trader\")\ncursor = conn.cursor()\n\ncursor.execute(\"\"\"\n    CREATE TABLE IF NOT EXISTS signals (\n        timestamp TIMESTAMP,\n        symbol TEXT,\n        timeframe TEXT,\n        signal TEXT,\n        type TEXT,\n        bias TEXT,\n        target_prices FLOAT[],  -- Native PostgreSQL array type\n        target_count INTEGER,\n        PRIMARY KEY (timestamp, symbol, timeframe)\n    )\n\"\"\")\n\n# Insert signals from DataFrame\nsignals_df = analyzed.filter(pl.col(\"signal\").is_not_null())\n\nfor row in signals_df.iter_rows(named=True):\n    cursor.execute(\"\"\"\n        INSERT INTO signals\n        VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n        ON CONFLICT (timestamp, symbol, timeframe) DO UPDATE\n        SET target_prices = EXCLUDED.target_prices,\n            target_count = EXCLUDED.target_count\n    \"\"\", (\n        row[\"timestamp\"],\n        row[\"symbol\"],\n        row[\"timeframe\"],\n        row[\"signal\"],\n        row[\"type\"],\n        row[\"bias\"],\n        row[\"target_prices\"],  # Native list[float] - no conversion needed\n        row[\"target_count\"]\n    ))\n\nconn.commit()\nconn.close()\n</code></pre> <p>SQLite (requires JSON conversion):</p> <pre><code>import sqlite3\nimport polars as pl\nimport json\n\n# Create database table\nconn = sqlite3.connect(\"trading.db\")\ncursor = conn.cursor()\n\ncursor.execute(\"\"\"\n    CREATE TABLE IF NOT EXISTS signals (\n        timestamp TIMESTAMP,\n        symbol TEXT,\n        timeframe TEXT,\n        signal TEXT,\n        type TEXT,\n        bias TEXT,\n        target_prices TEXT,  -- JSON string (SQLite doesn't have array type)\n        target_count INTEGER,\n        PRIMARY KEY (timestamp, symbol, timeframe)\n    )\n\"\"\")\n\n# Insert signals from DataFrame\nsignals_df = analyzed.filter(pl.col(\"signal\").is_not_null())\n\nfor row in signals_df.iter_rows(named=True):\n    # Convert list to JSON string for SQLite\n    target_prices_json = json.dumps(row[\"target_prices\"]) if row[\"target_prices\"] else None\n\n    cursor.execute(\"\"\"\n        INSERT OR REPLACE INTO signals\n        VALUES (?, ?, ?, ?, ?, ?, ?, ?)\n    \"\"\", (\n        row[\"timestamp\"].isoformat(),\n        row[\"symbol\"],\n        row[\"timeframe\"],\n        row[\"signal\"],\n        row[\"type\"],\n        row[\"bias\"],\n        target_prices_json,\n        row[\"target_count\"]\n    ))\n\nconn.commit()\nconn.close()\n</code></pre>"},{"location":"user-guide/signal-metadata/#querying-signal-data","title":"Querying Signal Data","text":"<p>PostgreSQL:</p> <pre><code># Query signals with SQL (PostgreSQL native array support)\ncursor.execute(\"\"\"\n    SELECT timestamp, symbol, signal, bias, target_prices, target_count\n    FROM signals\n    WHERE signal = '2D-2U' AND date(timestamp) = '2024-01-15'\n\"\"\")\n\nfor row in cursor.fetchall():\n    timestamp, symbol, signal, bias, target_prices, target_count = row\n    print(f\"{timestamp}: {signal} on {symbol}\")\n    print(f\"  Bias: {bias}\")\n    print(f\"  Targets: {target_prices}\")  # [155.0, 158.0, 160.0] (native list)\n    print(f\"  Count: {target_count}\")\n</code></pre> <p>SQLite:</p> <pre><code>import json\n\n# Query signals with SQL (SQLite JSON conversion needed)\ncursor.execute(\"\"\"\n    SELECT timestamp, symbol, signal, bias, target_prices, target_count\n    FROM signals\n    WHERE signal = '2D-2U' AND date(timestamp) = '2024-01-15'\n\"\"\")\n\nfor row in cursor.fetchall():\n    timestamp, symbol, signal, bias, target_prices_json, target_count = row\n    target_prices = json.loads(target_prices_json) if target_prices_json else []\n\n    print(f\"{timestamp}: {signal} on {symbol}\")\n    print(f\"  Bias: {bias}\")\n    print(f\"  Targets: {target_prices}\")  # [155.0, 158.0, 160.0] (after JSON parse)\n    print(f\"  Count: {target_count}\")\n</code></pre>"},{"location":"user-guide/signal-metadata/#signal-status-management","title":"Signal Status Management","text":"<pre><code>from thestrat.signals import SignalStatus\n\n# Signal lifecycle\nsignal.status = SignalStatus.PENDING     # Initial state\nsignal.status = SignalStatus.ACTIVE      # Entry triggered\nsignal.status = SignalStatus.TARGET_HIT  # Target reached\nsignal.status = SignalStatus.STOPPED     # Stop loss hit\nsignal.status = SignalStatus.EXPIRED     # Signal expired\nsignal.status = SignalStatus.CANCELLED   # Manually cancelled\n\n# Track execution times\nsignal.triggered_at = datetime.now()  # When entry was filled\nsignal.closed_at = datetime.now()     # When position was closed\nsignal.close_reason = \"target_hit\"    # Why position closed\n\n# Performance tracking (update as position runs)\nsignal.entry_filled_price = 245.80    # Actual fill price\nsignal.exit_price = 251.90           # Actual exit price\nsignal.pnl = 6.10                    # Realized P&amp;L\nsignal.max_favorable_excursion = 7.25 # Best unrealized gain\nsignal.max_adverse_excursion = -1.15  # Worst unrealized loss\n</code></pre>"},{"location":"user-guide/signal-metadata/#complete-metadata-fields","title":"Complete Metadata Fields","text":"<p>The <code>SignalMetadata</code> object contains 25+ fields organized by category:</p> <p>Core Signal Data: - <code>pattern</code>, <code>category</code>, <code>bias</code>, <code>bar_count</code></p> <p>Price Levels: - <code>entry_price</code>, <code>stop_price</code> - <code>target_prices</code> (list of <code>TargetLevel</code> objects) - <code>original_stop</code></p> <p>Risk Management: - <code>risk_amount</code>, <code>reward_amount</code>, <code>risk_reward_ratio</code></p> <p>State &amp; Lifecycle: - <code>signal_id</code>, <code>status</code>, <code>timestamp</code> - <code>triggered_at</code>, <code>closed_at</code>, <code>close_reason</code></p> <p>Change Tracking: - <code>change_history</code> (list of <code>PriceChange</code> objects)</p> <p>Context: - <code>symbol</code>, <code>timeframe</code></p> <p>Performance: - <code>entry_filled_price</code>, <code>exit_price</code>, <code>pnl</code> - <code>max_favorable_excursion</code>, <code>max_adverse_excursion</code></p> <p>Target Tracking (via <code>TargetLevel</code> objects): - <code>price</code>, <code>hit</code>, <code>hit_timestamp</code>, <code>id</code> (broker fill ID)</p>"},{"location":"user-guide/signal-metadata/#real-world-trading-example","title":"Real-World Trading Example","text":"<p>Here's a complete example showing how to detect patterns and create SignalMetadata objects for trade entry:</p> <pre><code>from thestrat import Factory, FactoryConfig, AggregationConfig, IndicatorsConfig\nfrom thestrat.schemas import TimeframeItemConfig, SwingPointsConfig, TargetConfig\nfrom thestrat.indicators import Indicators\nfrom polars import col\nimport polars as pl\n\ndef monitor_signals_for_trading(raw_data):\n    \"\"\"\n    Complete workflow: data processing \u2192 signal detection \u2192 trade preparation\n    \"\"\"\n    # 1. Configure TheStrat components with target detection\n    config = FactoryConfig(\n        aggregation=AggregationConfig(\n            target_timeframes=[\"5min\", \"1h\"],\n            asset_class=\"equities\"\n        ),\n        indicators=IndicatorsConfig(\n            timeframe_configs=[\n                TimeframeItemConfig(\n                    timeframes=[\"5min\"],\n                    swing_points=SwingPointsConfig(window=5, threshold=2.0),\n                    target_config=TargetConfig(\n                        upper_bound=\"higher_high\",\n                        lower_bound=\"lower_low\",\n                        max_targets=3\n                    )\n                ),\n                TimeframeItemConfig(\n                    timeframes=[\"1h\"],\n                    swing_points=SwingPointsConfig(window=5, threshold=2.0),\n                    target_config=TargetConfig(\n                        upper_bound=\"higher_high\",\n                        lower_bound=\"lower_low\",\n                        max_targets=3\n                    )\n                )\n            ]\n        )\n    )\n\n    # 2. Create processing pipeline\n    components = Factory.create_all(config)\n\n    # 3. Process raw OHLCV data (targets calculated eagerly during process())\n    aggregated_data = components[\"aggregation\"].process(raw_data)\n    analyzed_data = components[\"indicators\"].process(aggregated_data)\n\n    # 4. Filter for current signals (last few bars only)\n    # Note: target_prices and target_count are already populated in DataFrame\n    current_signals = analyzed_data.filter(\n        col(\"signal\").is_not_null() &amp;\n        (col(\"timestamp\") &gt;= analyzed_data[\"timestamp\"].max() - pl.duration(hours=2))\n    )\n\n    if len(current_signals) == 0:\n        print(\"No signals detected in recent data\")\n        return []\n\n    # 5. Evaluate each signal for trade entry\n    trade_candidates = []\n\n    for i in range(len(current_signals)):\n        # Get single-row DataFrame for this signal\n        signal_row_df = current_signals.slice(i, 1)\n\n        # Create SignalMetadata object from single row\n        signal = Indicators.get_signal_object(signal_row_df)\n        print(f\"\\n\ud83c\udfaf Signal Detected: {signal.pattern}\")\n        print(f\"   Symbol: {signal.symbol}\")\n        print(f\"   Timeframe: {signal.timeframe}\")\n        print(f\"   Bias: {signal.bias.value.upper()}\")\n        print(f\"   Category: {signal.category.value}\")\n\n        # Price levels for order placement\n        print(f\"\\n\ud83d\udcb0 Trading Levels:\")\n        print(f\"   Entry: ${signal.entry_price:.2f}\")\n        print(f\"   Stop:  ${signal.stop_price:.2f}\")\n\n        if signal.target_prices:\n            target_list = [f\"${t.price:.2f}\" for t in signal.target_prices]\n            print(f\"   Targets: {', '.join(target_list)}\")\n            print(f\"   Risk/Reward (first target): {signal.risk_reward_ratio:.2f}:1\")\n        else:\n            print(f\"   Targets: None (continuation signal)\")\n\n        # Risk management\n        risk_dollars = signal.risk_amount\n        print(f\"\\n\ud83d\udcca Risk Management:\")\n        print(f\"   Risk per share: ${risk_dollars:.2f}\")\n\n        # Position sizing (example: risk $100 per trade)\n        max_risk = 100.0\n        position_size = int(max_risk / risk_dollars)\n        print(f\"   Suggested position size: {position_size} shares\")\n        print(f\"   Total capital at risk: ${position_size * risk_dollars:.2f}\")\n\n        # Entry criteria check\n        entry_criteria = {\n            \"reasonable_risk_reward\": signal.risk_reward_ratio is None or signal.risk_reward_ratio &gt;= 1.5,\n            \"reasonable_risk_amount\": risk_dollars &lt;= 5.0,  # Max $5 risk per share\n            \"recent_signal\": True,  # Already filtered above\n            \"clear_levels\": abs(signal.entry_price - signal.stop_price) &gt; 0.01\n        }\n\n        all_criteria_met = all(entry_criteria.values())\n\n        print(f\"\\n\u2705 Entry Criteria:\")\n        for criterion, met in entry_criteria.items():\n            status = \"\u2713\" if met else \"\u2717\"\n            print(f\"   {status} {criterion.replace('_', ' ').title()}\")\n\n        if all_criteria_met:\n            trade_candidates.append({\n                \"signal\": signal,\n                \"action\": \"BUY\" if signal.bias.value == \"long\" else \"SELL\",\n                \"quantity\": position_size,\n                \"entry_price\": signal.entry_price,\n                \"stop_loss\": signal.stop_price,\n                \"targets\": [t.price for t in signal.target_prices],  # Multiple targets\n                \"risk_amount\": position_size * risk_dollars\n            })\n            print(f\"\\n\ud83d\ude80 TRADE READY: {signal.pattern} on {signal.symbol}\")\n        else:\n            print(f\"\\n\u23f8\ufe0f  Criteria not met - monitoring only\")\n\n    return trade_candidates\n\ndef execute_trades(trade_candidates):\n    \"\"\"\n    Execute trades using your broker API\n    \"\"\"\n    for trade in trade_candidates:\n        signal = trade[\"signal\"]\n\n        # Example order placement with multiple targets (adapt to your broker's API)\n        order_params = {\n            \"symbol\": signal.symbol,\n            \"side\": trade[\"action\"],\n            \"quantity\": trade[\"quantity\"],\n            \"type\": \"LIMIT\",\n            \"price\": trade[\"entry_price\"],\n            \"stop_loss\": trade[\"stop_loss\"],\n            \"targets\": trade[\"targets\"]  # List of target prices\n        }\n\n        print(f\"Placing order: {order_params}\")\n        # broker_api.place_bracket_order(**order_params)\n\n        # Store signal data for tracking (use DataFrame columns)\n        # database.store_active_signal(signal)\n\n# Usage example\nif __name__ == \"__main__\":\n    # Your raw market data (timestamp, open, high, low, close, volume, symbol)\n    raw_market_data = get_latest_market_data()  # Your data source\n\n    # Monitor for signals and get trade-ready candidates\n    candidates = monitor_signals_for_trading(raw_market_data)\n\n    if candidates:\n        print(f\"\\n\ud83c\udfaf Found {len(candidates)} trade candidates\")\n\n        # Execute trades (uncomment when ready)\n        # execute_trades(candidates)\n    else:\n        print(\"\\n\u23f3 No trade candidates found - continue monitoring\")\n</code></pre>"},{"location":"user-guide/signal-metadata/#key-benefits-of-this-approach","title":"Key Benefits of This Approach","text":"<p>Eager Evaluation: - Targets calculated during <code>process()</code> and immediately available in DataFrame - Database-ready output without additional method calls - Target prices and counts visible for troubleshooting and analysis</p> <p>Complete Trading Context: - Entry, stop, and multiple target prices calculated from actual market structure - Risk/reward ratios and position sizing based on real price levels - Target hit tracking with broker fill IDs for position scaling strategies</p> <p>Database Integration: - Native List[Float64] type for seamless PostgreSQL ARRAY storage - Store signal data as DataFrame columns for easy querying - Update stop levels as trades evolve - Maintain audit trail of all stop modifications</p> <p>Performance Optimized: - Fast vectorized detection identifies patterns quickly - <code>get_signal_object()</code> creates rich metadata objects from single-row queries - Native type conversion eliminates JSON parsing overhead</p>"},{"location":"user-guide/signal-metadata/#related-documentation","title":"Related Documentation","text":"<ul> <li>Pattern Terminology and Visual Guide - Definitions, diagrams, and price level rules</li> <li>DataFrame Schema - Output column specifications</li> <li>Asset Classes - Timezone and session configuration</li> <li>Examples - Real-world usage examples</li> </ul>"}]}