{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"TheStrat Documentation","text":"<p>A Python module for financial data aggregation and technical analysis using #TheStrat methodology.</p>"},{"location":"#overview","title":"Overview","text":"<p>TheStrat provides a comprehensive framework for implementing the #TheStrat trading methodology in Python. It offers high-performance timeframe aggregation, complete technical indicators, and robust support for multiple asset classes.</p>"},{"location":"#key-features","title":"Key Features","text":"<p> Multi-Timeframe Aggregation</p> <p>OHLCV data aggregation across multiple timeframes simultaneously with timezone handling</p> <p> #TheStrat Indicators</p> <p>Complete implementation of TheStrat technical indicators with per-timeframe configurations</p> <p> Multi-Asset Support</p> <p>Crypto, Equities, and FX with appropriate market hours and timezone handling</p> <p> Factory Pattern</p> <p>Clean component creation and configuration management</p> <p> High Performance</p> <p>Vectorized operations using Polars and Pandas for optimal speed</p> <p> Comprehensive Testing</p> <p>High test coverage with 190+ tests ensuring reliability</p>"},{"location":"#quick-example","title":"Quick Example","text":"Basic TheStrat Usage with Pydantic Models<pre><code>from thestrat import Factory\nfrom thestrat.schemas import (\n    FactoryConfig, AggregationConfig, IndicatorsConfig,\n    TimeframeItemConfig, SwingPointsConfig\n)\n\n# Configure your pipeline with Pydantic models\nconfig = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"5m\", \"15m\"],  # Multiple timeframes supported\n        asset_class=\"equities\",\n        timezone=\"US/Eastern\"\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"5m\"],\n                swing_points=SwingPointsConfig(window=3, threshold=1.5)  # Short-term settings\n            ),\n            TimeframeItemConfig(\n                timeframes=[\"15m\"],\n                swing_points=SwingPointsConfig(window=7, threshold=2.5)  # Long-term settings\n            )\n        ]\n    )\n)\n\n# Create and use components\npipeline = Factory.create_all(config)\naggregated = pipeline[\"aggregation\"].process(market_data)\nanalyzed = pipeline[\"indicators\"].process(aggregated)\n\nprint(f\"Processed {len(analyzed)} bars with TheStrat indicators\")\nprint(f\"Timeframes: {analyzed['timeframe'].unique()}\")\n</code></pre>"},{"location":"#core-components","title":"Core Components","text":"Component Purpose Features Aggregation OHLCV timeframe aggregation Timezone handling, simultaneous multi-timeframe processing Indicators TheStrat technical indicators Inside/Outside bars, Swing points, per-timeframe configurations Factory Component creation Validation, configuration management Schemas Configuration models Pydantic validation, comprehensive documentation"},{"location":"#supported-markets","title":"Supported Markets","text":"CryptoEquitiesForex <ul> <li>24/7 trading</li> <li>UTC timezone enforcement</li> <li>Continuous aggregation</li> </ul> <ul> <li>Market hours (9:30-16:00 ET)</li> <li>Configurable timezones</li> <li>Pre/post market handling</li> </ul> <ul> <li>24/5 trading (Sun 5pm - Fri 5pm ET)</li> <li>UTC timezone enforcement</li> <li>Weekend gap handling</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<p>Ready to implement #TheStrat in your trading system?</p> <p>Get Started with Installation View API Reference</p>"},{"location":"#project-status","title":"Project Status","text":"<p>This project is under active development with comprehensive test coverage and strict code quality standards.</p>"},{"location":"developer-guide/","title":"Developer Guide","text":"<p>Welcome to the TheStrat developer guide. This section provides comprehensive information for contributors and developers working with the TheStrat codebase.</p>"},{"location":"developer-guide/#for-maintainers","title":"For Maintainers","text":"<p>This project is currently private. Contact the author for access and contribution guidelines.</p>"},{"location":"developer-guide/#architecture-overview","title":"Architecture Overview","text":"<p>TheStrat follows a modular design with clear separation of concerns:</p>"},{"location":"developer-guide/#core-components","title":"Core Components","text":"<ul> <li>Factory - Component creation and configuration management</li> <li>Aggregation - OHLCV timeframe data processing</li> <li>Indicators - TheStrat technical analysis implementation</li> <li>Schemas - Configuration models and validation</li> </ul>"},{"location":"developer-guide/#design-patterns","title":"Design Patterns","text":"<ul> <li>Factory Pattern - Centralized component creation with validation</li> <li>Abstract Base Classes - Consistent interfaces across components</li> <li>Configuration-Driven - Flexible behavior through configuration objects</li> <li>Functional Programming - Immutable data transformations where possible</li> </ul>"},{"location":"developer-guide/#quick-development-setup","title":"Quick Development Setup","text":"<pre><code># Clone repository\ngit clone https://github.com/jlixfeld/thestrat.git\ncd thestrat\n\n# Install all development dependencies\nuv sync --extra test --extra dev --extra docs\n\n# Verify installation\nuv run pytest\nuv run ruff check .\nuv run mkdocs serve\n</code></pre>"},{"location":"developer-guide/#guide-sections","title":"Guide Sections","text":""},{"location":"developer-guide/#contributing","title":"Contributing","text":"<p>Guidelines for making contributions, code style, and pull request process.</p>"},{"location":"developer-guide/#development-workflow","title":"Development Workflow","text":"<ol> <li>Setup - Install dependencies and verify environment</li> <li>Development - Write code following project conventions</li> <li>Testing - Ensure comprehensive test coverage</li> <li>Documentation - Update docs for any API changes</li> <li>Quality - Run linting and formatting tools</li> <li>Review - Submit changes for review</li> </ol>"},{"location":"developer-guide/#code-quality-standards","title":"Code Quality Standards","text":"<ul> <li>Test Coverage: Maintain &gt;95% coverage</li> <li>Code Formatting: Automated with Ruff</li> <li>Type Hints: Required for all public APIs</li> <li>Documentation: Comprehensive docstrings</li> <li>Performance: Benchmarked critical paths</li> </ul>"},{"location":"developer-guide/#technology-stack","title":"Technology Stack","text":"<ul> <li>Python 3.11+ - Modern Python features</li> <li>Polars - High-performance data processing</li> <li>Pandas - Legacy support and interoperability</li> <li>Pytest - Testing framework</li> <li>Ruff - Linting and formatting</li> <li>MkDocs Material - Documentation</li> </ul>"},{"location":"developer-guide/#getting-help","title":"Getting Help","text":"<p>For development questions:</p> <ol> <li>Check existing documentation</li> <li>Review test cases for examples</li> <li>Contact the maintainer directly</li> </ol>"},{"location":"developer-guide/#project-status","title":"Project Status","text":"<p>Version: 1.0.1 - Production/Stable Maintenance: Active development License: Private - All rights reserved</p>"},{"location":"developer-guide/contributing/","title":"Contributing","text":"<p>Thank you for your interest in contributing to TheStrat! This guide outlines the process for making contributions to this private project.</p>"},{"location":"developer-guide/contributing/#getting-access","title":"Getting Access","text":"<p>This is a private module. Contact the author at <code>nominal_choroid0y@icloud.com</code> for:</p> <ul> <li>Access to the repository</li> <li>Contribution guidelines</li> <li>Development discussions</li> <li>Feature requests</li> </ul>"},{"location":"developer-guide/contributing/#development-setup","title":"Development Setup","text":"<p>Once you have access, set up your development environment:</p>"},{"location":"developer-guide/contributing/#1-clone-and-install","title":"1. Clone and Install","text":"<pre><code>git clone https://github.com/jlixfeld/thestrat.git\ncd thestrat\n\n# Install with all extras\nuv sync --extra test --extra dev --extra docs\n</code></pre>"},{"location":"developer-guide/contributing/#2-verify-setup","title":"2. Verify Setup","text":"<pre><code># Run tests\nuv run pytest\n\n# Check formatting\nuv run ruff format --check .\n\n# Check linting\nuv run ruff check .\n\n# Test documentation build\nuv run mkdocs serve\n</code></pre>"},{"location":"developer-guide/contributing/#3-run-quality-checks","title":"3. Run Quality Checks","text":"<pre><code># Check code quality\nuv run ruff check .\nuv run ruff format --check .\n</code></pre>"},{"location":"developer-guide/contributing/#code-standards","title":"Code Standards","text":""},{"location":"developer-guide/contributing/#code-style","title":"Code Style","text":"<p>We use Ruff for both linting and formatting:</p> <pre><code># Format code\nuv run ruff format .\n\n# Check linting\nuv run ruff check .\n\n# Auto-fix issues\nuv run ruff check --fix .\n</code></pre> <p>Configuration (already in <code>pyproject.toml</code>): - Line length: 120 characters - Quote style: Double quotes - Python target: 3.11+</p>"},{"location":"developer-guide/contributing/#type-hints","title":"Type Hints","text":"<p>All public APIs must include type hints:</p> <pre><code># Good\ndef process_data(data: PandasDataFrame, config: dict) -&gt; PandasDataFrame:\n    \"\"\"Process market data with configuration.\"\"\"\n    return data\n\n# Bad\ndef process_data(data, config):\n    return data\n</code></pre>"},{"location":"developer-guide/contributing/#documentation","title":"Documentation","text":"<p>Docstring Style: Use Google-style docstrings:</p> <pre><code>def aggregate_timeframe(data: PandasDataFrame, timeframe: str) -&gt; PandasDataFrame:\n    \"\"\"Aggregate OHLCV data to specified timeframe.\n\n    Args:\n        data: Input OHLCV DataFrame with required columns\n        timeframe: Target timeframe (e.g., '5m', '1h', '1d')\n\n    Returns:\n        Aggregated DataFrame with same schema as input\n\n    Raises:\n        ValueError: If required columns are missing\n\n    Example:\n        &gt;&gt;&gt; data = PandasDataFrame(...)\n        &gt;&gt;&gt; result = aggregate_timeframe(data, '5m')\n        &gt;&gt;&gt; len(result) &lt; len(data)  # Fewer bars after aggregation\n        True\n    \"\"\"\n</code></pre> <p>API Documentation: All public methods need comprehensive docstrings that will be included in the generated API documentation.</p>"},{"location":"developer-guide/contributing/#testing-requirements","title":"Testing Requirements","text":""},{"location":"developer-guide/contributing/#test-coverage","title":"Test Coverage","text":"<p>Maintain &gt;95% test coverage:</p> <pre><code># Run with coverage\nuv run pytest --cov=thestrat --cov-report=html\n\n# View coverage report\nopen htmlcov/index.html\n</code></pre>"},{"location":"developer-guide/contributing/#test-categories","title":"Test Categories","text":"<p>We use pytest markers to categorize tests:</p> <pre><code>import pytest\n\n@pytest.mark.unit\ndef test_aggregation_logic():\n    \"\"\"Unit test for aggregation logic.\"\"\"\n    pass\n\n@pytest.mark.integration\ndef test_full_pipeline():\n    \"\"\"Integration test for complete pipeline.\"\"\"\n    pass\n</code></pre> <p>Run specific categories:</p> <pre><code># Unit tests only\nuv run pytest -m unit\n\n# Integration tests only\nuv run pytest -m integration\n\n# All tests\nuv run pytest\n</code></pre>"},{"location":"developer-guide/contributing/#writing-tests","title":"Writing Tests","text":"<p>Test Structure: Follow the Arrange-Act-Assert pattern:</p> <pre><code>def test_timeframe_aggregation():\n    # Arrange\n    input_data = create_sample_ohlcv_data()\n    expected_bars = 20\n\n    # Act\n    result = aggregate_timeframe(input_data, '5m')\n\n    # Assert\n    assert len(result) == expected_bars\n    assert all(col in result.columns for col in REQUIRED_COLUMNS)\n</code></pre> <p>Test Data: Use fixtures for reusable test data:</p> <pre><code>@pytest.fixture\ndef sample_ohlcv():\n    \"\"\"Sample OHLCV data for testing.\"\"\"\n    return PandasDataFrame({\n        'timestamp': pd.date_range('2024-01-01', periods=100, freq='1min'),\n        'open': [100.0] * 100,\n        'high': [101.0] * 100,\n        'low': [99.0] * 100,\n        'close': [100.5] * 100,\n        'volume': [1000] * 100\n    })\n</code></pre>"},{"location":"developer-guide/contributing/#contribution-workflow","title":"Contribution Workflow","text":""},{"location":"developer-guide/contributing/#1-create-feature-branch","title":"1. Create Feature Branch","text":"<pre><code># From main branch\ngit checkout main\ngit pull origin main\n\n# Create feature branch\ngit checkout -b feature/your-feature-name\n</code></pre>"},{"location":"developer-guide/contributing/#2-make-changes","title":"2. Make Changes","text":"<ul> <li>Write code following our standards</li> <li>Add comprehensive tests</li> <li>Update documentation if needed</li> <li>Ensure all tests pass</li> </ul>"},{"location":"developer-guide/contributing/#3-quality-checks","title":"3. Quality Checks","text":"<p>Before committing, run full quality checks:</p> <pre><code># Format code\nuv run ruff format .\n\n# Check linting\nuv run ruff check .\n\n# Run full test suite\nuv run pytest --cov=thestrat\n\n# Test documentation\nuv run mkdocs build\n</code></pre>"},{"location":"developer-guide/contributing/#4-commit-changes","title":"4. Commit Changes","text":"<p>Use conventional commit messages:</p> <pre><code># Feature\ngit commit -m \"feat: add multi-timeframe aggregation support\"\n\n# Bug fix\ngit commit -m \"fix: handle missing volume data in aggregation\"\n\n# Documentation\ngit commit -m \"docs: add examples for forex analysis\"\n\n# Tests\ngit commit -m \"test: add integration tests for factory pattern\"\n</code></pre>"},{"location":"developer-guide/contributing/#5-push-and-create-pr","title":"5. Push and Create PR","text":"<pre><code>git push origin feature/your-feature-name\n</code></pre> <p>Then create a pull request with: - Clear description of changes - Link to any related issues - Test coverage report - Documentation updates</p>"},{"location":"developer-guide/contributing/#review-process","title":"Review Process","text":"<p>All contributions go through code review:</p> <ol> <li>Automated Checks: CI runs tests, linting, coverage</li> <li>Manual Review: Code quality, design, documentation</li> <li>Testing: Functionality and edge cases</li> <li>Documentation: API docs and user guides updated</li> </ol>"},{"location":"developer-guide/contributing/#areas-for-contribution","title":"Areas for Contribution","text":"<p>Current focus areas (contact maintainer for details):</p> <ul> <li>Performance Optimization: Polars-first implementations</li> <li>Additional Indicators: Extended TheStrat patterns</li> <li>Asset Class Support: New market types</li> <li>Testing: Edge cases and integration scenarios</li> <li>Documentation: More examples and tutorials</li> </ul>"},{"location":"developer-guide/contributing/#release-process","title":"Release Process","text":"<p>Releases follow semantic versioning:</p> <ul> <li>Patch (1.0.1): Bug fixes, documentation</li> <li>Minor (1.1.0): New features, backwards compatible</li> <li>Major (2.0.0): Breaking changes</li> </ul>"},{"location":"developer-guide/contributing/#getting-help","title":"Getting Help","text":"<p>For contribution questions:</p> <ol> <li>Documentation: Check existing docs and examples</li> <li>Issues: Search existing issues and discussions</li> <li>Contact: Email the maintainer directly</li> <li>Code Review: Learn from existing PR reviews</li> </ol>"},{"location":"developer-guide/contributing/#license","title":"License","text":"<p>All contributions are subject to the project's private license. By contributing, you agree that your contributions will be licensed under the same terms.</p> <p>Thank you for helping make TheStrat better!</p>"},{"location":"reference/","title":"API Reference","text":"<p>Complete API documentation for all TheStrat components.</p>"},{"location":"reference/#core-modules","title":"Core Modules","text":"Module Description aggregation OHLCV timeframe aggregation indicators TheStrat technical indicators signals Signal processing and metadata factory Component creation with factory pattern schemas Pydantic configuration schemas base Abstract base classes"},{"location":"reference/#quick-navigation","title":"Quick Navigation","text":"<ul> <li>Factory - Start here for component creation</li> <li>Schemas - Configuration models and validation</li> <li>Aggregation - Timeframe data processing</li> <li>Indicators - TheStrat analysis functions</li> <li>Base - Abstract base classes</li> </ul>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>thestrat<ul> <li>aggregation</li> <li>indicators</li> <li>signals</li> <li>factory</li> <li>schemas</li> <li>base</li> </ul> </li> </ul>"},{"location":"reference/thestrat/","title":"Thestrat","text":"<p>TheStrat package root</p>"},{"location":"reference/thestrat/#thestrat","title":"thestrat","text":"<p>TheStrat Python Module</p> <p>Standalone module for vectorized Strat technical analysis and OHLC timeframe aggregation. Supports historical and real-time market data processing across all asset classes.</p> <p>Modules:</p> Name Description <code>aggregation</code> <p>OHLC timeframe aggregation with precise time boundary control.</p> <code>base</code> <p>Base component classes for TheStrat module.</p> <code>factory</code> <p>Factory pattern for TheStrat component creation and configuration.</p> <code>indicators</code> <p>Vectorized Strat technical indicators implementation.</p> <code>schemas</code> <p>Pydantic schema models for TheStrat configuration validation.</p> <code>signals</code> <p>Signal metadata implementation for TheStrat trading system.</p> <p>Classes:</p> Name Description <code>Aggregation</code> <p>Convert OHLC data between timeframes with precise time boundary control.</p> <code>AggregationConfig</code> <p>Complete configuration for aggregation component with market-aware settings.</p> <code>Component</code> <p>Base class for all TheStrat components.</p> <code>Factory</code> <p>Factory class for creating TheStrat components.</p> <code>FactoryConfig</code> <p>Root configuration for Factory.create_all method with complete pipeline setup.</p> <code>GapDetectionConfig</code> <p>Configuration for gap detection with comprehensive threshold documentation.</p> <code>IndicatorSchema</code> <p>Complete Indicator Schema</p> <code>Indicators</code> <p>Vectorized implementation of all Strat technical indicators.</p> <code>IndicatorsConfig</code> <p>Complete configuration for indicators component with per-timeframe settings.</p> <code>PriceChange</code> <p>Track changes to stop/target prices.</p> <code>SignalBias</code> <p>Signal directional bias.</p> <code>SignalCategory</code> <p>Signal categorization types.</p> <code>SignalMetadata</code> <p>Complete signal metadata with change tracking and serialization.</p> <code>SignalStatus</code> <p>Signal lifecycle status.</p> <code>SwingPointsConfig</code> <p>Configuration for swing point detection with comprehensive parameter documentation.</p> <code>TimeframeItemConfig</code> <p>Configuration for a single timeframe item with flexible timeframe targeting.</p>"},{"location":"reference/thestrat/#thestrat.Aggregation","title":"Aggregation","text":"<pre><code>Aggregation(config: AggregationConfig)\n</code></pre> <p>               Bases: <code>Component</code></p> <p>Convert OHLC data between timeframes with precise time boundary control.</p> Features <ul> <li>Time Boundary Control: hour_boundary flag for hourly+ aggregation alignment</li> <li>Session Control: session_start parameter for sub-hourly alignment</li> <li>Asset Class Support: Crypto, equities, FX, futures with timezone handling</li> <li>Vectorized Processing: Pure Polars operations for maximum performance</li> </ul> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>AggregationConfig</code> <p>Validated AggregationConfig containing all configuration settings</p> required <p>Methods:</p> Name Description <code>normalize_timezone</code> <p>Convert naive timestamps to timezone-aware using timezone resolution priority.</p> <code>process</code> <p>Convert OHLC data to target timeframes with boundary alignment.</p> <code>validate_input</code> <p>Validate input data format.</p> Source code in <code>thestrat/aggregation.py</code> <pre><code>def __init__(self, config: AggregationConfig):\n    \"\"\"\n    Initialize aggregation component with validated configuration.\n\n    Args:\n        config: Validated AggregationConfig containing all configuration settings\n    \"\"\"\n    super().__init__()\n\n    # Store the validated Pydantic config\n    self.config = config\n\n    # Extract commonly used values for convenience\n    self.target_timeframes = config.target_timeframes.copy()\n    self.asset_class = config.asset_class\n\n    # These fields are guaranteed to be non-None after model validation\n    assert config.timezone is not None\n    assert config.session_start is not None\n    assert config.hour_boundary is not None\n\n    self.timezone = config.timezone\n    self.session_start = config.session_start\n    self.hour_boundary = config.hour_boundary\n\n    # Validate all timeframes\n    from .schemas import TimeframeConfig\n\n    for tf in self.target_timeframes:\n        if not TimeframeConfig.validate_timeframe(tf):\n            raise ValueError(\n                f\"Invalid timeframe '{tf}'. Supported timeframes: {sorted(TimeframeConfig.TIMEFRAME_METADATA.keys())}\"\n            )\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Aggregation.normalize_timezone","title":"normalize_timezone","text":"<pre><code>normalize_timezone(data: DataFrame) -&gt; DataFrame\n</code></pre> <p>Convert naive timestamps to timezone-aware using timezone resolution priority.</p> Source code in <code>thestrat/aggregation.py</code> <pre><code>def normalize_timezone(self, data: PolarsDataFrame) -&gt; PolarsDataFrame:\n    \"\"\"Convert naive timestamps to timezone-aware using timezone resolution priority.\"\"\"\n    df = data.clone()\n\n    # Check if timestamp is already timezone-aware\n    if df.schema[\"timestamp\"] == Datetime(\"us\", None):  # Naive timestamp\n        # Convert to timezone-aware\n        df = df.with_columns([col(\"timestamp\").dt.replace_time_zone(self.timezone).alias(\"timestamp\")])\n\n    return df\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Aggregation.process","title":"process","text":"<pre><code>process(data: DataFrame | DataFrame) -&gt; DataFrame\n</code></pre> <p>Convert OHLC data to target timeframes with boundary alignment. Supports both single-timeframe and multi-timeframe source data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | DataFrame</code> <p>Input DataFrame with OHLC data</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>Aggregated OHLC DataFrame with timeframe column</p> Source code in <code>thestrat/aggregation.py</code> <pre><code>def process(self, data: PolarsDataFrame | PandasDataFrame) -&gt; PolarsDataFrame:\n    \"\"\"\n    Convert OHLC data to target timeframes with boundary alignment.\n    Supports both single-timeframe and multi-timeframe source data.\n\n    Args:\n        data: Input DataFrame with OHLC data\n\n    Returns:\n        Aggregated OHLC DataFrame with timeframe column\n    \"\"\"\n    if not self.validate_input(data):\n        raise ValueError(\"Input data validation failed\")\n\n    df = self._convert_to_polars(data)\n    df = self.normalize_timezone(df)\n\n    # Auto-detect mode\n    is_multi_timeframe = \"timeframe\" in df.columns\n\n    if is_multi_timeframe:\n        return self._process_multi_timeframe_source(df)\n    else:\n        return self._process_single_timeframe_source(df)\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Aggregation.validate_input","title":"validate_input","text":"<pre><code>validate_input(data: DataFrame | DataFrame) -&gt; bool\n</code></pre> <p>Validate input data format.</p> Source code in <code>thestrat/aggregation.py</code> <pre><code>def validate_input(self, data: PolarsDataFrame | PandasDataFrame) -&gt; bool:\n    \"\"\"Validate input data format.\"\"\"\n    df = self._convert_to_polars(data)\n\n    # Check required columns using schema-driven approach\n    from .schemas import IndicatorSchema\n\n    required_cols = IndicatorSchema.get_required_input_columns()\n\n    # Remove timeframe if not in multi-timeframe mode\n    if \"timeframe\" not in df.columns and \"timeframe\" in required_cols:\n        required_cols = [col for col in required_cols if col != \"timeframe\"]\n\n    if not all(col in df.columns for col in required_cols):\n        return False\n\n    # Validate timeframes if in multi-timeframe mode\n    if \"timeframe\" in df.columns:\n        from .schemas import TimeframeConfig\n\n        unique_timeframes = df[\"timeframe\"].unique().to_list()\n        for tf in unique_timeframes:\n            if not TimeframeConfig.validate_timeframe(tf):\n                return False\n\n    # Check for minimum data points\n    if len(df) &lt; 2:\n        return False\n\n    return True\n</code></pre>"},{"location":"reference/thestrat/#thestrat.AggregationConfig","title":"AggregationConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Complete configuration for aggregation component with market-aware settings.</p> <p>Methods:</p> Name Description <code>apply_asset_class_defaults</code> <p>Apply AssetClassConfig defaults for timezone, hour_boundary, and session_start.</p> <code>validate_and_expand_target_timeframes</code> <p>Validate target_timeframes field and expand 'all' keyword.</p>"},{"location":"reference/thestrat/#thestrat.AggregationConfig.apply_asset_class_defaults","title":"apply_asset_class_defaults  <code>classmethod</code>","text":"<pre><code>apply_asset_class_defaults(data: Any) -&gt; Any\n</code></pre> <p>Apply AssetClassConfig defaults for timezone, hour_boundary, and session_start.</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@model_validator(mode=\"before\")\n@classmethod\ndef apply_asset_class_defaults(cls, data: Any) -&gt; Any:\n    \"\"\"Apply AssetClassConfig defaults for timezone, hour_boundary, and session_start.\"\"\"\n    if not isinstance(data, dict):\n        return data\n\n    # Get asset class, default to \"equities\"\n    asset_class = data.get(\"asset_class\", \"equities\")\n    asset_config = AssetClassConfig.get_config(asset_class)\n\n    # Force UTC timezone for crypto and fx regardless of input\n    if asset_class in [\"crypto\", \"fx\"]:\n        data[\"timezone\"] = \"UTC\"\n    elif \"timezone\" not in data or data[\"timezone\"] is None:\n        data[\"timezone\"] = asset_config.timezone\n\n    # Apply other defaults only if fields are not provided or are None\n    if \"hour_boundary\" not in data or data[\"hour_boundary\"] is None:\n        data[\"hour_boundary\"] = asset_config.hour_boundary\n    if \"session_start\" not in data or data[\"session_start\"] is None:\n        data[\"session_start\"] = asset_config.session_start\n\n    return data\n</code></pre>"},{"location":"reference/thestrat/#thestrat.AggregationConfig.validate_and_expand_target_timeframes","title":"validate_and_expand_target_timeframes  <code>classmethod</code>","text":"<pre><code>validate_and_expand_target_timeframes(\n    target_timeframes: list[str],\n) -&gt; list[str]\n</code></pre> <p>Validate target_timeframes field and expand 'all' keyword.</p> <p>This Pydantic field validator is automatically called when AggregationConfig is instantiated. It validates individual timeframes and expands ['all'] to all supported timeframes.</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@field_validator(\"target_timeframes\")\n@classmethod\ndef validate_and_expand_target_timeframes(cls, target_timeframes: list[str]) -&gt; list[str]:\n    \"\"\"\n    Validate target_timeframes field and expand 'all' keyword.\n\n    This Pydantic field validator is automatically called when AggregationConfig\n    is instantiated. It validates individual timeframes and expands ['all'] to\n    all supported timeframes.\n    \"\"\"\n    if not target_timeframes:\n        raise ValueError(\"target_timeframes cannot be empty\")\n\n    # Check for 'all' keyword\n    if \"all\" in target_timeframes:\n        if len(target_timeframes) &gt; 1:\n            raise ValueError(\"'all' cannot be combined with specific timeframes\")\n        # Expand to all supported timeframes\n        return list(TimeframeConfig.TIMEFRAME_METADATA.keys())\n\n    # Validate each specific timeframe\n    for i, timeframe in enumerate(target_timeframes):\n        if not isinstance(timeframe, str) or not timeframe.strip():\n            raise ValueError(f\"target_timeframes[{i}] must be a non-empty string\")\n\n        # Validate timeframe format using TimeframeConfig\n        if not TimeframeConfig.validate_timeframe(timeframe):\n            raise ValueError(f\"Invalid timeframe '{timeframe}'\")\n\n    return target_timeframes\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Component","title":"Component","text":"<pre><code>Component()\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Base class for all TheStrat components.</p> <p>Methods:</p> Name Description <code>process</code> <p>Process data and return Polars DataFrame results.</p> <code>validate_input</code> <p>Validate input data format.</p> Source code in <code>thestrat/base.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize base component with metadata tracking.\"\"\"\n    from datetime import datetime\n\n    self._created_at = datetime.now()\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Component.process","title":"process  <code>abstractmethod</code>","text":"<pre><code>process(data: DataFrame | DataFrame) -&gt; DataFrame\n</code></pre> <p>Process data and return Polars DataFrame results.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | DataFrame</code> <p>Input DataFrame (Polars or Pandas)</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>Processed PolarsDataFrame with results</p> Source code in <code>thestrat/base.py</code> <pre><code>@abstractmethod\ndef process(self, data: PolarsDataFrame | PandasDataFrame) -&gt; PolarsDataFrame:\n    \"\"\"\n    Process data and return Polars DataFrame results.\n\n    Args:\n        data: Input DataFrame (Polars or Pandas)\n\n    Returns:\n        Processed PolarsDataFrame with results\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Component.validate_input","title":"validate_input  <code>abstractmethod</code>","text":"<pre><code>validate_input(data: DataFrame | DataFrame) -&gt; None\n</code></pre> <p>Validate input data format.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | DataFrame</code> <p>Input DataFrame to validate</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If data format is invalid, with specific error message</p> Source code in <code>thestrat/base.py</code> <pre><code>@abstractmethod\ndef validate_input(self, data: PolarsDataFrame | PandasDataFrame) -&gt; None:\n    \"\"\"\n    Validate input data format.\n\n    Args:\n        data: Input DataFrame to validate\n\n    Raises:\n        ValueError: If data format is invalid, with specific error message\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Factory","title":"Factory","text":"<p>Factory class for creating TheStrat components.</p> <p>Provides static methods for creating individual components and class methods for creating complete processing pipelines. All methods accept validated Pydantic configuration models.</p> <p>Methods:</p> Name Description <code>create_aggregation</code> <p>Create aggregation component from validated configuration.</p> <code>create_all</code> <p>Create complete processing pipeline with aggregation and indicators.</p> <code>create_indicators</code> <p>Create indicators component from validated configuration.</p> <code>get_asset_class_config</code> <p>Get default configuration for specific asset class.</p> <code>get_supported_asset_classes</code> <p>Get list of supported asset classes.</p> <code>get_supported_timeframes</code> <p>Get list of all supported timeframes in chronological order.</p> <code>get_timeframe_metadata</code> <p>Get detailed metadata for a specific timeframe.</p>"},{"location":"reference/thestrat/#thestrat.Factory.create_aggregation","title":"create_aggregation  <code>staticmethod</code>","text":"<pre><code>create_aggregation(config: AggregationConfig) -&gt; Aggregation\n</code></pre> <p>Create aggregation component from validated configuration.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>AggregationConfig</code> <p>Validated AggregationConfig containing: - <code>target_timeframes</code>: Target timeframes list (e.g., [\"1H\", \"5m\", \"1D\"]) - <code>asset_class</code>: Asset class type (crypto, equities, fx, futures, commodities) - <code>timezone</code>: Timezone override (UTC asset classes always use UTC;            non-UTC uses priority: specified &gt; system &gt; asset_class default) - <code>hour_boundary</code>: Align to hour boundaries (auto-determined if None) - <code>session_start</code>: Session start time (asset class default if None)</p> required <p>Returns:</p> Type Description <code>Aggregation</code> <p>Configured Aggregation component</p> Example <p>from thestrat.schemas import AggregationConfig config = AggregationConfig( ...     target_timeframes=[\"5m\", \"1H\"], ...     asset_class=\"crypto\", ...     timezone=\"UTC\" ... ) aggregation = Factory.create_aggregation(config)</p> Source code in <code>thestrat/factory.py</code> <pre><code>@staticmethod\ndef create_aggregation(config: AggregationConfig) -&gt; Aggregation:\n    \"\"\"\n    Create aggregation component from validated configuration.\n\n    Args:\n        config: Validated AggregationConfig containing:\n            - `target_timeframes`: Target timeframes list (e.g., [\"1H\", \"5m\", \"1D\"])\n            - `asset_class`: Asset class type (crypto, equities, fx, futures, commodities)\n            - `timezone`: Timezone override (UTC asset classes always use UTC;\n                       non-UTC uses priority: specified &gt; system &gt; asset_class default)\n            - `hour_boundary`: Align to hour boundaries (auto-determined if None)\n            - `session_start`: Session start time (asset class default if None)\n\n    Returns:\n        Configured Aggregation component\n\n    Example:\n        &gt;&gt;&gt; from thestrat.schemas import AggregationConfig\n        &gt;&gt;&gt; config = AggregationConfig(\n        ...     target_timeframes=[\"5m\", \"1H\"],\n        ...     asset_class=\"crypto\",\n        ...     timezone=\"UTC\"\n        ... )\n        &gt;&gt;&gt; aggregation = Factory.create_aggregation(config)\n    \"\"\"\n    return Aggregation(config)\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Factory.create_all","title":"create_all  <code>classmethod</code>","text":"<pre><code>create_all(config: FactoryConfig) -&gt; ComponentDict\n</code></pre> <p>Create complete processing pipeline with aggregation and indicators.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>FactoryConfig</code> <p>Validated FactoryConfig containing: <code>aggregation</code>: AggregationConfig with target timeframes and settings <code>indicators</code>: IndicatorsConfig with per-timeframe configurations</p> required <p>Returns:</p> Type Description <code>ComponentDict</code> <p>Dictionary containing created components:</p> <code>ComponentDict</code> <p>{ \"aggregation\": Aggregation, \"indicators\": Indicators</p> <code>ComponentDict</code> <p>}</p> Example <p>from thestrat.schemas import FactoryConfig, AggregationConfig, IndicatorsConfig, TimeframeItemConfig config = FactoryConfig( ...     aggregation=AggregationConfig(target_timeframes=[\"5m\"]), ...     indicators=IndicatorsConfig( ...         timeframe_configs=[TimeframeItemConfig(timeframes=[\"all\"])] ...     ) ... ) components = Factory.create_all(config)</p> Source code in <code>thestrat/factory.py</code> <pre><code>@classmethod\ndef create_all(cls, config: FactoryConfig) -&gt; ComponentDict:\n    \"\"\"\n    Create complete processing pipeline with aggregation and indicators.\n\n    Args:\n        config: Validated FactoryConfig containing:\n            `aggregation`: AggregationConfig with target timeframes and settings\n            `indicators`: IndicatorsConfig with per-timeframe configurations\n\n    Returns:\n        Dictionary containing created components:\n        {\n            \"aggregation\": Aggregation,\n            \"indicators\": Indicators\n        }\n\n    Example:\n        &gt;&gt;&gt; from thestrat.schemas import FactoryConfig, AggregationConfig, IndicatorsConfig, TimeframeItemConfig\n        &gt;&gt;&gt; config = FactoryConfig(\n        ...     aggregation=AggregationConfig(target_timeframes=[\"5m\"]),\n        ...     indicators=IndicatorsConfig(\n        ...         timeframe_configs=[TimeframeItemConfig(timeframes=[\"all\"])]\n        ...     )\n        ... )\n        &gt;&gt;&gt; components = Factory.create_all(config)\n    \"\"\"\n    return {\n        \"aggregation\": cls.create_aggregation(config.aggregation),\n        \"indicators\": cls.create_indicators(config.indicators),\n    }\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Factory.create_indicators","title":"create_indicators  <code>staticmethod</code>","text":"<pre><code>create_indicators(config: IndicatorsConfig) -&gt; Indicators\n</code></pre> <p>Create indicators component from validated configuration.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>IndicatorsConfig</code> <p>Validated IndicatorsConfig containing per-timeframe configurations using Pydantic models</p> required <p>Returns:</p> Type Description <code>Indicators</code> <p>Configured Indicators component</p> Example <p>from thestrat.schemas import IndicatorsConfig, TimeframeItemConfig, SwingPointsConfig config = IndicatorsConfig( ...     timeframe_configs=[ ...         TimeframeItemConfig( ...             timeframes=[\"5m\", \"15m\"], ...             swing_points=SwingPointsConfig(window=7, threshold=3.0) ...         ) ...     ] ... ) indicators = Factory.create_indicators(config)</p> Source code in <code>thestrat/factory.py</code> <pre><code>@staticmethod\ndef create_indicators(config: IndicatorsConfig) -&gt; Indicators:\n    \"\"\"\n    Create indicators component from validated configuration.\n\n    Args:\n        config: Validated IndicatorsConfig containing per-timeframe configurations\n            using Pydantic models\n\n    Returns:\n        Configured Indicators component\n\n    Example:\n        &gt;&gt;&gt; from thestrat.schemas import IndicatorsConfig, TimeframeItemConfig, SwingPointsConfig\n        &gt;&gt;&gt; config = IndicatorsConfig(\n        ...     timeframe_configs=[\n        ...         TimeframeItemConfig(\n        ...             timeframes=[\"5m\", \"15m\"],\n        ...             swing_points=SwingPointsConfig(window=7, threshold=3.0)\n        ...         )\n        ...     ]\n        ... )\n        &gt;&gt;&gt; indicators = Factory.create_indicators(config)\n    \"\"\"\n    return Indicators(config)\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Factory.get_asset_class_config","title":"get_asset_class_config  <code>staticmethod</code>","text":"<pre><code>get_asset_class_config(asset_class: str) -&gt; dict[str, Any]\n</code></pre> <p>Get default configuration for specific asset class.</p> <p>Parameters:</p> Name Type Description Default <code>asset_class</code> <code>str</code> <p>Asset class type</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary with default <code>timezone</code> and <code>session_start</code></p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If asset_class is not supported</p> Source code in <code>thestrat/factory.py</code> <pre><code>@staticmethod\ndef get_asset_class_config(asset_class: str) -&gt; dict[str, Any]:\n    \"\"\"\n    Get default configuration for specific asset class.\n\n    Args:\n        asset_class: Asset class type\n\n    Returns:\n        Dictionary with default `timezone` and `session_start`\n\n    Raises:\n        ValueError: If asset_class is not supported\n    \"\"\"\n    from .schemas import AssetClassConfig\n\n    if asset_class not in Factory.get_supported_asset_classes():\n        raise ValueError(f\"Unsupported asset class: {asset_class}\")\n\n    return AssetClassConfig.REGISTRY[asset_class].model_dump()\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Factory.get_supported_asset_classes","title":"get_supported_asset_classes  <code>staticmethod</code>","text":"<pre><code>get_supported_asset_classes() -&gt; list[str]\n</code></pre> <p>Get list of supported asset classes.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of supported asset class strings</p> Source code in <code>thestrat/factory.py</code> <pre><code>@staticmethod\ndef get_supported_asset_classes() -&gt; list[str]:\n    \"\"\"\n    Get list of supported asset classes.\n\n    Returns:\n        List of supported asset class strings\n    \"\"\"\n    from .schemas import AssetClassConfig\n\n    return list(AssetClassConfig.REGISTRY.keys())\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Factory.get_supported_timeframes","title":"get_supported_timeframes  <code>cached</code> <code>staticmethod</code>","text":"<pre><code>get_supported_timeframes() -&gt; list[str]\n</code></pre> <p>Get list of all supported timeframes in chronological order.</p> <p>Returns a chronologically ordered list of timeframe strings that can be used with the aggregation and indicators components. These timeframes are validated when creating configurations.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>Chronologically ordered list of supported timeframe strings (shortest to longest)</p> Example <p>from thestrat import Factory timeframes = Factory.get_supported_timeframes() print(timeframes) ['1min', '5min', '15min', '30min', '1h', '4h', '6h', '12h', '1d', '1w', '1m', '1q', '1y']</p> Note <p>The timeframes are ordered by duration (shortest to longest) and follow standard conventions: - Minutes: <code>1min</code>, <code>5min</code>, <code>15min</code>, <code>30min</code> - Hours: <code>1h</code>, <code>4h</code>, <code>6h</code>, <code>12h</code> - Days/Weeks/Months: <code>1d</code>, <code>1w</code>, <code>1m</code> (month), <code>1q</code> (quarter), <code>1y</code></p> Source code in <code>thestrat/factory.py</code> <pre><code>@staticmethod\n@lru_cache(maxsize=1)\ndef get_supported_timeframes() -&gt; list[str]:\n    \"\"\"\n    Get list of all supported timeframes in chronological order.\n\n    Returns a chronologically ordered list of timeframe strings that can be used with\n    the aggregation and indicators components. These timeframes are\n    validated when creating configurations.\n\n    Returns:\n        Chronologically ordered list of supported timeframe strings (shortest to longest)\n\n    Example:\n        &gt;&gt;&gt; from thestrat import Factory\n        &gt;&gt;&gt; timeframes = Factory.get_supported_timeframes()\n        &gt;&gt;&gt; print(timeframes)\n        ['1min', '5min', '15min', '30min', '1h', '4h', '6h', '12h', '1d', '1w', '1m', '1q', '1y']\n\n        &gt;&gt;&gt; # Use in configuration\n        &gt;&gt;&gt; from thestrat.schemas import AggregationConfig\n        &gt;&gt;&gt; available_timeframes = Factory.get_supported_timeframes()\n        &gt;&gt;&gt; config = AggregationConfig(\n        ...     target_timeframes=[available_timeframes[0], available_timeframes[1]],\n        ...     asset_class=\"equities\"\n        ... )\n\n    Note:\n        The timeframes are ordered by duration (shortest to longest) and follow standard conventions:\n        - Minutes: `1min`, `5min`, `15min`, `30min`\n        - Hours: `1h`, `4h`, `6h`, `12h`\n        - Days/Weeks/Months: `1d`, `1w`, `1m` (month), `1q` (quarter), `1y`\n    \"\"\"\n    from .schemas import TimeframeConfig\n\n    # Pre-compute timeframes with their durations for efficient sorting\n    timeframes_with_duration = [\n        (tf, TimeframeConfig.TIMEFRAME_METADATA.get(tf, {}).get(\"seconds\", float(\"inf\")))\n        for tf in TimeframeConfig.TIMEFRAME_METADATA.keys()\n    ]\n\n    # Sort by duration and return just the timeframe strings\n    return [tf for tf, _ in sorted(timeframes_with_duration, key=lambda x: x[1])]\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Factory.get_supported_timeframes--use-in-configuration","title":"Use in configuration","text":"<p>from thestrat.schemas import AggregationConfig available_timeframes = Factory.get_supported_timeframes() config = AggregationConfig( ...     target_timeframes=[available_timeframes[0], available_timeframes[1]], ...     asset_class=\"equities\" ... )</p>"},{"location":"reference/thestrat/#thestrat.Factory.get_timeframe_metadata","title":"get_timeframe_metadata  <code>staticmethod</code>","text":"<pre><code>get_timeframe_metadata(timeframe: str) -&gt; dict[str, Any]\n</code></pre> <p>Get detailed metadata for a specific timeframe.</p> <p>Provides comprehensive information about a timeframe including its category, duration in seconds, description, and typical use cases. This is useful for understanding the characteristics and appropriate applications of different timeframes.</p> <p>Parameters:</p> Name Type Description Default <code>timeframe</code> <code>str</code> <p>Timeframe string to get metadata for (e.g., \"5min\", \"1h\", \"1d\")</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary containing:</p> <code>dict[str, Any]</code> <ul> <li><code>category</code>: Timeframe category (e.g., \"sub-hourly\", \"hourly\", \"daily\")</li> </ul> <code>dict[str, Any]</code> <ul> <li><code>seconds</code>: Duration in seconds</li> </ul> <code>dict[str, Any]</code> <ul> <li><code>description</code>: Human-readable description</li> </ul> <code>dict[str, Any]</code> <ul> <li><code>typical_use</code>: Common use cases for this timeframe</li> </ul> <code>dict[str, Any]</code> <ul> <li><code>data_volume</code>: Expected data volume level</li> </ul> <p>Raises:</p> Type Description <code>ValueError</code> <p>If timeframe is not supported</p> Example <p>from thestrat import Factory metadata = Factory.get_timeframe_metadata(\"1h\") print(metadata) {     'category': 'hourly',     'seconds': 3600,     'description': '1-hour bars for daily structure analysis',     'typical_use': 'Day trading context, hourly levels',     'data_volume': 'low' }</p> See Also <ul> <li>:meth:<code>get_supported_timeframes</code>: Get list of all supported timeframes</li> <li>:meth:<code>validate_timeframe_format</code>: Validate a timeframe string</li> </ul> Source code in <code>thestrat/factory.py</code> <pre><code>@staticmethod\ndef get_timeframe_metadata(timeframe: str) -&gt; dict[str, Any]:\n    \"\"\"\n    Get detailed metadata for a specific timeframe.\n\n    Provides comprehensive information about a timeframe including its\n    category, duration in seconds, description, and typical use cases.\n    This is useful for understanding the characteristics and appropriate\n    applications of different timeframes.\n\n    Args:\n        timeframe: Timeframe string to get metadata for (e.g., \"5min\", \"1h\", \"1d\")\n\n    Returns:\n        Dictionary containing:\n        - `category`: Timeframe category (e.g., \"sub-hourly\", \"hourly\", \"daily\")\n        - `seconds`: Duration in seconds\n        - `description`: Human-readable description\n        - `typical_use`: Common use cases for this timeframe\n        - `data_volume`: Expected data volume level\n\n    Raises:\n        ValueError: If timeframe is not supported\n\n    Example:\n        &gt;&gt;&gt; from thestrat import Factory\n        &gt;&gt;&gt; metadata = Factory.get_timeframe_metadata(\"1h\")\n        &gt;&gt;&gt; print(metadata)\n        {\n            'category': 'hourly',\n            'seconds': 3600,\n            'description': '1-hour bars for daily structure analysis',\n            'typical_use': 'Day trading context, hourly levels',\n            'data_volume': 'low'\n        }\n\n        &gt;&gt;&gt; # Check if a timeframe is suitable for day trading\n        &gt;&gt;&gt; metadata = Factory.get_timeframe_metadata(\"5min\")\n        &gt;&gt;&gt; if \"day trading\" in metadata[\"typical_use\"].lower():\n        ...     print(f\"5min is suitable for day trading\")\n\n        &gt;&gt;&gt; # Get all intraday timeframes\n        &gt;&gt;&gt; all_timeframes = Factory.get_supported_timeframes()\n        &gt;&gt;&gt; intraday = []\n        &gt;&gt;&gt; for tf in all_timeframes:\n        ...     meta = Factory.get_timeframe_metadata(tf)\n        ...     if meta[\"category\"] in [\"sub-hourly\", \"hourly\"]:\n        ...         intraday.append(tf)\n\n    See Also:\n        - :meth:`get_supported_timeframes`: Get list of all supported timeframes\n        - :meth:`validate_timeframe_format`: Validate a timeframe string\n    \"\"\"\n    # Use cached helper method to get metadata efficiently\n    metadata = Factory._get_cached_timeframe_metadata(timeframe)\n    return metadata.copy()  # Return a copy to prevent modification\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Factory.get_timeframe_metadata--check-if-a-timeframe-is-suitable-for-day-trading","title":"Check if a timeframe is suitable for day trading","text":"<p>metadata = Factory.get_timeframe_metadata(\"5min\") if \"day trading\" in metadata[\"typical_use\"].lower(): ...     print(f\"5min is suitable for day trading\")</p>"},{"location":"reference/thestrat/#thestrat.Factory.get_timeframe_metadata--get-all-intraday-timeframes","title":"Get all intraday timeframes","text":"<p>all_timeframes = Factory.get_supported_timeframes() intraday = [] for tf in all_timeframes: ...     meta = Factory.get_timeframe_metadata(tf) ...     if meta[\"category\"] in [\"sub-hourly\", \"hourly\"]: ...         intraday.append(tf)</p>"},{"location":"reference/thestrat/#thestrat.FactoryConfig","title":"FactoryConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Root configuration for Factory.create_all method with complete pipeline setup.</p> <p>Methods:</p> Name Description <code>validate_configuration_consistency</code> <p>Validate consistency between aggregation and indicators configurations.</p>"},{"location":"reference/thestrat/#thestrat.FactoryConfig.validate_configuration_consistency","title":"validate_configuration_consistency","text":"<pre><code>validate_configuration_consistency() -&gt; Self\n</code></pre> <p>Validate consistency between aggregation and indicators configurations.</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@model_validator(mode=\"after\")\ndef validate_configuration_consistency(self) -&gt; Self:\n    \"\"\"Validate consistency between aggregation and indicators configurations.\"\"\"\n    # Future enhancement: Could validate that indicator timeframes are compatible\n    # with aggregation target timeframes, but this is not currently enforced\n    # in the existing system\n    return self\n</code></pre>"},{"location":"reference/thestrat/#thestrat.GapDetectionConfig","title":"GapDetectionConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for gap detection with comprehensive threshold documentation.</p>"},{"location":"reference/thestrat/#thestrat.IndicatorSchema","title":"IndicatorSchema","text":"<p>               Bases: <code>BaseModel</code></p> <p>Complete Indicator Schema</p> <p>Defines all columns that are created by TheStrat processing pipeline. All columns are required as the indicators component creates them all.</p> <p>Methods:</p> Name Description <code>get_all_input_columns</code> <p>Get list of all input columns (required + optional).</p> <code>get_column_categories</code> <p>Get columns organized by functional categories.</p> <code>get_column_descriptions</code> <p>Get descriptions for all possible DataFrame columns.</p> <code>get_field_metadata</code> <p>Get json_schema_extra metadata for a field, safely handling missing data.</p> <code>get_optional_input_columns</code> <p>Get list of optional input columns based on schema definition.</p> <code>get_polars_dtypes</code> <p>Get Polars data types for all DataFrame columns.</p> <code>get_required_input_columns</code> <p>Get list of required input columns based on schema definition.</p> <code>validate_dataframe</code> <p>Validate input DataFrame columns and data types against IndicatorSchema input requirements.</p>"},{"location":"reference/thestrat/#thestrat.IndicatorSchema.get_all_input_columns","title":"get_all_input_columns  <code>classmethod</code>","text":"<pre><code>get_all_input_columns() -&gt; list[str]\n</code></pre> <p>Get list of all input columns (required + optional).</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of all input column names</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_all_input_columns(cls) -&gt; list[str]:\n    \"\"\"\n    Get list of all input columns (required + optional).\n\n    Returns:\n        List of all input column names\n    \"\"\"\n    return sorted(cls.get_required_input_columns() + cls.get_optional_input_columns())\n</code></pre>"},{"location":"reference/thestrat/#thestrat.IndicatorSchema.get_column_categories","title":"get_column_categories  <code>classmethod</code>","text":"<pre><code>get_column_categories() -&gt; dict[str, list[str]]\n</code></pre> <p>Get columns organized by functional categories.</p> <p>Dynamically extracts categories from the IndicatorSchema metadata.</p> <p>Returns:</p> Type Description <code>dict[str, list[str]]</code> <p>Dictionary mapping category names to lists of column names</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_column_categories(cls) -&gt; dict[str, list[str]]:\n    \"\"\"\n    Get columns organized by functional categories.\n\n    Dynamically extracts categories from the IndicatorSchema metadata.\n\n    Returns:\n        Dictionary mapping category names to lists of column names\n    \"\"\"\n    categories: dict[str, list[str]] = {}\n\n    for field_name, field_info in cls.model_fields.items():\n        json_extra = getattr(field_info, \"json_schema_extra\", {})\n        if isinstance(json_extra, dict) and \"category\" in json_extra:\n            category = json_extra[\"category\"]\n            if category not in categories:\n                categories[category] = []\n            categories[category].append(field_name)\n\n    # Sort columns within each category for consistent output\n    for category in categories:\n        categories[category].sort()\n\n    return categories\n</code></pre>"},{"location":"reference/thestrat/#thestrat.IndicatorSchema.get_column_descriptions","title":"get_column_descriptions  <code>classmethod</code>","text":"<pre><code>get_column_descriptions() -&gt; dict[str, str]\n</code></pre> <p>Get descriptions for all possible DataFrame columns.</p> <p>Returns:</p> Type Description <code>dict[str, str]</code> <p>Dictionary mapping column names to their descriptions</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_column_descriptions(cls) -&gt; dict[str, str]:\n    \"\"\"\n    Get descriptions for all possible DataFrame columns.\n\n    Returns:\n        Dictionary mapping column names to their descriptions\n    \"\"\"\n    descriptions = {}\n\n    # Get descriptions from the schema\n    for field_name, field_info in cls.model_fields.items():\n        if field_info.description:\n            descriptions[field_name] = field_info.description\n\n    return descriptions\n</code></pre>"},{"location":"reference/thestrat/#thestrat.IndicatorSchema.get_field_metadata","title":"get_field_metadata  <code>classmethod</code>","text":"<pre><code>get_field_metadata(field_name: str) -&gt; dict[str, Any]\n</code></pre> <p>Get json_schema_extra metadata for a field, safely handling missing data.</p> <p>Parameters:</p> Name Type Description Default <code>field_name</code> <code>str</code> <p>Name of the field to get metadata for</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary of metadata from json_schema_extra, empty dict if not found</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_field_metadata(cls, field_name: str) -&gt; dict[str, Any]:\n    \"\"\"\n    Get json_schema_extra metadata for a field, safely handling missing data.\n\n    Args:\n        field_name: Name of the field to get metadata for\n\n    Returns:\n        Dictionary of metadata from json_schema_extra, empty dict if not found\n    \"\"\"\n    field_info = cls.model_fields.get(field_name)\n    if not field_info:\n        return {}\n    return getattr(field_info, \"json_schema_extra\", {}) or {}\n</code></pre>"},{"location":"reference/thestrat/#thestrat.IndicatorSchema.get_optional_input_columns","title":"get_optional_input_columns  <code>classmethod</code>","text":"<pre><code>get_optional_input_columns() -&gt; list[str]\n</code></pre> <p>Get list of optional input columns based on schema definition.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of column names that are optional for input data</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_optional_input_columns(cls) -&gt; list[str]:\n    \"\"\"\n    Get list of optional input columns based on schema definition.\n\n    Returns:\n        List of column names that are optional for input data\n    \"\"\"\n    from pydantic_core import PydanticUndefined\n\n    optional_columns = []\n    for field_name, field_info in cls.model_fields.items():\n        json_extra = getattr(field_info, \"json_schema_extra\", {}) or {}\n        if (\n            json_extra.get(\"input\") is True  # Is an input column\n            and (\n                json_extra.get(\"optional\", False)  # Marked as optional\n                or getattr(field_info, \"default\", PydanticUndefined) is not PydanticUndefined\n            )  # Has default value\n        ):\n            optional_columns.append(field_name)\n    return sorted(optional_columns)\n</code></pre>"},{"location":"reference/thestrat/#thestrat.IndicatorSchema.get_polars_dtypes","title":"get_polars_dtypes  <code>classmethod</code>","text":"<pre><code>get_polars_dtypes() -&gt; dict[str, Any]\n</code></pre> <p>Get Polars data types for all DataFrame columns.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary mapping column names to their Polars data types</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_polars_dtypes(cls) -&gt; dict[str, Any]:\n    \"\"\"\n    Get Polars data types for all DataFrame columns.\n\n    Returns:\n        Dictionary mapping column names to their Polars data types\n    \"\"\"\n    types = {}\n\n    for field_name, field_info in cls.model_fields.items():\n        json_extra = getattr(field_info, \"json_schema_extra\", {})\n        if isinstance(json_extra, dict) and \"polars_dtype\" in json_extra:\n            types[field_name] = json_extra[\"polars_dtype\"]\n\n    return types\n</code></pre>"},{"location":"reference/thestrat/#thestrat.IndicatorSchema.get_required_input_columns","title":"get_required_input_columns  <code>classmethod</code>","text":"<pre><code>get_required_input_columns() -&gt; list[str]\n</code></pre> <p>Get list of required input columns based on schema definition.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of column names that are required for input data</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_required_input_columns(cls) -&gt; list[str]:\n    \"\"\"\n    Get list of required input columns based on schema definition.\n\n    Returns:\n        List of column names that are required for input data\n    \"\"\"\n    from pydantic_core import PydanticUndefined\n\n    required_columns = []\n    for field_name, field_info in cls.model_fields.items():\n        json_extra = getattr(field_info, \"json_schema_extra\", {}) or {}\n        if (\n            json_extra.get(\"input\") is True  # Is an input column\n            and not json_extra.get(\"optional\", False)  # Not marked as optional\n            and getattr(field_info, \"default\", PydanticUndefined)\n            is PydanticUndefined  # No default value (required)\n        ):\n            required_columns.append(field_name)\n    return sorted(required_columns)\n</code></pre>"},{"location":"reference/thestrat/#thestrat.IndicatorSchema.validate_dataframe","title":"validate_dataframe  <code>classmethod</code>","text":"<pre><code>validate_dataframe(df) -&gt; dict[str, Any]\n</code></pre> <p>Validate input DataFrame columns and data types against IndicatorSchema input requirements.</p> <p>Automatically converts Pandas DataFrames to Polars for consistent validation.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <p>Polars or Pandas DataFrame to validate</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary with validation results including missing/extra columns, type issues,</p> <code>dict[str, Any]</code> <p>and the converted Polars DataFrame if conversion occurred</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef validate_dataframe(cls, df) -&gt; dict[str, Any]:\n    \"\"\"\n    Validate input DataFrame columns and data types against IndicatorSchema input requirements.\n\n    Automatically converts Pandas DataFrames to Polars for consistent validation.\n\n    Args:\n        df: Polars or Pandas DataFrame to validate\n\n    Returns:\n        Dictionary with validation results including missing/extra columns, type issues,\n        and the converted Polars DataFrame if conversion occurred\n    \"\"\"\n    from polars import from_pandas\n\n    # Detect DataFrame type and convert if necessary\n    df_type = \"unknown\"\n    converted_df = None\n    conversion_errors = []\n\n    if hasattr(df, \"columns\"):\n        # Check if it's a Pandas DataFrame\n        if hasattr(df, \"dtypes\") and not hasattr(df, \"schema\"):\n            df_type = \"pandas\"\n            try:\n                # Convert Pandas to Polars\n                converted_df = from_pandas(df)\n                df = converted_df  # Use converted DataFrame for validation\n            except Exception as e:\n                conversion_errors.append(f\"Failed to convert Pandas to Polars: {str(e)}\")\n                # Fall back to column-only validation\n                df_columns = list(df.columns)\n                return {\n                    \"valid\": False,\n                    \"conversion_error\": conversion_errors[0],\n                    \"df_type\": df_type,\n                    \"columns\": df_columns,\n                    \"message\": \"Could not convert Pandas DataFrame to Polars for full validation\",\n                }\n        # Check if it's already a Polars DataFrame\n        elif hasattr(df, \"schema\"):\n            df_type = \"polars\"\n        else:\n            raise ValueError(\"Unknown DataFrame type - must be Pandas or Polars DataFrame\")\n\n        df_columns = list(df.columns)\n    else:\n        raise ValueError(\"Input must be a DataFrame with .columns attribute\")\n\n    required_fields = []\n    optional_fields = []\n    expected_types = {}\n\n    # Extract input field requirements from schema\n    for field_name, field_info in cls.model_fields.items():\n        json_extra = getattr(field_info, \"json_schema_extra\", {})\n        if isinstance(json_extra, dict) and json_extra.get(\"input\"):\n            if field_info.is_required():\n                required_fields.append(field_name)\n            else:\n                optional_fields.append(field_name)\n\n            # Store expected Polars type for validation\n            if \"polars_dtype\" in json_extra:\n                expected_types[field_name] = json_extra[\"polars_dtype\"]\n\n    # Check for missing and extra columns\n    missing_required = [col for col in required_fields if col not in df_columns]\n    missing_optional = [col for col in optional_fields if col not in df_columns]\n    extra_columns = [col for col in df_columns if col not in required_fields + optional_fields]\n\n    # Check data types for present columns (now guaranteed to be Polars)\n    type_issues = []\n    if hasattr(df, \"schema\"):  # Polars DataFrame\n        for col_name, expected_type in expected_types.items():\n            if col_name in df_columns:\n                actual_type = df.schema[col_name]\n                if actual_type != expected_type:\n                    type_issues.append(\n                        {\n                            \"column\": col_name,\n                            \"expected\": expected_type.__name__\n                            if hasattr(expected_type, \"__name__\")\n                            else str(expected_type),\n                            \"actual\": str(actual_type),\n                        }\n                    )\n\n    result = {\n        \"valid\": len(missing_required) == 0 and len(type_issues) == 0,\n        \"missing_required\": missing_required,\n        \"missing_optional\": missing_optional,\n        \"extra_columns\": extra_columns,\n        \"type_issues\": type_issues,\n        \"required_fields\": required_fields,\n        \"optional_fields\": optional_fields,\n        \"expected_types\": {k: v.__name__ if hasattr(v, \"__name__\") else str(v) for k, v in expected_types.items()},\n        \"df_type\": df_type,\n    }\n\n    # Include converted DataFrame if conversion occurred\n    if converted_df is not None:\n        result[\"converted_df\"] = converted_df\n        result[\"conversion_performed\"] = True\n    else:\n        result[\"conversion_performed\"] = False\n\n    return result\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Indicators","title":"Indicators","text":"<pre><code>Indicators(config: IndicatorsConfig)\n</code></pre> <p>               Bases: <code>Component</code></p> <p>Vectorized implementation of all Strat technical indicators.</p> <p>Provides comprehensive technical analysis including swing point detection, market structure analysis, pattern recognition, and gap detection optimized for TheStrat methodology.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>IndicatorsConfig</code> <p>Validated IndicatorsConfig containing per-timeframe configurations</p> required <p>Methods:</p> Name Description <code>get_signal_objects</code> <p>Create SignalMetadata objects on-demand from processed indicator results.</p> <code>process</code> <p>Calculate all Strat indicators for OHLC data.</p> <code>validate_input</code> <p>Validate input data format.</p> Source code in <code>thestrat/indicators.py</code> <pre><code>def __init__(self, config: IndicatorsConfig):\n    \"\"\"\n    Initialize indicators component with validated configuration.\n\n    Args:\n        config: Validated IndicatorsConfig containing per-timeframe configurations\n    \"\"\"\n    super().__init__()\n\n    # Store the validated Pydantic config\n    self.config = config\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Indicators.get_signal_objects","title":"get_signal_objects","text":"<pre><code>get_signal_objects(result_df: DataFrame) -&gt; list\n</code></pre> <p>Create SignalMetadata objects on-demand from processed indicator results.</p> <p>This method processes rows with signals and creates full SignalMetadata objects with prices and trading context. Only used when signal objects are needed.</p> <p>Parameters:</p> Name Type Description Default <code>result_df</code> <code>DataFrame</code> <p>DataFrame with processed indicators including signal columns</p> required <p>Returns:</p> Type Description <code>list</code> <p>List of SignalMetadata objects for rows with detected signals</p> Source code in <code>thestrat/indicators.py</code> <pre><code>def get_signal_objects(self, result_df: PolarsDataFrame) -&gt; list:\n    \"\"\"\n    Create SignalMetadata objects on-demand from processed indicator results.\n\n    This method processes rows with signals and creates full SignalMetadata objects\n    with prices and trading context. Only used when signal objects are needed.\n\n    Args:\n        result_df: DataFrame with processed indicators including signal columns\n\n    Returns:\n        List of SignalMetadata objects for rows with detected signals\n    \"\"\"\n    signal_objects = []\n\n    # Add row index to track original positions\n    df_with_index = result_df.with_row_index(\"__original_idx\")\n\n    # Filter to rows with signals\n    signal_rows = df_with_index.filter(col(\"signal\").is_not_null())\n\n    if len(signal_rows) == 0:\n        return signal_objects\n\n    # Convert to pandas for row-by-row processing\n    signal_data = signal_rows.to_pandas()\n\n    for _, row in signal_data.iterrows():\n        original_index = int(row[\"__original_idx\"])\n        signal_obj = self._create_signal_object(\n            df_with_index, original_index, row[\"signal\"], row[\"type\"], row[\"bias\"]\n        )\n        if signal_obj:\n            signal_objects.append(signal_obj)\n\n    return signal_objects\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Indicators.process","title":"process","text":"<pre><code>process(data: DataFrame | DataFrame) -&gt; DataFrame\n</code></pre> <p>Calculate all Strat indicators for OHLC data.</p> <p>Performs comprehensive technical analysis including swing point detection, market structure analysis, pattern recognition, and gap detection. Calculations run sequentially due to data dependencies between indicators.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | DataFrame</code> <p>Input DataFrame with OHLC data</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with all Strat indicators added</p> Source code in <code>thestrat/indicators.py</code> <pre><code>def process(self, data: PolarsDataFrame | PandasDataFrame) -&gt; PolarsDataFrame:\n    \"\"\"\n    Calculate all Strat indicators for OHLC data.\n\n    Performs comprehensive technical analysis including swing point detection, market structure\n    analysis, pattern recognition, and gap detection. Calculations run sequentially due to\n    data dependencies between indicators.\n\n    Args:\n        data: Input DataFrame with OHLC data\n\n    Returns:\n        DataFrame with all Strat indicators added\n    \"\"\"\n    self.validate_input(data)\n\n    # Convert to Polars if needed\n    df = self._convert_to_polars(data)\n\n    # Ensure optional schema columns are present\n    if \"symbol\" not in df.columns:\n        df = df.with_columns(lit(None, dtype=String).alias(\"symbol\"))\n\n    # Check if data has timeframe column for per-timeframe processing\n    if \"timeframe\" in df.columns:\n        # Check if \"all\" timeframe is configured\n        has_all_config = any(\"all\" in tf_config.timeframes for tf_config in self.config.timeframe_configs)\n\n        if has_all_config:\n            # Process all data with the \"all\" configuration\n            all_config = self._get_config_for_timeframe(\"any_timeframe_will_get_all_config\")\n            df = self._process_single_timeframe(df, all_config)\n        else:\n            # Process each timeframe group with its specific configuration\n            timeframe_groups = df.partition_by(\"timeframe\", as_dict=True)\n            processed_groups = []\n\n            for timeframe_key, timeframe_data in timeframe_groups.items():\n                # Extract timeframe string from tuple key\n                timeframe = timeframe_key[0] if isinstance(timeframe_key, tuple) else timeframe_key\n\n                # Get config for this timeframe\n                tf_config = self._get_config_for_timeframe(timeframe)\n\n                # Process this timeframe with its specific config\n                processed_data = self._process_single_timeframe(timeframe_data, tf_config)\n                processed_groups.append(processed_data)\n\n            # Combine all processed groups\n            df = processed_groups[0]\n            for group in processed_groups[1:]:\n                df = df.vstack(group)\n\n            # Sort by original order (symbol, timeframe, timestamp)\n            sort_cols = []\n            if \"symbol\" in df.columns:\n                sort_cols.append(\"symbol\")\n            sort_cols.extend([\"timeframe\", \"timestamp\"])\n            df = df.sort(sort_cols)\n    else:\n        # No timeframe column - must have \"all\" configuration\n        has_all_config = any(\"all\" in tf_config.timeframes for tf_config in self.config.timeframe_configs)\n        if not has_all_config:\n            raise ValueError(\"Data without timeframe column requires an 'all' timeframe configuration.\")\n\n        all_config = self._get_config_for_timeframe(\"any_timeframe_will_get_all_config\")\n        df = self._process_single_timeframe(df, all_config)\n\n    return df\n</code></pre>"},{"location":"reference/thestrat/#thestrat.Indicators.validate_input","title":"validate_input","text":"<pre><code>validate_input(data: DataFrame | DataFrame) -&gt; None\n</code></pre> <p>Validate input data format.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If data format is invalid, with specific error message</p> Source code in <code>thestrat/indicators.py</code> <pre><code>def validate_input(self, data: PolarsDataFrame | PandasDataFrame) -&gt; None:\n    \"\"\"\n    Validate input data format.\n\n    Raises:\n        ValueError: If data format is invalid, with specific error message\n    \"\"\"\n    df = self._convert_to_polars(data)\n\n    # Check required columns\n    required_cols = [\"timestamp\", \"open\", \"high\", \"low\", \"close\"]\n    missing_cols = [col for col in required_cols if col not in df.columns]\n    if missing_cols:\n        raise ValueError(f\"Missing required columns: {missing_cols}\")\n\n    # Note: Minimum data point validation removed as _calculate_swing_points\n    # now handles small datasets gracefully with proper safeguards\n\n    # Verify price data integrity\n    validations = df.select(\n        [\n            (col(\"high\") &gt;= col(\"low\")).all().alias(\"high_gte_low\"),\n            (col(\"high\") &gt;= col(\"open\")).all().alias(\"high_gte_open\"),\n            (col(\"high\") &gt;= col(\"close\")).all().alias(\"high_gte_close\"),\n            (col(\"low\") &lt;= col(\"open\")).all().alias(\"low_lte_open\"),\n            (col(\"low\") &lt;= col(\"close\")).all().alias(\"low_lte_close\"),\n        ]\n    )\n\n    validation_results = validations.to_numpy().flatten()\n    validation_names = [\"high &gt;= low\", \"high &gt;= open\", \"high &gt;= close\", \"low &lt;= open\", \"low &lt;= close\"]\n\n    failed_validations = [\n        name for name, result in zip(validation_names, validation_results, strict=False) if not result\n    ]\n    if failed_validations:\n        raise ValueError(f\"Invalid price data: failed validations: {failed_validations}\")\n</code></pre>"},{"location":"reference/thestrat/#thestrat.IndicatorsConfig","title":"IndicatorsConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Complete configuration for indicators component with per-timeframe settings.</p>"},{"location":"reference/thestrat/#thestrat.PriceChange","title":"PriceChange  <code>dataclass</code>","text":"<pre><code>PriceChange(\n    field_name: str,\n    from_value: float,\n    to_value: float,\n    timestamp: datetime,\n    reason: str | None = None,\n)\n</code></pre> <p>Track changes to stop/target prices.</p>"},{"location":"reference/thestrat/#thestrat.SignalBias","title":"SignalBias","text":"<p>               Bases: <code>Enum</code></p> <p>Signal directional bias.</p>"},{"location":"reference/thestrat/#thestrat.SignalCategory","title":"SignalCategory","text":"<p>               Bases: <code>Enum</code></p> <p>Signal categorization types.</p>"},{"location":"reference/thestrat/#thestrat.SignalMetadata","title":"SignalMetadata  <code>dataclass</code>","text":"<pre><code>SignalMetadata(\n    pattern: str,\n    category: SignalCategory,\n    bias: SignalBias,\n    bar_count: int,\n    entry_bar_index: int,\n    trigger_bar_index: int,\n    entry_price: float,\n    stop_price: float,\n    timestamp: datetime,\n    signal_id: str = (lambda: str(uuid4()))(),\n    target_bar_index: int | None = None,\n    target_price: float | None = None,\n    status: SignalStatus = PENDING,\n    triggered_at: datetime | None = None,\n    closed_at: datetime | None = None,\n    close_reason: str | None = None,\n    change_history: list[PriceChange] = list(),\n    symbol: str | None = None,\n    timeframe: str | None = None,\n    risk_amount: float | None = None,\n    reward_amount: float | None = None,\n    risk_reward_ratio: float | None = None,\n    entry_filled_price: float | None = None,\n    exit_price: float | None = None,\n    pnl: float | None = None,\n    max_favorable_excursion: float | None = None,\n    max_adverse_excursion: float | None = None,\n)\n</code></pre> <p>Complete signal metadata with change tracking and serialization.</p> <p>Methods:</p> Name Description <code>__post_init__</code> <p>Store original values and calculate metrics.</p> <code>from_dict</code> <p>Reconstruct SignalMetadata from dictionary.</p> <code>from_json</code> <p>Deserialize from JSON string.</p> <code>to_dict</code> <p>Convert to dictionary for JSON serialization.</p> <code>to_json</code> <p>Serialize to JSON string.</p> <code>trail_stop</code> <p>Trail stop loss, only allowing favorable moves.</p> <code>update_stop</code> <p>Update stop with change tracking.</p> <code>update_target</code> <p>Update target with change tracking.</p>"},{"location":"reference/thestrat/#thestrat.SignalMetadata.__post_init__","title":"__post_init__","text":"<pre><code>__post_init__()\n</code></pre> <p>Store original values and calculate metrics.</p> Source code in <code>thestrat/signals.py</code> <pre><code>def __post_init__(self):\n    \"\"\"Store original values and calculate metrics.\"\"\"\n    self.original_stop = self.stop_price\n    self.original_target = self.target_price\n    self._calculate_risk_metrics()\n</code></pre>"},{"location":"reference/thestrat/#thestrat.SignalMetadata.from_dict","title":"from_dict  <code>classmethod</code>","text":"<pre><code>from_dict(data: dict[str, Any]) -&gt; SignalMetadata\n</code></pre> <p>Reconstruct SignalMetadata from dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict[str, Any]</code> <p>Dictionary representation from <code>to_dict()</code></p> required <p>Returns:</p> Type Description <code>SignalMetadata</code> <p>SignalMetadata instance with original values and metrics recalculated</p> Source code in <code>thestrat/signals.py</code> <pre><code>@classmethod\ndef from_dict(cls, data: dict[str, Any]) -&gt; \"SignalMetadata\":\n    \"\"\"\n    Reconstruct SignalMetadata from dictionary.\n\n    Args:\n        data: Dictionary representation from `to_dict()`\n\n    Returns:\n        SignalMetadata instance with original values and metrics recalculated\n    \"\"\"\n    # Make a copy to avoid modifying the original\n    data = data.copy()\n\n    # Convert strings back to enums\n    data[\"category\"] = SignalCategory(data[\"category\"])\n    data[\"bias\"] = SignalBias(data[\"bias\"])\n    data[\"status\"] = SignalStatus(data[\"status\"])\n\n    # Convert ISO strings to datetime\n    data[\"timestamp\"] = datetime.fromisoformat(data[\"timestamp\"])\n\n    if data.get(\"triggered_at\"):\n        data[\"triggered_at\"] = datetime.fromisoformat(data[\"triggered_at\"])\n    if data.get(\"closed_at\"):\n        data[\"closed_at\"] = datetime.fromisoformat(data[\"closed_at\"])\n\n    # Reconstruct change history\n    data[\"change_history\"] = [\n        PriceChange(**{**ch, \"timestamp\": datetime.fromisoformat(ch[\"timestamp\"])})\n        for ch in data.get(\"change_history\", [])\n    ]\n\n    # Dynamically determine float fields from dataclass annotations\n    import types\n    import typing\n    from dataclasses import fields\n\n    float_fields = []\n    for field_info in fields(cls):\n        field_type = field_info.type\n        # Handle Union types like float | None (both typing.Union and types.UnionType)\n        origin = typing.get_origin(field_type)\n        if origin is typing.Union or origin is types.UnionType:\n            args = typing.get_args(field_type)\n            # Check if float is in the union (e.g., float | None)\n            if float in args:\n                float_fields.append(field_info.name)\n        # Handle direct float type\n        elif field_type is float:\n            float_fields.append(field_info.name)\n\n    for float_field in float_fields:\n        if data.get(float_field) is not None:\n            value = data[float_field]\n            # Ensure numeric values are floats (not int)\n            if isinstance(value, (int, float)):\n                data[float_field] = float(value)\n\n    # Remove fields that are calculated in __post_init__ and shouldn't be passed to constructor\n    calculated_fields = [\"original_stop\", \"original_target\", \"risk_amount\", \"reward_amount\", \"risk_reward_ratio\"]\n    for calc_field in calculated_fields:\n        data.pop(calc_field, None)\n\n    # Create the object (original values and metrics will be recalculated in __post_init__)\n    return cls(**data)\n</code></pre>"},{"location":"reference/thestrat/#thestrat.SignalMetadata.from_json","title":"from_json  <code>classmethod</code>","text":"<pre><code>from_json(json_str: str) -&gt; SignalMetadata\n</code></pre> <p>Deserialize from JSON string.</p> <p>Parameters:</p> Name Type Description Default <code>json_str</code> <code>str</code> <p>JSON string from <code>to_json()</code></p> required <p>Returns:</p> Type Description <code>SignalMetadata</code> <p>SignalMetadata instance reconstructed from JSON</p> Source code in <code>thestrat/signals.py</code> <pre><code>@classmethod\ndef from_json(cls, json_str: str) -&gt; \"SignalMetadata\":\n    \"\"\"\n    Deserialize from JSON string.\n\n    Args:\n        json_str: JSON string from `to_json()`\n\n    Returns:\n        SignalMetadata instance reconstructed from JSON\n    \"\"\"\n    return cls.from_dict(json.loads(json_str))\n</code></pre>"},{"location":"reference/thestrat/#thestrat.SignalMetadata.to_dict","title":"to_dict","text":"<pre><code>to_dict() -&gt; dict[str, Any]\n</code></pre> <p>Convert to dictionary for JSON serialization.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary representation with all fields serializable to JSON</p> Source code in <code>thestrat/signals.py</code> <pre><code>def to_dict(self) -&gt; dict[str, Any]:\n    \"\"\"\n    Convert to dictionary for JSON serialization.\n\n    Returns:\n        Dictionary representation with all fields serializable to JSON\n    \"\"\"\n    data = asdict(self)\n\n    # Convert enums to strings\n    data[\"category\"] = self.category.value\n    data[\"bias\"] = self.bias.value\n    data[\"status\"] = self.status.value\n\n    # Convert datetime to ISO format\n    data[\"timestamp\"] = self.timestamp.isoformat()\n\n    if self.triggered_at:\n        data[\"triggered_at\"] = self.triggered_at.isoformat()\n    if self.closed_at:\n        data[\"closed_at\"] = self.closed_at.isoformat()\n\n    # Convert change history\n    data[\"change_history\"] = [\n        {**asdict(change), \"timestamp\": change.timestamp.isoformat()} for change in self.change_history\n    ]\n\n    # Keep numeric fields as numbers for database compatibility\n    # No float-to-string conversion needed - JSON natively supports numbers\n    # This preserves proper types for database insertion\n\n    return data\n</code></pre>"},{"location":"reference/thestrat/#thestrat.SignalMetadata.to_json","title":"to_json","text":"<pre><code>to_json() -&gt; str\n</code></pre> <p>Serialize to JSON string.</p> <p>Returns:</p> Type Description <code>str</code> <p>JSON string representation of the signal metadata</p> Source code in <code>thestrat/signals.py</code> <pre><code>def to_json(self) -&gt; str:\n    \"\"\"\n    Serialize to JSON string.\n\n    Returns:\n        JSON string representation of the signal metadata\n    \"\"\"\n    return json.dumps(self.to_dict(), default=str)\n</code></pre>"},{"location":"reference/thestrat/#thestrat.SignalMetadata.trail_stop","title":"trail_stop","text":"<pre><code>trail_stop(new_stop: float, reason: str = 'trailing_stop') -&gt; bool\n</code></pre> <p>Trail stop loss, only allowing favorable moves.</p> <p>Parameters:</p> Name Type Description Default <code>new_stop</code> <code>float</code> <p>Proposed new stop price</p> required <code>reason</code> <code>str</code> <p>Reason for trailing (default: \"trailing_stop\")</p> <code>'trailing_stop'</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if stop was trailed, False if move was unfavorable and rejected</p> Source code in <code>thestrat/signals.py</code> <pre><code>def trail_stop(self, new_stop: float, reason: str = \"trailing_stop\") -&gt; bool:\n    \"\"\"\n    Trail stop loss, only allowing favorable moves.\n\n    Args:\n        new_stop: Proposed new stop price\n        reason: Reason for trailing (default: \"trailing_stop\")\n\n    Returns:\n        True if stop was trailed, False if move was unfavorable and rejected\n    \"\"\"\n    if self.bias == SignalBias.LONG:\n        # For long trades, only trail up\n        if new_stop &gt; self.stop_price:\n            self.update_stop(new_stop, reason)\n            return True\n    else:\n        # For short trades, only trail down\n        if new_stop &lt; self.stop_price:\n            self.update_stop(new_stop, reason)\n            return True\n    return False\n</code></pre>"},{"location":"reference/thestrat/#thestrat.SignalMetadata.update_stop","title":"update_stop","text":"<pre><code>update_stop(new_stop: float, reason: str = None) -&gt; None\n</code></pre> <p>Update stop with change tracking.</p> <p>Parameters:</p> Name Type Description Default <code>new_stop</code> <code>float</code> <p>New stop loss price</p> required <code>reason</code> <code>str</code> <p>Optional reason for the update (e.g., \"trailing_stop\", \"manual_adjustment\")</p> <code>None</code> Source code in <code>thestrat/signals.py</code> <pre><code>def update_stop(self, new_stop: float, reason: str = None) -&gt; None:\n    \"\"\"\n    Update stop with change tracking.\n\n    Args:\n        new_stop: New stop loss price\n        reason: Optional reason for the update (e.g., \"trailing_stop\", \"manual_adjustment\")\n    \"\"\"\n    if new_stop == self.stop_price:\n        return\n\n    change = PriceChange(\n        field_name=\"stop_price\",\n        from_value=self.stop_price,\n        to_value=new_stop,\n        timestamp=datetime.now(),\n        reason=reason,\n    )\n    self.change_history.append(change)\n    self.stop_price = new_stop\n    self._calculate_risk_metrics()\n</code></pre>"},{"location":"reference/thestrat/#thestrat.SignalMetadata.update_target","title":"update_target","text":"<pre><code>update_target(new_target: float, reason: str = None) -&gt; None\n</code></pre> <p>Update target with change tracking.</p> <p>Parameters:</p> Name Type Description Default <code>new_target</code> <code>float</code> <p>New target price</p> required <code>reason</code> <code>str</code> <p>Optional reason for the update (e.g., \"manual_adjustment\", \"scale_out\")</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If called on continuation signals (they have no target)</p> Source code in <code>thestrat/signals.py</code> <pre><code>def update_target(self, new_target: float, reason: str = None) -&gt; None:\n    \"\"\"\n    Update target with change tracking.\n\n    Args:\n        new_target: New target price\n        reason: Optional reason for the update (e.g., \"manual_adjustment\", \"scale_out\")\n\n    Raises:\n        ValueError: If called on continuation signals (they have no target)\n    \"\"\"\n    if self.category == SignalCategory.CONTINUATION:\n        raise ValueError(\"Continuation signals have no target\")\n\n    if new_target == self.target_price:\n        return\n\n    change = PriceChange(\n        field_name=\"target_price\",\n        from_value=self.target_price,\n        to_value=new_target,\n        timestamp=datetime.now(),\n        reason=reason,\n    )\n    self.change_history.append(change)\n    self.target_price = new_target\n    self._calculate_risk_metrics()\n</code></pre>"},{"location":"reference/thestrat/#thestrat.SignalStatus","title":"SignalStatus","text":"<p>               Bases: <code>Enum</code></p> <p>Signal lifecycle status.</p>"},{"location":"reference/thestrat/#thestrat.SwingPointsConfig","title":"SwingPointsConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for swing point detection with comprehensive parameter documentation.</p>"},{"location":"reference/thestrat/#thestrat.TimeframeItemConfig","title":"TimeframeItemConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for a single timeframe item with flexible timeframe targeting.</p> <p>Methods:</p> Name Description <code>validate_timeframe_combinations</code> <p>Validate that 'all' is not mixed with specific timeframes.</p>"},{"location":"reference/thestrat/#thestrat.TimeframeItemConfig.validate_timeframe_combinations","title":"validate_timeframe_combinations","text":"<pre><code>validate_timeframe_combinations() -&gt; Self\n</code></pre> <p>Validate that 'all' is not mixed with specific timeframes.</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@model_validator(mode=\"after\")\ndef validate_timeframe_combinations(self) -&gt; Self:\n    \"\"\"Validate that 'all' is not mixed with specific timeframes.\"\"\"\n    if \"all\" in self.timeframes and len(self.timeframes) &gt; 1:\n        raise ValueError(\"'all' cannot be combined with specific timeframes\")\n    return self\n</code></pre>"},{"location":"reference/thestrat/aggregation/","title":"Aggregation","text":"<p>OHLCV timeframe aggregation</p> <p>OHLC timeframe aggregation with precise time boundary control.</p> <p>This module provides vectorized OHLC aggregation across different timeframes with support for asset class-specific timezone handling and boundary alignment.</p> <p>Classes:</p> Name Description <code>Aggregation</code> <p>Convert OHLC data between timeframes with precise time boundary control.</p>"},{"location":"reference/thestrat/aggregation/#thestrat.aggregation.Aggregation","title":"Aggregation","text":"<pre><code>Aggregation(config: AggregationConfig)\n</code></pre> <p>               Bases: <code>Component</code></p> <p>Convert OHLC data between timeframes with precise time boundary control.</p> Features <ul> <li>Time Boundary Control: hour_boundary flag for hourly+ aggregation alignment</li> <li>Session Control: session_start parameter for sub-hourly alignment</li> <li>Asset Class Support: Crypto, equities, FX, futures with timezone handling</li> <li>Vectorized Processing: Pure Polars operations for maximum performance</li> </ul> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>AggregationConfig</code> <p>Validated AggregationConfig containing all configuration settings</p> required <p>Methods:</p> Name Description <code>normalize_timezone</code> <p>Convert naive timestamps to timezone-aware using timezone resolution priority.</p> <code>process</code> <p>Convert OHLC data to target timeframes with boundary alignment.</p> <code>validate_input</code> <p>Validate input data format.</p> Source code in <code>thestrat/aggregation.py</code> <pre><code>def __init__(self, config: AggregationConfig):\n    \"\"\"\n    Initialize aggregation component with validated configuration.\n\n    Args:\n        config: Validated AggregationConfig containing all configuration settings\n    \"\"\"\n    super().__init__()\n\n    # Store the validated Pydantic config\n    self.config = config\n\n    # Extract commonly used values for convenience\n    self.target_timeframes = config.target_timeframes.copy()\n    self.asset_class = config.asset_class\n\n    # These fields are guaranteed to be non-None after model validation\n    assert config.timezone is not None\n    assert config.session_start is not None\n    assert config.hour_boundary is not None\n\n    self.timezone = config.timezone\n    self.session_start = config.session_start\n    self.hour_boundary = config.hour_boundary\n\n    # Validate all timeframes\n    from .schemas import TimeframeConfig\n\n    for tf in self.target_timeframes:\n        if not TimeframeConfig.validate_timeframe(tf):\n            raise ValueError(\n                f\"Invalid timeframe '{tf}'. Supported timeframes: {sorted(TimeframeConfig.TIMEFRAME_METADATA.keys())}\"\n            )\n</code></pre>"},{"location":"reference/thestrat/aggregation/#thestrat.aggregation.Aggregation.normalize_timezone","title":"normalize_timezone","text":"<pre><code>normalize_timezone(data: DataFrame) -&gt; DataFrame\n</code></pre> <p>Convert naive timestamps to timezone-aware using timezone resolution priority.</p> Source code in <code>thestrat/aggregation.py</code> <pre><code>def normalize_timezone(self, data: PolarsDataFrame) -&gt; PolarsDataFrame:\n    \"\"\"Convert naive timestamps to timezone-aware using timezone resolution priority.\"\"\"\n    df = data.clone()\n\n    # Check if timestamp is already timezone-aware\n    if df.schema[\"timestamp\"] == Datetime(\"us\", None):  # Naive timestamp\n        # Convert to timezone-aware\n        df = df.with_columns([col(\"timestamp\").dt.replace_time_zone(self.timezone).alias(\"timestamp\")])\n\n    return df\n</code></pre>"},{"location":"reference/thestrat/aggregation/#thestrat.aggregation.Aggregation.process","title":"process","text":"<pre><code>process(data: DataFrame | DataFrame) -&gt; DataFrame\n</code></pre> <p>Convert OHLC data to target timeframes with boundary alignment. Supports both single-timeframe and multi-timeframe source data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | DataFrame</code> <p>Input DataFrame with OHLC data</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>Aggregated OHLC DataFrame with timeframe column</p> Source code in <code>thestrat/aggregation.py</code> <pre><code>def process(self, data: PolarsDataFrame | PandasDataFrame) -&gt; PolarsDataFrame:\n    \"\"\"\n    Convert OHLC data to target timeframes with boundary alignment.\n    Supports both single-timeframe and multi-timeframe source data.\n\n    Args:\n        data: Input DataFrame with OHLC data\n\n    Returns:\n        Aggregated OHLC DataFrame with timeframe column\n    \"\"\"\n    if not self.validate_input(data):\n        raise ValueError(\"Input data validation failed\")\n\n    df = self._convert_to_polars(data)\n    df = self.normalize_timezone(df)\n\n    # Auto-detect mode\n    is_multi_timeframe = \"timeframe\" in df.columns\n\n    if is_multi_timeframe:\n        return self._process_multi_timeframe_source(df)\n    else:\n        return self._process_single_timeframe_source(df)\n</code></pre>"},{"location":"reference/thestrat/aggregation/#thestrat.aggregation.Aggregation.validate_input","title":"validate_input","text":"<pre><code>validate_input(data: DataFrame | DataFrame) -&gt; bool\n</code></pre> <p>Validate input data format.</p> Source code in <code>thestrat/aggregation.py</code> <pre><code>def validate_input(self, data: PolarsDataFrame | PandasDataFrame) -&gt; bool:\n    \"\"\"Validate input data format.\"\"\"\n    df = self._convert_to_polars(data)\n\n    # Check required columns using schema-driven approach\n    from .schemas import IndicatorSchema\n\n    required_cols = IndicatorSchema.get_required_input_columns()\n\n    # Remove timeframe if not in multi-timeframe mode\n    if \"timeframe\" not in df.columns and \"timeframe\" in required_cols:\n        required_cols = [col for col in required_cols if col != \"timeframe\"]\n\n    if not all(col in df.columns for col in required_cols):\n        return False\n\n    # Validate timeframes if in multi-timeframe mode\n    if \"timeframe\" in df.columns:\n        from .schemas import TimeframeConfig\n\n        unique_timeframes = df[\"timeframe\"].unique().to_list()\n        for tf in unique_timeframes:\n            if not TimeframeConfig.validate_timeframe(tf):\n                return False\n\n    # Check for minimum data points\n    if len(df) &lt; 2:\n        return False\n\n    return True\n</code></pre>"},{"location":"reference/thestrat/base/","title":"Base","text":"<p>Abstract base classes</p> <p>Base component classes for TheStrat module.</p> <p>This module provides the abstract base class and core functionality for all TheStrat components.</p> <p>Classes:</p> Name Description <code>Component</code> <p>Base class for all TheStrat components.</p>"},{"location":"reference/thestrat/base/#thestrat.base.Component","title":"Component","text":"<pre><code>Component()\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Base class for all TheStrat components.</p> <p>Methods:</p> Name Description <code>process</code> <p>Process data and return Polars DataFrame results.</p> <code>validate_input</code> <p>Validate input data format.</p> Source code in <code>thestrat/base.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize base component with metadata tracking.\"\"\"\n    from datetime import datetime\n\n    self._created_at = datetime.now()\n</code></pre>"},{"location":"reference/thestrat/base/#thestrat.base.Component.process","title":"process  <code>abstractmethod</code>","text":"<pre><code>process(data: DataFrame | DataFrame) -&gt; DataFrame\n</code></pre> <p>Process data and return Polars DataFrame results.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | DataFrame</code> <p>Input DataFrame (Polars or Pandas)</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>Processed PolarsDataFrame with results</p> Source code in <code>thestrat/base.py</code> <pre><code>@abstractmethod\ndef process(self, data: PolarsDataFrame | PandasDataFrame) -&gt; PolarsDataFrame:\n    \"\"\"\n    Process data and return Polars DataFrame results.\n\n    Args:\n        data: Input DataFrame (Polars or Pandas)\n\n    Returns:\n        Processed PolarsDataFrame with results\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/thestrat/base/#thestrat.base.Component.validate_input","title":"validate_input  <code>abstractmethod</code>","text":"<pre><code>validate_input(data: DataFrame | DataFrame) -&gt; None\n</code></pre> <p>Validate input data format.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | DataFrame</code> <p>Input DataFrame to validate</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If data format is invalid, with specific error message</p> Source code in <code>thestrat/base.py</code> <pre><code>@abstractmethod\ndef validate_input(self, data: PolarsDataFrame | PandasDataFrame) -&gt; None:\n    \"\"\"\n    Validate input data format.\n\n    Args:\n        data: Input DataFrame to validate\n\n    Raises:\n        ValueError: If data format is invalid, with specific error message\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/thestrat/factory/","title":"Factory","text":"<p>Component creation with factory pattern</p> <p>Factory pattern for TheStrat component creation and configuration.</p> <p>This module provides clean factory methods for creating and configuring TheStrat components with Pydantic schema validation.</p> <p>Classes:</p> Name Description <code>ComponentDict</code> <p>Type definition for component dictionary returned by Factory.create_all().</p> <code>Factory</code> <p>Factory class for creating TheStrat components.</p>"},{"location":"reference/thestrat/factory/#thestrat.factory.ComponentDict","title":"ComponentDict","text":"<p>               Bases: <code>TypedDict</code></p> <p>Type definition for component dictionary returned by Factory.create_all().</p>"},{"location":"reference/thestrat/factory/#thestrat.factory.Factory","title":"Factory","text":"<p>Factory class for creating TheStrat components.</p> <p>Provides static methods for creating individual components and class methods for creating complete processing pipelines. All methods accept validated Pydantic configuration models.</p> <p>Methods:</p> Name Description <code>create_aggregation</code> <p>Create aggregation component from validated configuration.</p> <code>create_all</code> <p>Create complete processing pipeline with aggregation and indicators.</p> <code>create_indicators</code> <p>Create indicators component from validated configuration.</p> <code>get_asset_class_config</code> <p>Get default configuration for specific asset class.</p> <code>get_supported_asset_classes</code> <p>Get list of supported asset classes.</p> <code>get_supported_timeframes</code> <p>Get list of all supported timeframes in chronological order.</p> <code>get_timeframe_metadata</code> <p>Get detailed metadata for a specific timeframe.</p>"},{"location":"reference/thestrat/factory/#thestrat.factory.Factory.create_aggregation","title":"create_aggregation  <code>staticmethod</code>","text":"<pre><code>create_aggregation(config: AggregationConfig) -&gt; Aggregation\n</code></pre> <p>Create aggregation component from validated configuration.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>AggregationConfig</code> <p>Validated AggregationConfig containing: - <code>target_timeframes</code>: Target timeframes list (e.g., [\"1H\", \"5m\", \"1D\"]) - <code>asset_class</code>: Asset class type (crypto, equities, fx, futures, commodities) - <code>timezone</code>: Timezone override (UTC asset classes always use UTC;            non-UTC uses priority: specified &gt; system &gt; asset_class default) - <code>hour_boundary</code>: Align to hour boundaries (auto-determined if None) - <code>session_start</code>: Session start time (asset class default if None)</p> required <p>Returns:</p> Type Description <code>Aggregation</code> <p>Configured Aggregation component</p> Example <p>from thestrat.schemas import AggregationConfig config = AggregationConfig( ...     target_timeframes=[\"5m\", \"1H\"], ...     asset_class=\"crypto\", ...     timezone=\"UTC\" ... ) aggregation = Factory.create_aggregation(config)</p> Source code in <code>thestrat/factory.py</code> <pre><code>@staticmethod\ndef create_aggregation(config: AggregationConfig) -&gt; Aggregation:\n    \"\"\"\n    Create aggregation component from validated configuration.\n\n    Args:\n        config: Validated AggregationConfig containing:\n            - `target_timeframes`: Target timeframes list (e.g., [\"1H\", \"5m\", \"1D\"])\n            - `asset_class`: Asset class type (crypto, equities, fx, futures, commodities)\n            - `timezone`: Timezone override (UTC asset classes always use UTC;\n                       non-UTC uses priority: specified &gt; system &gt; asset_class default)\n            - `hour_boundary`: Align to hour boundaries (auto-determined if None)\n            - `session_start`: Session start time (asset class default if None)\n\n    Returns:\n        Configured Aggregation component\n\n    Example:\n        &gt;&gt;&gt; from thestrat.schemas import AggregationConfig\n        &gt;&gt;&gt; config = AggregationConfig(\n        ...     target_timeframes=[\"5m\", \"1H\"],\n        ...     asset_class=\"crypto\",\n        ...     timezone=\"UTC\"\n        ... )\n        &gt;&gt;&gt; aggregation = Factory.create_aggregation(config)\n    \"\"\"\n    return Aggregation(config)\n</code></pre>"},{"location":"reference/thestrat/factory/#thestrat.factory.Factory.create_all","title":"create_all  <code>classmethod</code>","text":"<pre><code>create_all(config: FactoryConfig) -&gt; ComponentDict\n</code></pre> <p>Create complete processing pipeline with aggregation and indicators.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>FactoryConfig</code> <p>Validated FactoryConfig containing: <code>aggregation</code>: AggregationConfig with target timeframes and settings <code>indicators</code>: IndicatorsConfig with per-timeframe configurations</p> required <p>Returns:</p> Type Description <code>ComponentDict</code> <p>Dictionary containing created components:</p> <code>ComponentDict</code> <p>{ \"aggregation\": Aggregation, \"indicators\": Indicators</p> <code>ComponentDict</code> <p>}</p> Example <p>from thestrat.schemas import FactoryConfig, AggregationConfig, IndicatorsConfig, TimeframeItemConfig config = FactoryConfig( ...     aggregation=AggregationConfig(target_timeframes=[\"5m\"]), ...     indicators=IndicatorsConfig( ...         timeframe_configs=[TimeframeItemConfig(timeframes=[\"all\"])] ...     ) ... ) components = Factory.create_all(config)</p> Source code in <code>thestrat/factory.py</code> <pre><code>@classmethod\ndef create_all(cls, config: FactoryConfig) -&gt; ComponentDict:\n    \"\"\"\n    Create complete processing pipeline with aggregation and indicators.\n\n    Args:\n        config: Validated FactoryConfig containing:\n            `aggregation`: AggregationConfig with target timeframes and settings\n            `indicators`: IndicatorsConfig with per-timeframe configurations\n\n    Returns:\n        Dictionary containing created components:\n        {\n            \"aggregation\": Aggregation,\n            \"indicators\": Indicators\n        }\n\n    Example:\n        &gt;&gt;&gt; from thestrat.schemas import FactoryConfig, AggregationConfig, IndicatorsConfig, TimeframeItemConfig\n        &gt;&gt;&gt; config = FactoryConfig(\n        ...     aggregation=AggregationConfig(target_timeframes=[\"5m\"]),\n        ...     indicators=IndicatorsConfig(\n        ...         timeframe_configs=[TimeframeItemConfig(timeframes=[\"all\"])]\n        ...     )\n        ... )\n        &gt;&gt;&gt; components = Factory.create_all(config)\n    \"\"\"\n    return {\n        \"aggregation\": cls.create_aggregation(config.aggregation),\n        \"indicators\": cls.create_indicators(config.indicators),\n    }\n</code></pre>"},{"location":"reference/thestrat/factory/#thestrat.factory.Factory.create_indicators","title":"create_indicators  <code>staticmethod</code>","text":"<pre><code>create_indicators(config: IndicatorsConfig) -&gt; Indicators\n</code></pre> <p>Create indicators component from validated configuration.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>IndicatorsConfig</code> <p>Validated IndicatorsConfig containing per-timeframe configurations using Pydantic models</p> required <p>Returns:</p> Type Description <code>Indicators</code> <p>Configured Indicators component</p> Example <p>from thestrat.schemas import IndicatorsConfig, TimeframeItemConfig, SwingPointsConfig config = IndicatorsConfig( ...     timeframe_configs=[ ...         TimeframeItemConfig( ...             timeframes=[\"5m\", \"15m\"], ...             swing_points=SwingPointsConfig(window=7, threshold=3.0) ...         ) ...     ] ... ) indicators = Factory.create_indicators(config)</p> Source code in <code>thestrat/factory.py</code> <pre><code>@staticmethod\ndef create_indicators(config: IndicatorsConfig) -&gt; Indicators:\n    \"\"\"\n    Create indicators component from validated configuration.\n\n    Args:\n        config: Validated IndicatorsConfig containing per-timeframe configurations\n            using Pydantic models\n\n    Returns:\n        Configured Indicators component\n\n    Example:\n        &gt;&gt;&gt; from thestrat.schemas import IndicatorsConfig, TimeframeItemConfig, SwingPointsConfig\n        &gt;&gt;&gt; config = IndicatorsConfig(\n        ...     timeframe_configs=[\n        ...         TimeframeItemConfig(\n        ...             timeframes=[\"5m\", \"15m\"],\n        ...             swing_points=SwingPointsConfig(window=7, threshold=3.0)\n        ...         )\n        ...     ]\n        ... )\n        &gt;&gt;&gt; indicators = Factory.create_indicators(config)\n    \"\"\"\n    return Indicators(config)\n</code></pre>"},{"location":"reference/thestrat/factory/#thestrat.factory.Factory.get_asset_class_config","title":"get_asset_class_config  <code>staticmethod</code>","text":"<pre><code>get_asset_class_config(asset_class: str) -&gt; dict[str, Any]\n</code></pre> <p>Get default configuration for specific asset class.</p> <p>Parameters:</p> Name Type Description Default <code>asset_class</code> <code>str</code> <p>Asset class type</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary with default <code>timezone</code> and <code>session_start</code></p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If asset_class is not supported</p> Source code in <code>thestrat/factory.py</code> <pre><code>@staticmethod\ndef get_asset_class_config(asset_class: str) -&gt; dict[str, Any]:\n    \"\"\"\n    Get default configuration for specific asset class.\n\n    Args:\n        asset_class: Asset class type\n\n    Returns:\n        Dictionary with default `timezone` and `session_start`\n\n    Raises:\n        ValueError: If asset_class is not supported\n    \"\"\"\n    from .schemas import AssetClassConfig\n\n    if asset_class not in Factory.get_supported_asset_classes():\n        raise ValueError(f\"Unsupported asset class: {asset_class}\")\n\n    return AssetClassConfig.REGISTRY[asset_class].model_dump()\n</code></pre>"},{"location":"reference/thestrat/factory/#thestrat.factory.Factory.get_supported_asset_classes","title":"get_supported_asset_classes  <code>staticmethod</code>","text":"<pre><code>get_supported_asset_classes() -&gt; list[str]\n</code></pre> <p>Get list of supported asset classes.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of supported asset class strings</p> Source code in <code>thestrat/factory.py</code> <pre><code>@staticmethod\ndef get_supported_asset_classes() -&gt; list[str]:\n    \"\"\"\n    Get list of supported asset classes.\n\n    Returns:\n        List of supported asset class strings\n    \"\"\"\n    from .schemas import AssetClassConfig\n\n    return list(AssetClassConfig.REGISTRY.keys())\n</code></pre>"},{"location":"reference/thestrat/factory/#thestrat.factory.Factory.get_supported_timeframes","title":"get_supported_timeframes  <code>cached</code> <code>staticmethod</code>","text":"<pre><code>get_supported_timeframes() -&gt; list[str]\n</code></pre> <p>Get list of all supported timeframes in chronological order.</p> <p>Returns a chronologically ordered list of timeframe strings that can be used with the aggregation and indicators components. These timeframes are validated when creating configurations.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>Chronologically ordered list of supported timeframe strings (shortest to longest)</p> Example <p>from thestrat import Factory timeframes = Factory.get_supported_timeframes() print(timeframes) ['1min', '5min', '15min', '30min', '1h', '4h', '6h', '12h', '1d', '1w', '1m', '1q', '1y']</p> Note <p>The timeframes are ordered by duration (shortest to longest) and follow standard conventions: - Minutes: <code>1min</code>, <code>5min</code>, <code>15min</code>, <code>30min</code> - Hours: <code>1h</code>, <code>4h</code>, <code>6h</code>, <code>12h</code> - Days/Weeks/Months: <code>1d</code>, <code>1w</code>, <code>1m</code> (month), <code>1q</code> (quarter), <code>1y</code></p> Source code in <code>thestrat/factory.py</code> <pre><code>@staticmethod\n@lru_cache(maxsize=1)\ndef get_supported_timeframes() -&gt; list[str]:\n    \"\"\"\n    Get list of all supported timeframes in chronological order.\n\n    Returns a chronologically ordered list of timeframe strings that can be used with\n    the aggregation and indicators components. These timeframes are\n    validated when creating configurations.\n\n    Returns:\n        Chronologically ordered list of supported timeframe strings (shortest to longest)\n\n    Example:\n        &gt;&gt;&gt; from thestrat import Factory\n        &gt;&gt;&gt; timeframes = Factory.get_supported_timeframes()\n        &gt;&gt;&gt; print(timeframes)\n        ['1min', '5min', '15min', '30min', '1h', '4h', '6h', '12h', '1d', '1w', '1m', '1q', '1y']\n\n        &gt;&gt;&gt; # Use in configuration\n        &gt;&gt;&gt; from thestrat.schemas import AggregationConfig\n        &gt;&gt;&gt; available_timeframes = Factory.get_supported_timeframes()\n        &gt;&gt;&gt; config = AggregationConfig(\n        ...     target_timeframes=[available_timeframes[0], available_timeframes[1]],\n        ...     asset_class=\"equities\"\n        ... )\n\n    Note:\n        The timeframes are ordered by duration (shortest to longest) and follow standard conventions:\n        - Minutes: `1min`, `5min`, `15min`, `30min`\n        - Hours: `1h`, `4h`, `6h`, `12h`\n        - Days/Weeks/Months: `1d`, `1w`, `1m` (month), `1q` (quarter), `1y`\n    \"\"\"\n    from .schemas import TimeframeConfig\n\n    # Pre-compute timeframes with their durations for efficient sorting\n    timeframes_with_duration = [\n        (tf, TimeframeConfig.TIMEFRAME_METADATA.get(tf, {}).get(\"seconds\", float(\"inf\")))\n        for tf in TimeframeConfig.TIMEFRAME_METADATA.keys()\n    ]\n\n    # Sort by duration and return just the timeframe strings\n    return [tf for tf, _ in sorted(timeframes_with_duration, key=lambda x: x[1])]\n</code></pre>"},{"location":"reference/thestrat/factory/#thestrat.factory.Factory.get_supported_timeframes--use-in-configuration","title":"Use in configuration","text":"<p>from thestrat.schemas import AggregationConfig available_timeframes = Factory.get_supported_timeframes() config = AggregationConfig( ...     target_timeframes=[available_timeframes[0], available_timeframes[1]], ...     asset_class=\"equities\" ... )</p>"},{"location":"reference/thestrat/factory/#thestrat.factory.Factory.get_timeframe_metadata","title":"get_timeframe_metadata  <code>staticmethod</code>","text":"<pre><code>get_timeframe_metadata(timeframe: str) -&gt; dict[str, Any]\n</code></pre> <p>Get detailed metadata for a specific timeframe.</p> <p>Provides comprehensive information about a timeframe including its category, duration in seconds, description, and typical use cases. This is useful for understanding the characteristics and appropriate applications of different timeframes.</p> <p>Parameters:</p> Name Type Description Default <code>timeframe</code> <code>str</code> <p>Timeframe string to get metadata for (e.g., \"5min\", \"1h\", \"1d\")</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary containing:</p> <code>dict[str, Any]</code> <ul> <li><code>category</code>: Timeframe category (e.g., \"sub-hourly\", \"hourly\", \"daily\")</li> </ul> <code>dict[str, Any]</code> <ul> <li><code>seconds</code>: Duration in seconds</li> </ul> <code>dict[str, Any]</code> <ul> <li><code>description</code>: Human-readable description</li> </ul> <code>dict[str, Any]</code> <ul> <li><code>typical_use</code>: Common use cases for this timeframe</li> </ul> <code>dict[str, Any]</code> <ul> <li><code>data_volume</code>: Expected data volume level</li> </ul> <p>Raises:</p> Type Description <code>ValueError</code> <p>If timeframe is not supported</p> Example <p>from thestrat import Factory metadata = Factory.get_timeframe_metadata(\"1h\") print(metadata) {     'category': 'hourly',     'seconds': 3600,     'description': '1-hour bars for daily structure analysis',     'typical_use': 'Day trading context, hourly levels',     'data_volume': 'low' }</p> See Also <ul> <li>:meth:<code>get_supported_timeframes</code>: Get list of all supported timeframes</li> <li>:meth:<code>validate_timeframe_format</code>: Validate a timeframe string</li> </ul> Source code in <code>thestrat/factory.py</code> <pre><code>@staticmethod\ndef get_timeframe_metadata(timeframe: str) -&gt; dict[str, Any]:\n    \"\"\"\n    Get detailed metadata for a specific timeframe.\n\n    Provides comprehensive information about a timeframe including its\n    category, duration in seconds, description, and typical use cases.\n    This is useful for understanding the characteristics and appropriate\n    applications of different timeframes.\n\n    Args:\n        timeframe: Timeframe string to get metadata for (e.g., \"5min\", \"1h\", \"1d\")\n\n    Returns:\n        Dictionary containing:\n        - `category`: Timeframe category (e.g., \"sub-hourly\", \"hourly\", \"daily\")\n        - `seconds`: Duration in seconds\n        - `description`: Human-readable description\n        - `typical_use`: Common use cases for this timeframe\n        - `data_volume`: Expected data volume level\n\n    Raises:\n        ValueError: If timeframe is not supported\n\n    Example:\n        &gt;&gt;&gt; from thestrat import Factory\n        &gt;&gt;&gt; metadata = Factory.get_timeframe_metadata(\"1h\")\n        &gt;&gt;&gt; print(metadata)\n        {\n            'category': 'hourly',\n            'seconds': 3600,\n            'description': '1-hour bars for daily structure analysis',\n            'typical_use': 'Day trading context, hourly levels',\n            'data_volume': 'low'\n        }\n\n        &gt;&gt;&gt; # Check if a timeframe is suitable for day trading\n        &gt;&gt;&gt; metadata = Factory.get_timeframe_metadata(\"5min\")\n        &gt;&gt;&gt; if \"day trading\" in metadata[\"typical_use\"].lower():\n        ...     print(f\"5min is suitable for day trading\")\n\n        &gt;&gt;&gt; # Get all intraday timeframes\n        &gt;&gt;&gt; all_timeframes = Factory.get_supported_timeframes()\n        &gt;&gt;&gt; intraday = []\n        &gt;&gt;&gt; for tf in all_timeframes:\n        ...     meta = Factory.get_timeframe_metadata(tf)\n        ...     if meta[\"category\"] in [\"sub-hourly\", \"hourly\"]:\n        ...         intraday.append(tf)\n\n    See Also:\n        - :meth:`get_supported_timeframes`: Get list of all supported timeframes\n        - :meth:`validate_timeframe_format`: Validate a timeframe string\n    \"\"\"\n    # Use cached helper method to get metadata efficiently\n    metadata = Factory._get_cached_timeframe_metadata(timeframe)\n    return metadata.copy()  # Return a copy to prevent modification\n</code></pre>"},{"location":"reference/thestrat/factory/#thestrat.factory.Factory.get_timeframe_metadata--check-if-a-timeframe-is-suitable-for-day-trading","title":"Check if a timeframe is suitable for day trading","text":"<p>metadata = Factory.get_timeframe_metadata(\"5min\") if \"day trading\" in metadata[\"typical_use\"].lower(): ...     print(f\"5min is suitable for day trading\")</p>"},{"location":"reference/thestrat/factory/#thestrat.factory.Factory.get_timeframe_metadata--get-all-intraday-timeframes","title":"Get all intraday timeframes","text":"<p>all_timeframes = Factory.get_supported_timeframes() intraday = [] for tf in all_timeframes: ...     meta = Factory.get_timeframe_metadata(tf) ...     if meta[\"category\"] in [\"sub-hourly\", \"hourly\"]: ...         intraday.append(tf)</p>"},{"location":"reference/thestrat/indicators/","title":"Indicators","text":"<p>TheStrat technical indicators</p> <p>Vectorized Strat technical indicators implementation.</p> <p>This module provides comprehensive Strat pattern analysis with high-performance vectorized calculations using Polars operations.</p> <p>Classes:</p> Name Description <code>Indicators</code> <p>Vectorized implementation of all Strat technical indicators.</p>"},{"location":"reference/thestrat/indicators/#thestrat.indicators.Indicators","title":"Indicators","text":"<pre><code>Indicators(config: IndicatorsConfig)\n</code></pre> <p>               Bases: <code>Component</code></p> <p>Vectorized implementation of all Strat technical indicators.</p> <p>Provides comprehensive technical analysis including swing point detection, market structure analysis, pattern recognition, and gap detection optimized for TheStrat methodology.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>IndicatorsConfig</code> <p>Validated IndicatorsConfig containing per-timeframe configurations</p> required <p>Methods:</p> Name Description <code>get_signal_objects</code> <p>Create SignalMetadata objects on-demand from processed indicator results.</p> <code>process</code> <p>Calculate all Strat indicators for OHLC data.</p> <code>validate_input</code> <p>Validate input data format.</p> Source code in <code>thestrat/indicators.py</code> <pre><code>def __init__(self, config: IndicatorsConfig):\n    \"\"\"\n    Initialize indicators component with validated configuration.\n\n    Args:\n        config: Validated IndicatorsConfig containing per-timeframe configurations\n    \"\"\"\n    super().__init__()\n\n    # Store the validated Pydantic config\n    self.config = config\n</code></pre>"},{"location":"reference/thestrat/indicators/#thestrat.indicators.Indicators.get_signal_objects","title":"get_signal_objects","text":"<pre><code>get_signal_objects(result_df: DataFrame) -&gt; list\n</code></pre> <p>Create SignalMetadata objects on-demand from processed indicator results.</p> <p>This method processes rows with signals and creates full SignalMetadata objects with prices and trading context. Only used when signal objects are needed.</p> <p>Parameters:</p> Name Type Description Default <code>result_df</code> <code>DataFrame</code> <p>DataFrame with processed indicators including signal columns</p> required <p>Returns:</p> Type Description <code>list</code> <p>List of SignalMetadata objects for rows with detected signals</p> Source code in <code>thestrat/indicators.py</code> <pre><code>def get_signal_objects(self, result_df: PolarsDataFrame) -&gt; list:\n    \"\"\"\n    Create SignalMetadata objects on-demand from processed indicator results.\n\n    This method processes rows with signals and creates full SignalMetadata objects\n    with prices and trading context. Only used when signal objects are needed.\n\n    Args:\n        result_df: DataFrame with processed indicators including signal columns\n\n    Returns:\n        List of SignalMetadata objects for rows with detected signals\n    \"\"\"\n    signal_objects = []\n\n    # Add row index to track original positions\n    df_with_index = result_df.with_row_index(\"__original_idx\")\n\n    # Filter to rows with signals\n    signal_rows = df_with_index.filter(col(\"signal\").is_not_null())\n\n    if len(signal_rows) == 0:\n        return signal_objects\n\n    # Convert to pandas for row-by-row processing\n    signal_data = signal_rows.to_pandas()\n\n    for _, row in signal_data.iterrows():\n        original_index = int(row[\"__original_idx\"])\n        signal_obj = self._create_signal_object(\n            df_with_index, original_index, row[\"signal\"], row[\"type\"], row[\"bias\"]\n        )\n        if signal_obj:\n            signal_objects.append(signal_obj)\n\n    return signal_objects\n</code></pre>"},{"location":"reference/thestrat/indicators/#thestrat.indicators.Indicators.process","title":"process","text":"<pre><code>process(data: DataFrame | DataFrame) -&gt; DataFrame\n</code></pre> <p>Calculate all Strat indicators for OHLC data.</p> <p>Performs comprehensive technical analysis including swing point detection, market structure analysis, pattern recognition, and gap detection. Calculations run sequentially due to data dependencies between indicators.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame | DataFrame</code> <p>Input DataFrame with OHLC data</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame with all Strat indicators added</p> Source code in <code>thestrat/indicators.py</code> <pre><code>def process(self, data: PolarsDataFrame | PandasDataFrame) -&gt; PolarsDataFrame:\n    \"\"\"\n    Calculate all Strat indicators for OHLC data.\n\n    Performs comprehensive technical analysis including swing point detection, market structure\n    analysis, pattern recognition, and gap detection. Calculations run sequentially due to\n    data dependencies between indicators.\n\n    Args:\n        data: Input DataFrame with OHLC data\n\n    Returns:\n        DataFrame with all Strat indicators added\n    \"\"\"\n    self.validate_input(data)\n\n    # Convert to Polars if needed\n    df = self._convert_to_polars(data)\n\n    # Ensure optional schema columns are present\n    if \"symbol\" not in df.columns:\n        df = df.with_columns(lit(None, dtype=String).alias(\"symbol\"))\n\n    # Check if data has timeframe column for per-timeframe processing\n    if \"timeframe\" in df.columns:\n        # Check if \"all\" timeframe is configured\n        has_all_config = any(\"all\" in tf_config.timeframes for tf_config in self.config.timeframe_configs)\n\n        if has_all_config:\n            # Process all data with the \"all\" configuration\n            all_config = self._get_config_for_timeframe(\"any_timeframe_will_get_all_config\")\n            df = self._process_single_timeframe(df, all_config)\n        else:\n            # Process each timeframe group with its specific configuration\n            timeframe_groups = df.partition_by(\"timeframe\", as_dict=True)\n            processed_groups = []\n\n            for timeframe_key, timeframe_data in timeframe_groups.items():\n                # Extract timeframe string from tuple key\n                timeframe = timeframe_key[0] if isinstance(timeframe_key, tuple) else timeframe_key\n\n                # Get config for this timeframe\n                tf_config = self._get_config_for_timeframe(timeframe)\n\n                # Process this timeframe with its specific config\n                processed_data = self._process_single_timeframe(timeframe_data, tf_config)\n                processed_groups.append(processed_data)\n\n            # Combine all processed groups\n            df = processed_groups[0]\n            for group in processed_groups[1:]:\n                df = df.vstack(group)\n\n            # Sort by original order (symbol, timeframe, timestamp)\n            sort_cols = []\n            if \"symbol\" in df.columns:\n                sort_cols.append(\"symbol\")\n            sort_cols.extend([\"timeframe\", \"timestamp\"])\n            df = df.sort(sort_cols)\n    else:\n        # No timeframe column - must have \"all\" configuration\n        has_all_config = any(\"all\" in tf_config.timeframes for tf_config in self.config.timeframe_configs)\n        if not has_all_config:\n            raise ValueError(\"Data without timeframe column requires an 'all' timeframe configuration.\")\n\n        all_config = self._get_config_for_timeframe(\"any_timeframe_will_get_all_config\")\n        df = self._process_single_timeframe(df, all_config)\n\n    return df\n</code></pre>"},{"location":"reference/thestrat/indicators/#thestrat.indicators.Indicators.validate_input","title":"validate_input","text":"<pre><code>validate_input(data: DataFrame | DataFrame) -&gt; None\n</code></pre> <p>Validate input data format.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If data format is invalid, with specific error message</p> Source code in <code>thestrat/indicators.py</code> <pre><code>def validate_input(self, data: PolarsDataFrame | PandasDataFrame) -&gt; None:\n    \"\"\"\n    Validate input data format.\n\n    Raises:\n        ValueError: If data format is invalid, with specific error message\n    \"\"\"\n    df = self._convert_to_polars(data)\n\n    # Check required columns\n    required_cols = [\"timestamp\", \"open\", \"high\", \"low\", \"close\"]\n    missing_cols = [col for col in required_cols if col not in df.columns]\n    if missing_cols:\n        raise ValueError(f\"Missing required columns: {missing_cols}\")\n\n    # Note: Minimum data point validation removed as _calculate_swing_points\n    # now handles small datasets gracefully with proper safeguards\n\n    # Verify price data integrity\n    validations = df.select(\n        [\n            (col(\"high\") &gt;= col(\"low\")).all().alias(\"high_gte_low\"),\n            (col(\"high\") &gt;= col(\"open\")).all().alias(\"high_gte_open\"),\n            (col(\"high\") &gt;= col(\"close\")).all().alias(\"high_gte_close\"),\n            (col(\"low\") &lt;= col(\"open\")).all().alias(\"low_lte_open\"),\n            (col(\"low\") &lt;= col(\"close\")).all().alias(\"low_lte_close\"),\n        ]\n    )\n\n    validation_results = validations.to_numpy().flatten()\n    validation_names = [\"high &gt;= low\", \"high &gt;= open\", \"high &gt;= close\", \"low &lt;= open\", \"low &lt;= close\"]\n\n    failed_validations = [\n        name for name, result in zip(validation_names, validation_results, strict=False) if not result\n    ]\n    if failed_validations:\n        raise ValueError(f\"Invalid price data: failed validations: {failed_validations}\")\n</code></pre>"},{"location":"reference/thestrat/schemas/","title":"Schemas","text":"<p>Pydantic configuration schemas</p> <p>Pydantic schema models for TheStrat configuration validation.</p> <p>This module provides comprehensive validation schemas that replace all manual validation logic in the Factory class. Models use Pydantic v2 features for maximum performance, type safety, and detailed error reporting.</p> <p>Classes:</p> Name Description <code>AggregationConfig</code> <p>Complete configuration for aggregation component with market-aware settings.</p> <code>AssetClassConfig</code> <p>Configuration for a specific asset class with comprehensive market metadata.</p> <code>FactoryConfig</code> <p>Root configuration for Factory.create_all method with complete pipeline setup.</p> <code>GapDetectionConfig</code> <p>Configuration for gap detection with comprehensive threshold documentation.</p> <code>IndicatorSchema</code> <p>Complete Indicator Schema</p> <code>IndicatorsConfig</code> <p>Complete configuration for indicators component with per-timeframe settings.</p> <code>SwingPointsConfig</code> <p>Configuration for swing point detection with comprehensive parameter documentation.</p> <code>TimeframeConfig</code> <p>Configuration and validation for timeframes with comprehensive metadata.</p> <code>TimeframeItemConfig</code> <p>Configuration for a single timeframe item with flexible timeframe targeting.</p>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.AggregationConfig","title":"AggregationConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Complete configuration for aggregation component with market-aware settings.</p> <p>Methods:</p> Name Description <code>apply_asset_class_defaults</code> <p>Apply AssetClassConfig defaults for timezone, hour_boundary, and session_start.</p> <code>validate_and_expand_target_timeframes</code> <p>Validate target_timeframes field and expand 'all' keyword.</p>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.AggregationConfig.apply_asset_class_defaults","title":"apply_asset_class_defaults  <code>classmethod</code>","text":"<pre><code>apply_asset_class_defaults(data: Any) -&gt; Any\n</code></pre> <p>Apply AssetClassConfig defaults for timezone, hour_boundary, and session_start.</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@model_validator(mode=\"before\")\n@classmethod\ndef apply_asset_class_defaults(cls, data: Any) -&gt; Any:\n    \"\"\"Apply AssetClassConfig defaults for timezone, hour_boundary, and session_start.\"\"\"\n    if not isinstance(data, dict):\n        return data\n\n    # Get asset class, default to \"equities\"\n    asset_class = data.get(\"asset_class\", \"equities\")\n    asset_config = AssetClassConfig.get_config(asset_class)\n\n    # Force UTC timezone for crypto and fx regardless of input\n    if asset_class in [\"crypto\", \"fx\"]:\n        data[\"timezone\"] = \"UTC\"\n    elif \"timezone\" not in data or data[\"timezone\"] is None:\n        data[\"timezone\"] = asset_config.timezone\n\n    # Apply other defaults only if fields are not provided or are None\n    if \"hour_boundary\" not in data or data[\"hour_boundary\"] is None:\n        data[\"hour_boundary\"] = asset_config.hour_boundary\n    if \"session_start\" not in data or data[\"session_start\"] is None:\n        data[\"session_start\"] = asset_config.session_start\n\n    return data\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.AggregationConfig.validate_and_expand_target_timeframes","title":"validate_and_expand_target_timeframes  <code>classmethod</code>","text":"<pre><code>validate_and_expand_target_timeframes(\n    target_timeframes: list[str],\n) -&gt; list[str]\n</code></pre> <p>Validate target_timeframes field and expand 'all' keyword.</p> <p>This Pydantic field validator is automatically called when AggregationConfig is instantiated. It validates individual timeframes and expands ['all'] to all supported timeframes.</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@field_validator(\"target_timeframes\")\n@classmethod\ndef validate_and_expand_target_timeframes(cls, target_timeframes: list[str]) -&gt; list[str]:\n    \"\"\"\n    Validate target_timeframes field and expand 'all' keyword.\n\n    This Pydantic field validator is automatically called when AggregationConfig\n    is instantiated. It validates individual timeframes and expands ['all'] to\n    all supported timeframes.\n    \"\"\"\n    if not target_timeframes:\n        raise ValueError(\"target_timeframes cannot be empty\")\n\n    # Check for 'all' keyword\n    if \"all\" in target_timeframes:\n        if len(target_timeframes) &gt; 1:\n            raise ValueError(\"'all' cannot be combined with specific timeframes\")\n        # Expand to all supported timeframes\n        return list(TimeframeConfig.TIMEFRAME_METADATA.keys())\n\n    # Validate each specific timeframe\n    for i, timeframe in enumerate(target_timeframes):\n        if not isinstance(timeframe, str) or not timeframe.strip():\n            raise ValueError(f\"target_timeframes[{i}] must be a non-empty string\")\n\n        # Validate timeframe format using TimeframeConfig\n        if not TimeframeConfig.validate_timeframe(timeframe):\n            raise ValueError(f\"Invalid timeframe '{timeframe}'\")\n\n    return target_timeframes\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.AssetClassConfig","title":"AssetClassConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for a specific asset class with comprehensive market metadata.</p> <p>Methods:</p> Name Description <code>get_config</code> <p>Get configuration for specific asset class.</p>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.AssetClassConfig.get_config","title":"get_config  <code>classmethod</code>","text":"<pre><code>get_config(asset_class: str) -&gt; AssetClassConfig\n</code></pre> <p>Get configuration for specific asset class.</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_config(cls, asset_class: str) -&gt; \"AssetClassConfig\":\n    \"\"\"Get configuration for specific asset class.\"\"\"\n    return cls.REGISTRY.get(asset_class, cls.REGISTRY[\"equities\"])\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.FactoryConfig","title":"FactoryConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Root configuration for Factory.create_all method with complete pipeline setup.</p> <p>Methods:</p> Name Description <code>validate_configuration_consistency</code> <p>Validate consistency between aggregation and indicators configurations.</p>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.FactoryConfig.validate_configuration_consistency","title":"validate_configuration_consistency","text":"<pre><code>validate_configuration_consistency() -&gt; Self\n</code></pre> <p>Validate consistency between aggregation and indicators configurations.</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@model_validator(mode=\"after\")\ndef validate_configuration_consistency(self) -&gt; Self:\n    \"\"\"Validate consistency between aggregation and indicators configurations.\"\"\"\n    # Future enhancement: Could validate that indicator timeframes are compatible\n    # with aggregation target timeframes, but this is not currently enforced\n    # in the existing system\n    return self\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.GapDetectionConfig","title":"GapDetectionConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for gap detection with comprehensive threshold documentation.</p>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.IndicatorSchema","title":"IndicatorSchema","text":"<p>               Bases: <code>BaseModel</code></p> <p>Complete Indicator Schema</p> <p>Defines all columns that are created by TheStrat processing pipeline. All columns are required as the indicators component creates them all.</p> <p>Methods:</p> Name Description <code>get_all_input_columns</code> <p>Get list of all input columns (required + optional).</p> <code>get_column_categories</code> <p>Get columns organized by functional categories.</p> <code>get_column_descriptions</code> <p>Get descriptions for all possible DataFrame columns.</p> <code>get_field_metadata</code> <p>Get json_schema_extra metadata for a field, safely handling missing data.</p> <code>get_optional_input_columns</code> <p>Get list of optional input columns based on schema definition.</p> <code>get_polars_dtypes</code> <p>Get Polars data types for all DataFrame columns.</p> <code>get_required_input_columns</code> <p>Get list of required input columns based on schema definition.</p> <code>validate_dataframe</code> <p>Validate input DataFrame columns and data types against IndicatorSchema input requirements.</p>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.IndicatorSchema.get_all_input_columns","title":"get_all_input_columns  <code>classmethod</code>","text":"<pre><code>get_all_input_columns() -&gt; list[str]\n</code></pre> <p>Get list of all input columns (required + optional).</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of all input column names</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_all_input_columns(cls) -&gt; list[str]:\n    \"\"\"\n    Get list of all input columns (required + optional).\n\n    Returns:\n        List of all input column names\n    \"\"\"\n    return sorted(cls.get_required_input_columns() + cls.get_optional_input_columns())\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.IndicatorSchema.get_column_categories","title":"get_column_categories  <code>classmethod</code>","text":"<pre><code>get_column_categories() -&gt; dict[str, list[str]]\n</code></pre> <p>Get columns organized by functional categories.</p> <p>Dynamically extracts categories from the IndicatorSchema metadata.</p> <p>Returns:</p> Type Description <code>dict[str, list[str]]</code> <p>Dictionary mapping category names to lists of column names</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_column_categories(cls) -&gt; dict[str, list[str]]:\n    \"\"\"\n    Get columns organized by functional categories.\n\n    Dynamically extracts categories from the IndicatorSchema metadata.\n\n    Returns:\n        Dictionary mapping category names to lists of column names\n    \"\"\"\n    categories: dict[str, list[str]] = {}\n\n    for field_name, field_info in cls.model_fields.items():\n        json_extra = getattr(field_info, \"json_schema_extra\", {})\n        if isinstance(json_extra, dict) and \"category\" in json_extra:\n            category = json_extra[\"category\"]\n            if category not in categories:\n                categories[category] = []\n            categories[category].append(field_name)\n\n    # Sort columns within each category for consistent output\n    for category in categories:\n        categories[category].sort()\n\n    return categories\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.IndicatorSchema.get_column_descriptions","title":"get_column_descriptions  <code>classmethod</code>","text":"<pre><code>get_column_descriptions() -&gt; dict[str, str]\n</code></pre> <p>Get descriptions for all possible DataFrame columns.</p> <p>Returns:</p> Type Description <code>dict[str, str]</code> <p>Dictionary mapping column names to their descriptions</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_column_descriptions(cls) -&gt; dict[str, str]:\n    \"\"\"\n    Get descriptions for all possible DataFrame columns.\n\n    Returns:\n        Dictionary mapping column names to their descriptions\n    \"\"\"\n    descriptions = {}\n\n    # Get descriptions from the schema\n    for field_name, field_info in cls.model_fields.items():\n        if field_info.description:\n            descriptions[field_name] = field_info.description\n\n    return descriptions\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.IndicatorSchema.get_field_metadata","title":"get_field_metadata  <code>classmethod</code>","text":"<pre><code>get_field_metadata(field_name: str) -&gt; dict[str, Any]\n</code></pre> <p>Get json_schema_extra metadata for a field, safely handling missing data.</p> <p>Parameters:</p> Name Type Description Default <code>field_name</code> <code>str</code> <p>Name of the field to get metadata for</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary of metadata from json_schema_extra, empty dict if not found</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_field_metadata(cls, field_name: str) -&gt; dict[str, Any]:\n    \"\"\"\n    Get json_schema_extra metadata for a field, safely handling missing data.\n\n    Args:\n        field_name: Name of the field to get metadata for\n\n    Returns:\n        Dictionary of metadata from json_schema_extra, empty dict if not found\n    \"\"\"\n    field_info = cls.model_fields.get(field_name)\n    if not field_info:\n        return {}\n    return getattr(field_info, \"json_schema_extra\", {}) or {}\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.IndicatorSchema.get_optional_input_columns","title":"get_optional_input_columns  <code>classmethod</code>","text":"<pre><code>get_optional_input_columns() -&gt; list[str]\n</code></pre> <p>Get list of optional input columns based on schema definition.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of column names that are optional for input data</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_optional_input_columns(cls) -&gt; list[str]:\n    \"\"\"\n    Get list of optional input columns based on schema definition.\n\n    Returns:\n        List of column names that are optional for input data\n    \"\"\"\n    from pydantic_core import PydanticUndefined\n\n    optional_columns = []\n    for field_name, field_info in cls.model_fields.items():\n        json_extra = getattr(field_info, \"json_schema_extra\", {}) or {}\n        if (\n            json_extra.get(\"input\") is True  # Is an input column\n            and (\n                json_extra.get(\"optional\", False)  # Marked as optional\n                or getattr(field_info, \"default\", PydanticUndefined) is not PydanticUndefined\n            )  # Has default value\n        ):\n            optional_columns.append(field_name)\n    return sorted(optional_columns)\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.IndicatorSchema.get_polars_dtypes","title":"get_polars_dtypes  <code>classmethod</code>","text":"<pre><code>get_polars_dtypes() -&gt; dict[str, Any]\n</code></pre> <p>Get Polars data types for all DataFrame columns.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary mapping column names to their Polars data types</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_polars_dtypes(cls) -&gt; dict[str, Any]:\n    \"\"\"\n    Get Polars data types for all DataFrame columns.\n\n    Returns:\n        Dictionary mapping column names to their Polars data types\n    \"\"\"\n    types = {}\n\n    for field_name, field_info in cls.model_fields.items():\n        json_extra = getattr(field_info, \"json_schema_extra\", {})\n        if isinstance(json_extra, dict) and \"polars_dtype\" in json_extra:\n            types[field_name] = json_extra[\"polars_dtype\"]\n\n    return types\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.IndicatorSchema.get_required_input_columns","title":"get_required_input_columns  <code>classmethod</code>","text":"<pre><code>get_required_input_columns() -&gt; list[str]\n</code></pre> <p>Get list of required input columns based on schema definition.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of column names that are required for input data</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_required_input_columns(cls) -&gt; list[str]:\n    \"\"\"\n    Get list of required input columns based on schema definition.\n\n    Returns:\n        List of column names that are required for input data\n    \"\"\"\n    from pydantic_core import PydanticUndefined\n\n    required_columns = []\n    for field_name, field_info in cls.model_fields.items():\n        json_extra = getattr(field_info, \"json_schema_extra\", {}) or {}\n        if (\n            json_extra.get(\"input\") is True  # Is an input column\n            and not json_extra.get(\"optional\", False)  # Not marked as optional\n            and getattr(field_info, \"default\", PydanticUndefined)\n            is PydanticUndefined  # No default value (required)\n        ):\n            required_columns.append(field_name)\n    return sorted(required_columns)\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.IndicatorSchema.validate_dataframe","title":"validate_dataframe  <code>classmethod</code>","text":"<pre><code>validate_dataframe(df) -&gt; dict[str, Any]\n</code></pre> <p>Validate input DataFrame columns and data types against IndicatorSchema input requirements.</p> <p>Automatically converts Pandas DataFrames to Polars for consistent validation.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <p>Polars or Pandas DataFrame to validate</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary with validation results including missing/extra columns, type issues,</p> <code>dict[str, Any]</code> <p>and the converted Polars DataFrame if conversion occurred</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef validate_dataframe(cls, df) -&gt; dict[str, Any]:\n    \"\"\"\n    Validate input DataFrame columns and data types against IndicatorSchema input requirements.\n\n    Automatically converts Pandas DataFrames to Polars for consistent validation.\n\n    Args:\n        df: Polars or Pandas DataFrame to validate\n\n    Returns:\n        Dictionary with validation results including missing/extra columns, type issues,\n        and the converted Polars DataFrame if conversion occurred\n    \"\"\"\n    from polars import from_pandas\n\n    # Detect DataFrame type and convert if necessary\n    df_type = \"unknown\"\n    converted_df = None\n    conversion_errors = []\n\n    if hasattr(df, \"columns\"):\n        # Check if it's a Pandas DataFrame\n        if hasattr(df, \"dtypes\") and not hasattr(df, \"schema\"):\n            df_type = \"pandas\"\n            try:\n                # Convert Pandas to Polars\n                converted_df = from_pandas(df)\n                df = converted_df  # Use converted DataFrame for validation\n            except Exception as e:\n                conversion_errors.append(f\"Failed to convert Pandas to Polars: {str(e)}\")\n                # Fall back to column-only validation\n                df_columns = list(df.columns)\n                return {\n                    \"valid\": False,\n                    \"conversion_error\": conversion_errors[0],\n                    \"df_type\": df_type,\n                    \"columns\": df_columns,\n                    \"message\": \"Could not convert Pandas DataFrame to Polars for full validation\",\n                }\n        # Check if it's already a Polars DataFrame\n        elif hasattr(df, \"schema\"):\n            df_type = \"polars\"\n        else:\n            raise ValueError(\"Unknown DataFrame type - must be Pandas or Polars DataFrame\")\n\n        df_columns = list(df.columns)\n    else:\n        raise ValueError(\"Input must be a DataFrame with .columns attribute\")\n\n    required_fields = []\n    optional_fields = []\n    expected_types = {}\n\n    # Extract input field requirements from schema\n    for field_name, field_info in cls.model_fields.items():\n        json_extra = getattr(field_info, \"json_schema_extra\", {})\n        if isinstance(json_extra, dict) and json_extra.get(\"input\"):\n            if field_info.is_required():\n                required_fields.append(field_name)\n            else:\n                optional_fields.append(field_name)\n\n            # Store expected Polars type for validation\n            if \"polars_dtype\" in json_extra:\n                expected_types[field_name] = json_extra[\"polars_dtype\"]\n\n    # Check for missing and extra columns\n    missing_required = [col for col in required_fields if col not in df_columns]\n    missing_optional = [col for col in optional_fields if col not in df_columns]\n    extra_columns = [col for col in df_columns if col not in required_fields + optional_fields]\n\n    # Check data types for present columns (now guaranteed to be Polars)\n    type_issues = []\n    if hasattr(df, \"schema\"):  # Polars DataFrame\n        for col_name, expected_type in expected_types.items():\n            if col_name in df_columns:\n                actual_type = df.schema[col_name]\n                if actual_type != expected_type:\n                    type_issues.append(\n                        {\n                            \"column\": col_name,\n                            \"expected\": expected_type.__name__\n                            if hasattr(expected_type, \"__name__\")\n                            else str(expected_type),\n                            \"actual\": str(actual_type),\n                        }\n                    )\n\n    result = {\n        \"valid\": len(missing_required) == 0 and len(type_issues) == 0,\n        \"missing_required\": missing_required,\n        \"missing_optional\": missing_optional,\n        \"extra_columns\": extra_columns,\n        \"type_issues\": type_issues,\n        \"required_fields\": required_fields,\n        \"optional_fields\": optional_fields,\n        \"expected_types\": {k: v.__name__ if hasattr(v, \"__name__\") else str(v) for k, v in expected_types.items()},\n        \"df_type\": df_type,\n    }\n\n    # Include converted DataFrame if conversion occurred\n    if converted_df is not None:\n        result[\"converted_df\"] = converted_df\n        result[\"conversion_performed\"] = True\n    else:\n        result[\"conversion_performed\"] = False\n\n    return result\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.IndicatorsConfig","title":"IndicatorsConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Complete configuration for indicators component with per-timeframe settings.</p>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.SwingPointsConfig","title":"SwingPointsConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for swing point detection with comprehensive parameter documentation.</p>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.TimeframeConfig","title":"TimeframeConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration and validation for timeframes with comprehensive metadata.</p> <p>Methods:</p> Name Description <code>get_optimal_source_timeframe</code> <p>Get optimal source timeframe for aggregating to target.</p> <code>get_polars_format</code> <p>Get the Polars format for a timeframe.</p> <code>validate_timeframe</code> <p>Validate that the timeframe is supported (strict mode only).</p>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.TimeframeConfig.get_optimal_source_timeframe","title":"get_optimal_source_timeframe  <code>classmethod</code>","text":"<pre><code>get_optimal_source_timeframe(\n    target_timeframe: str, available_timeframes: list[str]\n) -&gt; str | None\n</code></pre> <p>Get optimal source timeframe for aggregating to target.</p> <p>Parameters:</p> Name Type Description Default <code>target_timeframe</code> <code>str</code> <p>Target timeframe to aggregate to</p> required <code>available_timeframes</code> <code>list[str]</code> <p>List of available source timeframes</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>Optimal source timeframe or None if target already exists or no valid source</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_optimal_source_timeframe(cls, target_timeframe: str, available_timeframes: list[str]) -&gt; str | None:\n    \"\"\"\n    Get optimal source timeframe for aggregating to target.\n\n    Args:\n        target_timeframe: Target timeframe to aggregate to\n        available_timeframes: List of available source timeframes\n\n    Returns:\n        Optimal source timeframe or None if target already exists or no valid source\n    \"\"\"\n    # If target exists, use it directly (pass-through)\n    if target_timeframe in available_timeframes:\n        return target_timeframe\n\n    target_metadata = cls.TIMEFRAME_METADATA.get(target_timeframe)\n    if not target_metadata:\n        return None\n\n    target_seconds = target_metadata[\"seconds\"]\n\n    # Find all mathematically valid sources (those that divide evenly into target)\n    valid_sources = []\n    for source_tf in available_timeframes:\n        source_metadata = cls.TIMEFRAME_METADATA.get(source_tf)\n        if source_metadata:\n            source_seconds = source_metadata[\"seconds\"]\n            if target_seconds % source_seconds == 0:\n                valid_sources.append((source_tf, source_seconds))\n\n    if not valid_sources:\n        return None\n\n    # Return the source with the largest duration (minimize aggregation operations)\n    return max(valid_sources, key=lambda x: x[1])[0]\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.TimeframeConfig.get_polars_format","title":"get_polars_format  <code>classmethod</code>","text":"<pre><code>get_polars_format(timeframe: str) -&gt; str\n</code></pre> <p>Get the Polars format for a timeframe.</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef get_polars_format(cls, timeframe: str) -&gt; str:\n    \"\"\"Get the Polars format for a timeframe.\"\"\"\n    metadata = cls.TIMEFRAME_METADATA.get(timeframe)\n    if metadata:\n        return metadata.get(\"polars_format\", timeframe)\n    return timeframe\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.TimeframeConfig.validate_timeframe","title":"validate_timeframe  <code>classmethod</code>","text":"<pre><code>validate_timeframe(timeframe: str) -&gt; bool\n</code></pre> <p>Validate that the timeframe is supported (strict mode only).</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@classmethod\ndef validate_timeframe(cls, timeframe: str) -&gt; bool:\n    \"\"\"Validate that the timeframe is supported (strict mode only).\"\"\"\n    return timeframe in cls.TIMEFRAME_METADATA\n</code></pre>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.TimeframeItemConfig","title":"TimeframeItemConfig","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for a single timeframe item with flexible timeframe targeting.</p> <p>Methods:</p> Name Description <code>validate_timeframe_combinations</code> <p>Validate that 'all' is not mixed with specific timeframes.</p>"},{"location":"reference/thestrat/schemas/#thestrat.schemas.TimeframeItemConfig.validate_timeframe_combinations","title":"validate_timeframe_combinations","text":"<pre><code>validate_timeframe_combinations() -&gt; Self\n</code></pre> <p>Validate that 'all' is not mixed with specific timeframes.</p> Source code in <code>thestrat/schemas.py</code> <pre><code>@model_validator(mode=\"after\")\ndef validate_timeframe_combinations(self) -&gt; Self:\n    \"\"\"Validate that 'all' is not mixed with specific timeframes.\"\"\"\n    if \"all\" in self.timeframes and len(self.timeframes) &gt; 1:\n        raise ValueError(\"'all' cannot be combined with specific timeframes\")\n    return self\n</code></pre>"},{"location":"reference/thestrat/signals/","title":"Signals","text":"<p>Signal processing and metadata</p> <p>Signal metadata implementation for TheStrat trading system.</p> <p>This module provides comprehensive signal metadata objects that transform simple pattern strings into rich objects with trading logic, risk management, and change tracking.</p> <p>Classes:</p> Name Description <code>PriceChange</code> <p>Track changes to stop/target prices.</p> <code>SignalBias</code> <p>Signal directional bias.</p> <code>SignalCategory</code> <p>Signal categorization types.</p> <code>SignalMetadata</code> <p>Complete signal metadata with change tracking and serialization.</p> <code>SignalStatus</code> <p>Signal lifecycle status.</p>"},{"location":"reference/thestrat/signals/#thestrat.signals.PriceChange","title":"PriceChange  <code>dataclass</code>","text":"<pre><code>PriceChange(\n    field_name: str,\n    from_value: float,\n    to_value: float,\n    timestamp: datetime,\n    reason: str | None = None,\n)\n</code></pre> <p>Track changes to stop/target prices.</p>"},{"location":"reference/thestrat/signals/#thestrat.signals.SignalBias","title":"SignalBias","text":"<p>               Bases: <code>Enum</code></p> <p>Signal directional bias.</p>"},{"location":"reference/thestrat/signals/#thestrat.signals.SignalCategory","title":"SignalCategory","text":"<p>               Bases: <code>Enum</code></p> <p>Signal categorization types.</p>"},{"location":"reference/thestrat/signals/#thestrat.signals.SignalMetadata","title":"SignalMetadata  <code>dataclass</code>","text":"<pre><code>SignalMetadata(\n    pattern: str,\n    category: SignalCategory,\n    bias: SignalBias,\n    bar_count: int,\n    entry_bar_index: int,\n    trigger_bar_index: int,\n    entry_price: float,\n    stop_price: float,\n    timestamp: datetime,\n    signal_id: str = (lambda: str(uuid4()))(),\n    target_bar_index: int | None = None,\n    target_price: float | None = None,\n    status: SignalStatus = PENDING,\n    triggered_at: datetime | None = None,\n    closed_at: datetime | None = None,\n    close_reason: str | None = None,\n    change_history: list[PriceChange] = list(),\n    symbol: str | None = None,\n    timeframe: str | None = None,\n    risk_amount: float | None = None,\n    reward_amount: float | None = None,\n    risk_reward_ratio: float | None = None,\n    entry_filled_price: float | None = None,\n    exit_price: float | None = None,\n    pnl: float | None = None,\n    max_favorable_excursion: float | None = None,\n    max_adverse_excursion: float | None = None,\n)\n</code></pre> <p>Complete signal metadata with change tracking and serialization.</p> <p>Methods:</p> Name Description <code>__post_init__</code> <p>Store original values and calculate metrics.</p> <code>from_dict</code> <p>Reconstruct SignalMetadata from dictionary.</p> <code>from_json</code> <p>Deserialize from JSON string.</p> <code>to_dict</code> <p>Convert to dictionary for JSON serialization.</p> <code>to_json</code> <p>Serialize to JSON string.</p> <code>trail_stop</code> <p>Trail stop loss, only allowing favorable moves.</p> <code>update_stop</code> <p>Update stop with change tracking.</p> <code>update_target</code> <p>Update target with change tracking.</p>"},{"location":"reference/thestrat/signals/#thestrat.signals.SignalMetadata.__post_init__","title":"__post_init__","text":"<pre><code>__post_init__()\n</code></pre> <p>Store original values and calculate metrics.</p> Source code in <code>thestrat/signals.py</code> <pre><code>def __post_init__(self):\n    \"\"\"Store original values and calculate metrics.\"\"\"\n    self.original_stop = self.stop_price\n    self.original_target = self.target_price\n    self._calculate_risk_metrics()\n</code></pre>"},{"location":"reference/thestrat/signals/#thestrat.signals.SignalMetadata.from_dict","title":"from_dict  <code>classmethod</code>","text":"<pre><code>from_dict(data: dict[str, Any]) -&gt; SignalMetadata\n</code></pre> <p>Reconstruct SignalMetadata from dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict[str, Any]</code> <p>Dictionary representation from <code>to_dict()</code></p> required <p>Returns:</p> Type Description <code>SignalMetadata</code> <p>SignalMetadata instance with original values and metrics recalculated</p> Source code in <code>thestrat/signals.py</code> <pre><code>@classmethod\ndef from_dict(cls, data: dict[str, Any]) -&gt; \"SignalMetadata\":\n    \"\"\"\n    Reconstruct SignalMetadata from dictionary.\n\n    Args:\n        data: Dictionary representation from `to_dict()`\n\n    Returns:\n        SignalMetadata instance with original values and metrics recalculated\n    \"\"\"\n    # Make a copy to avoid modifying the original\n    data = data.copy()\n\n    # Convert strings back to enums\n    data[\"category\"] = SignalCategory(data[\"category\"])\n    data[\"bias\"] = SignalBias(data[\"bias\"])\n    data[\"status\"] = SignalStatus(data[\"status\"])\n\n    # Convert ISO strings to datetime\n    data[\"timestamp\"] = datetime.fromisoformat(data[\"timestamp\"])\n\n    if data.get(\"triggered_at\"):\n        data[\"triggered_at\"] = datetime.fromisoformat(data[\"triggered_at\"])\n    if data.get(\"closed_at\"):\n        data[\"closed_at\"] = datetime.fromisoformat(data[\"closed_at\"])\n\n    # Reconstruct change history\n    data[\"change_history\"] = [\n        PriceChange(**{**ch, \"timestamp\": datetime.fromisoformat(ch[\"timestamp\"])})\n        for ch in data.get(\"change_history\", [])\n    ]\n\n    # Dynamically determine float fields from dataclass annotations\n    import types\n    import typing\n    from dataclasses import fields\n\n    float_fields = []\n    for field_info in fields(cls):\n        field_type = field_info.type\n        # Handle Union types like float | None (both typing.Union and types.UnionType)\n        origin = typing.get_origin(field_type)\n        if origin is typing.Union or origin is types.UnionType:\n            args = typing.get_args(field_type)\n            # Check if float is in the union (e.g., float | None)\n            if float in args:\n                float_fields.append(field_info.name)\n        # Handle direct float type\n        elif field_type is float:\n            float_fields.append(field_info.name)\n\n    for float_field in float_fields:\n        if data.get(float_field) is not None:\n            value = data[float_field]\n            # Ensure numeric values are floats (not int)\n            if isinstance(value, (int, float)):\n                data[float_field] = float(value)\n\n    # Remove fields that are calculated in __post_init__ and shouldn't be passed to constructor\n    calculated_fields = [\"original_stop\", \"original_target\", \"risk_amount\", \"reward_amount\", \"risk_reward_ratio\"]\n    for calc_field in calculated_fields:\n        data.pop(calc_field, None)\n\n    # Create the object (original values and metrics will be recalculated in __post_init__)\n    return cls(**data)\n</code></pre>"},{"location":"reference/thestrat/signals/#thestrat.signals.SignalMetadata.from_json","title":"from_json  <code>classmethod</code>","text":"<pre><code>from_json(json_str: str) -&gt; SignalMetadata\n</code></pre> <p>Deserialize from JSON string.</p> <p>Parameters:</p> Name Type Description Default <code>json_str</code> <code>str</code> <p>JSON string from <code>to_json()</code></p> required <p>Returns:</p> Type Description <code>SignalMetadata</code> <p>SignalMetadata instance reconstructed from JSON</p> Source code in <code>thestrat/signals.py</code> <pre><code>@classmethod\ndef from_json(cls, json_str: str) -&gt; \"SignalMetadata\":\n    \"\"\"\n    Deserialize from JSON string.\n\n    Args:\n        json_str: JSON string from `to_json()`\n\n    Returns:\n        SignalMetadata instance reconstructed from JSON\n    \"\"\"\n    return cls.from_dict(json.loads(json_str))\n</code></pre>"},{"location":"reference/thestrat/signals/#thestrat.signals.SignalMetadata.to_dict","title":"to_dict","text":"<pre><code>to_dict() -&gt; dict[str, Any]\n</code></pre> <p>Convert to dictionary for JSON serialization.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary representation with all fields serializable to JSON</p> Source code in <code>thestrat/signals.py</code> <pre><code>def to_dict(self) -&gt; dict[str, Any]:\n    \"\"\"\n    Convert to dictionary for JSON serialization.\n\n    Returns:\n        Dictionary representation with all fields serializable to JSON\n    \"\"\"\n    data = asdict(self)\n\n    # Convert enums to strings\n    data[\"category\"] = self.category.value\n    data[\"bias\"] = self.bias.value\n    data[\"status\"] = self.status.value\n\n    # Convert datetime to ISO format\n    data[\"timestamp\"] = self.timestamp.isoformat()\n\n    if self.triggered_at:\n        data[\"triggered_at\"] = self.triggered_at.isoformat()\n    if self.closed_at:\n        data[\"closed_at\"] = self.closed_at.isoformat()\n\n    # Convert change history\n    data[\"change_history\"] = [\n        {**asdict(change), \"timestamp\": change.timestamp.isoformat()} for change in self.change_history\n    ]\n\n    # Keep numeric fields as numbers for database compatibility\n    # No float-to-string conversion needed - JSON natively supports numbers\n    # This preserves proper types for database insertion\n\n    return data\n</code></pre>"},{"location":"reference/thestrat/signals/#thestrat.signals.SignalMetadata.to_json","title":"to_json","text":"<pre><code>to_json() -&gt; str\n</code></pre> <p>Serialize to JSON string.</p> <p>Returns:</p> Type Description <code>str</code> <p>JSON string representation of the signal metadata</p> Source code in <code>thestrat/signals.py</code> <pre><code>def to_json(self) -&gt; str:\n    \"\"\"\n    Serialize to JSON string.\n\n    Returns:\n        JSON string representation of the signal metadata\n    \"\"\"\n    return json.dumps(self.to_dict(), default=str)\n</code></pre>"},{"location":"reference/thestrat/signals/#thestrat.signals.SignalMetadata.trail_stop","title":"trail_stop","text":"<pre><code>trail_stop(new_stop: float, reason: str = 'trailing_stop') -&gt; bool\n</code></pre> <p>Trail stop loss, only allowing favorable moves.</p> <p>Parameters:</p> Name Type Description Default <code>new_stop</code> <code>float</code> <p>Proposed new stop price</p> required <code>reason</code> <code>str</code> <p>Reason for trailing (default: \"trailing_stop\")</p> <code>'trailing_stop'</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if stop was trailed, False if move was unfavorable and rejected</p> Source code in <code>thestrat/signals.py</code> <pre><code>def trail_stop(self, new_stop: float, reason: str = \"trailing_stop\") -&gt; bool:\n    \"\"\"\n    Trail stop loss, only allowing favorable moves.\n\n    Args:\n        new_stop: Proposed new stop price\n        reason: Reason for trailing (default: \"trailing_stop\")\n\n    Returns:\n        True if stop was trailed, False if move was unfavorable and rejected\n    \"\"\"\n    if self.bias == SignalBias.LONG:\n        # For long trades, only trail up\n        if new_stop &gt; self.stop_price:\n            self.update_stop(new_stop, reason)\n            return True\n    else:\n        # For short trades, only trail down\n        if new_stop &lt; self.stop_price:\n            self.update_stop(new_stop, reason)\n            return True\n    return False\n</code></pre>"},{"location":"reference/thestrat/signals/#thestrat.signals.SignalMetadata.update_stop","title":"update_stop","text":"<pre><code>update_stop(new_stop: float, reason: str = None) -&gt; None\n</code></pre> <p>Update stop with change tracking.</p> <p>Parameters:</p> Name Type Description Default <code>new_stop</code> <code>float</code> <p>New stop loss price</p> required <code>reason</code> <code>str</code> <p>Optional reason for the update (e.g., \"trailing_stop\", \"manual_adjustment\")</p> <code>None</code> Source code in <code>thestrat/signals.py</code> <pre><code>def update_stop(self, new_stop: float, reason: str = None) -&gt; None:\n    \"\"\"\n    Update stop with change tracking.\n\n    Args:\n        new_stop: New stop loss price\n        reason: Optional reason for the update (e.g., \"trailing_stop\", \"manual_adjustment\")\n    \"\"\"\n    if new_stop == self.stop_price:\n        return\n\n    change = PriceChange(\n        field_name=\"stop_price\",\n        from_value=self.stop_price,\n        to_value=new_stop,\n        timestamp=datetime.now(),\n        reason=reason,\n    )\n    self.change_history.append(change)\n    self.stop_price = new_stop\n    self._calculate_risk_metrics()\n</code></pre>"},{"location":"reference/thestrat/signals/#thestrat.signals.SignalMetadata.update_target","title":"update_target","text":"<pre><code>update_target(new_target: float, reason: str = None) -&gt; None\n</code></pre> <p>Update target with change tracking.</p> <p>Parameters:</p> Name Type Description Default <code>new_target</code> <code>float</code> <p>New target price</p> required <code>reason</code> <code>str</code> <p>Optional reason for the update (e.g., \"manual_adjustment\", \"scale_out\")</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If called on continuation signals (they have no target)</p> Source code in <code>thestrat/signals.py</code> <pre><code>def update_target(self, new_target: float, reason: str = None) -&gt; None:\n    \"\"\"\n    Update target with change tracking.\n\n    Args:\n        new_target: New target price\n        reason: Optional reason for the update (e.g., \"manual_adjustment\", \"scale_out\")\n\n    Raises:\n        ValueError: If called on continuation signals (they have no target)\n    \"\"\"\n    if self.category == SignalCategory.CONTINUATION:\n        raise ValueError(\"Continuation signals have no target\")\n\n    if new_target == self.target_price:\n        return\n\n    change = PriceChange(\n        field_name=\"target_price\",\n        from_value=self.target_price,\n        to_value=new_target,\n        timestamp=datetime.now(),\n        reason=reason,\n    )\n    self.change_history.append(change)\n    self.target_price = new_target\n    self._calculate_risk_metrics()\n</code></pre>"},{"location":"reference/thestrat/signals/#thestrat.signals.SignalStatus","title":"SignalStatus","text":"<p>               Bases: <code>Enum</code></p> <p>Signal lifecycle status.</p>"},{"location":"user-guide/","title":"User Guide","text":"<p>Welcome to the TheStrat user guide. This section provides comprehensive documentation for using the TheStrat Python module in your trading applications.</p>"},{"location":"user-guide/#what-is-thestrat","title":"What is #TheStrat?","text":""},{"location":"user-guide/#thestrat-is-a-technical-analysis-methodology-that-focuses-on-understanding-market-structure-through-the-identification-of-specific-bar-patterns-and-their-relationships-across-multiple-timeframes","title":"TheStrat is a technical analysis methodology that focuses on understanding market structure through the identification of specific bar patterns and their relationships across multiple timeframes.","text":""},{"location":"user-guide/#guide-structure","title":"Guide Structure","text":"<p>This user guide is organized into the following sections:</p>"},{"location":"user-guide/#installation","title":"Installation","text":"<p>How to install and set up the TheStrat module in your environment.</p>"},{"location":"user-guide/#quick-start","title":"Quick Start","text":"<p>Get up and running quickly with basic examples and common use cases.</p>"},{"location":"user-guide/#examples","title":"Examples","text":"<p>Detailed examples showing how to use each component and feature.</p>"},{"location":"user-guide/#asset-classes","title":"Asset Classes","text":"<p>Understanding how different asset classes work within the framework.</p>"},{"location":"user-guide/#prerequisites","title":"Prerequisites","text":"<p>Before using TheStrat, you should have:</p> <ul> <li>Python 3.11 or higher installed</li> <li>Basic understanding of financial markets and OHLCV data</li> <li>Familiarity with Python data structures (pandas/polars DataFrames)</li> </ul>"},{"location":"user-guide/#key-concepts","title":"Key Concepts","text":""},{"location":"user-guide/#timeframe-aggregation","title":"Timeframe Aggregation","text":"<p>TheStrat works across multiple timeframes. The aggregation component handles converting your base timeframe data (e.g., 1-minute bars) into higher timeframes (e.g., 5-minute, 15-minute, hourly).</p>"},{"location":"user-guide/#inside-and-outside-bars","title":"Inside and Outside Bars","text":"<p>Core to #TheStrat methodology: - Inside Bar: High \u2264 previous high AND Low \u2265 previous low - Outside Bar: High &gt; previous high AND Low &lt; previous low</p>"},{"location":"user-guide/#swing-points-and-market-structure","title":"Swing Points and Market Structure","text":"<p>TheStrat uses precise swing point detection to identify market structure:</p> <ul> <li>Swing High: A price peak that is the highest point within its lookback/lookahead window and meets the percentage threshold compared to the previous swing high</li> <li>Swing Low: A price trough that is the lowest point within its lookback/lookahead window and meets the percentage threshold compared to the previous swing low</li> <li>Higher High (HH): Each new swing high that is higher than the previous swing high (bullish structure)</li> <li>Lower High (LH): Each new swing high that is lower than the previous swing high (bearish structure)</li> <li>Higher Low (HL): Each new swing low that is higher than the previous swing low (bullish structure)</li> <li>Lower Low (LL): Each new swing low that is lower than the previous swing low (bearish structure)</li> </ul>"},{"location":"user-guide/#configuration-parameters","title":"Configuration Parameters","text":"<p>Swing point detection can be configured per timeframe:</p> <ul> <li>Window Size: Number of bars to look back and ahead for peak/valley confirmation (default: 5)</li> <li>Threshold: Minimum percentage change required to confirm a new swing point (default: 2.0%)</li> </ul>"},{"location":"user-guide/#signals-and-patterns","title":"Signals and Patterns","text":"<p>The indicators component identifies key pattern sequences and generates actionable signals based on TheStrat rules.</p>"},{"location":"user-guide/#getting-help","title":"Getting Help","text":"<p>If you need assistance:</p> <ol> <li>Check the Examples section for similar use cases</li> <li>Review the API Reference for detailed method documentation</li> <li>Contact the maintainer for private module support</li> </ol> <p>Let's get started with Installation!</p>"},{"location":"user-guide/asset-classes/","title":"Asset Classes","text":"<p>TheStrat supports multiple asset classes, each with specific market characteristics and trading hours. This guide explains how to configure and work with different asset classes effectively.</p>"},{"location":"user-guide/asset-classes/#overview","title":"Overview","text":"<p>Asset classes in TheStrat determine:</p> <ul> <li>Trading hours and session handling</li> <li>Timezone requirements and defaults</li> <li>Gap handling for market opens/closes</li> <li>Aggregation behavior for weekends and holidays</li> </ul>"},{"location":"user-guide/asset-classes/#supported-asset-classes","title":"Supported Asset Classes","text":"<p>TheStrat currently supports three major asset classes: crypto, equities, and fx. Each has been optimized for their specific market characteristics.</p>"},{"location":"user-guide/asset-classes/#crypto-247-trading","title":"Crypto (24/7 Trading)","text":"<p>Cryptocurrency markets trade continuously without breaks.</p> <p>Configuration: <pre><code>from thestrat.schemas import FactoryConfig, AggregationConfig, IndicatorsConfig\n\ncrypto_config = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"1h\"],\n        asset_class=\"crypto\",\n        timezone=\"UTC\"  # Always UTC for crypto\n    )\n)\n</code></pre></p> <p>Characteristics: - Trading Hours: 24/7/365 continuous - Timezone: UTC (required) - Session Handling: No sessions or gaps - Weekend Behavior: Trades through weekends</p> <p>Example Usage: <pre><code>from thestrat import Factory\nfrom thestrat.schemas import (\n    FactoryConfig, AggregationConfig, IndicatorsConfig,\n    TimeframeItemConfig, SwingPointsConfig\n)\n\n# Bitcoin hourly analysis\nbtc_config = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"4h\"],\n        asset_class=\"crypto\",\n        timezone=\"UTC\"\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"all\"],\n                swing_points=SwingPointsConfig(\n                    window=6,           # Longer window for 4h timeframe\n                    threshold=4.0       # Higher threshold for crypto volatility\n                )\n            )\n        ]\n    )\n)\n\npipeline = Factory.create_all(btc_config)\n</code></pre></p> <p>Best Practices: - Use higher volatility thresholds (3-5%) - Consider larger swing windows due to 24/7 nature - Include incomplete bars for real-time analysis</p>"},{"location":"user-guide/asset-classes/#equities-market-hours","title":"Equities (Market Hours)","text":"<p>Traditional stock markets with defined trading sessions.</p> <p>Configuration: <pre><code>from thestrat.schemas import FactoryConfig, AggregationConfig\n\nequity_config = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"5min\"],\n        asset_class=\"equities\",\n        timezone=\"US/Eastern\"  # NYSE/NASDAQ\n    )\n)\n</code></pre></p> <p>Characteristics: - Trading Hours: 9:30 AM - 4:00 PM ET (regular session) - Timezone: US/Eastern (default), configurable - Session Handling: Pre-market, regular, after-hours - Weekend Behavior: No trading weekends/holidays</p> <p>Market Sessions:</p> <p>TheStrat automatically handles market hours for equities. You can configure different timeframes for different analysis needs:</p> <pre><code># Short-term intraday analysis\nshort_term_config = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"1m\"],\n        asset_class=\"equities\",\n        timezone=\"US/Eastern\"\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"all\"],\n                swing_points=SwingPointsConfig(window=3, threshold=1.0)\n            )\n        ]\n    )\n)\n\n# Regular session analysis\nregular_config = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"5m\"],\n        asset_class=\"equities\",\n        timezone=\"US/Eastern\"\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"all\"],\n                swing_points=SwingPointsConfig(window=5, threshold=2.0)\n            )\n        ]\n    )\n)\n\n# Create pipelines\nshort_pipeline = Factory.create_all(short_term_config)\nregular_pipeline = Factory.create_all(regular_config)\n</code></pre> <p>International Equities: <pre><code># London Stock Exchange\nlse_config = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"15m\"],\n        asset_class=\"equities\",\n        timezone=\"Europe/London\"  # 8:00-16:30 GMT\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"all\"],\n                swing_points=SwingPointsConfig(window=5, threshold=2.0)\n            )\n        ]\n    )\n)\n\n# Tokyo Stock Exchange\ntse_config = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"30m\"],\n        asset_class=\"equities\",\n        timezone=\"Asia/Tokyo\"    # 9:00-15:00 JST\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"all\"],\n                swing_points=SwingPointsConfig(window=5, threshold=2.0)\n            )\n        ]\n    )\n)\n</code></pre></p>"},{"location":"user-guide/asset-classes/#forex-245-trading","title":"Forex (24/5 Trading)","text":"<p>Foreign exchange markets trade 24/5 from Sunday 5 PM to Friday 5 PM ET.</p> <p>Configuration: <pre><code>from thestrat.schemas import FactoryConfig, AggregationConfig\n\nfx_config = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"1h\"],\n        asset_class=\"fx\",\n        timezone=\"UTC\"  # Always UTC for FX\n    )\n)\n</code></pre></p> <p>Characteristics: - Trading Hours: Sun 5 PM - Fri 5 PM ET (24/5) - Timezone: UTC (required) - Session Handling: Asian, London, New York sessions - Weekend Behavior: Gap handling for weekend closes</p> <p>Major FX Sessions: <pre><code>def analyze_fx_sessions(eurusd_data):\n    \"\"\"Analyze EUR/USD across major FX sessions.\"\"\"\n\n    sessions = {\n        \"asian\": FactoryConfig(\n            aggregation=AggregationConfig(\n                target_timeframes=[\"1h\"],\n                asset_class=\"fx\",\n                timezone=\"UTC\"  # Asian session: 10 PM - 8 AM UTC\n            )\n        ),\n        \"london\": FactoryConfig(\n            aggregation=AggregationConfig(\n                target_timeframes=[\"30min\"],\n                asset_class=\"fx\",\n                timezone=\"UTC\"  # London session: 7 AM - 4 PM UTC\n            )\n        ),\n        \"newyork\": FactoryConfig(\n            aggregation=AggregationConfig(\n                target_timeframes=[\"15min\"],\n                asset_class=\"fx\",\n                timezone=\"UTC\"  # New York session: 12 PM - 9 PM UTC\n            )\n        )\n    }\n\n    results = {}\n    for session, config in sessions.items():\n        pipeline = Factory.create_all(config)\n        analyzed = pipeline[\"indicators\"].process(\n            pipeline[\"aggregation\"].process(eurusd_data)\n        )\n        results[session] = analyzed\n\n    return results\n</code></pre></p> <p>Currency-Specific Examples: <pre><code># Major pairs with different characteristics\npairs = {\n    \"EURUSD\": {\"threshold\": 0.3, \"window\": 5},   # Lower volatility\n    \"GBPJPY\": {\"threshold\": 0.8, \"window\": 4},   # Higher volatility\n    \"AUDUSD\": {\"threshold\": 0.4, \"window\": 6},   # Commodity currency\n    \"USDCAD\": {\"threshold\": 0.5, \"window\": 5}    # Oil correlation\n}\n\nfor pair, params in pairs.items():\n    config = FactoryConfig(\n        aggregation=AggregationConfig(\n            target_timeframes=[\"4h\"],\n            asset_class=\"fx\",\n            timezone=\"UTC\"\n        ),\n        indicators=IndicatorsConfig(\n            timeframe_configs=[\n                TimeframeItemConfig(\n                    timeframes=[\"all\"],\n                    swing_points=SwingPointsConfig(**params)\n                )\n            ]\n        )\n    )\n    # Process each pair...\n</code></pre></p>"},{"location":"user-guide/asset-classes/#asset-class-comparison","title":"Asset Class Comparison","text":"Asset Class Trading Hours Timezone Gap Handling Volatility Recommended Timeframes Crypto 24/7 UTC None High 1h, 4h, 1d Equities 9:30-16:00 ET US/Eastern Daily gaps Medium 1m, 5m, 15m, 1h Forex 24/5 UTC Weekend gaps Medium 15m, 1h, 4h"},{"location":"user-guide/asset-classes/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"user-guide/asset-classes/#custom-market-configuration","title":"Custom Market Configuration","text":"<pre><code># Define custom market behavior using supported parameters\ncustom_config = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"15m\"],  # Use supported timeframe\n        asset_class=\"equities\",     # Base on existing class\n        timezone=\"US/Pacific\",      # Custom timezone\n        session_start=\"06:30\"       # Custom session start\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"all\"],\n                swing_points=SwingPointsConfig(window=5, threshold=2.0)\n            )\n        ]\n    )\n)\n</code></pre>"},{"location":"user-guide/asset-classes/#multi-asset-portfolio","title":"Multi-Asset Portfolio","text":"<pre><code>def analyze_multi_asset_portfolio(assets):\n    \"\"\"Analyze multiple asset classes in one portfolio.\"\"\"\n\n    results = {}\n\n    for asset_name, (data, asset_class) in assets.items():\n        # Get appropriate config for asset class\n        base_config = {\n            \"crypto\": {\"target_timeframes\": [\"4h\"], \"timezone\": \"UTC\", \"threshold\": 3.0},\n            \"equities\": {\"target_timeframes\": [\"15min\"], \"timezone\": \"US/Eastern\", \"threshold\": 1.5},\n            \"fx\": {\"target_timeframes\": [\"1h\"], \"timezone\": \"UTC\", \"threshold\": 0.5}\n        }\n\n        if asset_class in base_config:\n            config = FactoryConfig(\n                aggregation=AggregationConfig(\n                    asset_class=asset_class,\n                    target_timeframes=base_config[asset_class][\"target_timeframes\"],\n                    timezone=base_config[asset_class][\"timezone\"]\n                ),\n                indicators=IndicatorsConfig(\n                    timeframe_configs=[\n                        TimeframeItemConfig(\n                            timeframes=[\"all\"],\n                            swing_points=SwingPointsConfig(\n                                window=5,\n                                threshold=base_config[asset_class][\"threshold\"]\n                            )\n                        )\n                    ]\n                )\n            )\n\n            pipeline = Factory.create_all(config)\n            aggregated = pipeline[\"aggregation\"].process(data)\n            analyzed = pipeline[\"indicators\"].process(aggregated)\n\n            results[asset_name] = {\n                'asset_class': asset_class,\n                'data': analyzed,\n                'inside_bars': analyzed['inside_bar'].sum(),\n                'outside_bars': analyzed['outside_bar'].sum()\n            }\n\n    return results\n\n# Example usage\nportfolio = {\n    'BTC': (btc_data, 'crypto'),\n    'AAPL': (aapl_data, 'equities'),\n    'EURUSD': (eurusd_data, 'fx')\n}\n\nportfolio_analysis = analyze_multi_asset_portfolio(portfolio)\n</code></pre>"},{"location":"user-guide/asset-classes/#best-practices-by-asset-class","title":"Best Practices by Asset Class","text":""},{"location":"user-guide/asset-classes/#crypto","title":"Crypto","text":"<ul> <li>Use UTC timezone exclusively</li> <li>Higher volatility thresholds (3-5%)</li> <li>Consider 24/7 nature in signal interpretation</li> <li>Include incomplete bars for real-time analysis</li> </ul>"},{"location":"user-guide/asset-classes/#equities","title":"Equities","text":"<ul> <li>Respect market hours and gaps</li> <li>Lower volatility thresholds (1-2%)</li> <li>Consider pre/post market sessions separately</li> <li>Account for earnings and announcement gaps</li> </ul>"},{"location":"user-guide/asset-classes/#forex","title":"Forex","text":"<ul> <li>Use UTC timezone for consistency</li> <li>Medium volatility thresholds (0.5-1%)</li> <li>Consider major session overlaps</li> <li>Handle weekend gaps appropriately</li> </ul> <p>Choose the asset class configuration that matches your data and trading requirements. The framework handles the complex details of market hours, timezone conversions, and gap handling automatically.</p>"},{"location":"user-guide/configuration/","title":"Configuration Reference","text":"<p>Configuration documentation will be generated during build.</p>"},{"location":"user-guide/dataframe-schema/","title":"Database Integration Guide","text":"<p>The <code>IndicatorSchema</code> class provides essential schema information for integrating TheStrat output with databases and validation systems. This guide shows how to use the schema to create database tables, validate data, and ensure consistent integration.</p>"},{"location":"user-guide/dataframe-schema/#quick-start","title":"Quick Start","text":"<pre><code>from thestrat import IndicatorSchema\nfrom polars import DataFrame\nfrom datetime import datetime\n\n# Validate input DataFrame\ndata = {\n    \"timestamp\": [datetime.now()],\n    \"open\": [100.0], \"high\": [105.0], \"low\": [95.0], \"close\": [102.0],\n    \"symbol\": [\"AAPL\"], \"volume\": [1000000.0], \"timeframe\": [\"5min\"]\n}\n\ndf = DataFrame(data, schema=IndicatorSchema.get_polars_dtypes())\nresult = IndicatorSchema.validate_dataframe(df)\n\nprint(f\"Valid: {result['valid']}\")\nprint(f\"Missing columns: {result['missing_required']}\")\n</code></pre>"},{"location":"user-guide/dataframe-schema/#database-schema-generation","title":"Database Schema Generation","text":""},{"location":"user-guide/dataframe-schema/#sql-table-creation","title":"SQL Table Creation","text":"<pre><code># Get column types and descriptions\ndescriptions = IndicatorSchema.get_column_descriptions()\npolars_types = IndicatorSchema.get_polars_dtypes()\n\n# Map Polars types to SQL types\nfrom polars import Datetime, Float64, String, Boolean, Int32\n\ntype_mapping = {\n    Datetime: \"TIMESTAMP\",\n    Float64: \"DOUBLE PRECISION\",\n    String: \"VARCHAR(50)\",\n    Boolean: \"BOOLEAN\",\n    Int32: \"INTEGER\"\n}\n\n# Generate CREATE TABLE statement\ndef generate_sql_schema(table_name: str) -&gt; str:\n    lines = [f\"CREATE TABLE {table_name} (\"]\n\n    for col, polars_type in polars_types.items():\n        sql_type = type_mapping.get(polars_type, \"TEXT\")\n        description = descriptions.get(col, \"\").replace(\"'\", \"''\")\n        lines.append(f\"  {col} {sql_type}, -- {description}\")\n\n    lines.append(\"  PRIMARY KEY (timestamp, symbol, timeframe)\")\n    lines.append(\");\")\n    return \"\\n\".join(lines)\n\nschema_sql = generate_sql_schema(\"thestrat_indicators\")\n</code></pre>"},{"location":"user-guide/dataframe-schema/#column-categories","title":"Column Categories","text":"<p>Organize columns by functionality for targeted database operations:</p> <pre><code>categories = IndicatorSchema.get_column_categories()\n\n# Create separate tables by category\nfor category, columns in categories.items():\n    if category == \"base_ohlc\":\n        # Core market data table\n        create_base_table(columns)\n    elif category == \"signals\":\n        # Trading signals table with indexes\n        create_signals_table(columns)\n    elif category == \"swing_points\":\n        # Technical analysis table\n        create_analysis_table(columns)\n</code></pre>"},{"location":"user-guide/dataframe-schema/#input-validation","title":"Input Validation","text":""},{"location":"user-guide/dataframe-schema/#required-columns-check","title":"Required Columns Check","text":"<pre><code>def validate_input_data(df) -&gt; dict:\n    \"\"\"Validate DataFrame before processing.\"\"\"\n    result = IndicatorSchema.validate_dataframe(df)\n\n    if not result['valid']:\n        errors = []\n        if result['missing_required']:\n            errors.append(f\"Missing: {result['missing_required']}\")\n        if result['type_issues']:\n            errors.append(f\"Type errors: {result['type_issues']}\")\n\n        raise ValueError(f\"Invalid DataFrame: {'; '.join(errors)}\")\n\n    return result['converted_df'] if result['conversion_performed'] else df\n</code></pre>"},{"location":"user-guide/dataframe-schema/#auto-conversion-from-pandas","title":"Auto-conversion from Pandas","text":"<pre><code>from pandas import DataFrame as PandasDataFrame\n\n# Pandas DataFrame automatically converts\ndf_pandas = PandasDataFrame(data)\ndf_pandas['timestamp'] = pd.to_datetime(df_pandas['timestamp'])\n\nresult = IndicatorSchema.validate_dataframe(df_pandas)\n# result['converted_df'] contains Polars DataFrame\n</code></pre>"},{"location":"user-guide/dataframe-schema/#column-documentation","title":"Column Documentation","text":""},{"location":"user-guide/dataframe-schema/#get-field-information","title":"Get Field Information","text":"<pre><code># Column descriptions for documentation\ndescriptions = IndicatorSchema.get_column_descriptions()\npolars_types = IndicatorSchema.get_polars_dtypes()\n\n# Generate documentation\nfor col in [\"swing_high\", \"continuity\", \"signal\"]:\n    print(f\"**{col}**: {descriptions[col]}\")\n    print(f\"Type: `{polars_types[col].__name__}`\\n\")\n</code></pre>"},{"location":"user-guide/dataframe-schema/#category-based-operations","title":"Category-based Operations","text":"<pre><code>categories = IndicatorSchema.get_column_categories()\n\n# Process only price analysis columns\nprice_cols = categories['price_analysis']\ndf_prices = df.select(price_cols)\n\n# Extract signal columns for trading system\nsignal_cols = categories['signals']\ndf_signals = df.select(signal_cols)\n</code></pre>"},{"location":"user-guide/dataframe-schema/#advanced-sql-schema-generation","title":"Advanced SQL Schema Generation","text":"<p>Generate complete SQL DDL with nullable constraints by examining the schema metadata:</p> <pre><code>from thestrat.schemas import IndicatorSchema\n\n# Get schema information\ndescriptions = IndicatorSchema.get_column_descriptions()\npolars_types = IndicatorSchema.get_polars_dtypes()\n\ndef generate_sql_with_constraints(table_name: str) -&gt; str:\n    \"\"\"Generate SQL schema with proper NULL/NOT NULL constraints.\"\"\"\n    lines = [f\"CREATE TABLE {table_name} (\"]\n\n    # Map Polars types to SQL types\n    type_mapping = {\n        \"Datetime\": \"TIMESTAMP\",\n        \"Float64\": \"DOUBLE PRECISION\",\n        \"String\": \"VARCHAR(255)\",\n        \"Boolean\": \"BOOLEAN\",\n        \"Int32\": \"INTEGER\"\n    }\n\n    # Process each field using the new helper method\n    for field_name in IndicatorSchema.model_fields.keys():\n        # Get SQL type from Polars type\n        polars_type = polars_types.get(field_name)\n        polars_type_name = polars_type.__name__ if polars_type and hasattr(polars_type, '__name__') else \"String\"\n        sql_type = type_mapping.get(polars_type_name, \"TEXT\")\n\n        # Get nullable constraint using helper method\n        metadata = IndicatorSchema.get_field_metadata(field_name)\n        nullable = metadata.get('nullable', True)\n        constraint = \"\" if nullable else \" NOT NULL\"\n\n        # Add description as comment\n        description = descriptions.get(field_name, \"\").replace(\"'\", \"''\")\n        lines.append(f\"  {field_name} {sql_type}{constraint}, -- {description}\")\n\n    lines.append(\"  PRIMARY KEY (timestamp, symbol, timeframe)\")\n    lines.append(\");\")\n    return \"\\n\".join(lines)\n\nschema_sql = generate_sql_with_constraints(\"thestrat_indicators\")\nprint(schema_sql)\n</code></pre>"},{"location":"user-guide/dataframe-schema/#field-classification-by-type","title":"Field Classification by Type","text":"<p>Organize columns by input/output type and nullable constraints:</p> <pre><code># Classify fields by their purpose using the helper method\ninput_fields = []\noutput_fields = []\nnullable_fields = []\nrequired_fields = []\n\nfor field_name in IndicatorSchema.model_fields.keys():\n    metadata = IndicatorSchema.get_field_metadata(field_name)\n\n    # Classify by input/output\n    if metadata.get('input', False):\n        input_fields.append(field_name)\n    if metadata.get('output', False):\n        output_fields.append(field_name)\n\n    # Classify by nullable constraint\n    if metadata.get('nullable', True):\n        nullable_fields.append(field_name)\n    else:\n        required_fields.append(field_name)\n\nprint(f\"Input fields ({len(input_fields)}): {input_fields}\")\nprint(f\"Output fields ({len(output_fields)}): {output_fields}\")\nprint(f\"Nullable fields ({len(nullable_fields)}): {nullable_fields}\")\nprint(f\"Required (non-null) fields ({len(required_fields)}): {required_fields}\")\n</code></pre>"},{"location":"user-guide/dataframe-schema/#integration-patterns","title":"Integration Patterns","text":""},{"location":"user-guide/dataframe-schema/#database-insert-with-validation","title":"Database Insert with Validation","text":"<pre><code>def insert_thestrat_data(df, connection):\n    \"\"\"Insert validated DataFrame into database.\"\"\"\n    # Validate first\n    validated_df = validate_input_data(df)\n\n    # Get column info for proper insertion\n    polars_types = IndicatorSchema.get_polars_dtypes()\n\n    # Insert with proper type handling\n    for row in validated_df.iter_rows(named=True):\n        insert_row(connection, row, polars_types)\n\ndef insert_row(conn, row_data, type_info):\n    \"\"\"Insert single row with type conversion.\"\"\"\n    columns = list(row_data.keys())\n    placeholders = \", \".join([\"?\" for _ in columns])\n\n    # Convert values based on schema\n    from polars import Datetime\n    values = []\n    for col, value in row_data.items():\n        if col in type_info and type_info[col] == Datetime:\n            values.append(value.isoformat() if value else None)\n        else:\n            values.append(value)\n\n    query = f\"INSERT INTO thestrat_indicators ({', '.join(columns)}) VALUES ({placeholders})\"\n    conn.execute(query, values)\n</code></pre>"},{"location":"user-guide/dataframe-schema/#api-response-validation","title":"API Response Validation","text":"<pre><code>from polars import DataFrame\n\ndef validate_api_response(json_data: list) -&gt; DataFrame:\n    \"\"\"Convert and validate API data.\"\"\"\n    df = DataFrame(json_data)\n\n    # Validate structure\n    result = IndicatorSchema.validate_dataframe(df)\n    if not result['valid']:\n        raise ValueError(f\"API data invalid: {result}\")\n\n    return result.get('converted_df', df)\n</code></pre>"},{"location":"user-guide/dataframe-schema/#best-practices","title":"Best Practices","text":"<ul> <li>Always validate input data before processing</li> <li>Use column categories to organize database tables efficiently</li> <li>Leverage auto-conversion for Pandas compatibility</li> <li>Check type_issues for data quality problems</li> <li>Use descriptions for database comments and API documentation</li> </ul>"},{"location":"user-guide/examples/","title":"Examples","text":"<p>This section provides comprehensive examples of using TheStrat for various trading scenarios and asset classes.</p>"},{"location":"user-guide/examples/#basic-examples","title":"Basic Examples","text":""},{"location":"user-guide/examples/#simple-5-minute-analysis","title":"Simple 5-Minute Analysis","text":"<pre><code>from pandas import DataFrame as PandasDataFrame\nfrom thestrat import Factory\nfrom thestrat.schemas import (\n    FactoryConfig, AggregationConfig, IndicatorsConfig,\n    TimeframeItemConfig, SwingPointsConfig\n)\n\n# Sample market data\ndata = PandasDataFrame({\n    'timestamp': pd.date_range('2024-01-01 09:30', periods=300, freq='1min'),\n    'open': [100 + i*0.1 for i in range(300)],\n    'high': [100.5 + i*0.1 for i in range(300)],\n    'low': [99.5 + i*0.1 for i in range(300)],\n    'close': [100.2 + i*0.1 for i in range(300)],\n    'volume': [1000 + i*10 for i in range(300)]\n})\n\n# Configure for 5-minute equity analysis with Pydantic models\nconfig = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"5m\"],\n        asset_class=\"equities\",\n        timezone=\"US/Eastern\"\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"all\"],\n                swing_points=SwingPointsConfig(window=5, threshold=2.0)\n            )\n        ]\n    )\n)\n\n# Process the data\npipeline = Factory.create_all(config)\naggregated = pipeline[\"aggregation\"].process(data)\nanalyzed = pipeline[\"indicators\"].process(aggregated)\n\n# Display results\nprint(f\"Converted {len(data)} 1-minute bars to {len(aggregated)} 5-minute bars\")\nprint(f\"Found {analyzed['inside_bar'].sum()} inside bars\")\nprint(f\"Found {analyzed['outside_bar'].sum()} outside bars\")\n</code></pre>"},{"location":"user-guide/examples/#multi-timeframe-analysis","title":"Multi-Timeframe Analysis","text":"<pre><code>from thestrat import Factory\nfrom thestrat.schemas import (\n    FactoryConfig, AggregationConfig, IndicatorsConfig,\n    TimeframeItemConfig, SwingPointsConfig\n)\nfrom pandas import DataFrame as PandasDataFrame\n\ndef analyze_multiple_timeframes(data, timeframes=['5m', '15m', '1h']):\n    \"\"\"Analyze data across multiple timeframes using Pydantic models.\"\"\"\n    # Single configuration for multiple timeframes using models\n    config = FactoryConfig(\n        aggregation=AggregationConfig(\n            target_timeframes=timeframes,  # Process all timeframes together\n            asset_class=\"equities\",\n            timezone=\"US/Eastern\"\n        ),\n        indicators=IndicatorsConfig(\n            timeframe_configs=[\n                TimeframeItemConfig(\n                    timeframes=[\"5m\"],\n                    swing_points=SwingPointsConfig(window=3, threshold=1.5)  # Short-term settings\n                ),\n                TimeframeItemConfig(\n                    timeframes=[\"15m\", \"1h\"],\n                    swing_points=SwingPointsConfig(window=7, threshold=2.5)  # Long-term settings\n                )\n            ]\n        )\n    )\n\n    # Single pipeline processes all timeframes\n    pipeline = Factory.create_all(config)\n    aggregated = pipeline[\"aggregation\"].process(data)\n    analyzed = pipeline[\"indicators\"].process(aggregated)\n\n    # Extract results by timeframe from normalized output\n    results = {}\n    for tf in timeframes:\n        tf_data = analyzed[analyzed['timeframe'] == tf]\n        results[tf] = {\n            'data': tf_data,\n            'inside_bars': tf_data['inside_bar'].sum(),\n            'outside_bars': tf_data['outside_bar'].sum(),\n            'pivot_highs': tf_data['pivot_high'].sum() if 'pivot_high' in tf_data.columns else 0,\n            'pivot_lows': tf_data['pivot_low'].sum() if 'pivot_low' in tf_data.columns else 0\n        }\n\n    return results, analyzed  # Return both summary and full data\n\n# Use with your data\nmulti_tf_analysis, full_data = analyze_multiple_timeframes(sample_data)\n\n# Display summary\nfor tf, result in multi_tf_analysis.items():\n    print(f\"{tf}: {result['inside_bars']} inside, {result['outside_bars']} outside\")\n\nprint(f\"Total processed: {len(full_data)} bars across {len(full_data['timeframe'].unique())} timeframes\")\n</code></pre>"},{"location":"user-guide/examples/#asset-class-specific-examples","title":"Asset Class Specific Examples","text":""},{"location":"user-guide/examples/#cryptocurrency-247-trading","title":"Cryptocurrency (24/7 Trading)","text":"<pre><code># Bitcoin/crypto configuration with Pydantic models\ncrypto_config = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"1h\"],\n        asset_class=\"crypto\",\n        timezone=\"UTC\"  # Always UTC for crypto\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"all\"],\n                swing_points=SwingPointsConfig(\n                    window=6,  # Slightly larger window for hourly\n                    threshold=3.0  # Higher threshold for crypto volatility\n                )\n            )\n        ]\n    )\n)\n\ncrypto_pipeline = Factory.create_all(crypto_config)\n\n# Process crypto data (note: no market hours restrictions)\ncrypto_analyzed = crypto_pipeline[\"aggregation\"].process(btc_data)\ncrypto_signals = crypto_pipeline[\"indicators\"].process(crypto_analyzed)\n\nprint(f\"Crypto analysis: 24/7 trading, {len(crypto_signals)} hourly bars\")\n</code></pre>"},{"location":"user-guide/examples/#forex-245-trading","title":"Forex (24/5 Trading)","text":"<pre><code># EUR/USD analysis with Pydantic models\nfx_config = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"4h\"],\n        asset_class=\"fx\",\n        timezone=\"UTC\"\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"all\"],\n                swing_points=SwingPointsConfig(\n                    window=4,\n                    threshold=0.5  # Lower threshold for FX (measured in %)\n                )\n            )\n        ]\n    )\n)\n\nfx_pipeline = Factory.create_all(fx_config)\n\n# FX data processing handles weekend gaps automatically\neurusd_aggregated = fx_pipeline[\"aggregation\"].process(eurusd_1m_data)\neurusd_analyzed = fx_pipeline[\"indicators\"].process(eurusd_aggregated)\n\n# Find major swing points (check for boolean columns indicating new pivots)\nmajor_swings = eurusd_analyzed[\n    (eurusd_analyzed.get('new_pivot_high', False) == True) |\n    (eurusd_analyzed.get('new_pivot_low', False) == True)\n] if 'new_pivot_high' in eurusd_analyzed.columns or 'new_pivot_low' in eurusd_analyzed.columns else []\nprint(f\"Found {len(major_swings)} major swing points in EUR/USD\")\n</code></pre>"},{"location":"user-guide/examples/#multi-timeframe-examples","title":"Multi-Timeframe Examples","text":""},{"location":"user-guide/examples/#single-request-multi-timeframe-analysis","title":"Single Request Multi-Timeframe Analysis","text":"<pre><code>from thestrat import Factory\n\n# Process multiple timeframes with different configurations using Pydantic models\nconfig = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"5m\", \"15m\", \"1h\", \"1d\"],  # All timeframes together\n        asset_class=\"equities\",\n        timezone=\"US/Eastern\"\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"5m\"],  # Short-term aggressive settings\n                swing_points=SwingPointsConfig(window=3, threshold=1.0)\n            ),\n            TimeframeItemConfig(\n                timeframes=[\"15m\"],  # Medium-term balanced settings\n                swing_points=SwingPointsConfig(window=5, threshold=2.0)\n            ),\n            TimeframeItemConfig(\n                timeframes=[\"1h\", \"1d\"],  # Long-term conservative settings\n                swing_points=SwingPointsConfig(window=10, threshold=3.0)\n            )\n        ]\n    )\n)\n\npipeline = Factory.create_all(config)\naggregated = pipeline[\"aggregation\"].process(market_data)\nanalyzed = pipeline[\"indicators\"].process(aggregated)\n\n# Extract results for each timeframe from normalized output\nfor tf in [\"5m\", \"15m\", \"1h\", \"1d\"]:\n    tf_data = analyzed[analyzed['timeframe'] == tf]\n    print(f\"{tf}: {len(tf_data)} bars, {tf_data['inside_bar'].sum()} inside bars\")\n\nprint(f\"Total: {len(analyzed)} bars across {len(analyzed['timeframe'].unique())} timeframes\")\n</code></pre>"},{"location":"user-guide/examples/#swing-point-analysis","title":"Swing Point Analysis","text":""},{"location":"user-guide/examples/#understanding-swing-point-detection","title":"Understanding Swing Point Detection","text":"<p>Swing points are critical for identifying market structure in TheStrat methodology. The implementation uses precise peak/valley detection with configurable parameters.</p> <pre><code>from thestrat import Factory\nfrom thestrat.schemas import (\n    FactoryConfig, AggregationConfig, IndicatorsConfig,\n    TimeframeItemConfig, SwingPointsConfig\n)\nfrom pandas import DataFrame as PandasDataFrame\n\ndef analyze_swing_points(data):\n    \"\"\"Demonstrate swing point detection with different configurations.\"\"\"\n\n    # Configuration with detailed swing point settings\n    config = FactoryConfig(\n        aggregation=AggregationConfig(\n            target_timeframes=[\"5m\"],\n            asset_class=\"equities\",\n            timezone=\"US/Eastern\"\n        ),\n        indicators=IndicatorsConfig(\n            timeframe_configs=[\n                TimeframeItemConfig(\n                    timeframes=[\"all\"],\n                    swing_points=SwingPointsConfig(\n                        window=5,        # Look 5 bars back and ahead\n                        threshold=2.0    # Require 2% price change to confirm\n                    )\n                )\n            ]\n        )\n    )\n\n    # Process the data\n    pipeline = Factory.create_all(config)\n    aggregated = pipeline[\"aggregation\"].process(data)\n    analyzed = pipeline[\"indicators\"].process(aggregated)\n\n    # Analyze swing point results\n    swing_highs = analyzed.filter(analyzed['new_swing_high'] == True)\n    swing_lows = analyzed.filter(analyzed['new_swing_low'] == True)\n\n    print(f\"Detected {len(swing_highs)} swing highs\")\n    print(f\"Detected {len(swing_lows)} swing lows\")\n\n    # Market structure analysis\n    higher_highs = analyzed.filter(analyzed['new_higher_high'] == True)\n    lower_lows = analyzed.filter(analyzed['new_lower_low'] == True)\n\n    print(f\"Higher highs: {len(higher_highs)} (bullish structure)\")\n    print(f\"Lower lows: {len(lower_lows)} (bearish structure)\")\n\n    return analyzed\n\n# Example usage with trending data\ntrending_data = PandasDataFrame({\n    'timestamp': pd.date_range('2024-01-01 09:30', periods=100, freq='5min'),\n    'open': [100 + i*0.5 + (i%10)*0.2 for i in range(100)],    # Trending up with oscillations\n    'high': [101 + i*0.5 + (i%10)*0.3 for i in range(100)],\n    'low': [99 + i*0.5 + (i%10)*0.1 for i in range(100)],\n    'close': [100.5 + i*0.5 + (i%10)*0.25 for i in range(100)],\n    'volume': [1000 + i*10 for i in range(100)]\n})\n\nresults = analyze_swing_points(trending_data)\n</code></pre>"},{"location":"user-guide/examples/#swing-point-configuration-strategies","title":"Swing Point Configuration Strategies","text":"<p>Different market conditions and trading styles require different swing point settings:</p> <pre><code>def compare_swing_configurations(data):\n    \"\"\"Compare different swing point configurations.\"\"\"\n\n    configurations = [\n        (\"Scalping\", SwingPointsConfig(window=3, threshold=0.5)),     # Very sensitive\n        (\"Day Trading\", SwingPointsConfig(window=5, threshold=1.5)),  # Balanced\n        (\"Swing Trading\", SwingPointsConfig(window=10, threshold=3.0)), # Conservative\n        (\"Position Trading\", SwingPointsConfig(window=20, threshold=5.0)) # Very conservative\n    ]\n\n    results = {}\n\n    for strategy_name, swing_config in configurations:\n        config = FactoryConfig(\n            aggregation=AggregationConfig(\n                target_timeframes=[\"5m\"],\n                asset_class=\"equities\"\n            ),\n            indicators=IndicatorsConfig(\n                timeframe_configs=[\n                    TimeframeItemConfig(\n                        timeframes=[\"all\"],\n                        swing_points=swing_config\n                    )\n                ]\n            )\n        )\n\n        pipeline = Factory.create_all(config)\n        aggregated = pipeline[\"aggregation\"].process(data)\n        analyzed = pipeline[\"indicators\"].process(aggregated)\n\n        # Count swing points detected\n        swing_count = len(analyzed.filter(\n            (analyzed['new_swing_high'] == True) |\n            (analyzed['new_swing_low'] == True)\n        ))\n\n        results[strategy_name] = {\n            'config': swing_config,\n            'swing_points': swing_count,\n            'frequency': f\"{swing_count/len(analyzed)*100:.1f}% of bars\"\n        }\n\n        print(f\"{strategy_name}: {swing_count} swing points ({results[strategy_name]['frequency']})\")\n\n    return results\n\n# Compare configurations\nconfig_results = compare_swing_configurations(trending_data)\n</code></pre>"},{"location":"user-guide/examples/#market-structure-trend-analysis","title":"Market Structure Trend Analysis","text":"<p>Understanding the relationship between swing highs and lows reveals market trends:</p> <pre><code>def analyze_market_structure_trend(analyzed_data):\n    \"\"\"Analyze trend direction using market structure.\"\"\"\n\n    # Get chronological swing points\n    swing_points = analyzed_data.filter(\n        (analyzed_data['new_swing_high'] == True) |\n        (analyzed_data['new_swing_low'] == True)\n    ).sort('timestamp')\n\n    if len(swing_points) &lt; 4:\n        return \"Insufficient swing points for trend analysis\"\n\n    # Count recent structure patterns\n    recent_data = analyzed_data.tail(50)  # Last 50 bars\n\n    hh_count = len(recent_data.filter(recent_data['new_higher_high'] == True))\n    hl_count = len(recent_data.filter(recent_data['new_higher_low'] == True))\n    lh_count = len(recent_data.filter(recent_data['new_lower_high'] == True))\n    ll_count = len(recent_data.filter(recent_data['new_lower_low'] == True))\n\n    bullish_signals = hh_count + hl_count\n    bearish_signals = lh_count + ll_count\n\n    print(f\"Recent Market Structure (last 50 bars):\")\n    print(f\"  Higher Highs: {hh_count}\")\n    print(f\"  Higher Lows: {hl_count}\")\n    print(f\"  Lower Highs: {lh_count}\")\n    print(f\"  Lower Lows: {ll_count}\")\n    print(f\"  Bullish signals: {bullish_signals}\")\n    print(f\"  Bearish signals: {bearish_signals}\")\n\n    if bullish_signals &gt; bearish_signals * 1.5:\n        trend = \"Strong Uptrend\"\n    elif bearish_signals &gt; bullish_signals * 1.5:\n        trend = \"Strong Downtrend\"\n    elif bullish_signals &gt; bearish_signals:\n        trend = \"Weak Uptrend\"\n    elif bearish_signals &gt; bullish_signals:\n        trend = \"Weak Downtrend\"\n    else:\n        trend = \"Sideways/Consolidation\"\n\n    print(f\"  Trend Assessment: {trend}\")\n    return trend\n\n# Analyze the trend\ntrend_assessment = analyze_market_structure_trend(results)\n</code></pre>"},{"location":"user-guide/examples/#performance-considerations","title":"Performance Considerations","text":"<p>TheStrat's swing point detection is fully vectorized for optimal performance:</p> <pre><code>import time\n\ndef benchmark_swing_detection(data_size=10000):\n    \"\"\"Benchmark swing point detection performance.\"\"\"\n\n    # Generate large dataset\n    large_data = PandasDataFrame({\n        'timestamp': pd.date_range('2024-01-01', periods=data_size, freq='1min'),\n        'open': [100 + i*0.01 + (i%100)*0.1 for i in range(data_size)],\n        'high': [100.5 + i*0.01 + (i%100)*0.15 for i in range(data_size)],\n        'low': [99.5 + i*0.01 + (i%100)*0.05 for i in range(data_size)],\n        'close': [100.2 + i*0.01 + (i%100)*0.12 for i in range(data_size)],\n        'volume': [1000 + i for i in range(data_size)]\n    })\n\n    config = FactoryConfig(\n        aggregation=AggregationConfig(\n            target_timeframes=[\"5m\"],\n            asset_class=\"equities\"\n        ),\n        indicators=IndicatorsConfig(\n            timeframe_configs=[\n                TimeframeItemConfig(\n                    timeframes=[\"all\"],\n                    swing_points=SwingPointsConfig(window=5, threshold=2.0)\n                )\n            ]\n        )\n    )\n\n    pipeline = Factory.create_all(config)\n\n    # Benchmark aggregation\n    start_time = time.time()\n    aggregated = pipeline[\"aggregation\"].process(large_data)\n    agg_time = time.time() - start_time\n\n    # Benchmark indicators (including swing points)\n    start_time = time.time()\n    analyzed = pipeline[\"indicators\"].process(aggregated)\n    indicator_time = time.time() - start_time\n\n    print(f\"Performance Benchmark ({data_size:,} input rows):\")\n    print(f\"  Aggregation: {agg_time:.3f}s ({len(large_data)/agg_time:,.0f} rows/sec)\")\n    print(f\"  Indicators: {indicator_time:.3f}s ({len(aggregated)/indicator_time:,.0f} rows/sec)\")\n    print(f\"  Total: {agg_time + indicator_time:.3f}s\")\n    print(f\"  Output: {len(analyzed)} bars with full indicator analysis\")\n\n# Run performance benchmark\nbenchmark_swing_detection(10000)\n</code></pre>"},{"location":"user-guide/examples/#cross-timeframe-signal-correlation","title":"Cross-Timeframe Signal Correlation","text":"<pre><code>def analyze_cross_timeframe_signals(data):\n    \"\"\"Analyze signal correlation across multiple timeframes.\"\"\"\n    config = FactoryConfig(\n        aggregation=AggregationConfig(\n            target_timeframes=[\"5m\", \"15m\", \"1h\"],\n            asset_class=\"equities\"\n        ),\n        indicators=IndicatorsConfig(\n            timeframe_configs=[\n                TimeframeItemConfig(\n                    timeframes=[\"all\"],\n                    swing_points=SwingPointsConfig(window=5, threshold=2.0)\n                )\n            ]\n        )\n    )\n\n    pipeline = Factory.create_all(config)\n    aggregated = pipeline[\"aggregation\"].process(data)\n    analyzed = pipeline[\"indicators\"].process(aggregated)\n\n    # Find synchronized signals across timeframes\n    synchronized_signals = []\n\n    # Get latest bar for each timeframe\n    latest_by_tf = {}\n    for tf in [\"5m\", \"15m\", \"1h\"]:\n        tf_data = analyzed[analyzed['timeframe'] == tf]\n        if len(tf_data) &gt; 0:\n            latest_by_tf[tf] = tf_data.iloc[-1]\n\n    # Check for signal alignment\n    if all(bar.get('outside_bar', False) for bar in latest_by_tf.values()):\n        synchronized_signals.append({\n            'type': 'multi_timeframe_breakout',\n            'timeframes': list(latest_by_tf.keys()),\n            'timestamp': list(latest_by_tf.values())[0]['timestamp']\n        })\n\n    return synchronized_signals, analyzed\n\n# Example usage\nsignals, full_analysis = analyze_cross_timeframe_signals(sample_data)\nprint(f\"Found {len(signals)} synchronized signals across multiple timeframes\")\n</code></pre>"},{"location":"user-guide/examples/#advanced-analysis-examples","title":"Advanced Analysis Examples","text":""},{"location":"user-guide/examples/#custom-signal-detection","title":"Custom Signal Detection","text":"<pre><code>def detect_strat_patterns(data):\n    \"\"\"Detect common TheStrat patterns.\"\"\"\n    patterns = []\n\n    for i in range(2, len(data)):\n        current = data.iloc[i]\n        prev1 = data.iloc[i-1]\n        prev2 = data.iloc[i-2]\n\n        # Inside bar followed by breakout (2-1-2 Continuation)\n        if (prev2['outside_bar'] and\n            prev1['inside_bar'] and\n            current['close'] &gt; prev2['high']):\n            patterns.append({\n                'timestamp': current['timestamp'],\n                'pattern': '2-1-2_bullish_continuation',\n                'entry_price': prev2['high'],\n                'target': current['close'] + (current['close'] - prev2['low']) * 0.5\n            })\n\n        # Outside bar reversal\n        if (current['outside_bar'] and\n            prev1['close'] &gt; prev1['open'] and  # Previous bar was bullish\n            current['close'] &lt; current['open']):  # Current bar is bearish\n            patterns.append({\n                'timestamp': current['timestamp'],\n                'pattern': 'outside_bar_reversal',\n                'entry_price': current['low'],\n                'stop_loss': current['high']\n            })\n\n    return patterns\n\n# Apply pattern detection\npatterns = detect_strat_patterns(analyzed_data)\nprint(f\"Detected {len(patterns)} TheStrat patterns\")\n\n# Display recent patterns\nfor pattern in patterns[-5:]:\n    print(f\"{pattern['timestamp']}: {pattern['pattern']} @ {pattern['entry_price']}\")\n</code></pre>"},{"location":"user-guide/examples/#risk-management-integration","title":"Risk Management Integration","text":"<pre><code>def calculate_position_sizes(signals, account_balance, risk_percent=2.0):\n    \"\"\"Calculate position sizes based on TheStrat signals.\"\"\"\n    positions = []\n\n    for signal in signals:\n        if 'entry_price' in signal and 'stop_loss' in signal:\n            # Calculate risk per share\n            risk_per_share = abs(signal['entry_price'] - signal['stop_loss'])\n\n            # Calculate position size\n            risk_amount = account_balance * (risk_percent / 100)\n            position_size = int(risk_amount / risk_per_share) if risk_per_share &gt; 0 else 0\n\n            positions.append({\n                **signal,\n                'position_size': position_size,\n                'risk_amount': risk_amount,\n                'risk_per_share': risk_per_share\n            })\n\n    return positions\n\n# Example usage\naccount_balance = 100000  # $100k account\nrisk_per_trade = 2.0      # 2% risk per trade\n\nsized_positions = calculate_position_sizes(patterns, account_balance, risk_per_trade)\n\nfor pos in sized_positions:\n    if pos['position_size'] &gt; 0:\n        print(f\"Signal: {pos['pattern']}\")\n        print(f\"Entry: ${pos['entry_price']:.2f}\")\n        print(f\"Size: {pos['position_size']} shares\")\n        print(f\"Risk: ${pos['risk_amount']:.2f}\")\n        print(\"---\")\n</code></pre>"},{"location":"user-guide/examples/#real-time-analysis-simulation","title":"Real-Time Analysis Simulation","text":"<pre><code>import time\nfrom datetime import datetime\n\ndef simulate_real_time_analysis(historical_data, interval_seconds=60):\n    \"\"\"Simulate real-time TheStrat analysis with Pydantic models.\"\"\"\n\n    config = FactoryConfig(\n        aggregation=AggregationConfig(target_timeframes=[\"5m\"], asset_class=\"equities\"),\n        indicators=IndicatorsConfig(\n            timeframe_configs=[\n                TimeframeItemConfig(\n                    timeframes=[\"all\"],\n                    swing_points=SwingPointsConfig(window=5, threshold=2.0)\n                )\n            ]\n        )\n    )\n\n    pipeline = Factory.create_all(config)\n\n    # Simulate streaming data\n    for i in range(50, len(historical_data), 5):  # Add 5 bars at a time\n        current_data = historical_data.iloc[:i]\n\n        # Process latest data\n        aggregated = pipeline[\"aggregation\"].process(current_data)\n        analyzed = pipeline[\"indicators\"].process(aggregated)\n\n        # Check for new signals (last bar)\n        if len(analyzed) &gt; 0:\n            latest = analyzed.iloc[-1]\n\n            if latest['inside_bar']:\n                print(f\"{datetime.now()}: Inside bar detected @ {latest['close']:.2f}\")\n            elif latest['outside_bar']:\n                print(f\"{datetime.now()}: Outside bar detected @ {latest['close']:.2f}\")\n\n            # Check for pivot points\n            if latest.get('new_pivot_high', False):\n                print(f\"{datetime.now()}: New Pivot HIGH @ {latest['high']:.2f}\")\n            elif latest.get('new_pivot_low', False):\n                print(f\"{datetime.now()}: New Pivot LOW @ {latest['low']:.2f}\")\n\n        time.sleep(interval_seconds)\n\n# Run simulation (comment out for docs)\n# simulate_real_time_analysis(sample_data, interval_seconds=2)\n</code></pre>"},{"location":"user-guide/examples/#performance-optimization-examples","title":"Performance Optimization Examples","text":""},{"location":"user-guide/examples/#batch-processing","title":"Batch Processing","text":"<pre><code>def batch_process_symbols(symbol_data_dict, config_template):\n    \"\"\"Process multiple symbols efficiently with new API.\"\"\"\n    results = {}\n\n    # Create pipeline once - supports multiple timeframes per symbol\n    pipeline = Factory.create_all(config_template)\n\n    for symbol, data in symbol_data_dict.items():\n        try:\n            # Process each symbol - now handles multiple timeframes\n            aggregated = pipeline[\"aggregation\"].process(data)\n            analyzed = pipeline[\"indicators\"].process(aggregated)\n\n            # Store results with timeframe breakdown\n            results[symbol] = {\n                'data': analyzed,\n                'timeframes': analyzed['timeframe'].unique().tolist(),\n                'inside_bars': analyzed['inside_bar'].sum(),\n                'outside_bars': analyzed['outside_bar'].sum(),\n                'last_price': analyzed.iloc[-1]['close'],\n                'total_bars': len(analyzed)\n            }\n\n            print(f\"Processed {symbol}: {len(analyzed)} bars across {len(analyzed['timeframe'].unique())} timeframes\")\n\n        except Exception as e:\n            print(f\"Error processing {symbol}: {e}\")\n            results[symbol] = None\n\n    return results\n\n# Example usage\nsymbols_data = {\n    'AAPL': aapl_data,\n    'MSFT': msft_data,\n    'GOOGL': googl_data\n}\n\nbatch_results = batch_process_symbols(symbols_data, config)\n</code></pre>"},{"location":"user-guide/examples/#memory-efficient-processing","title":"Memory Efficient Processing","text":"<pre><code>def process_large_dataset(data, chunk_size=1000):\n    \"\"\"Process large datasets in chunks to manage memory with new API.\"\"\"\n\n    config = FactoryConfig(\n        aggregation=AggregationConfig(\n            target_timeframes=[\"5m\"],\n            asset_class=\"equities\"\n        ),\n        indicators=IndicatorsConfig(\n            timeframe_configs=[\n                TimeframeItemConfig(\n                    timeframes=[\"all\"],\n                    swing_points=SwingPointsConfig(window=5)\n                )\n            ]\n        )\n    )\n\n    pipeline = Factory.create_all(config)\n    results = []\n\n    # Process in chunks\n    for start_idx in range(0, len(data), chunk_size):\n        end_idx = min(start_idx + chunk_size, len(data))\n        chunk = data.iloc[start_idx:end_idx]\n\n        # Include overlap for continuity\n        if start_idx &gt; 0:\n            overlap = data.iloc[max(0, start_idx-100):start_idx]\n            chunk = pd.concat([overlap, chunk])\n\n        # Process chunk\n        aggregated = pipeline[\"aggregation\"].process(chunk)\n        analyzed = pipeline[\"indicators\"].process(aggregated)\n\n        # Store results (excluding overlap)\n        if start_idx &gt; 0:\n            analyzed = analyzed.iloc[20:]  # Remove overlap portion\n\n        results.append(analyzed)\n        print(f\"Processed chunk {start_idx//chunk_size + 1}\")\n\n    # Combine results\n    final_result = pd.concat(results, ignore_index=True)\n    return final_result\n</code></pre>"},{"location":"user-guide/examples/#integration-examples","title":"Integration Examples","text":""},{"location":"user-guide/examples/#with-popular-trading-libraries","title":"With Popular Trading Libraries","text":"<pre><code># Integration with backtrader\nimport backtrader as bt\n\nclass TheStratStrategy(bt.Strategy):\n    def __init__(self):\n        self.thestrat_config = FactoryConfig(\n            aggregation=AggregationConfig(\n                target_timeframes=[\"5m\"],\n                asset_class=\"equities\"\n            ),\n            indicators=IndicatorsConfig(\n                timeframe_configs=[\n                    TimeframeItemConfig(\n                        timeframes=[\"all\"],\n                        swing_points=SwingPointsConfig(window=5, threshold=2.0)\n                    )\n                ]\n            )\n        )\n        self.pipeline = Factory.create_all(self.thestrat_config)\n\n    def next(self):\n        # Convert backtrader data to DataFrame\n        data = self.convert_bt_data()\n\n        # Apply TheStrat analysis\n        analyzed = self.pipeline[\"indicators\"].process(\n            self.pipeline[\"aggregation\"].process(data)\n        )\n\n        # Trading logic based on TheStrat signals\n        if analyzed.iloc[-1]['outside_bar'] and not self.position:\n            self.buy()\n        elif analyzed.iloc[-1]['inside_bar'] and self.position:\n            self.close()\n\n# Integration with zipline\nfrom zipline.api import order, record, symbol\n\ndef thestrat_zipline_algo(context, data):\n    # Get price data\n    prices = data.history(symbol('AAPL'), ['open', 'high', 'low', 'close'], 100, '1d')\n\n    # Apply TheStrat with new API\n    config = FactoryConfig(\n        aggregation=AggregationConfig(target_timeframes=[\"1d\"]),\n        indicators=IndicatorsConfig(\n            timeframe_configs=[\n                TimeframeItemConfig(\n                    timeframes=[\"all\"],\n                    swing_points=SwingPointsConfig(window=5)\n                )\n            ]\n        )\n    )\n    pipeline = Factory.create_all(config)\n    aggregated = pipeline[\"aggregation\"].process(prices.reset_index())\n    analyzed = pipeline[\"indicators\"].process(aggregated)\n\n    # Trading decisions\n    if analyzed.iloc[-1]['outside_bar']:\n        order(symbol('AAPL'), 100)\n\n    record(inside_bars=analyzed['inside_bar'].sum())\n</code></pre> <p>These examples demonstrate the flexibility and power of TheStrat for various trading scenarios. Adapt the configurations and logic to match your specific trading strategy and requirements.</p>"},{"location":"user-guide/installation/","title":"Installation","text":"<p>This guide covers how to install the TheStrat module in different environments and scenarios.</p>"},{"location":"user-guide/installation/#prerequisites","title":"Prerequisites","text":"<p>Before installing TheStrat, ensure you have:</p> <ul> <li>Python 3.11 or higher</li> <li>uv package manager (recommended) or pip</li> <li>Git (for development installation)</li> </ul>"},{"location":"user-guide/installation/#installing-uv-recommended","title":"Installing uv (Recommended)","text":"<p>If you don't have <code>uv</code> installed, it's the fastest Python package installer:</p> <pre><code># On macOS and Linux\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# On Windows\npowershell -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n\n# Or with pip\npip install uv\n</code></pre>"},{"location":"user-guide/installation/#installation-options","title":"Installation Options","text":""},{"location":"user-guide/installation/#option-1-direct-installation-recommended","title":"Option 1: Direct Installation (Recommended)","text":"<p>Install directly from the GitHub repository:</p> Install TheStrat<pre><code>uv add git+https://github.com/jlixfeld/thestrat.git\n</code></pre>"},{"location":"user-guide/installation/#option-2-development-installation","title":"Option 2: Development Installation","text":"<p>For development work or to run tests:</p> Development Setup<pre><code># Clone the repository\ngit clone https://github.com/jlixfeld/thestrat.git\ncd thestrat\n\n# Install with development dependencies\nuv sync --extra test --extra dev --extra docs\n</code></pre>"},{"location":"user-guide/installation/#option-3-using-pip","title":"Option 3: Using pip","text":"<p>If you prefer using pip:</p> <pre><code>pip install git+https://github.com/jlixfeld/thestrat.git\n</code></pre>"},{"location":"user-guide/installation/#verify-installation","title":"Verify Installation","text":"<p>Test your installation by importing the module:</p> Verify Installation<pre><code>import thestrat\nprint(f\"TheStrat version: {thestrat.__version__}\")  # Dynamic version from package\n\n# Test basic functionality with Pydantic models\nfrom thestrat import Factory\nfrom thestrat.schemas import (\n    FactoryConfig, AggregationConfig, IndicatorsConfig,\n    TimeframeItemConfig, SwingPointsConfig\n)\n\nconfig = FactoryConfig(\n    aggregation=AggregationConfig(target_timeframes=[\"5m\"]),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"all\"],\n                swing_points=SwingPointsConfig(window=5, threshold=2.0)\n            )\n        ]\n    )\n)\n\ncomponents = Factory.create_all(config)\nprint(\"Installation successful!\")\n</code></pre>"},{"location":"user-guide/installation/#development-setup","title":"Development Setup","text":"<p>If you're planning to contribute or modify the code:</p>"},{"location":"user-guide/installation/#1-clone-and-install","title":"1. Clone and Install","text":"<pre><code>git clone https://github.com/jlixfeld/thestrat.git\ncd thestrat\nuv sync --extra test --extra dev --extra docs\n</code></pre>"},{"location":"user-guide/installation/#2-verify-development-environment","title":"2. Verify Development Environment","text":"<pre><code># Run tests\nuv run pytest\n\n# Check code formatting\nuv run ruff check .\n\n# Format code\nuv run ruff format .\n\n# Build documentation\nuv run mkdocs serve\n</code></pre>"},{"location":"user-guide/installation/#3-run-development-tests","title":"3. Run Development Tests","text":"<p>Verify your development environment:</p> <pre><code># Run all tests\nuv run pytest\n\n# Check code quality\nuv run ruff check .\n</code></pre>"},{"location":"user-guide/installation/#dependencies","title":"Dependencies","text":"<p>TheStrat has the following dependencies:</p>"},{"location":"user-guide/installation/#core-dependencies","title":"Core Dependencies","text":"<ul> <li>polars[timezone] \u22651.0.0 - High-performance data processing</li> <li>pandas \u22651.5.0 - Data manipulation and analysis</li> <li>numpy \u22651.21.0 - Numerical computing</li> <li>pytz \u22652022.1 - Timezone handling</li> </ul>"},{"location":"user-guide/installation/#development-dependencies","title":"Development Dependencies","text":"<ul> <li>pytest \u22656.0 - Testing framework</li> <li>ruff ==0.11.13 - Linting and formatting</li> <li>pytest-cov \u22652.0 - Coverage reporting</li> </ul>"},{"location":"user-guide/installation/#documentation-dependencies","title":"Documentation Dependencies","text":"<ul> <li>mkdocs-material \u22659.4.0 - Documentation theme</li> <li>mkdocstrings[python] \u22650.24.0 - API documentation generation</li> </ul>"},{"location":"user-guide/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-guide/installation/#common-issues","title":"Common Issues","text":"<p>Import Error: <code>ModuleNotFoundError: No module named 'thestrat'</code> :   Ensure you've activated the correct Python environment and the module is installed.</p> <p>Version Conflicts: Dependency resolution errors :   Use <code>uv</code> which has better dependency resolution than pip:     <pre><code>uv add git+https://github.com/jlixfeld/thestrat.git\n</code></pre></p> <p>Permission Errors: Cannot write to installation directory :   Use a virtual environment or user installation:     <pre><code># Create virtual environment\nuv venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\nuv add git+https://github.com/jlixfeld/thestrat.git\n</code></pre></p> <p>Test Failures: Tests failing during development setup :   Ensure you have the test dependencies:     <pre><code>uv sync --extra test\nuv run pytest -v\n</code></pre></p>"},{"location":"user-guide/installation/#getting-help","title":"Getting Help","text":"<p>If you encounter issues not covered here:</p> <ol> <li>Check that all prerequisites are installed</li> <li>Verify your Python version: <code>python --version</code></li> <li>Try creating a fresh virtual environment</li> <li>Contact the maintainer with error details</li> </ol>"},{"location":"user-guide/installation/#next-steps","title":"Next Steps","text":"<p>Once installation is complete, proceed to the Quick Start guide to begin using TheStrat in your applications.</p>"},{"location":"user-guide/quickstart/","title":"Quick Start","text":"<p>Get up and running with TheStrat in just a few minutes. This guide assumes you have already installed the module.</p>"},{"location":"user-guide/quickstart/#basic-workflow","title":"Basic Workflow","text":"<p>TheStrat follows a simple workflow:</p> <ol> <li>Configure your components using the Factory pattern</li> <li>Aggregate your data to the desired timeframe</li> <li>Analyze with TheStrat indicators</li> <li>Extract signals and insights</li> </ol>"},{"location":"user-guide/quickstart/#your-first-thestrat-analysis","title":"Your First TheStrat Analysis","text":"<p>Let's start with a complete example using sample market data:</p> <pre><code>from pandas import DataFrame as PandasDataFrame\nfrom thestrat import Factory\nfrom thestrat.schemas import (\n    FactoryConfig, AggregationConfig, IndicatorsConfig,\n    TimeframeItemConfig, SwingPointsConfig\n)\n\n# Sample OHLCV data (1-minute bars)\nsample_data = PandasDataFrame({\n    'timestamp': pd.date_range('2024-01-01 09:30', periods=100, freq='1min'),\n    'open': [100.0] * 100,\n    'high': [101.0] * 100,\n    'low': [99.0] * 100,\n    'close': [100.5] * 100,\n    'volume': [1000] * 100\n})\n\n# Configure TheStrat components with Pydantic models\nconfig = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"5m\"],  # Aggregate to 5-minute bars (now supports multiple)\n        asset_class=\"equities\",    # US equity market\n        timezone=\"US/Eastern\"      # Eastern timezone\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"all\"],    # Apply to all target timeframes\n                swing_points=SwingPointsConfig(\n                    window=5,            # 5-period swing detection\n                    threshold=2.0        # 2% threshold for significance\n                )\n            )\n        ]\n    )\n)\n\n# Create components using Factory\npipeline = Factory.create_all(config)\n\n# Process the data - now returns normalized output with timeframe column\naggregated_data = pipeline[\"aggregation\"].process(sample_data)\nanalyzed_data = pipeline[\"indicators\"].process(aggregated_data)\n\nprint(f\"Original bars: {len(sample_data)}\")\nprint(f\"Aggregated bars: {len(aggregated_data)}\")\nprint(f\"Analysis complete: {len(analyzed_data)} bars with TheStrat indicators\")\nprint(f\"Timeframes processed: {analyzed_data['timeframe'].unique()}\")\n</code></pre>"},{"location":"user-guide/quickstart/#step-by-step-breakdown","title":"Step-by-Step Breakdown","text":""},{"location":"user-guide/quickstart/#step-1-configure-components","title":"Step 1: Configure Components","text":"<p>The Factory pattern centralizes configuration:</p> <pre><code>from thestrat import Factory\nfrom thestrat.schemas import (\n    FactoryConfig, AggregationConfig, IndicatorsConfig,\n    TimeframeItemConfig, SwingPointsConfig\n)\n\n# Minimal configuration using models\nsimple_config = FactoryConfig(\n    aggregation=AggregationConfig(target_timeframes=[\"5m\"]),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(timeframes=[\"all\"])\n        ]\n    )\n)\n\n# Full configuration with all options\nfull_config = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"5m\", \"15m\"],  # Multiple timeframes supported\n        asset_class=\"equities\",\n        timezone=\"US/Eastern\"\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"5m\"],\n                swing_points=SwingPointsConfig(window=5, threshold=2.0)\n            ),\n            TimeframeItemConfig(\n                timeframes=[\"15m\"],\n                swing_points=SwingPointsConfig(window=7, threshold=3.0)\n            )\n        ]\n    )\n)\n\ncomponents = Factory.create_all(full_config)\n</code></pre>"},{"location":"user-guide/quickstart/#step-2-timeframe-aggregation","title":"Step 2: Timeframe Aggregation","text":"<p>Transform your base timeframe data:</p> <pre><code># Get the aggregation component\naggregator = components[\"aggregation\"]\n\n# Process your 1-minute data into 5-minute bars\nfive_min_bars = aggregator.process(one_minute_data)\n\n# The aggregated data maintains OHLCV structure and includes timeframe column\nprint(five_min_bars.columns)\n# ['timestamp', 'open', 'high', 'low', 'close', 'volume', 'timeframe']\n</code></pre>"},{"location":"user-guide/quickstart/#step-3-apply-thestrat-indicators","title":"Step 3: Apply TheStrat Indicators","text":"<p>Analyze market structure:</p> <pre><code># Get the indicators component\nindicators = components[\"indicators\"]\n\n# Apply TheStrat analysis\nanalyzed = indicators.process(five_min_bars)\n\n# New columns are added for TheStrat metrics\nprint(analyzed.columns)\n# Original OHLCV + TheStrat indicators like:\n# 'inside_bar', 'outside_bar', 'pivot_high', 'pivot_low', etc.\n</code></pre>"},{"location":"user-guide/quickstart/#step-4-extract-insights","title":"Step 4: Extract Insights","text":"<p>Work with the results:</p> <pre><code># Find inside bars\ninside_bars = analyzed[analyzed['inside_bar'] == True]\nprint(f\"Found {len(inside_bars)} inside bars\")\n\n# Find pivot points (pivot_high and pivot_low contain price values, not booleans)\npivot_highs = analyzed[analyzed['new_pivot_high'] == True] if 'new_pivot_high' in analyzed.columns else []\npivot_lows = analyzed[analyzed['new_pivot_low'] == True] if 'new_pivot_low' in analyzed.columns else []\n\nprint(f\"Pivot highs: {len(pivot_highs) if hasattr(pivot_highs, '__len__') else 0}\")\nprint(f\"Pivot lows: {len(pivot_lows) if hasattr(pivot_lows, '__len__') else 0}\")\n\n# Get the latest signals\nlatest_signals = analyzed.tail(10)[['timestamp', 'inside_bar', 'outside_bar']]\nprint(latest_signals)\n</code></pre>"},{"location":"user-guide/quickstart/#asset-class-examples","title":"Asset Class Examples","text":"<p>Different asset classes require different configurations:</p>"},{"location":"user-guide/quickstart/#crypto-247-trading","title":"Crypto (24/7 Trading)","text":"<pre><code>crypto_config = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"1h\"],\n        asset_class=\"crypto\",\n        timezone=\"UTC\"  # Always UTC for crypto\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"all\"],\n                swing_points=SwingPointsConfig(window=5, threshold=2.0)\n            )\n        ]\n    )\n)\n\ncrypto_pipeline = Factory.create_all(crypto_config)\n</code></pre>"},{"location":"user-guide/quickstart/#forex-245-trading","title":"Forex (24/5 Trading)","text":"<pre><code>fx_config = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"4h\"],\n        asset_class=\"fx\",\n        timezone=\"UTC\"  # Always UTC for FX\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"all\"],\n                swing_points=SwingPointsConfig(window=5, threshold=1.0)\n            )\n        ]\n    )\n)\n\nfx_pipeline = Factory.create_all(fx_config)\n</code></pre>"},{"location":"user-guide/quickstart/#common-patterns","title":"Common Patterns","text":""},{"location":"user-guide/quickstart/#multiple-timeframe-analysis","title":"Multiple Timeframe Analysis","text":"<pre><code># Analyze multiple timeframes in a single operation using Pydantic models\nconfig = FactoryConfig(\n    aggregation=AggregationConfig(\n        target_timeframes=[\"5m\", \"15m\", \"1h\"],  # Process all timeframes together\n        asset_class=\"equities\"\n    ),\n    indicators=IndicatorsConfig(\n        timeframe_configs=[\n            TimeframeItemConfig(\n                timeframes=[\"5m\"],\n                swing_points=SwingPointsConfig(window=3, threshold=1.5)  # Aggressive for short timeframe\n            ),\n            TimeframeItemConfig(\n                timeframes=[\"15m\", \"1h\"],\n                swing_points=SwingPointsConfig(window=7, threshold=2.5)  # Conservative for longer timeframes\n            )\n        ]\n    )\n)\n\npipeline = Factory.create_all(config)\naggregated = pipeline[\"aggregation\"].process(raw_data)\nanalyzed = pipeline[\"indicators\"].process(aggregated)\n\n# Filter results by timeframe using the normalized output\nfor tf in [\"5m\", \"15m\", \"1h\"]:\n    tf_data = analyzed[analyzed['timeframe'] == tf]\n    print(f\"{tf}: {len(tf_data)} bars, {tf_data['inside_bar'].sum()} inside bars\")\n\nprint(f\"Total analysis: {len(analyzed)} bars across {len(analyzed['timeframe'].unique())} timeframes\")\n</code></pre>"},{"location":"user-guide/quickstart/#signal-detection","title":"Signal Detection","text":"<pre><code># Custom signal detection\ndef find_breakouts(data):\n    \"\"\"Find potential breakout signals\"\"\"\n    breakouts = []\n\n    for i in range(1, len(data)):\n        current = data.iloc[i]\n        previous = data.iloc[i-1]\n\n        # Outside bar followed by continuation\n        if (previous['outside_bar'] and\n            current['close'] &gt; previous['high']):\n            breakouts.append({\n                'timestamp': current['timestamp'],\n                'type': 'bullish_breakout',\n                'price': current['close']\n            })\n\n    return breakouts\n\n# Apply to your analyzed data\nsignals = find_breakouts(analyzed_data)\nprint(f\"Found {len(signals)} breakout signals\")\n</code></pre>"},{"location":"user-guide/quickstart/#next-steps","title":"Next Steps","text":"<p>Now that you understand the basics:</p> <ol> <li>Explore Examples - More detailed use cases and advanced features</li> <li>Review Asset Classes - Understand market-specific behaviors</li> <li>Check API Reference - Detailed documentation of all methods and parameters</li> </ol>"},{"location":"user-guide/quickstart/#common-questions","title":"Common Questions","text":"<p>Q: What timeframes are supported? A: Standard timeframes: 1m, 5m, 15m, 30m, 1h, 4h, 1d. Custom intervals can be configured.</p> <p>Q: Can I use my own data format? A: Yes, as long as it has OHLCV columns and a timestamp. The data will be automatically standardized.</p> <p>Q: How do I handle missing data? A: TheStrat includes built-in handling for gaps and missing bars appropriate to each asset class.</p> <p>Q: Can I backtest strategies? A: TheStrat provides the analysis foundation. You'll need to combine it with your backtesting framework.</p>"},{"location":"user-guide/signal-metadata/","title":"Signal Metadata","text":"<p>Complete guide to signal metadata objects, examples, and database integration</p> <p>TheStrat signals return rich metadata objects that provide comprehensive trading information including entry/stop/target levels, risk management data, and change tracking capabilities.</p>"},{"location":"user-guide/signal-metadata/#overview","title":"Overview","text":"<p>When TheStrat indicators detect trading patterns, they generate signals with detailed metadata through the <code>SignalMetadata</code> class. This metadata transforms simple pattern strings into actionable trading objects with:</p> <ul> <li>Price levels: Entry, stop, and target prices</li> <li>Risk management: Risk/reward ratios and position sizing data</li> <li>State tracking: Signal lifecycle and execution status</li> <li>Change history: Audit trail for stop/target adjustments</li> <li>Database integration: Full serialization/deserialization support</li> </ul>"},{"location":"user-guide/signal-metadata/#basic-signal-example","title":"Basic Signal Example","text":"<pre><code>from datetime import datetime\nfrom thestrat.signals import SignalMetadata, SignalCategory, SignalBias\n\n# Create a reversal signal\nsignal = SignalMetadata(\n    pattern=\"3-2U\",\n    category=SignalCategory.REVERSAL,\n    bias=SignalBias.LONG,\n    bar_count=2,\n    entry_bar_index=100,\n    trigger_bar_index=99,\n    target_bar_index=98,\n    entry_price=150.0,\n    stop_price=148.0,\n    target_price=155.0,\n    timestamp=datetime.now(),\n    symbol=\"AAPL\",\n    timeframe=\"5min\"\n)\n\nprint(f\"Signal: {signal.pattern}\")\nprint(f\"Entry: ${signal.entry_price}\")\nprint(f\"Stop: ${signal.stop_price}\")\nprint(f\"Target: ${signal.target_price}\")\nprint(f\"Risk/Reward: {signal.risk_reward_ratio:.2f}\")\n</code></pre> <p>Output: <pre><code>Signal: 3-2U\nEntry: $150.0\nStop: $148.0\nTarget: $155.0\nRisk/Reward: 2.50\n</code></pre></p>"},{"location":"user-guide/signal-metadata/#signal-categories-and-examples","title":"Signal Categories and Examples","text":""},{"location":"user-guide/signal-metadata/#reversal-signals","title":"Reversal Signals","text":"<p>Reversal signals have entry, stop, and target prices:</p> <pre><code># Long reversal signal\nlong_reversal = SignalMetadata(\n    pattern=\"2D-2U\",\n    category=SignalCategory.REVERSAL,\n    bias=SignalBias.LONG,\n    bar_count=2,\n    entry_bar_index=50,\n    trigger_bar_index=49,\n    target_bar_index=48,\n    entry_price=125.50,\n    stop_price=123.75,\n    target_price=129.00,\n    timestamp=datetime.now()\n)\n\n# Short reversal signal\nshort_reversal = SignalMetadata(\n    pattern=\"2U-2D\",\n    category=SignalCategory.REVERSAL,\n    bias=SignalBias.SHORT,\n    bar_count=2,\n    entry_bar_index=75,\n    trigger_bar_index=74,\n    target_bar_index=73,\n    entry_price=98.25,\n    stop_price=99.50,\n    target_price=95.00,\n    timestamp=datetime.now()\n)\n</code></pre>"},{"location":"user-guide/signal-metadata/#continuation-signals","title":"Continuation Signals","text":"<p>Continuation signals have no target (trend-following):</p> <pre><code># Long continuation signal\ncontinuation = SignalMetadata(\n    pattern=\"2U-2U\",\n    category=SignalCategory.CONTINUATION,\n    bias=SignalBias.LONG,\n    bar_count=2,\n    entry_bar_index=200,\n    trigger_bar_index=199,\n    entry_price=87.50,\n    stop_price=85.25,\n    timestamp=datetime.now()\n)\n\n# Note: target_price is None for continuation signals\nassert continuation.target_price is None\nassert continuation.reward_amount is None\n</code></pre>"},{"location":"user-guide/signal-metadata/#risk-management-data","title":"Risk Management Data","text":"<p>All signals automatically calculate risk metrics:</p> <pre><code>signal = SignalMetadata(\n    pattern=\"3-1-2U\",\n    category=SignalCategory.REVERSAL,\n    bias=SignalBias.LONG,\n    bar_count=3,\n    entry_bar_index=100,\n    trigger_bar_index=99,\n    target_bar_index=97,\n    entry_price=100.0,\n    stop_price=97.0,\n    target_price=106.0,\n    timestamp=datetime.now()\n)\n\n# Automatic risk calculations\nprint(f\"Risk Amount: ${signal.risk_amount}\")      # $3.00 (100 - 97)\nprint(f\"Reward Amount: ${signal.reward_amount}\")  # $6.00 (106 - 100)\nprint(f\"R/R Ratio: {signal.risk_reward_ratio}\")   # 2.0 (6 / 3)\n\n# Original values preserved\nprint(f\"Original Stop: ${signal.original_stop}\")     # $97.0\nprint(f\"Original Target: ${signal.original_target}\") # $106.0\n</code></pre>"},{"location":"user-guide/signal-metadata/#updating-stop-and-target-prices","title":"Updating Stop and Target Prices","text":""},{"location":"user-guide/signal-metadata/#adjusting-stop-loss","title":"Adjusting Stop Loss","text":"<pre><code># Trail stop loss (with change tracking)\nsignal.update_stop(98.0, \"trailing_stop\")\n\nprint(f\"New Stop: ${signal.stop_price}\")           # $98.0\nprint(f\"Updated Risk: ${signal.risk_amount}\")      # $2.0 (100 - 98)\nprint(f\"New R/R: {signal.risk_reward_ratio}\")      # 3.0 (6 / 2)\n\n# Check change history\nchange = signal.change_history[0]\nprint(f\"Change: {change.field_name} from ${change.from_value} to ${change.to_value}\")\nprint(f\"Reason: {change.reason}\")\nprint(f\"Time: {change.timestamp}\")\n</code></pre>"},{"location":"user-guide/signal-metadata/#smart-trailing","title":"Smart Trailing","text":"<p>The <code>trail_stop()</code> method only allows favorable moves:</p> <pre><code># For long signals, only trails stop UP\nresult = signal.trail_stop(99.0)  # Move stop from 98 to 99\nprint(f\"Trailed successfully: {result}\")  # True\n\nresult = signal.trail_stop(96.0)  # Try to move stop DOWN\nprint(f\"Trailed successfully: {result}\")  # False (rejected)\nprint(f\"Stop unchanged: ${signal.stop_price}\")  # Still $99.0\n\n# For short signals, only trails stop DOWN\nshort_signal.trail_stop(95.0)  # Move stop from 99.50 to 95.0 \u2713\nshort_signal.trail_stop(101.0) # Try to move stop UP \u2717 (rejected)\n</code></pre>"},{"location":"user-guide/signal-metadata/#adjusting-targets","title":"Adjusting Targets","text":"<pre><code># Extend target for reversal signals\nsignal.update_target(108.0, \"extended_target\")\n\nprint(f\"New Target: ${signal.target_price}\")       # $108.0\nprint(f\"New Reward: ${signal.reward_amount}\")      # $8.0 (108 - 100)\nprint(f\"New R/R: {signal.risk_reward_ratio}\")      # 4.0 (8 / 2)\n\n# Continuation signals cannot have targets\ntry:\n    continuation_signal.update_target(90.0)\nexcept ValueError as e:\n    print(f\"Error: {e}\")  # \"Continuation signals have no target\"\n</code></pre>"},{"location":"user-guide/signal-metadata/#database-integration","title":"Database Integration","text":""},{"location":"user-guide/signal-metadata/#serializing-for-database-storage","title":"Serializing for Database Storage","text":"<pre><code># Convert signal to database-friendly dictionary\nsignal_dict = signal.to_dict()\n\n# All fields are JSON-serializable\nimport json\njson_data = json.dumps(signal_dict)\n\n# Example database insert (using any database library)\ncursor.execute(\"\"\"\n    INSERT INTO signals (\n        signal_id, pattern, category, bias, entry_price, stop_price,\n        target_price, timestamp, symbol, timeframe, signal_data\n    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n\"\"\", (\n    signal.signal_id,\n    signal.pattern,\n    signal.category.value,\n    signal.bias.value,\n    signal.entry_price,\n    signal.stop_price,\n    signal.target_price,\n    signal.timestamp.isoformat(),\n    signal.symbol,\n    signal.timeframe,\n    json_data  # Complete metadata as JSON\n))\n</code></pre>"},{"location":"user-guide/signal-metadata/#recreating-signals-from-database","title":"Recreating Signals from Database","text":"<pre><code># Retrieve from database\ncursor.execute(\"SELECT signal_data FROM signals WHERE signal_id = ?\", (signal_id,))\njson_data = cursor.fetchone()[0]\n\n# Method 1: From JSON string\nrestored_signal = SignalMetadata.from_json(json_data)\n\n# Method 2: From dictionary\nsignal_dict = json.loads(json_data)\nrestored_signal = SignalMetadata.from_dict(signal_dict)\n\n# All metadata is preserved\nassert restored_signal.pattern == original_signal.pattern\nassert restored_signal.entry_price == original_signal.entry_price\nassert restored_signal.risk_reward_ratio == original_signal.risk_reward_ratio\nassert len(restored_signal.change_history) == len(original_signal.change_history)\n\n# Original values and calculations are restored\nprint(f\"Original stop restored: ${restored_signal.original_stop}\")\nprint(f\"Risk metrics recalculated: {restored_signal.risk_reward_ratio}\")\n</code></pre>"},{"location":"user-guide/signal-metadata/#complete-database-workflow-example","title":"Complete Database Workflow Example","text":"<pre><code>import json\nimport sqlite3\nfrom datetime import datetime\nfrom thestrat.signals import SignalMetadata, SignalCategory, SignalBias\n\n# 1. Create and modify a signal\nsignal = SignalMetadata(\n    pattern=\"1-2D-2U\",\n    category=SignalCategory.REVERSAL,\n    bias=SignalBias.LONG,\n    bar_count=3,\n    entry_bar_index=500,\n    trigger_bar_index=499,\n    target_bar_index=496,  # Rev Strat uses 4th bar back\n    entry_price=245.75,\n    stop_price=243.50,\n    target_price=250.00,\n    timestamp=datetime.now(),\n    symbol=\"SPY\",\n    timeframe=\"15min\"\n)\n\n# Apply some updates\nsignal.update_stop(244.00, \"partial_trail\")\nsignal.update_target(252.00, \"extended_target\")\n\n# 2. Store in database\nconn = sqlite3.connect(\"trading.db\")\ncursor = conn.cursor()\n\n# Create table\ncursor.execute(\"\"\"\n    CREATE TABLE IF NOT EXISTS signals (\n        signal_id TEXT PRIMARY KEY,\n        pattern TEXT,\n        symbol TEXT,\n        timeframe TEXT,\n        entry_price REAL,\n        current_stop REAL,\n        current_target REAL,\n        status TEXT,\n        created_at TEXT,\n        signal_metadata TEXT\n    )\n\"\"\")\n\n# Insert signal\ncursor.execute(\"\"\"\n    INSERT INTO signals VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n\"\"\", (\n    signal.signal_id,\n    signal.pattern,\n    signal.symbol,\n    signal.timeframe,\n    signal.entry_price,\n    signal.stop_price,\n    signal.target_price,\n    signal.status.value,\n    signal.timestamp.isoformat(),\n    signal.to_json()\n))\n\nconn.commit()\n\n# 3. Retrieve and reconstruct\ncursor.execute(\"SELECT signal_metadata FROM signals WHERE signal_id = ?\",\n               (signal.signal_id,))\njson_data = cursor.fetchone()[0]\n\n# Restore complete signal object\nrestored_signal = SignalMetadata.from_json(json_data)\n\n# 4. Continue trading operations\nprint(f\"Restored signal: {restored_signal.pattern}\")\nprint(f\"Current stop: ${restored_signal.stop_price}\")\nprint(f\"Changes made: {len(restored_signal.change_history)}\")\n\n# Apply more updates\nif restored_signal.trail_stop(244.50, \"continued_trail\"):\n    print(\"Stop trailed successfully\")\n\n    # Update database with new state\n    cursor.execute(\"\"\"\n        UPDATE signals\n        SET current_stop = ?, signal_metadata = ?\n        WHERE signal_id = ?\n    \"\"\", (\n        restored_signal.stop_price,\n        restored_signal.to_json(),\n        restored_signal.signal_id\n    ))\n    conn.commit()\n\nconn.close()\n</code></pre>"},{"location":"user-guide/signal-metadata/#signal-status-management","title":"Signal Status Management","text":"<pre><code>from thestrat.signals import SignalStatus\n\n# Signal lifecycle\nsignal.status = SignalStatus.PENDING     # Initial state\nsignal.status = SignalStatus.ACTIVE      # Entry triggered\nsignal.status = SignalStatus.TARGET_HIT  # Target reached\nsignal.status = SignalStatus.STOPPED     # Stop loss hit\nsignal.status = SignalStatus.EXPIRED     # Signal expired\nsignal.status = SignalStatus.CANCELLED   # Manually cancelled\n\n# Track execution times\nsignal.triggered_at = datetime.now()  # When entry was filled\nsignal.closed_at = datetime.now()     # When position was closed\nsignal.close_reason = \"target_hit\"    # Why position closed\n\n# Performance tracking (update as position runs)\nsignal.entry_filled_price = 245.80    # Actual fill price\nsignal.exit_price = 251.90           # Actual exit price\nsignal.pnl = 6.10                    # Realized P&amp;L\nsignal.max_favorable_excursion = 7.25 # Best unrealized gain\nsignal.max_adverse_excursion = -1.15  # Worst unrealized loss\n</code></pre>"},{"location":"user-guide/signal-metadata/#complete-metadata-fields","title":"Complete Metadata Fields","text":"<p>The <code>SignalMetadata</code> object contains 30+ fields organized by category:</p> <p>Core Signal Data: - <code>pattern</code>, <code>category</code>, <code>bias</code>, <code>bar_count</code> - <code>entry_bar_index</code>, <code>trigger_bar_index</code>, <code>target_bar_index</code></p> <p>Price Levels: - <code>entry_price</code>, <code>stop_price</code>, <code>target_price</code> - <code>original_stop</code>, <code>original_target</code></p> <p>Risk Management: - <code>risk_amount</code>, <code>reward_amount</code>, <code>risk_reward_ratio</code></p> <p>State &amp; Lifecycle: - <code>signal_id</code>, <code>status</code>, <code>timestamp</code> - <code>triggered_at</code>, <code>closed_at</code>, <code>close_reason</code></p> <p>Change Tracking: - <code>change_history</code> (list of <code>PriceChange</code> objects)</p> <p>Context: - <code>symbol</code>, <code>timeframe</code></p> <p>Performance: - <code>entry_filled_price</code>, <code>exit_price</code>, <code>pnl</code> - <code>max_favorable_excursion</code>, <code>max_adverse_excursion</code></p> <p>All fields support full serialization and database integration with type preservation.</p>"}]}